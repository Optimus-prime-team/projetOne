Paris 9e (75),"Apprentissage, Contrat pro",,Alternance - Data Scientist H/F,Malakoff Humanis,- Paris 9e (75),"Contrat
ALTERNANCE
Finalité du poste
Au sein du service DATA, vous participerez à la mise en œuvre des méthodes /techniques de Data science pour répondre à la mise en œuvre d'un produit DATA répondant à une question majeure du métier.
Vos missions
Dans le cadre de votre alternance et en collaboration avec un data scientist et un product owner, vos missions seront:
étudier des données disponibles qui permettront de définir les données qui seront utilisées dans l'élaboration du produit data selon les règles de conformité groupe et accord du Data
identifier les données complémentaires à obtenir
récupérer et analyser les données identifées pour le produit data à mettre en œuvre
identifier la problématique des directions métiers pour réaliser le(s) modèle(s) initial(aux) et les évolutions successives répondant à la problématique
élaborer les mécaniques anticipant l'évolution des données utilisées dans les modèles
élaborer les systèmes auto apprenant
élaborer le monitoring des modèles mis en œuvre
modéliser les résultats pour les rendre exploitables par les managers et la direction générale
supporter la direction métier dans la définition des KPI permettant de mesurer la valeur attendue, contribuer a leur analyse et la définition du plan d'action d'améliorations des algorithmes
s'assurer de la mise en place des conditions d'industrialisation sur l'ensemble des dimensions organisationnelle, compétences, outils....
mettre en place la boucle d'apprentissage permettant l'amélioration des algorithmes
Profil recherché
Vous préparez un Bac+5 en alternance dans le domaine de la Data Science, Mathématiques appliquées, statistiques et informatiques, ou de type écoles d'ingénieurs.
Vous connaissez les enjeux des directions métiers assurance.
Vous avez une appétence forte pour la gestion des données. Et une première expérience en data science et en particulier en machine Learning.
Vous connaissez les environnement Big Data.
Vous aimez travailler en équipe et êtes un bon communiquant (écrit et oral). Vous avez des capacités d'écoute et d'analyse ainsi qu'un sens du contact, une disponibilité et une réactivité.
La connaissance des outils d'analyse de données, d'exploration de données et de la programmation ainsi que de R et Python seraient un plus"
Nanterre (92),,,Data Scientist confirmé H/F,METRO,- Nanterre (92),"DESCRIPTION DU POSTE
Vos challenges :
Proposer et exécuter des méthodes d’analyses (simples ou complexes), en assurant l’uniformisation (interprétation unique) des résultats dans différents domaines. Connaissances clients/produits/fournisseurs : - Définir les indicateurs et mettre en œuvre les outils de pilotage en collaboration avec les services concernés - Mettre en œuvre et garantir la modélisation statistique des données clients (pour développer les segmentations clients, caractériser le cycle de vie des clients, développer des algorithmes d’apprentissage et scénarii prédictifs des comportements clients). - Proposer le développement de levier de création de valeur client (optimisation des assortiments, modèles d’efficacité op, test de performance) Analyser et optimiser des campagnes et opérations commerciales avec les services concernés : - Définir les critères de ciblage des campagnes de marketing direct afin d’optimiser les investissements, et la pression commerciale. - Définir les indicateurs de mesure et d’analyse de la performance des opérations commerciales, quantifier le CA additionnel généré et mesure le ROI.Identifier et rassembler l’ensemble des sources de données structurées (transactionnelles) ou non structurées (qualitatives, relation client, commentaires sur réseaux sociaux) nécessaires pour l’appropriation et l’exploitation de la donnée (client, produit & fournisseur) : - Etudier et mettre en place les meilleures solutions techniques pour gérer les grands volumes de données, en collaboration avec le pôle « BI » de la DSI. - Tester, contrôler et valider la qualité et la cohérence des données pour une correcte exploitation.
CANDIDAT
Votre profil :
Diplômé d'une école d'ingénieur ou d'un Master en statistique et informatique décisionnelle, économétrie. Vous justifiez d'une expérience réussie et signification de 3 à 5 ans minimum dans la valorisation des données clients.
Une première expérience en management est requise.
Une expérience dans le retail serait un plus. Compétences en R, Python, Tableau, QlikView et SQL.
DÉTAILS
Informations complémentaires
- Statut Cadre- Rémunération sur 13 mois + variable + intéressement + participation - Remise sur les achats- Perspectives d'évolution au sein d'un grand groupe international"
Paris (75),,,DATA analyste informatique (F/H),ACCEO CONSULTING,- Paris (75),"Actuellement, au sein des équipes BIG DATA et Machine learning de notre client, grande entité bancaire, l’objectif au quotidien est d’acquérir une expertise sur l’ensemble des informations liées aux données marketing et commercial des différentes entités, c’est pourquoi nous recherchons un(e) :

DATA ANALYST (F/H)

Vos principales missions :
Mise en place d’un dictionnaire de données / catalogue, à disposition des chefs de projets et des data scientists afin de les aider, lors de la mise en place de projets BIG DATA ou machine learning.
Manipulation, analyse et mise à disposition des données collectées.
Reporting
Vous serez également en charge de toutes les demandes liées à l’exploitation des données

Votre Profil :
Issu(e) d’une formation supérieure de type BAC + 5 en informatique, statistiques ou en big data, vous avez acquis une expérience de minimum 3 ans dans le traitement et l’analyse de données dans un environnement bancaire.

Pour ce poste, ous recherchons un profil avec un très bon relationnel pouvant communiquer aisément entre les différents services et interlocuteurs.

A l’aise dans la transmission des informations, vous avez aussi une réelle appétence pour manier les données.

Bon communiquant, vous avez un sens du service développé."
Paris (75),Stage,,DATA SCIENTIST / MACHINE LEARNING RESEARCHER INTERN,Joko,- Paris (75),"DESCRIPTIF DU POSTE
Tu seras responsable du développement d'algorithmes de Machine Learning et de la réalisation d'analyses de données avancées. Tu travailleras au sein de l'équipe Data Science en interaction directe avec l'équipe de développeurs. Selon sa nature, un accent “recherche” pourra être donné au stage (avec notamment des possibilités de publications).
Voici une liste non-exhaustive des missions possibles durant le stage :
Tu travailleras au développement et à la constante amélioration des algorithmes de recommandation d'offres au sein de l'application, afin d'offrir l'expérience la plus personnalisée possible à nos utilisateurs.
Tu participeras à la continuelle évolution des algorithmes permettant de qualifier le plus précisément possible la donnée brute envoyée par les banques.
Tu réaliseras des analyses de données avancées afin d'appuyer la prise de décisions et la stratégie des équipes commerciales et des équipes produits.
Tu participeras à toutes les étapes du processus de développement, depuis la modélisation des problèmes jusqu'au déploiement des modèles en production.
PROFIL RECHERCHÉ
Tu as le profil idéal si :
Tu es autonome, créatif et tu sais gérer ton temps et ta to-do comme personne
Tu as de bonnes connaissances dans différents domaines du Machine Learning
Tu es un expert en Python
Tu sais résoudre des problèmes complexes et abstraits
Tu as éventuellement déjà travaillé avec des séries temporelles et des réseaux de neurones récurrents, ou tu es familier avec des algorithmes d'analyse de graphe
Tout ce que tu pourras apporter d'autre sera le bienvenu, c'est important pour nous de constituer une équipe aussi diverse que possible en termes d'expériences, de cultures, de passions, etc.
INFORMATIONS COMPLÉMENTAIRES
Type de contrat : Stage (4 à 6 mois)
Date de début : 10 août 2020
Lieu : Paris, France (75001)
Télétravail total possible"
Paris 9e (75),"Temps plein, CDI",,Data Scientist H/F,NEOBRAIN,- Paris 9e (75),"Neobrain développe des solutions digitales intuitives pour aider l’Homme à gérer sa carrière dans un monde en pleine mutation. Orientation professionnelle, gestion de carrière, recrutement, nous intégrons l’intelligence artificielle en support de l’Homme pour le centrer sur son cœur de métier. Créé en 2018, Neobrain compte déjà une trentaine de clients (grands comptes) et 2 bureaux (Lisbonne et Paris).
L'équipe de Data Science de Neobrain applique l'apprentissage machine learning à divers problèmes liés au domaine des ressources humaines. En tant que Data Scientist au sein de cette équipe, tu travailleras en étroite collaboration avec des data engineers et des développeurs pour prendre en charge des problèmes réels en matière de ressources humaines.
Le cadre réel de ce travail signifie qu'il y a beaucoup de data à explorer, à développer des algorithmes de PNL et de voir l'impact réel de ton travail sur la vie professionnelle des utilisateurs finaux. La complexité et l'ampleur des problèmes exigent des solutions véritablement innovantes. En tant que tel, tu continueras à bénéficier d'une grande liberté car notre objectif est de te permettre de développer des idées innovantes.
Un Data Scientist de ce groupe peut être issu de la reconnaissance vocale ou du traitement du langage naturel, mais il peut aussi venir d'un apprentissage machine plus général.
Si tu souhaites être autonome, évoluer au sein d'une équipe engagée, dynamique et motivée, occuper une position clé dans le développement de l'entreprise, nous sommes impatients de te rencontrer !
Tes missions
* Mener des recherches appliquées ciblées pour aider à résoudre des problèmes difficiles dans le domaine des ressources humaines
* Identifier les opportunités commerciales et opérationnelles pour générer de la valeur grâce à des solutions intelligentes
* Concevoir, mettre en œuvre, évaluer et optimiser des algorithmes et des modèles de PNL qui conduisent à une amélioration des performances des applications Neobrain dans des scénarios du monde réel
* Utiliser des techniques efficaces de représentation de texte et des algorithmes de classification
* Réaliser des études empiriques de la précision des algorithmes sur de grands ensembles de données
* Développer une large base de code, par la conception, la révision, la maintenance et la collaboration avec des codes externes
* Développer des processus de collecte de données à grande échelle sur le web à partir de différentes sources afin de développer des ensembles de données à l'usage des membres de l'équipe
* Créer ou mettre à jour la documentation et les rapports si nécessaire
* Proposer, concevoir et construire des outils réutilisables pour favoriser une interaction et une expansion rapides
* Partager la connaissance, chez Neobrain l'apprentissage fait partie de nos valeurs fondatrices. Tu devras documenter ton expertise en combinant études de marché, entretiens, analyses et suivi méthodologique
Profil recherché
Tu es un expert en Python, SQL, tu as des connaissances en statistiques et en machine learning
Tu connais Docker, Git, Tensorflow ou Pythorch
Tu es propriétaire de tes projets : tu prends l'initiative, tu es flexible et autonome, et tu fais preuve d'une grande rigueur
Tu es une personne de confiance
Tu es synthétique, clair et as de bonnes capacités de communication
Tu as une courbe d'apprentissage très élevée, tu es capable de t'adapter à un écosystème en constante évolution et apprends très rapidement à garder une longueur d'avance
Tu as l'esprit d'équipe : tu a de bonnes qualités relationnelles, aimes le partage et les défis
Tu sais faire preuve d'empathie
Travailler dans une start-up en pleine expansion te motive tout particulièrement !
Avoir un impact sur la vie des utilisateurs te motive constamment
Encore une chose ?
Nous sommes constamment à la recherche de talents. Si tu penses avoir les compétences nécessaires pour nous rejoindre, nous sommes heureux de lire les candidatures spontanées.
Nous nous engageons à offrir un environnement de travail exigeant, mais dans la bonne humeur et la bonne volonté.
Tu participeras à l'élaboration d'un projet collectif passionnant, comportant de grands défis.
Nos bureaux sont situés à Notre-Dame de Lorette dans le 9ème arrondissement de Paris et tu seras couvert par Alan, l'assurance maladie 2.0 : ), bien sûr nous te fournirons un ordinateur portable.
Tu as la possibilité de travailler à Paris ou à Lisbonne.
Engagés dans un processus d'intégration très inclusif, nous examinons avec le même intérêt toutes les candidatures sans différenciation.
Type d'emploi : Temps plein, CDI
Expérience:
data scientist h/f : 2 ans (Souhaité)
Langue:
Anglais (Requis)
Télétravail:
Temporairement en raison du COVID-19"
Boulogne-Billancourt (92),"Apprentissage, Contrat pro",,Alternant(e) Data Scientist H/F,TF1,- Boulogne-Billancourt (92),"Type de contrat:
CDD Profession.

Métier:
Digital, Data, Développement web

Société:
TF1 SA

Faisons connaissance
Première chaîne de télévision généraliste française, le Groupe TF1 ne compte pas que ses chaînes.

En effet, TF1 a engagé depuis plus de 25 ans une diversification de ses activités et est devenue un groupe de communication intégré qui développe au-delà de son cœur de métier, des activités sur des segments porteurs tels que la production audiovisuelle, le digital, la télévision payante, le e-commerce mais aussi l'exploitation de salles et la production de spectacles, les licences et les jeux.

Au sein de la Direction Innovation et Digital, l’équipe Data & Analytics renforce la stratégie globale de groupe TF1 avec un objectif principal : la création de valeur à partir des données collectées.

A ce titre l’équipe Data & Analytics accompagne toutes les directions métiers et développe des outils innovants et des modèles algorithmiques qui permettent d’optimiser l’expérience client, de piloter la performance et de monétiser les données en déployant en production différents projets stratégiques, à forte visibilité.
Votre rôle au sein de l’équipe
Au sein de l’équipe DATA, vous aurez pour missions de développer les outils statistiques et informatiques du DataLake.

Vous apporterez vos connaissances dans le traitement et l’agrégation de données provenant de sources variées et hétérogènes (logs techniques, bases CRM, études, réseaux sociaux, données marché,…). Egalement, vous aurez pour mission de mettre en place des processus d’alimentation de données dans l’optique de création de modèles statistiques dans le cloud (Microsoft Azure).

Tout au long de l’année, vous serez amené(e) à :
Approfondir les nouvelles techniques de traitements des plateformes big data
Mettre en place des alimentations de données dans le but de statistiques
Intégrer les données en base grâce aux différents outils de manipulation de données
Développer des rapports simples en Tableau

Localisation du poste
Lieu de travail : Boulogne Billancourt
Vos atouts pour faire la différence
Etudiant(e) en fin de cycle informatique et BigData, datascience ou équivalent
Rigoureux(se), vous avez un bon esprit de synthèse et un raisonnement structuré
Vous avez des connaissances en : Python / SQL / Machine Learning"
Suresnes (92),CDI,,Data Scientist F/H,KERTIOS CONSULTING,- Suresnes (92),"Le Data Scientist a pour mission le traitement et la valorisation de données massives. Il est à la fois analyste statisticien et informaticien et a pour mission d’apporter des informations aux métiers en structurant et en manipulant habilement les données complexes du Big Data.

Si vous souhaitez…

Travailler au sein d’une Direction Métier (Digital, Marketing, Risques et Actuariat) d’une Banque ou d’une Assurance,

Réaliser des études quantitatives et qualitatives (offres produits et tarification, analyse de campagnes, …) visant à améliorer la connaissance client et piloter les actions commerciales

Participer à des projets d’envergure, à forte valeur ajoutée

Alors pourquoi pas vous ?
Profil recherché Vous aimez travailler dans un environnement stimulant et challengeant ? Vous possédez d’excellentes capacités d’analyse, de synthèse et le travail en équipe est votre point fort ?

De formation Bac+5 en école d’ingénieur ou parcours universitaire en analyse statistiques ou économétrie, vous êtes dotés d’une forte sensibilité marketing.

La maitrise de certains des outils suivants seront un atout pour le poste :

Data Viz / Data Prep : Tableau Software, Qlik Sense, Microsoft Power BI, Data IKU, Alteryx, …

Reporting et décisionnels : IBM Cognos, SAP BO, langage SQL, …

Statistiques et langage de manipulation : SAS, Python, R, SPSS, …

Python : ⭐⭐⭐

Maths et Stats : ⭐⭐⭐⭐

Data viz : ⭐⭐⭐⭐

N’hésitez plus, rejoignez-nous !
Entreprise KERTIOS

est une société de conseil en management et en informatique, spécialisée dans la gestion du capital humain et la mise en œuvre d'applications packagées. Nos clients sont des entreprises internationales prêtes à transformer leurs processus pour atteindre les meilleures pratiques dans leur domaine. Notre accompagnement se fait dans toutes les phases de leur transformation, de la stratégie à la mise en œuvre.

Les ""Plus"" KERTIOS Consulting :
Développer une triple compétence : métier, projet et système d’information en évoluant au cœur de projets complexes et ambitieux, accompagné par nos consultants seniors experts

Evoluer au sein d’une société qui exige le meilleur de ses collaborateurs tout en cultivant la cohésion et l’esprit d’équipe"
La Défense (92),"Temps plein, CDI",,Data SCIENTIST,Kaisens Data,- La Défense (92),"Kaisens Data est un éditeur logiciel spécialisé(e) en Data Science/Big Data et Machine Learning avec une branche de conseil. Nous recherchons un data scientist qui aura pour missions :
-Participer à l’élaboration des modules machine Learning pour des projets prédictifs dans un contexte Big Data.
- Adapter les outils de traitement statistique de données
- Présenter et diffuser les résultats des études réalisées
- Management d'équipe ou de projet selon sa séniorité
Profil recherché
-Maîtrise d'un langage d'analyse de données R, Python ou Spark et une bonne compréhension des structures de données
-Bon niveau gestion des bases de données relationnelles (SQL) idéalement connaissance en NoSql.
-Des compétences en gestion de projet seront également appréciées.
-Connaissances en Text Mining seront très apprécies
Avantages
-Un cadre de travail agréable, une rémunération selon le profil
-Participation à des projets à haute valeur ajoutée avec des technologies récentes
-plusieurs possibilités d'évolution de carrières
Type d'emploi : Temps plein, CDI"
Courbevoie (92),CDI,,Data Scientist H/F,DIANE CONSULTING,- Courbevoie (92),"Diane Consulting est un cabinet de conseil à taille humaine créé il y a 11 ans et spécialisé dans le domaine de la Data.
Nous accompagnons des grands groupes sur la conception, l'audit, le développement de solutions BI & Big Data: Société Générale, EDF, Arval Trading, Saint Gobain, ClearChannel, RATP, ...
Dans le cadre de notre développement, nous recherchons un Data Scientist H/F pour accompagner notre développement chez un de nos clients.
Les compétences requises pour la mission sont :
Maîtrise de la programmation Python ou R
Maitrise de GIT
Maitrise des langages ou libraires de data visualisation
Expérience de méthodes de modélisation, de machine learning
Capacité à travailler dans des environnements Linux, Hadoop
Rigueur, autonomie, bonnes capacités rédactionnelles.
Profil :
Minimum 2 ans d’expérience dans le domaine
Connaissance Python / Machine Learning / GIT
Analyse de données
Lieu : Courbevoie
Type d'emploi : CDI
Expérience:
data scientist h/f ou similaire: 3 ans (Souhaité)"
La Défense (92),,,Stagiaire Data Scientist,Kaisens Data,- La Défense (92),"Kaisens data est éditeur logiciel spécialisé en Data science / Machine Learning / TextMining et possédant une branche de conseil, recherche un stagiaire en Data Science (H/F).
Actuellement en formation dans une école d’ingénieurs en informatique, à l’université ou dans une école avec une spécialisation en informatique, Data Science ou Big Data, vous cherchez un stage de fin d’étude.
Missions :
-Assurer une veille technologique sur les solutions Big Data.
-Participation aux expérimentations Big Data menées en interne ou chez nos clients
- Conseiller sur les meilleurs choix techniques en fonction des cas d'usages.
-Concevoir et développer des solutions Big Data industrialisées
-Assurer le suivi, les tests et la qualité des développements réalisés.
Qualités requises :
- Solide socle technique (BI / Big Data / Traitement de la donnée/Analyse textuelle)
- Autonomie, initiative et sens de la pédagogie
- La maitrise, à minima, de l’un des langages suivants est un pré requis : Java, Scala, Python
Type d'emploi : Temps plein
Télétravail:
Temporairement en raison du COVID-19"
Suresnes (92),"Temps plein, CDI",40 000 € - 60 000 € par an,Data Scientist,Kertios,- Suresnes (92),"Le Data Scientist a pour mission le traitement et la valorisation de données massives. Il est à la fois analyste statisticien et informaticien et a pour mission d’apporter des informations aux métiers en structurant et en manipulant habilement les données complexes du Big Data.
Si vous souhaitez…
Travailler au sein d’une Direction Métier (Digital, Marketing, Risques et Actuariat) d’une Banque ou d’une Assurance,
Réaliser des études quantitatives et qualitatives (offres produits et tarification, analyse de campagnes, …) visant à améliorer la connaissance client et piloter les actions commerciales
Participer à des projets d’envergure, à forte valeur ajoutée
Alors pourquoi pas vous ?
Vous aimez travailler dans un environnement stimulant et challengeant ?
Vous possédez d’excellentes capacités d’analyse, de synthèse et le travail en équipe est votre point fort ?
De formation Bac+5 en école d’ingénieur ou parcours universitaire en analyse statistiques ou économétrie, vous êtes dotés d’une forte sensibilité marketing.
La maitrise de certains des outils suivants seront un atout pour le poste :
- Data Viz / Data Prep : Tableau Software, Qlik Sense, Microsoft Power BI, Data IKU, Alteryx, …
- Reporting et décisionnels : IBM Cognos, SAP BO, langage SQL, …
- Statistiques et langage de manipulation : SAS, Python, R, SPSS, …
Python : ⭐⭐⭐
Maths et Stats : ⭐⭐⭐⭐
Data viz : ⭐⭐⭐⭐
N’hésitez plus, rejoignez-nous !
Type d'emploi : Temps plein, CDI
Salaire : 40 000,00€ à 60 000,00€ /an
Expérience:
data scientist ou similaire: 2 ans (Requis)"
Neuilly-sur-Seine (92),"Temps plein, CDI",40 000 € - 70 000 € par an,CONSULTANT DATA SCIENTIST H/F,EVERSA,- Neuilly-sur-Seine (92),"Pour intervenir sur nos missions de conseil et d’expertise à haute valeur ajoutée, nous recherchons un “Data Scientist”, dont le rôle sera d’assurer des missions de conseil et d’accompagnement de nos clients sur leurs besoins.
Vous aurez pour mission de déterminer, à partir de sources de données multiples et dispersées, des indicateurs permettant la mise en place d’une stratégie répondant à une problématique. A ce titre, voici vos principales missions :
Identifier les besoins et la problématique des directions métiers
Définir une modélisation statistique qui permette de répondre à la problématique
Construire des outils d’analyse pour collecter les données de l’entreprise
Sourcer et rassembler l’ensemble des sources de données structurées ou non structurées nécessaires à l’analyse et pertinentes
Organiser, étudier et synthétiser ces sources de données sous forme de résultats exploitables
Modéliser les comportements et en extraire de nouveaux usages utilisateurs
La maitrise des sujets suivants est indispensable :
Langages de programmation : Python/ R
Bases de données : SQL (SQL Server ou PostgreSQL ou MySQL), NoSQL (MongoDB, Cassandre, Couchbase)
Compétences en Machine Learning : Clustering, Neural networks ou réseaux de neurones, Classification, Régression, Random forest, Support Vector Machines, …
La maitrise des sujets suivants est appréciée :
Langages de programmation : Spark
Machine learning: K nearest neighbours, Naive Bayes
Avantages :
Titre-restaurant / Panier
Participation au transport
Pour plus d'informations: https://eversa.fr/carrieres/consultant-data-scientist-h-f/
Type d'emploi : Temps plein, CDI
Salaire : 40 000,00€ à 70 000,00€ /an
Expérience:
consultant data scientist h/f ou similaire: 3 ans (Requis)
Télétravail:
Temporairement en raison du COVID-19"
Boulogne-Billancourt (92),"Temps plein, CDI",,Data Scientist/Engineer H/F,Pierre Fabre,- Boulogne-Billancourt (92),"Votre mission
Au sein de la Direction Médicale & Relations Patients/Consommateurs et rattaché à la Directrice Projets RWE & Datas, vous serez l’expert identifié de la gestion et de l’analyse des données Big data des différents métiers de la direction et serez responsable du croisement de ces données avec celles mises à disposition via les services et canaux digitaux dans le but de donner du sens à ces données et en extraire de la valeur pour appuyer les équipes dans la prise de décisions stratégiques ou opérationnelles.
Plus précisément, vous :

participez à la mise en place des solutions « real-world data » et à la création des outils pour collecter des données Big Data dans le but de soutenir les différents métiers (RWE, Medical Affairs, Market Access, HEOR, Patient centricity, MSL, Marketing, ...) sur l’ensemble du portefeuille Pierre Fabre, y compris oncologie, dermato-cosmétologie ;
identifiez les besoins et la problématique des directions métiers et anticipez les besoins en data en recherchant en continu de nouvelles sources d’informations pertinentes ;
élaborez une vision stratégique et globale assurant une prise de décision éclairée et définissez une modélisation statistique ou des modélisations « machine learning » qui permettent de répondre à la problématique ;
développez des solutions innovantes pour collecter des données de vraie vie ou des études cliniques ;
investiguez l'ensemble des sources de données pertinentes structurées ou non structurées nécessaires à l'analyse et vous organisez, étudiez et synthétisez ces données sous forme de résultats exploitables ;
concevez les modèles et algorithmes pour collecter, stocker, traiter et restituer les données ;
imaginez de nouveaux modèles d'analyse pour traiter des données brutes et hétérogènes qui ne peuvent pas être analysées à l'aide d'outils classiques de gestion de bases de données ;
collaborez de façon étroite avec les équipes d’autres fonctions comme Centre d'Excellence de la Data, Social listening, les marques et les filiales.
Profil recherché
Formation Bac+4/5 de type Ecole d’ingénieur avec une spécialisation en Data Science (ou connaissances équivalentes acquises par expérience professionnelle).
Expérience de 3 ans minimum dans une expérience similaire. Une expérience dans le développement d’API serait appréciée.
Maîtrise de Python et/ou R. Le codage sous SAS est un atout.
Connaissance ou forte appétence pour les technologies telles que Docker.
Anglais professionnel, écrit et oral.
Vous témoignez d’un fort intérêt pour le développement en langage Big Data et pour le secteur de la santé.
Créatif et agile, vous disposez de bonnes capacités d’adaptation, vous avez le sens du collectif."
Paris 8e (75),CDI,45 000 € - 55 000 € par an,"Développeur Backend, Data, Cloud Adtech",HireFirst,- Paris 8e (75),"Le client final
• Solution qui permet aux éditeurs et annonceurs de diffuser leurs campagnes publicitaires sur des formats pertinents et pour une audience adaptée en fonction de leur image de marque. • Société créée en 2012, 150 personnes • Siège parisien et plusieurs bureaux à Londres, Düsseldorf, Singapour et New-York • 250 millions de visiteurs par mois


Votre mission
En tant que développeur bakend et data, votre rôle sera de développer et maintenir l’outil de tracking server side, les datalake/Warehouse/Mart et les outils de reporting. Plus précisément vous serez en charge de : • Concevoir et implémenter des pipelines pour alimenter les modèles de données depuis différentes sources dans un environnement distribué (AWS) • Travailler sur des API utilisées par les développeurs fullstack • Développer des reportings automatiques pour les équipes Business • Participer au de choix de conception big data • Être le relais des équipes techniques afin de leur expliquer les choix liés à l’architecture des applications dont vous serez référent


Votre profil
• Au moins 3 ans d’expérience en tant que développeur backend/data • Expérience dans les architectures Data et les pipelines de données • Expérience avec les services big data d’AWS (Redshift, Glue, Pipeline, Kinesis Firehose, S3, Athena ou Spectrum) • Connaissance de Php Laravel (Stack actuelle, en migration vers Python) • Connaissance de Python dans un contexte data


Environnement technique
Environnement technique : - Python - ETL - SQL - PostgreSQL - AWS - Node.JS - Devops"
Paris (75),,,Manager Data Scientist Marketing (F/H),Novencia,- Paris (75),"Contexte
Big Data, Open data, IOT, IA, les possibilités de croisement et de valorisation des données deviennent infinies.
NOVENCIA Group dispose de Data Science et Data Analysis capables d’accompagner ses clients dans l’identification des cas d’usages, leur expérimentation et l’industrialisation des plus valorisants.
En décryptant les données et en procédant aux croisements les plus pertinents, notamment au travers de méthodes de Machine Learning, nos Data Scientists et Data Analysts savent tirer le meilleur parti des données clients.
Data Scientist expérimenté ou Chef de Projet Data Science avec au moins 8 ans d’expérience, vous êtes à la recherche de nouveaux défis. Bouclez votre ceinture, la suite est pour vous !
Compétences
AYANT LES COMPÉTENCES EN
Anglais Machine Learning Power BI Python R SAS SQL Statistiques
Profil
Carnet de route
Nos 35 référencements auprès de Grands Comptes et bien d’autres à venir offrent un large champ de possibles : E-commerce, Média, Banque, Assurance, Service, … !
Évidemment, nous privilégions les environnements innovants et Data-centric.
Exemples de missions :
Analyses à des fins d’amélioration de la connaissance client et d’optimisation de parcours clients, de segmentation d’offre, de prédictions de comportement (Média)
Analyses du comportement client à des fins d’optimisation des opérations commerciales (Service)
Prévision de vente de milliers de pièces détachées automobiles (Automobile)
Votre rôle
Encadrer des Data Scientists et Data Analysts
Intervenir sur des projets complexes de Data Science
Gérer et piloter des projets Data Science
Manager la relation client et être garant de la qualité des prestations
Accompagner les Data Analysts et les Data Scientists dans leurs parcours et leur évolution (organisation de challenges, contribution de l’animation de notre Tribu Data, …)
Participer au développement de l’offre en produisant des contenus (Webinar, meet-up, ….)
Contribuer au recrutement
Assurer un rôle commercial en détectant des besoins et en participant à des avant-ventes
À vous de choisir. Chez NOVENCIA, chaque consultant a le choix de sa mission et décide de la façon dont il souhaite évoluer.
De la technique et de la personnalité
Meneur : Entraîne ses équipes, les challenge, les motive
Explorateur : part à la recherche de données sur des terres inconnues
Savant : découvre et expérimente de nouveaux outils de récupération des données, d’exploration, de modélisation, …
Jongleur : aime manier les chiffres
Caricaturiste : reformule, vulgarise, schématise
Fin limier : trouve les meilleures solutions
Curieux : ne passe pas à côté d’une information essentielle
Bilingue : passe aisément du français au langage statistique
Couteau suisse : passe d’un rôle d’expert de la Data et de la modélisation à Manager d’équipes à Responsable de propositions commerciales
Avancer en équipe
NOVENCIA, c’est avant tout un projet collectif.
Validation par un pair. Après les formules d’usage du premier entretien, vous rencontrez un de nos consultants lors d’un second échange pour qu’il puisse appréhender votre niveau technique et vous en dire plus sur l’écosystème de NOVENCIA. (C’est souvent là que tout bascule…).
Partage d’expérience. NOVENCIA compte 7 communautés : Partners – Finance/ Prodigi – Agile / Craft / ActiveViam / UX@Scale / Data / GDPR, dont le fonctionnement est indépendant. Dotées de leur propre budget, elles sont libres de récolter et diffuser des informations. L’objectif : encourager la veille technique et l’évolution professionnelle.
Expertise. Meet-up, webinar, articles, vidéos…Au-delà d’un objectif purement professionnel, technique ou fonctionnel, NOVENCIA vous donne la possibilité de vous exprimer. Environ 80 événements annuels sont organisés. Autant d’occasions pour un collaborateur de se dépasser. Crédibilité et notoriété du parcours sont donc au rendez-vous !
Formation sur mesure. NOVENCIA possède son propre centre de formation. Technique ou fonctionnelle, les formations proposées sont, pour la plupart, certifiantes.
Suivi personnalisé. Qu’elle soit personnelle ou professionnelle, votre évolution est notre priorité. C’est pourquoi nous avons créé les Instants RH et Objectifs Carrière. Vous l’avez compris, chez NOVENCIA on ne lâche rien !
Notre objectif commun : co-construire votre carrière en fonction de vos aspirations et de vos compétences.

S’engager en faveur du handicap c’est garantir l’égalité des chances dès le recrutement.
À compétences égales, nos postes sont ouverts aux personnes en situation de handicap."
Le Plessis-Robinson (92),,,Data Integration Engineer F/H,TRIMANE,- Le Plessis-Robinson (92),"TRIMANE est une société de service spécialisée dans les systèmes d’information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l’information au sein de leur entreprise. En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d’expertise de nos consultants.Nous accompagnons nos clients (CAC 40 et SBF 120) sur des prestations de Conseil, MOA et MOE, autour du traitement et l’analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique. TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d’outils d’Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique.Dans le cadre de la mise en place et le développement de projets décisionnels, vous accompagnerez nos clients autour de la mise en place de solutions BI. Vos missions principales consistent en : - Analyse des spécifications fonctionnelles fournies par la MOA- Conception de la solution technique- Enrichissement du modèle de données- Rédaction des spécifications techniques détaillées- Développement des flux d'alimentation avec un ETL- Bâtir les stratégies de recette, mener les tests d'intégration technique et fonctionnelle ainsi que leur validation par les référents métiers- Suivi de production des différentes applications. Diplômé d’une école d’ingénieur ou d’un Master autour de la Data, vous bénéficiez d'une première de 2 ans minimum environnement dans ce domaine.Vous êtes passionné par la Data et vous effectuez une veille permanente autour des sujets suivants : Gouvernance des données ;Data Intelligence : traitement ETL, modélisation datawarehouses, datamarts, analyse multidimensionnelle OLAPData Visualisation : Tableau Software, Qlik Sense, PowerBI, Tibco, Microstrategy, R Shiny, Oracle Data Visualisation etc. ;Bases de données relationnelles & NoSQL (MongoDB, Cassandre, Hbase,..) et langages de requête (Hive, Pig) ;Environnements Cloud (Microsoft Azure, Google Cloud, AWS) ;

Data"
Paris 6e (75),"Temps plein, CDD",1 850 € - 2 500 € par mois,Statisticien/ Data Manager,ASSISTANCE PUBLIQUE HOPITAUX DE PARIS,- Paris 6e (75),"Missions et responsabilités
Suite à la constitution d'un Entrepôt de Données de Santé à l'Assistance Publique - Hôpitaux de Paris, l'Unité de Recherche Clinique des hôpitaux de Cochin et Necker cherchent un data manager / statisticien.
L'assistant aura la possibilité de travailler sur de nombreux projets à la pointe de la recherche médicale, notamment sur les projets relatifs au Covid-19. Dans le cadre de ces projets, l'assistant sera amené à :
Aider à la rédaction des projets de recherche
Structurer les données pour les projets de recherche
Réaliser les analyses statistiques
Enfin, il pourra être amené à participer aux travaux de recherche des équipes de recherche de l'Unité de Recherche Clinique, sur des travaux de pointe en recherche médicale sur données.
Les formations adéquates aux outils spécifiques seront proposées afin qu'il puisse assurer ses missions.
Profil recherché
Le candidat devra disposer d'un diplôme de grade master en statistique, biostatistique, mathématiques ou informatique.
La maîtrise des bases de l'analyse statistique est requise.
L'assistant sera amené à travailler avec le langage R ou le langage Python. La maîtrise d'un de ces langages est nécessaire.
La connaissance du monde la santé et de la recherche médicale sera fortement appréciée.
La connaissance de l'anglais est un plus.
Avantages :
Participation au transport
RTT
Type d'emploi : Temps plein, CDD
Salaire : 1 850,00€ à 2 500,00€ /mois
Expérience:
statisticien/ data manager ou similaire: 1 an (Souhaité)
Télétravail:
Temporairement en raison du COVID-19"
Boulogne-Billancourt (92),"Apprentissage, Contrat pro",,Alternant(e) Data Analyst H/F,TF1,- Boulogne-Billancourt (92),"Type de contrat:
CDD Profession.

Métier:
Digital, Data, Développement web

Société:
TF1 SA

Faisons connaissance
Première chaîne de télévision généraliste française, le Groupe TF1 ne compte pas que ses chaînes.

En effet, TF1 a engagé depuis plus de 25 ans une diversification de ses activités et est devenue un groupe de communication intégré qui développe au-delà de son cœur de métier, des activités sur des segments porteurs tels que la production audiovisuelle, le digital, la télévision payante, le e-commerce mais aussi l'exploitation de salles et la production de spectacles, les licences et les jeux.

Au sein de la Direction Digital et Innovation, l’équipe Data & Analytics renforce la stratégie globale de groupe TF1 avec un objectif principal : la création de valeur à partir des données collectées.

A ce titre l’équipe Data & Analytics accompagne toutes les directions métiers et développe des outils innovants et des modèles algorithmiques qui permettent d’optimiser l’expérience client, de piloter la performance et de monétiser les données en déployant en production différents projets stratégiques, à forte visibilité.
Votre rôle au sein de l’équipe
Au sein de l’équipe DATA, vous aurez pour missions de développer les outils statistiques et informatiques du DataLake.

Vous apporterez vos connaissances dans le traitement et l’agrégation de données provenant de sources variées et hétérogènes (logs techniques, bases CRM, études, réseaux sociaux, données marché,…). Egalement, vous aurez pour mission de mettre en place des processus d’alimentation de données dans l’optique de restituer des données auprès des différents métiers via outils de dataviz ou présentations. Enfin, vous travaillerez sur les différentes programmatiques liées à la publicité en ligne (optimisation ciblages, mise en place de nouveaux produits publicitaires).

Tout au long de l’année, vous serez amené(e) à :
Approfondir les nouvelles techniques de traitements des plateformes big data
Mettre en place des alimentations de données dans le but de statistiques
Intégrer les données en base grâce aux différents outils de manipulation de données
Développer des dashboards sous Tableau
Apprentissage du monde digital

Localisation du poste
Lieu de travail : Boulogne Billancourt
Vos atouts pour faire la différence
Vous êtes étudiant(e) en fin de cycle informatique et BigData, datascience ou équivalent
Rigoureux(se), vous avez un bon esprit de synthèse et un raisonnement structuré
Bonne maitrise SQL / PYTHON OU R / Gestion de projets"
Puteaux (92),CDI,,Consultant Data Scientist F/H,EVERSA,- Puteaux (92),"Vous aurez pour mission de déterminer, à partir de sources de données multiples et dispersées, des indicateurs permettant la mise en place d'une stratégie répondant à une problématique. A ce titre, voici vos principales missions :

Identifier les besoins et la problématique des directions métiers

Définir une modélisation statistique qui permette de répondre à la problématique

Construire des outils d'analyse pour collecter les données de l'entreprise

Sourcer et rassembler l'ensemble des sources de données structurées ou non structurées nécessaires à l'analyse et pertinentes

Organiser, étudier et synthétiser ces sources de données sous forme de résultats exploitables

Modéliser les comportements et en extraire de nouveaux usages utilisateurs
Profil recherché De formation supérieure, vous disposez d’une expérience d’au moins 2 ans sur une fonction similaire.

La maitrise des sujets suivants est indispensable :
Langages de programmation : Python/ R

Bases de données : SQL (SQL Server ou PostgreSQL ou MySQL), NoSQL (MongoDB, Cassandre, Couchbase)

Compétences en Machine Learning : Clustering, Neural networks ou réseaux de neurones, Classification, Régression, Random forest, Support Vector Machines, …

La maitrise des sujets suivants est appréciée :
Langages de programmation : Spark

Machine learning: K nearest neighbours, Naive Bayes

Un bon relationnel, une facilité à vous adresser aux métiers, une grande capacité d’adaptation et de la rigueur sont des qualités essentielles chez EVERSA.

Pour plus d'informations: https://eversa.fr/carrieres/consultant-data-scientist-h-f/
Entreprise Rejoindre EVERSA, c’est la possibilité d’acquérir une expérience valorisante au sein d’une structure composée exclusivement d’experts BI, Big data et Administration de bases de données. Nous accompagnons individuellement chacun de nos collaborateurs grâce à un management de proximité.

Nos clients sont essentiellement des entreprises de taille intermédiaire dans les univers du retail, du e-commerce, du tourisme ou du service aux entreprises. Nous intervenons sur des projets en cycle court, à forts enjeux business, auprès d’entreprises ultra dynamiques."
Paris 9e (75),"Temps plein, CDI",,Data Engineer H/F,NEOBRAIN,- Paris 9e (75),"Neobrain développe des solutions digitales intuitives pour aider l’Homme à gérer sa carrière dans un monde en pleine mutation. Orientation professionnelle, gestion de carrière, recrutement, nous intégrons l’intelligence artificielle en support de l’Homme pour le centrer sur son cœur de métier. Créé en 2018, Neobrain compte déjà une trentaine de clients (grands comptes) et 2 bureaux (Lisbonne et Paris).
L'équipe de Data Science de Neobrain applique l'apprentissage machine learning à divers problèmes liés au domaine des ressources humaines. En tant que Data Engineer au sein de cette équipe, tu travailleras en étroite collaboration avec des data scientist et des développeurs pour prendre en charge des problèmes réels en matière de ressources humaines.
Le cadre de ce travail signifie qu'il y a beaucoup de data à explorer, à développer des algorithmes de PNL et de voir l'impact réel de ton travail sur la vie professionnelle des utilisateurs finaux. La complexité et l'ampleur des problèmes exigent des solutions véritablement innovantes. En tant que tel, tu continueras à bénéficier d'une grande liberté car notre objectif est de te permettre de développer des idées innovantes.
Un Data Engineer de ce groupe peut être issu de la reconnaissance vocale ou du traitement du langage naturel, mais il peut aussi venir d'un apprentissage machine plus général.
Si tu souhaites être autonome, évoluer au sein d'une équipe engagée, dynamique et motivée, occuper une position clé dans le développement de l'entreprise, nous sommes impatients de te rencontrer !
Tes missions
* Manipuler des données structurées et non structurées pour appliquer le ciblage de la recherche afin d'aider à résoudre des problèmes difficiles dans le domaine des ressources humaines
* Identifier les opportunités commerciales et opérationnelles pour générer de la valeur grâce à des solutions intelligentes
* Concevoir, mettre en œuvre, évaluer et optimiser l'architecture des pipelines de données et déployer des modèles prédictifs ; lancer des API qui conduisent à une amélioration des performances des applications Neobrain dans des scénarios réels
* Développer une large base de code, par la conception, la révision, la maintenance et la collaboration avec du code extérieur
* Développer des processus de grattage web à grande échelle pour la collecte de données provenant de différentes sources afin de développer des ensembles de données à l'usage des membres de l'équipe
* Créer ou mettre à jour la documentation et les rapports si nécessaire
* Suggérer, concevoir et construire des outils réutilisables pour favoriser une interaction et une expansion rapides
* Partager les connaissances, chez Neobrain l'apprentissage fait partie de nos valeurs fondatrices. Tu devras documenter ton expertise en combinant études de marché, entretiens, analyses et suivi méthodologique
Profil recherché
* Tu es un expert en Python, SQL, Java, tu as des connaissances en statistiques et en machine learning
* Tu connais Docker, Git, Spark, Hadoop et Kafka
* Capacité à travailler sur des données structurées, semi-structurées et non structurées, à extraire des informations et à identifier des liens entre des ensembles de données disparates
* Expérience et intérêt pour les plateformes de cloud computing telles que AWS, Azure, Google Platform ou Databricks
* Expérience dans de multiples technologies de bases de données telles que EMR, MS SQL Server, Oracle, MySQL, PostgresSQL, MPP, NoSQL
* Expérience dans les outils traditionnels d'entreposage de données/ETL
* Souci extraordinaire du détail
* Tu es propriétaire de tes projets : tu prends l'initiative, tu es flexible et autonome, et tu fais preuve d'une grande rigueur
* Tu es une personne de confiance
* Tu es synthétique, clair et as de bonnes capacités de communication
* Tu as une courbe d'apprentissage très élevée, tu es capable de t'adapter à un écosystème en constante évolution et tu apprends très vite à garder une longueur d'avance.
* Tu as l'esprit d'équipe : tu as de bonnes qualités relationnelles, aimes le partage et les défis.
* Tu sais faire preuve d'empathie
* Travailler dans une start-up en pleine expansion te motive tout particulièrement !
* Avoir un impact sur la vie des utilisateurs te motive constamment
Encore une chose ?
Nous sommes constamment à la recherche de talents. Si tu penses avoir les compétences nécessaires pour nous rejoindre, nous sommes heureux de lire les candidatures spontanées.
Nous nous engageons à offrir un environnement de travail exigeant, mais dans la bonne humeur et la bonne volonté.
Tu participeras à l'élaboration d'un projet collectif passionnant, comportant de grands défis.
Nos bureaux sont situés à Notre-Dame de Lorette dans le 9ème arrondissement de Paris et tu seras couvert par Alan, l'assurance maladie 2.0 : ), bien sûr nous te fournirons un ordinateur portable.
Tu as la possibilité de travailler à Paris ou à Lisbonne.
Engagés dans un processus d'intégration très inclusif, nous examinons avec le même intérêt toutes les candidatures sans différenciation.
Avantages :
Participation au transport
Type d'emploi : Temps plein, CDI
Expérience:
data engineer h/f ou similaire: 2 ans (Souhaité)
Langue:
Anglais (Requis)
Télétravail:
Temporairement en raison du COVID-19"
La Défense (92),,,Ingénieur Machine Learning / Big Data (F/H),Triskell Consulting,- La Défense (92),"La mission
Dans le cadre du développement de nouvelles solutions liées à la télévision numérique, nous recrutons un ingénieur en Machine Learning. L’objectif de cette mission est de développer d’enrichir les données et les fonctionnalités de smart services.
Vos responsabilités seront d’assurer :
Le traitement de la donnée
L’étude et la mise en place des algorithmes de machine learning
La mise en place de modèles d’apprentissage
Les développements sont réalisés en Python.
Le profil recherché
Expert data scientist / big data vous possédez une très bonne connaissance de l’analyse de données et des outils / librairies associées en Machine Learning.
La rémunération
A négocier, selon profil
Autre suggestion de poste
https://www.triskell-consulting.com/poste/achitecte-big-data-f-h/"
Saint-Ouen (93),"Temps plein, Apprentissage, Contrat pro",,Alternant - Appui Data Scientist (H/F),ENGIE SA > E&C,- Saint-Ouen (93),"Le Groupe ENGIE , l'un des premiers énergéticiens au niveau mondial, est présent sur l'ensemble de la chaîne de l'énergie, en électricité et en gaz naturel, de l'amont à l'aval. ENGIE s'appuie sur un portefeuille d'approvisionnement diversifié et un parc de production flexible et performant pour proposer des solutions énergétiques innovantes aux particuliers, aux collectivités et aux entreprises.

Au sein d’Engie SA, la Business Entity « Entreprises et collectivités » a pour mission la commercialisation d’énergie (gaz et électricité) auprès de ses clients entreprises et collectivités locales (BtoB).

Nous accompagnons la transition énergétique et numérique de nos clients.

Avec environ 750 collaborateurs et un maillage territorial fort, nous sommes en France, concepteurs et fournisseurs de solutions d’efficacité énergétique BtoB incluant les services et la vente d’énergie.

Présents sur l’ensemble de la chaîne de valeur des services à l’énergie jusqu’à la commercialisation d’énergie, nous sommes présents sur trois marchés clés : les bâtiments et l’industrie, les villes et territoires et les grandes infrastructures.

Partenaires de nos clients dans la durée, nous développons et mettons en œuvre des solutions innovantes adaptées à leurs besoins et usages et leur garantissons une performance durable.

En France, nous sommes ainsi leader des services en efficacité énergétique et environnementale, leader de la commercialisation de gaz naturel et le premier challenger de la vente d’électricité.
Notre objectif : renforcer notre leadership en développant des énergies locales et renouvelables, des offres globales et innovantes mixant énergie et digital (mobilité, bâtiments intelligents...), de nouveaux métiers et en enrichissant le savoir-faire de nos équipes.

Le pôle DATA recherche 4 apprenti(e)s :

Alternant – Data Scientist (H/F)

Lieu de travail : Saint-Ouen
Durée du contrat d’alternance souhaité : 1 ou 2 ans
Niveau de diplôme préparé : Bac +5
Poste à pourvoir pour septembre 2020

En tant que Data Scientist, vous contribuez activement au développement de modèles analytiques et statistiques permettant d’optimiser nos ventes, puis à leur déploiement en collaboration avec les équipes de vente et de marketing.

Vous intervenez en particulier sur les missions suivantes :

Analyser le comportement de nos clients via des études statistiques afin d’en déduire leurs attentes et d’identifier les facteurs inducteurs de valeur.
Concevoir des modèles statistiques quantitatifs qui permettront de prédire les ventes futures, de fidéliser les clients, de réduire les risques de pertes ou encore de cibler les prospects à contacter en priorité lors de campagnes marketing.
Automatiser la mise en œuvre opérationnelle des modèles les plus pertinents.
Préconiser des actions concrètes et proposer des outils d’aide à la décision permettant de maximiser la rentabilité d’E&C
Apporter une expertise en réponse aux demandes d’analyses statistiques provenant des équipes de vente ou du marketing
Produire des livrables ad hoc permettant aux différentes équipes d’E&C d’appréhender et d’utiliser les analyses statistiques réalisées.

Qualifications
Profil recherché :
De formation Bac+5, en Ecole d’Ingénieur ou Master en Mathématiques, vous êtes spécialisé en statistiques, mathématiques appliquées et ou informatique. La maîtrise de quelques fondamentaux en finance ou économie serait un plus.
Vous êtes fortement motivé par la mise en œuvre de méthodes statistiques avancées à des cas concrets dans la commercialisation d’énergie. La connaissance du Groupe et plus généralement du secteur de l’énergie est un plus.
Doté d'un excellent relationnel, curieux, concret et pragmatique, vous avez une excellente capacité d’analyse et de synthèse. Vous êtes rigoureux, organisé et autonome.
Compétences :
Très bon niveau en statistiques : séries temporelles, machine learning, méthodes de classification et de prédiction avancées.
Maitrise d’un logiciel de programmation statistique, en particulier des outils tels que R et/ou Python.
La maîtrise de quelques fondamentaux en finance ou économie serait un plus.
Intérêt prononcé pour la production d’outils statistiques à haute valeur ajoutée et pour des activités de vulgarisation scientifique.
Maîtrise des outils Word, Excel, Powerpoint.

Emploi
: Digital et IT
Lieu principal
: Europe-France-Île-de-France-Saint-Ouen
Organisation
: Entreprises & Collectivités
Horaire
: Temps plein
Nature de responsabilité
: Opérationnel
Publication d'offre
: 14 mai 2020, 11:40:14"
La Défense (92),CDI,,Consultant Risk Data Analyst / Data Scientist (H/F),Deloitte,- La Défense (92),"La complexité croissante de l'environnement des systèmes d'information dans un contexte de digitalisation des métiers, d'une flexibilité et d'une adaptabilité accrue, et de profondes avancées technologiques, impose un recours à des compétences pointues en analytics pour nos missions de gestion des risques.
Dans une dynamique de croissance constante, nous souhaitons renforcer nos équipes et nos solutions en recrutant des consultants expérimentés désireux d'intégrer une équipe motivée, professionnelle et intervenant auprès d'entreprises prestigieuses.

Vous participerez à des missions variées visant à accompagner nos clients, privés ou organismes publics, dans les différentes disciplines et métiers de la gestion des risques, en apportant vos compétences en analytics, en data mining, en business intelligence, en statistiques, en intelligence artificielle et en modélisation.

Vous serez amené(e) à intervenir sur les types de missions suivants :
Data analytics et data mining dans le cadre de diagnostics opérationnels et financiers pour l'ensemble des secteurs d'activité ;
Audit and control analytics : mise en oeuvre de techniques avancées d'analyse de données en remplacement des diligences traditionnelles d'audit ;
Prédictions et modélisations, sur des sujets réglementaires ou métiers financiers (ex : quantification, risques de crédit...), mais également sur des missions opérationnelles (ex : prévision des ventes, prévision des risques projets...) ;
Data visualisation : mise en oeuvre de tableaux de bords et d'outils d'analyse exploratoire sur les données risque de nos clients ;
Conception de solutions technologiques adaptées aux besoins de nos clients et missions, sous l'angle « data » : structuration, architecture, modélisation, moteur d'analyse, intégration, expérience utilisateur.
Compétences recherchées :
Vous disposez de compétences parmi les éléments suivants, que vous souhaitez développer sur nos différents projets :
Bases de données: SQL Server for windows, PostGreSQL, MySQL, MongoDB
ETL: SSIS, Talend, Informatica
Big Data : Hadoop, Spark, Hive, Hortonworks HDP, Cloudera
Programmation : SQL, SAS, R, SPSS, Python, C#, Java
Statistiques
Machine learning
Visualisation : QlikView, QlikSense, Tableau, PowerBI, D3.js
Data virtualization
Votre parcours :
En rejoignant Deloitte, vous aurez l'opportunité de développer un set de compétences, partagées avec notre réseau international, et structurées autour des dimensions suivantes : leadership, métier et spécialité. Grâce aux missions variées auxquelles vous participerez et au programme de formations proposé, vous pourrez renforcer progressivement ces compétences, en acquérir de nouvelles et progresser ainsi au sein de notre firme.

Profil
De formation supérieure (école d'ingénieurs ou université), idéalement complétée par un cursus suivi à l'étranger dans un pays anglophone, vous avez une première expérience réussie au sein d'un cabinet de conseil ou d'une grande société dans une des disciplines analytics ou data science.
Vous avez participé ou géré des projets d'envergure dans les domaines de la gestion, l'analyse et l'interprétation des données.
Dynamique et entreprenant(e), vous avez envie de vous impliquer activement dans le développement d'offres de service.
Vous avez la capacité de travailler en équipe pluridisciplinaire et une réelle appétence pour l'analyse des données, les systèmes d'information, les problématiques métier et la gestion des risques.
Vous avez l'habitude d'encadrer des missions et avez développé des qualités managériales.
Autonome, dynamique et doté(e) de très bonnes qualités relationnelles, vous avez un goût affirmé pour la relation client et les missions d'audit et de conseil.
Vous avez un souci constant de développer vos connaissances et de mettre votre compétence au service des autres.
Votre rigueur, votre sens relationnel et vos capacités rédactionnelles contribueront à l'excellence de notre service auprès des clients.
La maîtrise de l'anglais oral et écrit est nécessaire."
Paris 3e (75),CDI,,Consultant(e) data F/H,DATATORII,- Paris 3e (75),"Vous effectuez des missions à forte valeur ajoutée au sein de dispositifs pluridisciplinaires (Ingénieur, Data Scientist, Architecte, Chef de projet, Formateur, etc.).

Vous intervenez en AMOA et MOE sur les projets majeurs de transformation des usages de la Business Intelligence et/ou Data Science de nos clients.

Au sein d’une équipe solidaire, dynamique et audacieuse, selon vos compétences et vos appétences, vous participerez ou prendrez le lead sur :

Le cadrage en amont du projet

Le management du projet

L’assistance à maîtrise d’ouvrage du SI Décisionnel

L’accompagnement de la MOE sur les réalisations (SSIS, SSAS, SSRS, PowerBI, Microsoft Azure, Python)

Le choix d’orientation et déploiement cloud de nos clients (Microsoft Azure)

La conception d’offres innovantes leur promotion (UX BI, BI Self-service, Data Science, ...)

La rédaction de propositions sur mesure et leur soutenance

La formation interne ou externe au sein de notre organisme de formation

Grâce à nos capitalisations, nos méthodes et notre dispositif d’accompagnement, Datatorii vous intègre dans un parcours certifiant et vous offre toutes les chances de réussir avec des perspectives de carrière motivantes.
Profil recherché Formation initiale

BAC +5 Scientifique (mathématiques, statistiques et traitement du signal, informatique) ou Ecole de commerce (Data Analyst, Data Business)

Connaissances ou expériences

Vous possédez une première expérience significative sur la Business Intelligence où vous êtes intervenu de manière opérationnelle sur tout ou partie du cycle « projet » décisionnel (MOE puis AMOA).

Vous y avez développé des compétences analytiques (modélisation, data management, algorithmie, statistiques, dataviz), notamment sur les langages R, Python et la suite Microsoft BI.

Qualités

Excellent relationnel

Bon communicant

Proactif

Pédagogue

Capacité d’analyse et de synthèse
Entreprise Datatorii est une société de conseil spécialiste de la donnée : Business Intelligence et Data Science.

Partenaires des directions métiers et informatiques, nous accompagnons nos clients dans la mise en place de solutions techniques (architecture, infra, cloud, etc.), ainsi que dans l’expression de la valeur de leurs données.

La R&D réalisée en interne (Data Dojo) autour des évolutions technologiques Microsoft nous positionne également comme un partenaire d’innovation et de mise en place des meilleures pratiques du marché.

Reconnus comme organisme de formation, nous accompagnons nos clients de la prise en main jusqu’à la maîtrise des solutions techniques Microsoft, ainsi que sur l’état de l’art des projets BI.

Nichés dans le 3éme arrondissement de Paris, nos locaux vous offrent tout le confort pour vous former, échanger régulièrement avec vos pairs, participer aux ateliers internes, organiser vos événements R&D et recevoir nos clients.

Datatorii vous donne la possibilité de réaliser vos prochains challenges !"
Levallois-Perret (92),CDI,,Docteur R&D – Machine Learning / Data Scientist – WIS F/H,RD2 CONSEIL,- Levallois-Perret (92),"Notre client souhaite aujourd’hui renforcer son pôle de Recherche & Développement spécialisé sur l’analyse de données (Data Science) par le recrutement d’un Docteur Junior (1er CDI impératif) en Informatique, spécialisé en traitement et analyse de données, optimisation de bases de données, afin de prendre en charge les travaux de Recherche ET de Développement.

Vous interviendrez en interaction avec 2 autres Docteurs / Data Scientists au sein de la structure, pour gérer les problématiques et actions autour de la collecte, du traitement et de l’analyse des données (par des méthodes issues de l’Intelligence Artificielle).

Les projets sont aujourd’hui menés sur des problématiques d’analyse de données RH pour mettre en adéquation de façon automatique les compétences et motivations des collaborateurs avec les besoins de recrutement des entreprises. Dans ce contexte, l’objectif est de favoriser le bien-être au travail des collaborateurs, de fluidifier les parcours de carrière et de développer l’employabilité au sein des organisations.
Profil recherché Vos travaux porteront ainsi sur des projets en lien avec les données issues des clients (base de données, ERP clients) mais également issues du web (données structurées et non structurées, base de données relationnelles / non relationnelles). Dans ce cas, vous aurez à mener des actions de collecte et d’analyse de données dans le cadre du développement de systèmes apprenants et de systèmes de recommandations : vous maîtrisez ou avez une connaissance forte des techniques d’apprentissage automatique / Machine Learning.

Vous maîtrisez également la programmation informatique permettant de concevoir et d’implémenter l’ensemble de ces systèmes (en particulier Python et / ou Java).

Dans ce cadre, nous recherchons un candidat très autonome, n’ayant pas besoin d’un encadrement structuré pour mener ses travaux à bien et capable d’être force de propositions et de prendre des initiatives et des responsabilités.

Dans une société de conseil en stratégie apportant une forte valeur ajoutée à des clients de renom, nous recherchons une personne dont la qualité professionnelle, la capacité d’implication et le sens des responsabilités sont reconnues.

Si vous pensez être cette personne, que vous êtes titulaire d’un Doctorat et n’avez jamais été embauché en CDI après votre thèse (contrainte impérative pour respecter les critères du CIR), nous vous invitons à nous faire parvenir votre CV et lettre de motivation par mail sous la référence WIS.
Entreprise RD2 Conseil est un cabinet de recrutement spécialisé sur la

recherche de compétences scientifiques

pour les besoins en R&D des PME innovantes et entreprises privées, souhaitant se doter de compétences pointues et de réelles ressources humaines en matière d’Innovation.

Nous recrutons actuellement un(e) Docteur Junior H/F (1er CDI) en Machine Learning / Data Science.

Notre client est une « boutique », cabinet de conseil en stratégie situé à Paris, apportant à ses clients (dont de nombreux grands groupes français tels que la SNCF, EDF, Michelin, Bouygues) ses conseils et services sur 3 principaux domaines d’intervention :

La stratégie d’Innovation

La performance client

La transformation / conduite du changement"
Paris (75),"Apprentissage, Contrat pro",,Alternant(e) - Ingénieur télécom et data scientist,SFR,- Paris (75),"Vous travaillerez au sein de la direction de l'ingénierie mobile dans le service Etude QoS. Ce service a pour objectif l'amélioration de la qualité vu du client. Un des objectifs majeurs de 2020 est l'améliorations des performance data mobile (débits 4G, latence, qualité du streaming, du web browsing).
L'équipe est constituée d'ingénieurs et d'experts télécoms.
Vos principales missions seront de :
1- Contribution à la mise en place d'une solution de sondes actives permettant de s'assurer de la performance IP du réseau (gestion de projet /réunion fournisseur/analyses/validation)
2- Intégration de nouveaux équipements et de compteurs dans les outils de suivi de performance (parsing de fichier xml, gestion des compteurs) sur techno FH, baies 2G 3G 4G et 5G.
3- Mappiing topologique : maintien et amélioration de scripts permettant de produire la topologie des équipements de transmission (python)
4- Autoprovisionning des sondes actives 5G (pearl)
5- Analyse des data IP issues de nos mesures terrain et des data issues du crowdsourcing (SQL, Python).
Profil
Vous savez manipuler et interpréter des gros volumes de données.
Vous êtes curieux(se) (pour analyser des problèmes réseau, mesurer les résultats de nos modifications sur le réseu, proposer de nouvelles idées).
Sens du client connaissances spécifiques :
Connaissance des réseau de télécommunication mobile. Une connaissance du réseau d'accès radio est un plus
Pratique des langages R, python, SQL"
Paris (75),,,Data Scientist (F/H),Novencia,- Paris (75),"Contexte
Data is fuel ! Quelle que soit la façon dont elle est structurée, la data n’est plus l’apanage des SI… mais bien au coeur des activités et des Métiers. Aujourd’hui, de nombreuses entreprises ont besoin d’être accompagnées dans la gestion de leurs données afin de s’en servir à bon escient. La manipulation de la data est devenue une équation à plusieurs inconnues où Objectif = (Technique X Data) + (Outil X Data)… Vous l’aurez compris, pour résoudre l’équation, il devient urgent pour les organisations d’être conseillées par des spécialistes des données numériques.
Data Scientist depuis 3 ans, vous êtes à la recherche de nouveaux défis. Bouclez votre ceinture, la suite est pour vous !
Compétences
AYANT LES COMPÉTENCES EN
Machine Learning Python R SAS SQL Statistiques
Profil
Carnet de route
Nos 35 référencements et bien d’autres à venir offrent un large champ de possibles !
Évidemment, nous privilégions les environnements innovants et donc organisés autour de méthodologies Agile.
Exemples de missions :
Text mining : analyse d’historique de la maladie des patients pour évaluer la durée de séjour à l’hôpital (Santé)
Mise en œuvre des outils de lutte contre la fraude pour les activités de BFI (Finance de marché)
Analyses du comportement client à des fins d’optimisation des opérations commerciales (Marketing opérationnel)
Création d’un outil d’aide à la décision pour l’évaluation du risque des aéronefs (Sécurité aérienne)
Prévision de vente de milliers de pièces détachées automobiles (Automobile)
Stress-tests : Développement de programmes (Banque)
Votre rôle
Traiter les données, structurées ou non structurées
Contrôler la qualité des données, détecter des patterns, des outliers
Concevoir les datamarts
Proposer et mettre en pratique les modèles statistiques (régressions…) ou de datascience (machine learning…) pour résoudre les problématiques métier
Collaborer avec les équipes technique et métier pour définir les besoins et expliciter les résultats
Restituer les résultats (rapports, présentations…)
À vous de choisir. Chez NOVENCIA, chaque consultant a le choix de sa mission et décide de la façon dont il souhaite évoluer.
De la technique et de la personnalité
Explorateur : part à la recherche de données sur des terres inconnues
Calculateur : aime les chiffres
Caricaturiste : reformule, vulgarise, schématise
Fin limier : trouve les meilleures solutions
Curieux : ne passe pas à côté d’une information essentielle
Bilingue : passe aisément du français au langage statistique
Avancer en équipe
NOVENCIA, c’est avant tout un projet collectif.
Validation par un pair. Après les formules d’usage du premier entretien, vous rencontrez un de nos consultants lors d’un second échange pour qu’il puisse appréhender votre niveau technique et vous en dire plus sur l’écosystème de NOVENCIA. (C’est souvent là que tout bascule…).
Partage d’expérience. NOVENCIA compte 7 communautés : Partners – Finance/ Prodigi – Agile / Craft / ActiveViam / UX@Scale / Data / GDPR, dont le fonctionnement est indépendant. Dotées de leur propre budget, elles sont libres de récolter et diffuser des informations. L’objectif : encourager la veille technique et l’évolution professionnelle.
Expertise. Meet-up, webinar, articles, vidéos…Au-delà d’un objectif purement professionnel, technique ou fonctionnel, NOVENCIA vous donne la possibilité de vous exprimer. Environ 80 événements annuels sont organisés. Autant d’occasions pour un collaborateur de se dépasser. Crédibilité et notoriété du parcours sont donc au rendez-vous !
Formation sur mesure. NOVENCIA possède son propre centre de formation. Technique ou fonctionnelle, les formations proposées sont, pour la plupart, certifiantes.
Suivi personnalisé. Qu’elle soit personnelle ou professionnelle, votre évolution est notre priorité. C’est pourquoi nous avons créé les Instants RH et Objectifs Carrière. Vous l’avez compris, chez NOVENCIA on ne lâche rien !
Notre objectif commun : co-construire votre carrière en fonction de vos aspirations et de vos compétences.

S’engager en faveur du handicap c’est garantir l’égalité des chances dès le recrutement.
À compétences égales, nos postes sont ouverts aux personnes en situation de handicap."
Le Plessis-Robinson (92),,,Data Analyst PowerBI,TRIMANE,- Le Plessis-Robinson (92),"TRIMANE est une société de service spécialisée dans les systèmes d’information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l’information au sein de leur entreprise.En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d’expertise de nos consultants.Nous accompagnons nos clients (CAC 40 et SBF 120) sur des prestations de Conseil, MOA et MOE, autour du traitement et l’analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique.TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d’outils d’Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique.Nous recherchons un Data Analyst afin d'accompagner notre client dans le développement de ses outils de reporting. Tes missions : Recueil et analyse du besoinAccompagner le Lead dev dans les développements Power BIConception, développement des rapportsRefonte d’une application web en application Power BI- Diplômé d'une école d'ingénieur ou d'un Master avec une spécilisation relative au traitement et à l'analyse de la donnée, - Une expérience d'un an minimum en environnement PowerBI : Power Query et son langage M, Power Pivot et son langage DAX - La connaissance/expérience de la suite Microsoft BI : SSIS, SSAS, SSRS

Data"
Paris (75),"Temps plein, Intérim",,CDD - Data Scientist ou Statisticien (F/H),Allianz France,- Paris (75),"Description de la mission
Diplômé(e) en Data Science ou en Statistiques, vous cherchez un poste où vos compétences sont valorisées.
Vous souhaitez travailler en équipe et évoluer dans une entreprise qui met ses collaborateurs au coeur de sa stratégie de développement !
Venez apporter votre technicité et votre bonne humeur au sein de notre centre de compétences Data & Performance Vie & Santé !
Responsabilités clés
Vous réalisez la rétro-documentation des Model points ;
Vous construisez des référentiels ;
Vous mettez en place des traitements industriels de données sur le périmètre Life & Health (projet Arpia) ;
Vous sécurisez le Run sur la construction des Model points.
Profil / Compétences
Vous êtes diplômé(e) Bac+5 en Data Science ou en Statistiques ;
Votre très bonne maîtrise des techniques d’exploitation des données est reconnue grâce à une première expérience réussie ;
Vous connaissez l’assurance ;
Vous faites preuve d’adaptabilité ;
Vos capacités d’analyse et de synthèse ne sont plus à démontrer ;
- Votre communication est aisée et vous partagez volontiers vos connaissances techniques vis-à-vis de personnes n’ayant pas les mêmes compétences ;
Vous êtes curieux et force de proposition ;
Votre maîtrise de SAS, Python, MS Office en fait pâlir plus d’un ; de même que celle de l’anglais (à l’écrit et à l’oral).
Informations complémentaires
CDD de 8 mois maximum à pourvoir dès que possible.

Merci de transmettre votre candidature complète (CV & lettre de motivation en précisant vos dates de disponibilité et la durée).

Localisation du poste : Paris La Défense, Tour Neptune (M° Esplanade de La Défense).
Code de référence
AZFR-7382783-1
Allianz est l’univers pour ceux qui osent – un environnement qui soutient ceux qui prennent des initiatives pour faire évoluer leur carrière et pour participer activement au renforcement de notre position de leader mondial. En accordant une réelle importance aux hommes et aux femmes – à la fois à ses 88 millions de clients particuliers et professionnels, et à ses 140 000 collaborateurs – Allianz favorise une culture dans laquelle chaque collaborateur est encouragé à travailler en équipe, à se dépasser et à innover, pour relever les défis du secteur de l’assurance. Notre principale ambition est d’être le partenaire de confiance de nos clients et de leur permettre d’avancer avec l’assurance que nous sommes là pour les accompagner. Si vous avez de l’audace, rejoignez le Groupe Allianz.

De plus, en qualité d’employeur engagé, Allianz reconnaît que sa force se trouve dans la diversité de ses collaborateurs. Nous sommes fiers de promouvoir l’intégration et l’égalité des chances quel que soit le sexe, l’âge, l’origine, la nationalité, la religion, le handicap, ou l’orientation sexuelle de nos collaborateurs.
Toutes nos offres d'emploi sont ouvertes aux personnes en situation de handicap."
Courbevoie (92),CDI,,Docteur Data Scientist F/H,Kaisens data,- Courbevoie (92),"Nous disposons aujourd'hui d'un ensemble de données qui restent insuffisamment exploitées : il peut s’agir du comportement des utilisateurs du site web, du tracking à partir de newsletters, des informations issues des systèmes d’informations.

L’objectif du recrutement d’un(e) Docteur vise à pouvoir collecter ces données, les regrouper / classifier dans des systèmes de gestion de bases de données, et les traiter par des méthodes d’apprentissage automatique (Machine Learning) pour permettre une meilleure exploitation de ces données.

En particulier, l’objectif est de mettre en place des systèmes de recommandation pour améliorer les solutions de marketing digital (identification des produits à valoriser, accompagnement au processus d’achat des utilisateurs web, réponses adaptées en fonction du comportement et de la classification des utilisateurs).
Profil recherché Dans ce contexte, nous cherchons un(e) candidat(e) disposant en particulier des compétences suivantes :

Maîtrise des algorithmes de Machine Learning (supervisés et non supervisés)

Data Science : collecte, traitement et analyse de données

Connaissances des outils Big Data (Spark)Maîtrise des langages de programmation permettant d’implémenter les méthodes et algorithmes imaginés (Python, Scala, Java)

Des connaissances sur la stack web (Node.js, React) seront particulièrement appréciées.

La personne que nous souhaitons recruter devra impérativement être titulaire d’un Doctorat.

Quelles sont les qualités importantes pour ce poste ?

Autonome et proactif(ve)

Intérêt pour les métiers du marketing digital.

Esprit entrepreneurial, capable de travailler au sein d’une petite équipe.

Ouvert(e), pédagogue, sympathique.

Pragmatique.

KAISENS DATA recherche des collaborateurs engagés et dynamiques pour intégrer une équipe soudée
Entreprise KaisensData est un éditeur en IA avec une branche ESN spécialisé Big Data, Data Science, Text Mining et Deep Learning. Après des années de R&D, nos solutions brevetées sont sollicitées par plusieurs grandes sociétés afin de répondre à des différentes problématiques. Nous traitons le churn en temps réel, le smart pricing, la détection de fraude, le dédoublonnage de stock, la prédiction de pannes, la réduction de coûts, les campagnes marketing, l'analyse de sentiments, et plusieurs autres applications."
Boulogne-Billancourt (92),CDI,,Consultant Data Scientist F/H,Viseo,- Boulogne-Billancourt (92),"Vos Missions:
Dans le cadre de notre pôle Data Science, nous souhaitons recruter un Data Scientist pour assurer des missions de conseil chez nos clients, dans des équipes pluridisciplinaires.
Les missions de conseils nécessitent :
La compréhension des cas d’usage et la transformation des données
La proposition de modèles d'analyse et de valorisation
L'implémentation de nouvelles solutions méthodologiques et technologiques du traitement de ces données dans divers secteurs.
Nos clients sont entre autres présents dans les secteurs du retail / e-commerce, bancassurance, énergie, industrie.

Le champ d’intervention de nos consultants s’étend sur une grande variété de problématiques : modélisation dans le marketing digital, maintenance prédictive, voitures autonomes, détection d’objets dans des images.
Votre Profil :
École d’ingénieur ou master avec une spécialisation Data
Doctorat sciences/informatique/mathématique avec pratique dans des cas industriels
Participation à des challenges Data science, concours Kaggles, driven data
Vous justifiez d’un minimum de 3 ans d’expérience sur un poste similaire
Compétences requises :
Solides compétences en programmation tels que R, Python et de langages de gestion de BD (SQL, NoSQL)
Compétences d'analyse et aptitudes à résoudre des problématiques de façon créative
Maîtrise des algorithmes de Machine Learning (supervisés et non supervisés)
Justifier d’une première expérience en gestion de projet
Anglais courant
Qualités requises :
Grande rigueur, aisance orale et écrite (présentations, rapports, articles...)
Implication et capacité de travail en équipe
Autonomie, agilité et créativité"
Asnières-sur-Seine (92),,,Data Scientist,Fujitsu,- Asnières-sur-Seine (92),"Data Scientist
Paris Area, France

Are you a motivated professional, passionate about new technologies with a desire to transform the way people do business? Do you enjoy helping customers to enhance their business by applying cutting edge technologies ? Are you business minded, pro-active, curious and independent? If you enjoy working with statistical models and complex algorithms on diverse business environments then you are the one we are looking for to reinforce our Digital Software and Solutions team as a Data Scientist!

As part of our practice in France, you will be at the forefront of digital, part of our solution development team to help our customers make faster, smarter decisions and solve business issues by developing new data driven solutions. Your responsibilities include the design, development, testing and implementation of issue-based solutions, more precisely by:

Collecting and formulating the business requirements & analyzing the customer’s needs;
Building and implementing deep learning computer vision models to enhance our business solutions;
Building and implement machine learning models and prototype solutions for proof-of-concept;
Developing data products and predictive models in collaboration with the developers;
Relying on evolutionary computing techniques to solve optimization problems;
Predicting, classifying and relating data;
Supporting the customer throughout the entire implementation schedule;
Working in close collaboration with the product owner and the customer’s project team;
Coaching junior data scientists

Your profile
You have a degree in Computer Science, Mathematics, or Engineering, hands-on experience (minimum 4 years) within the IT or a start-up and with machine learning, deep learning and computer vision technologies. You have already worked with edge computing solutions and can think about optimization both in terms of computing performance as well as accuracy. You are also familiar with languages such as Python, SQL, and frameworks such as Tensor Flow. As a person you are curious and independent by nature, you like to combine your technological background to a business environment and enjoy working and interacting on daily basis with clients. On top of that, you have excellent communication skills and focus all efforts on ensuring the customer satisfaction. Next to this you have excellent French and English language skills.

What You Can Expect From Us
It is an extraordinary time to be in business. As digital transformation continues to accelerate, Fujitsu wants to be in the heart/center of our clients’ digital journeys and offering our professionals exciting career opportunities. In this changing fast pace environment, we value the work-life balance (flexible working times, home office etc.). You will be able to reinforce your skills with our tailored made training conducted in the classroom, online, or in collaboration with teammates. You will be part of a company promotes diversity, equality and inclusion. We offer you an attractive salary and secondary benefits, including a variable bonus scheme.

About Fujitsu
Fujitsu is the leading Japanese information and communication technology (ICT) company, offering a full range of technology products, solutions, and services. We use our experience and the power of ICT to shape the future of society with our customers. More information: www.fujitsu.com

We promote a Human Centric Intelligent Society, in which innovation is driven by the integration of people, information and infrastructure. We are committed to Digital Co-creation; blending business expertise with digital technology and creating new value together. More information: http://www.fujitsu.com/fts/about/

At Fujitsu we empower human difference and as we want the best people on our team, we welcome and encourage applications from people with diverse experiences, backgrounds and identities. We are committed to equality of opportunity for all.
All other company or product names mentioned herein are trademarks or registered trademarks of their respective owners. Information provided in this press release is accurate at time of publication and is subject to change without advance notice.
#Fujitsu named to #FORTUNE Magazine's 2020 list of ""World's Most Admired Companies"" for second year running"
Issy-les-Moulineaux (92),,,CDI Data Analyst - Scientist - Connaissance Client F/H,Groupe CANAL+,- Issy-les-Moulineaux (92),"Description de l'entreprise
Premier groupe de média audiovisuel français, le Groupe CANAL+ rassemble une communauté de talents ouverts sur le monde et présents dans 30 pays pour offrir à plus de 15 millions d’abonnés, le meilleur de l’entertainment.
A travers myCANAL, l’App TV la plus utilisée en France, le Groupe est reconnu pour sa capacité́ d’innovation. myCANAL propose à la fois les programmes en live des plus grandes chaînes, des milliers de films et séries, dont ses Créations Originales reconnues mondialement (Le Bureau des Légendes, Engrenages, Hippocrate, Young Pope, Versailles, etc.) et partage l’émotion des grandes compétitions sportives (Ligue 1, Top 14, Formule 1, D1, Premier League, etc.). Partenaire historique des Césars et du Festival de Cannes, le groupe CANAL+ participe au rayonnement de l’exception culturelle européenne et investit plus de 500 millions d’euros dans le cinéma français et européen.

Description du poste
Au sein du département Marketing Offre et Valeur Parc de CANAL+ (Direction Marketing), le pôle Data Science est en charge des différentes modélisations (prédictions et segmentations) permettant d'accompagner les différentes directions de l'entreprise afin de mieux prédire le comportement de nos abonnés, mais aussi d'optimiser nos activations marketing et commerciales. En ce sens, ce pôle constitue une brique essentielle du plan de Transformation Data, projet majeur inscrit dans les objectifs du Groupe.
Vos missions:
Développer les scores et segmentations nécessaires à notre stratégie de pilotage par la data, afin d'optimiser les activations marketing et commerciales.
Intervenir comme un réel traducteur data au service des chefs de produits, afin de poursuivre l'optimisation de leurs campagnes, mais aussi de trouver des KPI client centric leur permettant de mieux piloter leur activité.
Proposer de nouveaux usecase data driven permettant de moderniser la gestion de nos abonnés.
Faire le lien avec les équipes informatiques pour accompagner au mieux la mise en place de la nouvelle infrastructure Big Data.
Accompagner l'équipe quant à la modernisation du langage de programmation utilisé (Python).
Optimiser et challenger nos outils à l'aide de procédés de Machine Learning novateurs, pour tendre de plus en plus vers des mises à jour en temps réel.
Travailler en étroite collaboration avec toutes les entités du service Etudes (études audiences, études Distribution, études Editoriales) et capitaliser sur la data dans les différentes analyses menées
Suivre les usages sur myCANAL afin de participer aux réflexions des équipes du Digital
Vous aurez l'opportunité de travailler sur des données riches et variées (navigation, usages, text mining…).

Qualifications
De formation Bac+5 universitaire ou grande école spécialisée en machine learning, datamining, économétrie, optimisation numérique, ou mathématiques appliquées.
Le candidat détient idéalement une expérience réussie (5 ans minimum) dans l'analyse de comportements clients et la modélisation à l'aide de techniques de segmentation et de scoring poussées.
Ce profil est également à l'aise avec différents langages de programmation (SAS, Python, SQL…) et est en mesure de formaliser et vulgariser ses résultats auprès d'un public non expert.
A l'aise avec les grandes volumétries de données structurées et non structurées, vous savez identifier les informations pertinentes et utiliser les méthodologies statistiques appropriées afin de répondre à des problématiques Big Data complexes.
Vous êtes autonome et capable de réaliser des projets de bout en bout : recueil des besoins, cadrage et choix de la méthodologie, construction des bases d'études, réalisation des analyses et modélisations, documentation et restitution.
Vous êtes également en capacité de traiter en mode « recherche » des sujets novateurs.

Informations complémentaires

null"
Ivry-sur-Seine (94),40 000 € - 50 000 € par an,,Consultant Data CDI,AfterData,- Ivry-sur-Seine (94),"Passionné par la data, vous cherchez à développer votre maîtrise des données dans des cas concrets ?
Rejoignez-nous !

La mission


Vous intégrez notre équipe de DataScientist au sein de la R&D AfterData.

Epaulé par deux consultants séniors, CTO et COO AfterData, vous participez aux projets clients et vous apportez votre brique à la construction de la plateforme AfterData.
Votre objectif : manipuler les données client et externes afin d’en faire un levier de valeurs

Vos missions seront les suivantes :
Communiquer avec nos data scientists et nos clients pour mener les projets à leur terme
Participer aux ateliers métier et data
Participer à la préparation de données et à l'évaluation des modèles
Etre force de proposition sur l’amélioration de la solution et de la méthodologie
Participer à la roadmap produit

Votre profil


Diplôme ingénieur ou Master 2
3 ans d'expérience dans un poste similaire
Passionné(e) de nouvelles technologies et curieux(se)
Conscient(e) des enjeurs clients, terre à terre
Vous maîtrisez le language Python, en particulier la librairie Pandas
Vous connaissez les principes du Machine Learning, principaux modèles et leurs usages.
Bonne capacité à faire le lien entre un jeu de données et sa signification dans le monde réel ! Vous savez faire preuve de créativité.

Pratique


CDI
Début : Dès que possible
Salaire entre 40K € et 50K € selon expérience
Tickets restaurants, mutuelle, pass navigo…
Paris - Ivry-sur-Seine"
Paris (75),Stage,,Data Scientist / Data Analyst,Ledger,- Paris (75),"Ledger is a leader in security and infrastructure solutions for cryptocurrencies and blockchain applications. We are looking for a Data Scientist/Data Analyst for a 6 months end of study internship with a high probability of conversion to a full time job. Due to the Covid-19 lockdown, the whole recruitment process will be done remotely and the job itself will be remote at least until August 2020. Ledger has always considered data as one of the key growth drivers for our different business lines and a determining factor in our decision making.
Your responsibilities:
Analyze correlation between Ledger KPI and market metrics to help us better understand what drives our sells of hardware wallet and our user activity on Ledger Live
Create reports in Periscope and/or Mixpanel to share data to various departments according to their needs
Analyze feature usage of Ledger Live and bring recommendations to Product management team
Lead data workshops with various departments to determine which KPI we should follow
Work on data quality and data governance
Help us determine the tools and technologies needed to bring the data team to the next level
Requirements:
Pursuing a Degree in a tier-1 engineering school
Hands-on person with strong analytical, communication and leadership skills
Good knowledge of a data science language and of data science models
Good knowledge of SQL
Passionate about the crypto market
Fluent english
What’s in it for me:
Opportunity to work on our already well structured data stack : Redshift, Segment, Mixpanel, Periscope, Airflow.
Get direct exposure to to C-Level executives including our CEO
Learn a lot about the crypto industry from the inside
Work with talented individuals from all fields
Generous compensation
An opportunity to convert your internship to a full time position"
Paris,,,Data Scientist spécialisé Machine Learning / Leader entertainment / Multiprojet / 40-55k,In-Team,- Paris,"Vous cherchez une entreprise qui cartonne et l’entertainment ça vous parle ?
Vous souhaitez apporter du machine learning pour aller encore plus loin, plus haut, plus fort ?

Le poste
Leader français des apps ludiques dans le secteur de l’entertainment, cette startup d’une cinquantaine de personnes compte déjà avec succès plusieurs centaines de million de téléchargement sur l’apps store & le play store, et plusieurs dizaines de millions de levées de fonds en moins de dix ans. Elle possède une forte dimension internationale, elle est déjà présente dans plus de 100 pays. Pour soutenir sa croissance, elle cherche à développer de nouvelles fonctionnalité grâce à la manipulation de la data et au Machine Learning.

Stack technique :
Python, R, Spark, Panda, Librairie data python, environnement Google, Machine Learning

Les responsabilités :
Force de proposition et identification des besoins
Conception des prototypes, suivi et réalisation des algorithmes nécessaires
Suivi des prototypes et vérifier qu’ils sont utilisables
Présence sur toutes les activités de l’entreprise pour scrapper les données nécessaires
Développer et produire les algorithmes finaux pour les intégrer aux services

Votre profil :
Diplômé d’un Bac+5 (formation statistiques apprécié) ou expérience significative
Solides bases en DataScience et maîtrise d’un des frameworks liés au Machine Learning (Python, R, Spark, Panda, TensorFlow ou autre…)
Expérience en Machine Learning et réseaux de neurones (passionné bienvenu)
Bon niveau en math et envie d’en apprendre encore
Rigoureux, pragmatique et apte à travailler en binôme avec un développeur Backend

Pourquoi travailler pour ce client ?
Une start up très dynamique qui soutient une croissance forte dans l’entertainment
Un environnement de travail rêvé basé sur le bien être, une équipe soudée et passionnée dont 30 personnes sont des techs et un cadre stimulant pour gagner rapidement de expérience
Un projet riche de plusieurs apps & produits à destination des professionnels comme des particuliers
Des possibilités d’évolution et d’implication à court terme

Salaire et avantage :
40-55k
Variable possible selon les profils
Salle de sport
Package très complet (Abondement / Actions / BSPCE / Perco)
Beaucoup d’activités d’équipe (Même dans les bureaux !)
Intéressement à 15%

Arrivé jusqu’ici ? Ce poste est fait pour vous !
Pour plus d’informations, contactez moi au
Afficher le nº de téléphone
, ou postulez ici !

A très bientôt !"
Clichy (92),,,Data Scientist / ML Engineer Supply Chain,L'Oreal,- Clichy (92),"CONTEXT :

Within the Beauty Tech Factory, the Tech Accelerator has to support and accelerate the transformation of L’Oréal on new technologies: Data Science & AI, IoT, Blockchain, UX / UI...

You will join the Data Science team for Supply chain use cases, whose defines the Group' Data Science & AI standards and implement them by delivering strategic and high priority projects for the group.

Its 4 main missions are:

Delivery :

Ensure the Data Science developments of Supply chain projects and develop scalable tech assets, starting with Demand Sensing project
Enrich a portfolio of data & analytics micro services at a global level
Standards :
Stimulate IT transformation by applying standards in terms of methodology, code, MLOps…
Manage an ecosystem of data science & tech partners and ensure high level of expertise
Data Culture :
Build, lead and orchestrate the global data science community
Scale and share technical assets
Tech Academy :
Ensure consistency of HR strategy through strong support for recruitments & academic partnerships
Contribute to learning journey definition and contents


You will evolve in a favorable environment:

Development of projects with many experts in their respective fields: Data Science, AI, Agility, Business experts, UX/UI, Data engineering, Big Data and Cloud architecture ;
Diversity of Data (internal / external, structured or not) and missions (marketing, supply, retail, ...) ;
International environment


MISSIONS :

As a Data Scientist / ML Engineer you will use Machine learning approaches, with huge code quality and engineering skills to develop Data Science and AI products.
You will contribute to the design and development of Data Science solutions for strategic business cases with support of external Tech partners, and ensure the consistency of Tech Accelerator guidelines within these projects.

Your mission will be to develop Demand Sensing solution at group level with the main missions bellow:

Increase demand forecast accuracy by developing models, with huge code quality, based on time series, internal and external features ;
Challenge external Tech partners on their code and approaches in an agile delivery squad ;
Ensure consistency of Tech Accelerator standards within the squad ;
Share Tech Accelerator standards with L’Oréal Data Science community ;


SKILLS :


Tech skills :

Experience applying ML / DL to solve challenging problems ;
Knowledge and practical experience on a project or proof of value ;
Experience working effectively with engineering teams ;
Programming skills : Python, Tensorflow, PyTorch, Keras, Spark or other frameworks ;


Soft skills

Excellent verbal and written communication (French and fluent English) and presentation skills, ability to convey technical concepts and their implications to non-experts
Flexibility and open-mindedness; alertness and argumentation; entrepreneurial spirit; relationship skills;
Collaborative mindset with different Tech profiles (data scientists, engineers & architects) and business (data owners & stewards, business owners)"
Paris 15e (75),CDI,,Consultant Data scientist F/H,INEOX,- Paris 15e (75),"Dans le cadre de sa croissance exponentielle, INEOX recrute un Consultant(e) Data Scientist H/F

Poste et missions

En qualité de Consultant Data Scientist, vous aurez pour rôle d’assurer l’ensemble des missions répondant à des problématiques data science et modélisation, dans un contexte CRM / Marketing client ; en intégrant leur restitution au client.

A titre d’exemple, les missions du poste intègrent tout type des projets autour des sujets data science :

Etude connaissance client & Marketing : analyse de profils clients, analyse de la performance des actions marketing…

Analyses Web Analytics / Analyse de parcours clients Web

Conduite de projets modélisation & machine learning : segmentation, scoring, recommandations, text-mining…

Construction de solutions de data visualisation

Dans ce cadre, le périmètre de mission associé au poste couvre notamment les éléments suivants :

Identifier et recueillir avec nos Clients leurs besoins et leurs attentes

Cadrer les réalisations d’un projet

Restituer du contenu et des livrables de qualité, répondant aux objectifs et apportant de la valeur ajoutée pour nos clients

Etre force de proposition sur les recommandations et mes axes d’optimisation pour nos clients sur la base des études menées

En conséquence, le poste nécessite de contribuer à des actions transverses :

Assurer la qualité des livrables

Respecter les charges et des délais d’un projet

Compétences :
Le poste à pourvoir et les différentes prestations proposées nécessitent une forte polyvalence et une capacité d'adaptation, afin de pouvoir répondre à l'environnement technique des différents clients d’INEOX.

Les compétences requises pour le poste sont les suivantes :
Maîtrise des bases de données et du langage SQL

Bonne maîtrise d’au moins deux logiciels / langage de programmation orienté data science : R, SAS, Python, SPSS Modeler, Dataiku…

Bonne maîtrise des méthodes statistiques classiques, ainsi que des mécanismes et des méthodes de machine learning / apprentissage : prédiction, classification, recommandations

Connaissances solides autour des technologies et écosystèmes digital et data

Une connaissance d’outils de BI ou d’outils marketing (Gestion de campagnes, DMP, Web Analytics…) serait un plus.

Une connaissance autour des écosystèmes Big Data, accompagné d’une expertise sur des outils Big Data (Hive, Impala, Pig, Spark…) sera fortement appréciée.

Le poste pourra être amené à évoluer en termes de périmètre en intégrant les dimensions suivantes :

Poste de consultant Sénior

Accompagnement de consultants Junior

Participation à des missions data plus transverses : gestion de projet, expertise fonctionnelle orientée Data sur des outils CRM, veille technologique, intelligence artificielle
Profil recherché De formation supérieure (Ingénieur, Bac +4/+5) à dominante statistiques ou à dominante informatique avec une expérience dans la donnée, vous êtes passionné par la data et le machine learning. Vous êtes volontaires, curieux et faites preuve d’initiatives dans les missions qui vous sont confiées.

Votre rigueur, esprit d'analyse et de synthèse seront les atouts qui vous permettront d’assurer la réussite de vos missions au sein d’INEOX. De plus, votre autonomie, sens de l'initiative, force de proposition et votre excellence adaptabilité sont autant d’atouts qui vous permettront d’apporter de la valeur ajoutée aux projets.

La maitrise (parlé, écrit, lu) du Français et de l’anglais sont impératifs. L’espagnol serait un plus.

Si vous souhaitez :
Intégrer une équipe dynamique et motivée où vos talents, idée et proactivité seront reconnus et encouragés

Découvrir une diversité de projets qui vous permettra de connaître et d’appréhender plusieurs secteurs d’activité/métiers

Gagner en responsabilités et présenter de réelles perspectives d’évolution

Alors REJOIGNEZ NOUS!

Le poste à pourvoir est basé à Sainte-Clotilde Sur L'île de la Réunion (Mobilité internationale indispensable)

CDI - Rémunération Fixe attractive + Variable selon le profil.
Entreprise La société de conseil INEOX, experte en transformation, regroupant des compétences pluridisciplinaires au service de l'innovation, de l'interaction et du développement de la relation Client, recherche de nouveaux talents afin d'intégrer son équipe. INEOX intervient auprès de ses Clients, notamment pour la mise en place de projets de gestion de campagnes, pour les aider dans leurs phases de recherche, d’étude et de déploiement de solutions technologiques liées au marketing : plateforme digitale, Sales Force Automation, CRM multicanal, Data Management Platform, Big Data, BI, Web analytics…"
Paris (75),,,Data Analyst Marketing (F/H),Novencia,- Paris (75),"Contexte
Big Data, Open data, IOT, IA, les possibilités de croisement et de valorisation des données deviennent infinies.
NOVENCIA Group dispose de Data Science et Data Analysis capables d’accompagner ses clients dans l’identification des cas d’usages, leur expérimentation et l’industrialisation des plus valorisants.
En décryptant les données et en procédant aux croisements les plus pertinents, notamment au travers de méthodes de Machine Learning, nos Data Scientists et Data Analysts savent tirer le meilleur parti des données clients.
Data Aanalyst depuis au moins 3 ans, vous êtes à la recherche de nouveaux défis. Bouclez votre ceinture, la suite est pour vous !
Compétences
AYANT LES COMPÉTENCES EN
Anglais Dataiku Power BI Python R SAS SQL Statistiques
Profil
Carnet de route
Nos 35 référencements auprès de Grands Comptes et bien d’autres à venir offrent un large champ de possibles : e-commerce, Banque, Assurance, Service, … !
Évidemment, nous privilégions les environnements innovants et Data-centric.
Exemples de missions :
Analyses à des fins d’amélioration de la connaissance client et d’optimisation de parcours clients, de segmentation d’offre, de prédictions de comportement (Média)
Etude du comportement client à des fins d’optimisation des opérations commerciales (Service)
Analyse des données clients pour déterminer les prévisions de campagnes ou de ventes (Distribution spécialisée)
Votre rôle
Réaliser des études statistiques afin d’apporter des réponses opérationnelles aux problématiques marketing de nos clients : fidélisation, recrutement, attrition, appétence, ….
Proposer et mettre en pratique les modèles statistiques, développer les programmes, déployer les outils et méthodes adaptés pour répondre aux problématiques posées.
Restituer les résultats (rapports, présentations, …) et accompagner à l’industrialisation
Mesurer l’efficacité des actions marketing et digitales mises en place
À vous de choisir. Chez NOVENCIA, chaque consultant a le choix de sa mission et décide de la façon dont il souhaite évoluer.
De la technique et de la personnalité
Explorateur : part à la recherche de données sur des terres inconnues
Savant : découvre et expérimente de nouveaux outils analytiques
Jongleur : aime manier les chiffres
Caricaturiste : reformule, vulgarise, schématise
Fin limier : trouve les meilleures solutions
Curieux : ne passe pas à côté d’une information essentielle
Bilingue : passe aisément du français au langage statistique
Avancer en équipe
NOVENCIA, c’est avant tout un projet collectif.
Validation par un pair. Après les formules d’usage du premier entretien, vous rencontrez un de nos consultants lors d’un second échange pour qu’il puisse appréhender votre niveau technique et vous en dire plus sur l’écosystème de NOVENCIA. (C’est souvent là que tout bascule…).
Partage d’expérience. NOVENCIA compte 7 communautés : Partners – Finance/ Prodigi – Agile / Craft / ActiveViam / UX@Scale / Data / GDPR, dont le fonctionnement est indépendant. Dotées de leur propre budget, elles sont libres de récolter et diffuser des informations. L’objectif : encourager la veille technique et l’évolution professionnelle.
Expertise. Meet-up, webinar, articles, vidéos…Au-delà d’un objectif purement professionnel, technique ou fonctionnel, NOVENCIA vous donne la possibilité de vous exprimer. Environ 80 événements annuels sont organisés. Autant d’occasions pour un collaborateur de se dépasser. Crédibilité et notoriété du parcours sont donc au rendez-vous !
Formation sur mesure. NOVENCIA possède son propre centre de formation. Technique ou fonctionnelle, les formations proposées sont, pour la plupart, certifiantes.
Suivi personnalisé. Qu’elle soit personnelle ou professionnelle, votre évolution est notre priorité. C’est pourquoi nous avons créé les Instants RH et Objectifs Carrière. Vous l’avez compris, chez NOVENCIA on ne lâche rien !
Notre objectif commun : co-construire votre carrière en fonction de vos aspirations et de vos compétences.

S’engager en faveur du handicap c’est garantir l’égalité des chances dès le recrutement.
À compétences égales, nos postes sont ouverts aux personnes en situation de handicap."
Boulogne-Billancourt (92),,,Data Scientist,DEGETEL,- Boulogne-Billancourt (92),"Degetel ? Degetel et le digital ont en commun bien plus que des consonnes : ils partagent le même ADN.En plus de 20 ans d’histoire, Degetel n’a eu de cesse d’accompagner ses clients dans leur transformation digitale. Nous leur faisons bénéficier de notre parti pris d’innovation, fruit de notre R&D et de notre expérience multisectorielle. Nous anticipons à leur profit les évolutions des technologies, des usages et des tendances.Plus que du texte et des longues phrases, Degetel c’est ça : https://www.youtube.com/watch?v=4-bzgNnvzPA Dans cette logique et afin de renforcer notre communauté du Digital Performance, nous cherchons une nouvelle pépite en qualité de : Nous recherchons : Data Scientist (H/F)Pour : Définir une modélisation statistique ; Identifier les outils d’analyse à utiliser pour collecter les données, parfois les construire ; Étudier les données ; Synthétiser les résultats dégagés et les rendre exploitables facilement. Audit des solutions et des outils, évaluation des prestataires et solutions Enrichissement des bases de données tout en satisfaisant les exigences de qualité des données recueillies. Conception et mise en œuvre des outils pour la réalisation et le fonctionnement de la DATA Warehouse En qualité de consultant Degetel, vous êtes amené à intervenir en régie, intégré aux équipes de nos clients, et dans différents secteurs d’activités (industrie, banque, assurance, média, e-commerce…) Nos missions longues (de 1 à 3 ans) sont situées à Paris petite couronne et en proche banlieue.

Ayant : De formation supérieure (BAC +5ou Doctorat avec un profil scientifique) Une expérience de 1 à 4 ans en tant que data scientist Multiples compétences scientifiques (mathématiques, statistiques, modélisation, analyse de données Des connaissances ou une maitrise technique (Big data, python, hadoop, spark, scala..) et un plus Travaillé en méthodologies Agile (Kanban, Scrum) Pour vous accompagner : Le collaborateur est au centre du dispositif « partner centric » qui lui permettra au travers des suivis RH, Managers ou Commerce un accompagnement de proximité et HUMAIN lui permettant une pérennité d’activité et un développement de sa carrière Rencontres nous et juges par toi-même pour embarquer vers ta prochaine destination degetelienne !Degetel, ESN spécialisée dans le digital est une ESN (Entreprise de Services du Numériques) de 450 personnes et a réalisé un chiffre d’affaires de 46 millions d’euros en 2019 et fait partie du groupe Technology&Strategy (T&S). Crée en 2008, T&S est un groupe de conseil européen dont le siège est basé à Strasbourg. Ce nouvel ensemble regroupe plus de 1800 collaborateurs."
Paris (75),CDI,,STATISTICIEN - DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Statisticien - Data Scientist H/F dans le cadre d’une création de poste.
Vous rejoindrez la Direction des Données et des Services Analytiques (DDSA) qui met en œuvre la stratégie définie par le Chief Data Officer de la Banque de France afin que la Banque transforme ses données en un capital pleinement valorisé.

Présentation du Service
Au sein de la Direction des données et des services analytiques (DDSA), le service des analyses quantitatives et méthodes avancées (QUANTIM) :
Développe un savoir-faire en matière d'analyse des données qu'il met au service des métiers ;
Contribue à la mise en œuvre de la plateforme analytique du datalake ;
Anime les communautés dédiées aux méthodes de traitement de données.

Descriptif de mission
Sous la responsabilité du Chef de service et intégré à une équipe de 10 personnes, vous aurez pour missions principales :
Explorer les outils d'analyse des données issus de la Data science et de l'Intelligence artificielle ; définir des bonnes pratiques dans l'usage de ces méthodes ;
Développer une expertise sur la visualisation des données granulaires (cartographie, diagrammes de flux) ;
Mobiliser des sources de données issues du Web (Google trends) afin de proposer des indicateurs alternatifs ;
Réaliser des analyses innovantes à l'attention des autorités de la Banque des thèmes-clés ayant trait au financement de l'économie, à la politique monétaire et à la stabilité financière (analyse de réseaux, finance verte) ;
Présenter des travaux dans des séminaires internes et des colloques internationaux.

Profil recherché
De formation supérieure (école d’ingénieur, écoles spécialisées de type ENSAE/ENSAI, formation universitaire avec une spécialisation sciences des données ou statistiques), vous disposez impérativement d’une première expérience dans le domaine de la Data Science (stage de 6 mois minimum).
Vous avez une réelle appétence pour l’utilisation d’outils innovants liés à la Data Science et disposez de bonnes compétences en statistiques et en économétrie.
Vous maitrisez des outils de traitement statistique de données (R Shiny, SAS, Stata, Eviews, Matlab, Python, etc.).
Vous disposez d’excellentes capacités rédactionnelles et maîtrisez l’anglais à l’écrit et à l’oral (échange avec des acteurs extérieurs à la Banque de France).
Enfin, vous faites preuve des qualités suivantes : esprit d’analyse, agilité, implication.
La Banque de france est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes recrutées."
Paris (75),"Temps plein, Stage",,Stagiaire Data Scientist H/F,Cocoparks,- Paris (75),"Description de l'entreprise
Cocoparks is an early stage tech startup. We believe revolutionizing the parking experience and related infrastructure management solutions is one the biggest levers to save time, money and CO2. We also believe in a responsible use of Artificial Intelligence to serve cities and businesses.
https://cocoparks.io
https://www.linkedin.com/company/cocoparks/
Description du poste
Your impact :
Taking part of the early stage phase of a disruptive tech startup
Working directly with the founder
Shaping the core of the technology
Designing & scaling ML algorithms
Tests and production mode
Technology watch
Profile :
Engineering school or Bac+5 internship
You love machine learning
You are both autonomous and a great team player
You want to serve high impact issues with your skills
You are smart !
Required skills:
Statistics and applied maths: problem modeling, data analysis
Coding: Python, NodeJS, image processing, Docker, Github
Machine learning: computer vision, CNN, algorithm and proof-of-concept development
Industrie : Numérique et développement informatique
Avantages :
Travail à distance possible
Horaires flexibles
Durée du contrat : 6 mois
Type d'emploi : Temps plein, Stage
Expérience:
stagiaire data scientist h/f ou similaire: 1 an (Souhaité)
Télétravail:
Oui"
Paris (75),"Temps plein, CDI",,Consultant Data Scientist (H/F),INVENTIV IT,- Paris (75),"Et si vous découvriez une ESN fondée par des consultants pour les consultants ?
Vous recherchez une entreprise…
Avec un fonctionnement horizontal ? Nos consultants ont des responsabilités au sein de nos 4 pôles centraux ERP, Big Data, Business Intelligence et NTIC.
Avec une expertise dans la valorisation de la donnée ? Nous sommes présents depuis plus de10 ans dans ce secteur avec un écosystème d’experts, un Pôle R&D.
Référencée au sein des grands comptes du CAC 40, et impliquée sur toutes les phases de projets passionnants ? Retrouvez les interviews des Inventifs sur LinkedIn avec #LesInterviewsDesInventifs
Rejoignez Inventiv IT !
Vous êtes au cœur de nos priorités, nos actions en sont le reflet : des activités sportives et ludiques hebdomadaires, un accompagnement par un Coach tout au long de votre carrière, une flexibilité d’horaires et du télétravail, qui apportent un équilibre de vie professionnelle et privée.
Qui êtes-vous ?
Ingénieur de formation, vous disposez d’au moins 3 ans d’expérience dans l'exploitation de données.
Vous avez un esprit entrepreneurial et souhaitez vous investir pour faire grandir l’entreprise dans laquelle vous travaillez.
Vous savez fédérer les équipes autour de vous et avez une réelle expertise et rigueur dans ce domaine. Vous possédez un bon niveau d’anglais.
Vos compétences et ce que nous attendons
Recueillir les besoins du client - Modéliser les données
Développer des algorithmes et scénarios pour répondre aux besoins de l’analyse
Tester, contrôler la qualité et la cohérence des résultats
Etre en veille sur les technologies data et les modèles de data science (Machine Learning, Deep Learning…)
Posséder des connaissances en mathématiques, en analyse de données et en langages statistiques tels que Python, R…
Maîtrise des méthodes de machine learning (SVM, Random Forest, Kmeans…)
Utilisation des outils d’intégration continue (Jenkins, Sonar…)
Bonne connaissance des technologies Big Data les plus courantes : Hadoop, Pig, Hive, Spark, Hbase…
Expérience sur une base de données et des connaissances en SQL
Avantages :
Participation au transport
RTT
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
consultant data scientist (h/f) ou similaire: 3 ans (Requis)"
Paris 14e (75),CDI,,Data Scientist F/H,ANALYSE INFORMATIQUE DE DONNEES,- Paris 14e (75),"AI&Data recherche aujourd'hui des Data Scientist expérimentés (2 ans d'expérience minimum) avec une appétence pour le Big Data.

Nos consultants aident les entreprises à tirer le meilleur parti des données, à mettre en place des solutions opérationnelles, à identifier et mettre en œuvre les projets liés à la transformation digitale.

Il s'agira d'intégrer notre Pôle DATA SCIENCE, constitué d'une trentaine de Data Scientists.

Sur ce poste, vous serez amené à intervenir pour de grandes entreprises sur des projets à forte valeur ajoutée :

Vous aurez en charge des études menées le plus souvent pour des besoins marketing et CRM (fidélisation, recrutement, attrition, appétence, valeur client, performance commerciale…) en réalisant :
= > Segmentations, scorings, études de comportement clients, mesures de performance, estimations de potentiels, analyses d’association de produits, des traitements d’enquêtes, etc.

Vous traiterez des données variées : vie des contrats, données d’achat / de consommation, actions et réactions de marketing direct, réclamations client, utilisations des sites web et applications mobiles.
Sur opportunité de mission, vous pourrez monter en compétences sur les outils de Big data analytics et l’analyse des parcours clients

AI&Data, partenaire de nombreuses grandes entreprises françaises depuis plus de 40 ans, est une entreprise innovante qui utilise des technologies récentes. Vous collaborerez avec des data Scientist et des data manager.

L’AI&Data Academy vous fera bénéficier de ses formations les plus innovantes, et vous serez amené vous-même à animer des séminaires ou formations pour nos clients ou collaborateurs.
Profil recherché De formation supérieure en statistiques et mathématiques, vous justifiez d’au moins 2 années d’expérience acquises dans le traitement des données et les études statistiques, idéalement en société de services, dans un département de type « connaissance client » ou R&D.

Vous avez impérativement déjà pratiqué la programmation R (dont R shiny) et PYTHON (idéalement d’autres logiciels comme SPSS Modeler, SAS, JMP).

Vous maîtrisez le requêtage en SQL.

Une première expérience avec les technologies Big data spark (sparkr-sparklyr,Pyspark), hadoop, hive, ou des méthodes d’analyse de séquences serait un plus.

Vous souhaitez vous investir dans des projets challengeants, monter rapidement en compétences, avec la possibilité de gagner en responsabilités, ce poste n'attend que vous.

La société est depuis quelques années en pleine croissance et cultive son esprit start up et son ambiance conviviale. Baby foot, table de ping pong, workshops internes et afterworks font partie de nos rituels d'entreprise.

Vous baignerez alors dans un environnement de travail idéal pour développer votre créativité et prendre des initiatives.

Je vous invite à consulter notre site et nos réseaux sociaux (Cf ci-dessous) et à revenir vers moi pour échanger sur nos opportunités.
Entreprise AI&Data, Agence Data et Datascience

AI&Data possède trois domaines d'expertise : Datascience, CRM et Big data.

1er hébergeur de bases de données marketing et de datalakes en France cumulant plus de 220 millions de clients et plus de 45 milliards d’interactions.

AI&Data offre une chaine de valeur complète autour de l’analyse, du traitement, de l’exploitation et de la transformation des données en performance marketing.

Opérant des données clients dans plus de 12 pays, AI&Data travaille avec les plus grands des secteurs des télécoms, de l’énergie, de la banque, de l’ hôtellerie, des jeux et des loisirs."
Issy-les-Moulineaux (92),,,CDI-DATA ANALYST DTSI H/F,Groupe CANAL+,- Issy-les-Moulineaux (92),"Description de l'entreprise
Au sein de la Direction Financière et Performance du groupe CANAL+, le Pôle Analyse de la Performance et Connaissance Client a pour mission de mener des études de suivi de la performance des ventes et des mouvements du parc abonnés ainsi que la prévision annuelle des résultats du groupe.
Le Pôle est notamment en charge d'accompagner les responsables opérationnels des directions métiers (marketing, stratégie, finance, commerce et service client) et les aider dans la prise de décision avec une approche factuelle, quantifiée et orientée valeur client.

Description du poste
En lien étroit avec les responsables de la direction du groupe, vous êtes en charge d'analyser les données clients pour expliquer et prévoir les évolutions des indicateurs de performance.
Vous aurez notamment à :
Suivre et analyser de façon fine la performance globale et présenter les résultats en Comité de Direction.
Analyser, en s'appuyant sur des techniques de modélisation statistique, le comportement et le cycle de vie de nos clients.
Segmenter les usages de nos abonnés.
Exploiter et valoriser l'ensemble des données de l'entreprise et construire une vision 360 degrés du client.
Participer à la construction de business plan afin d'orienter les décisions opérationnelles et stratégiques de l'entreprise et proposer des recommandations visant à optimiser les stratégies du groupe.
Participer aux travaux de réflexion sur les techniques novatrices de Machine Learning et de Big Data.

Qualifications
Particulièrement à l'aise avec les grandes volumétries de données structurées et non structurées, vous savez identifier les informations pertinentes et utiliser les méthodologies statistiques appropriées afin de répondre à des problématiques Business.
Vous êtes autonome et assurez de bout en bout la réalisation de vos études et projets : recueil des besoins, cadrage et choix de la méthodologie, construction des bases d'études, réalisation des analyses et modélisations, restitution aux différents interlocuteurs internes.
De formation Bac+5 en statistiques, datamining, analyse de données, économétrie, mathématiques appliquées ou big data, vous avez une première expérience d'au moins 2 ans (hors stages et alternances) dans l'analyse des comportements clients et la modélisation à l'aide de techniques de segmentation et de prévision.
Vous maitrisez les outils SAS, le langage SQL et R et êtes à l'aise quant à la formalisation d'une synthèse des résultats sous PowerPoint.
Vous êtes enthousiaste, dynamique, curieux, rigoureux dans vos analyses et savez faire preuve de force de conviction.
Vous êtes idéalement attiré par le secteur des médias.

Informations complémentaires

null"
Paris (75),CDI,,DATA SCIENTIST MONETISATION / FRAUDE,Happn,- Paris (75),"Description du poste
Environnement
Vous voulez trouver des insights forts pour accélérer la croissance d’une startup innovante et développer des algorithmes business driven? Rejoignez notre équipe data riche en compétences, vivante et éclectique qui regroupe data scientists, engineers, BI et analysts. On attend de vous que vous soyez force de proposition dans l'équipe, qui est toujours à la recherche d'idées nouvelles!
Descriptif de missions
Au travers d’études descriptives et prédictives approfondies, estimation du ROI d'un projet, ton rôle sera d’identifier les principaux leviers de monétisation, de life time value, de réachat, de panier moyen, ainsi que de lutter contre la fraude
Tu seras force de proposition d'opportunités de mise en œuvre de machine learning et / ou scores répondant aux besoins métier pour co-construire la roadmap Monétisation avec le Product Owner ;
Participation au cadrage / kick-off avec le Produit : objectif, périmètre, méthode ainsi que capacité d’industrialisation pour obtenir la validation métier et technique avant démarrage;
Développement des modèles et méthodes d’apprentissage automatique permettant de répondre à une problématique métier en accord avec la roadmap stratégique. Les problématiques de monétisation seront liées au business model existant ou à venir, à la propension à souscrire à des abonnements ou des consommables, ou encore à la création de valeur à partir des fonctionnalités de l’application ;
Référent dans la lutte contre la fraude (scam) en étroite collaboration avec le service client : appropriation et amélioration du modèle anti-scam implémenté actuellement en Tensorflow, compréhension des différents patterns de scam, ajustements du modèle et des règles anti-fraude existantes, suivi étroit des KPIs relatifs à la fraude ;
Test de robustesse de tes algorithmes sur des jeux de données adaptés;
Définition et analyse des A/B tests de monétisation;
Vulgarisation de tes travaux (lors des démos et ateliers de travail) en présentations captivantes, visuelles et synthétiques aux équipes business et à la direction afin de mobiliser les différentes équipes associées à tes projets et de te synchroniser avec elles.
Méthodologies et bonnes pratiques:
Référent en statistique de l’équipe data, tu accompagneras les différents métiers de la data pour contribuer à l’amélioration de l’A/B tests framework (tests statistiques, KPIs à suivre, périmètre de l’A/B test).
Suite à tes études, tu pourras recommander aux ingénieurs BI la mise en place de nouveaux indicateurs clés, perfectionnant les tableaux de bord existants.
Tu participeras à l'amélioration de bonnes pratiques au sein du CORE Data science : enrichissement de la plateforme Data science pour développer, tester et industrialiser les modèles, développement d’outils et de librairies en Python, workshop avec Google quand nécessaire, travaux avec les data ingénieurs, versionning avec Github…
Profil recherché
Formation
De formation supérieure d’une grande école d’ingénieur spécialisée en statistiques / datamining /mathématiques.
Vous avez 2 ans d’expérience minimum en tant que data scientist dans le domaine du digital
Hard skills (Compétences métier)
Obligatoire : Python / SQL / connaissances statistiques et machine learning / Tensorflow
Subsidiaire : Elastic Search / Spark / R / Git / Tableau
Soft skills (Compétences interpersonnelles)
Vous êtes owners de vos projets: vous prenez des initiatives, vous êtes flexible et autonome, et faites preuve d’une grande rigueur
Vous êtes une personne de confiance
Vous êtes synthétique, clair(e) et avez de bonnes qualités de communication
Vous avez l’esprit d’équipe: vous avez un bon relationnel, aimez le partage et le challenge
Vous savez faire preuve d’empathie"
Paris (75),CDI,,Data Scientist,QuickSign,- Paris (75),"L’équipe
Des dizaines de milliers de comptes sont ouverts via notre plateforme chaque jour. La solution SDM (Smart Document Management) de QuickSign gère l’ensemble des modules d’analyse de documents : classification, lecture et contrôles sur la qualité et le contenu des documents. Chez QuickSign, elle permet de traiter chaque jour automatiquement un nombre important de dossiers pour les plus grandes banques en ligne.
Afin d’accélérer le temps de traitement des dossiers (en limitant le nombre de vérifications manuelles à mener), il est nécessaire d’avoir des algorithmes rapides et précis pour les différentes étapes. Pour ce faire, nous nous appuyons sur l’état de l’art en Deep Learning pour construire nos propres algorithmes d’analyse d’image et de texte.
L’ouverture de ces comptes génère par ailleurs des millions de logs qui, très divers, contiennent énormément d’informations pouvant être exploitées pour produire des statistiques, mais aussi accélérer le temps de traitement, augmenter le taux de transformation et limiter les fraudes.
Tu travailleras au sein de l’équipe Data, dont le but principal est de valoriser ce grand volume de données entrantes (dossiers, pièces justificatives, logs…). Notre équipe est aujourd’hui composée de 2 Data Scientists, 2 Data Engineers et 2 développeurs Python, et vise à être complétée dans l’année par un Data Scientist, un Data Engineer et un architecte Data. Elle couvre des thématiques larges telles que :
Vision artificielle : lecture et reconnaissance automatique de documents structurés ou non structurés (OCR), classification, analyse sémantique (NLP), approches hybride texte + image, évaluation de la qualité d’un document
Business Intelligence : ETLs permettant de produire des métriques métier à destinations des autres équipes de QuickSign, ou de nos clients
Datalake : projet de mise à plat de l’accès à toutes les données produites par QuickSign à des fins exploratoires
Lutte contre la fraude : détection de fraude à l’ouverture d’un compte.
Améliorer les performances de nos algorithmes, en concevoir de nouveaux, et explorer nos données afin de guider nos choix de R&D sont donc des enjeux essentiels au sein de l’équipe. Ces tâches s’inscrivent dans un effort plus large d’industrialisation des productions de l’équipe afin de concentrer les travaux des Data Scientists au développement de nouveaux modèles. Nous menons par exemple un chantier d’apprentissage continu avec les Data Engineers de l’équipe afin de réduire le temps nécessaire au réentrainement des modèles et d’être garant du maintien de bonnes performances en production.
Tes missions
Ta mission principale consistera à développer des modules de traitement de données images et texte essentiellement, à l’aide des technologies à l’état de l’art en Deep Learning et en NLP. Il faudra ainsi participer à l’amélioration des modules existants et à la création de nouveaux modules répondant à des besoins clients tels que :
Lecture, classification de nouveaux documents
Prise en charge de nouvelles zones géographiques
Lutte contre la fraude / KYC
Tu seras garant de la mise en oeuvre de ces modules chez QuickSign, depuis leur conception jusqu’à leur mise en production, ainsi que de leur suivi, avec le soutien des développeurs Python et des Data Engineers de l’équipe, ainsi que celui de nos DevOps.
Dans une démarche d’amélioration continue de la performance chez QuickSign, une veille régulière sur les sujets Data est primordiale, et l’équipe t’encouragera vivement à assister et à présenter les travaux menés chez QuickSign dans le cadre de Meetups, GdR et/ou conférences en France/Europe portant sur nos domaines de spécialité.
Profil recherché
Niveau d’études, expériences
Nous recherchons quelqu’un ayant entre 2 et 4 ans d’expérience en tant que Data Scientist, ayant travaillé sur des problématiques de vision et/ou de NLP, ou sortant d’une thèse dans le domaine, et travaillant en Python.
Compétences requises
Python 3
Docker
TensorFlow
Git
Nous apprecions aussi
NoSQL (pour info nous utilisons MongoDB)
gestionnaire de workflow pour le Deep Learning : AirFlow, Prefect…
GCP
TF-Serving, TF-Extended
Outil de versioning général (poetry) et pour le Deep Learning (DVC)
Ton état d’esprit
Ce poste couvrant, d’une part, des études R&D sur des thématiques Data au sens large afin de maintenir les produits proposés chez QuickSign à l’état de l’art, tu dois être force de proposition sur l’adaptation d’algorithmes récents à nos problématiques.
D’autre part, le passage des études R&D en production nécessite de garantir des taux de performances élevés (compromis ressources, temps, qualité). Tu dois donc avoir de l’appétence pour développer du code suivant les guidelines de bon développement, en portant une attention particulière aux test et au monitoring, afin de garantir le bon fonctionnement des modules Data en production."
Paris 1er (75),CDI,,Data Scientist -NLP & Computer Vision F/H,SEPT LIEUES,- Paris 1er (75),"Tes missions seront les suivantes :
amélioration des modules existants et être force de proposition pour les futurs
traitement de données et d'images
conception, mise en production et suivi
Collaboration avec les data engineers et les devOps

Profil recherché Profil :
Bac +5 et équivalent
Minimum 2 années d'expérience
Maîtrise de Python, notamment Python 3
Compétences en Deep Learning
Le plus : compétences/connaissances en MongoDB
Entreprise Fintech française qui qui facilite la digitalisation en supprimant tous les processus papiers pour les services financiers en B2C.

Cette start up propose un tout-en-un digital: gestion de documents automatisée, signature électronique, entre autres = > développement constant à l'international

Avantages : Variable, mutuelle, CE, flexibilité horaires, tickets Restaurant, évènements d'entreprise..."
Paris (75),CDI,,DATA SCIENTIST MARKETING,Happn,- Paris (75),"Description du poste
Environnement
Vous voulez trouver des insights forts pour accélérer la croissance d’une startup innovante et développer des algorithmes business driven ? Rejoignez notre équipe data riche en compétences, vivante et éclectique qui regroupe data scientists, engineers, BI et analysts.
On attend de vous que vous soyez force de proposition dans l'équipe, qui est toujours à la recherche d'idées nouvelles!
Descriptif de missions
Au travers d’études descriptives et prédictives approfondies, estimation du ROI d'un projet, ton rôle sera d’identifier les principaux leviers de marketing et de mettre en place les outils d’aide à la décision pour l’acquisition de nouveaux utilisateurs
Tu seras force de proposition d'opportunités de mise en œuvre de machine learning et / ou scores répondant aux besoins métier de l’acquisition ;
Développement des modèles et méthodes d’apprentissage automatique nécessaires à l’évaluation et au pilotage des décisions marketing : projection d’inscrits, de revenu, rétention, récurrence d’achat, revenu indirect ;
Mise en place d’outils d’aide à la mesure de la performance des campagnes Organic ou Paid, calcul de ROI et de payback period, recommandations ;
Participation au cadrage / kick-off avec l’acquisition : objectif, périmètre, méthode ainsi que capacité d’analyse et d’industrialisation pour obtenir la validation métier et technique avant démarrage;
Compréhension et maitrise des modèles d’acquisition, des modes d’inscription, du tracking et des spécificités de chaque plateforme ;
Test de robustesse de tes algorithmes sur des jeux de données adaptés;
Définition et analyse des A/B tests d’acquisition, de landings ;
Vulgarisation de tes travaux (lors des démos et ateliers de travail) en présentations captivantes, visuelles et synthétiques aux équipes business et à la direction afin de mobiliser les différentes équipes associées à tes projets et de te synchroniser avec elles.
Méthodologies et bonnes pratiques:
Référent en statistique de l’équipe data, tu accompagneras les différents métiers de la data pour contribuer à la connaissance et la maitrise des problématiques d’acquisition (tests statistiques, KPIs à suivre, périmètre de l’A/B test).
Suite à tes études, tu pourras recommander aux ingénieurs BI la mise en place de nouveaux indicateurs clés, perfectionnant les tableaux de bord existants.
Tu participeras à l'amélioration de bonnes pratiques au sein du CORE Data science : enrichissement de la plateforme Data science pour développer, tester et industrialiser les modèles, développement d’outils et de librairies en Python, workshop avec Google quand nécessaire, travaux avec les data ingénieurs, versionning avec Github…
Profil recherché
Formation
De formation supérieure d’une grande école d’ingénieur spécialisée en statistiques / datamining / mathématiques.
Vous avez 2 ans d’expérience minimum en tant que data scientist dans le domaine du digital
Hard skills (Compétences métier)
Obligatoire : Python / SQL / connaissances statistiques et machine learning
Subsidiaire : Tensorflow / Elastic Search / Spark / R / Git / Tableau
Soft skills (Compétences interpersonnelles)
Vous êtes owners de vos projets: vous prenez des initiatives, vous êtes flexible et autonome, et faites preuve d’une grande rigueur
Vous êtes une personne de confiance
Vous êtes synthétique, clair(e) et avez de bonnes qualités de communication
Vous avez l’esprit d’équipe: vous avez un bon relationnel, aimez le partage et le challenge
Vous savez faire preuve d’empathie"
Paris (75),42 000 € par an,,Data Scientist - H/F,emagine Consulting,- Paris (75),"emagine recrute des Data Scientists pour accompagner ses clients du CAC 40 et du SBF 120 dans leurs projets de transformation de la Data.

Missions et responsabilités :
Au sein des datalab, des data factory ou des équipes Big Data/IA de nos clients, vous collaborerez avec l’ensemble des entités internes (Marketing, IT, Finance, Ressources Humaines, CRM ) pour concevoir, réaliser et supporter les différents projets d’analyse de données.

Votre mission :
Comprendre les problématiques des clients internes
Proposer des analyses (exploratoires, descriptives ou prédictives) pertinentes et à forte valeur ajoutée
Réaliser et maintenir les analyses proposées
Participer à la construction de différents use-cases.
Communiquer le résultat de vos solutions développées aux entités internes (Marketing, IT, Finance, Ressources Humaines, CRM ) ainsi qu’aux différentes équipes impliquées
Participer à la définition des normes, des modèles et outils afin de répandre les best practices
Mettre en place des modèles de machine learning
Assurer l’amélioration et la pérennisation des modèles et analyses développés et/ou déjà existants

Vos atouts indispensables :
Diplôme type Ecole d’Ingénieur: BAC+4/5 spécialisation Data Science, Statistique, Informatique ou Master équivalent ;
Anglais Courant ;
Compétences mathématiques ;
Expertise en analyse de donnés et manipulation de données avec de fortes volumétrie (SQL, Hive, Spark ) ;
Machine learning (supervisé et non supervisé : clustering, régression, système de recommandation, text mining, graph mining ...) ;
Très bonnes connaissances ou même maîtrise des langages de programmation SAS, R, Python et éventuellement Java/Scala) ;
Connaissances en probabilités et statistiques ;
Maîtrise des technologies Big Data (Hadoop, MapReduce ) ;
Connaissance d’outils de visualisation de données (PowerBI, Spotfire, Tableau, Qlik, ) ;
Curiosité naturelle ;
Bonne communication auprès d’interlocuteurs différents (techniques et non techniques) ;"
Paris (75),,,Data Scientist Marketing (F/H),Novencia,- Paris (75),"Contexte
Big Data, Open data, IOT, IA, les possibilités de croisement et de valorisation des données deviennent infinies.
NOVENCIA Group dispose de Data Science et Data Analysis capables d’accompagner ses clients dans l’identification des cas d’usages, leur expérimentation et l’industrialisation des plus valorisants.
En décryptant les données et en procédant aux croisements les plus pertinents, notamment au travers de méthodes de Machine Learning, nos Data Scientists et Data Analysts savent tirer le meilleur parti des données clients.
Data Scientist depuis au moins 3 ans, vous êtes à la recherche de nouveaux défis. Bouclez votre ceinture, la suite est pour vous !
Compétences
AYANT LES COMPÉTENCES EN
Anglais Machine Learning Power BI Python R SAS SQL Statistiques
Profil
Carnet de route
Nos 35 référencements auprès de Grands Comptes et bien d’autres à venir offrent un large champ de possibles : e-commerce, Banque, Assurance, Service, … !
Évidemment, nous privilégions les environnements innovants et Data-centric.
Exemples de missions :
Analyses à des fins d’amélioration de la connaissance client et d’optimisation de parcours clients, de segmentation d’offre, de prédictions de comportement (Média)
Analyses du comportement client à des fins d’optimisation des opérations commerciales (Service)
Prévision de vente de milliers de pièces détachées automobiles (Automobile)
Votre rôle
Cruncher, analyser et exploiter les données, structurées ou non structurées (CRM, web, open data, …)
Contrôler la qualité des données, détecter des patterns, des outliers
Concevoir les datamarts
Proposer et développer des algorithmes et des outils en Python ou R, en vous appuyant sur les librairies statistiques et de datascience associés, pour résoudre les problématiques métier
Collaborer avec les équipes technique et métier pour définir les besoins et expliciter les résultats
Restituer les résultats (rapports, présentations…) et accompagner à l’industrialisation
À vous de choisir. Chez NOVENCIA, chaque consultant a le choix de sa mission et décide de la façon dont il souhaite évoluer.
De la technique et de la personnalité
Explorateur : part à la recherche de données sur des terres inconnues
Savant : découvre et expérimente de nouveaux outils de récupération des données, d’exploration, de modélisation, …
Jongleur : aime manier les chiffres
Caricaturiste : reformule, vulgarise, schématise
Fin limier : trouve les meilleures solutions
Curieux : ne passe pas à côté d’une information essentielle
Bilingue : passe aisément du français au langage statistique
Avancer en équipe
NOVENCIA, c’est avant tout un projet collectif.
Validation par un pair. Après les formules d’usage du premier entretien, vous rencontrez un de nos consultants lors d’un second échange pour qu’il puisse appréhender votre niveau technique et vous en dire plus sur l’écosystème de NOVENCIA. (C’est souvent là que tout bascule…).
Partage d’expérience. NOVENCIA compte 7 communautés : Partners – Finance/ Prodigi – Agile / Craft / ActiveViam / UX@Scale / Data / GDPR, dont le fonctionnement est indépendant. Dotées de leur propre budget, elles sont libres de récolter et diffuser des informations. L’objectif : encourager la veille technique et l’évolution professionnelle.
Expertise. Meet-up, webinar, articles, vidéos…Au-delà d’un objectif purement professionnel, technique ou fonctionnel, NOVENCIA vous donne la possibilité de vous exprimer. Environ 80 événements annuels sont organisés. Autant d’occasions pour un collaborateur de se dépasser. Crédibilité et notoriété du parcours sont donc au rendez-vous !
Formation sur mesure. NOVENCIA possède son propre centre de formation. Technique ou fonctionnelle, les formations proposées sont, pour la plupart, certifiantes.
Suivi personnalisé. Qu’elle soit personnelle ou professionnelle, votre évolution est notre priorité. C’est pourquoi nous avons créé les Instants RH et Objectifs Carrière. Vous l’avez compris, chez NOVENCIA on ne lâche rien !
Notre objectif commun : co-construire votre carrière en fonction de vos aspirations et de vos compétences.

S’engager en faveur du handicap c’est garantir l’égalité des chances dès le recrutement.
À compétences égales, nos postes sont ouverts aux personnes en situation de handicap."
Levallois-Perret (92),"Temps plein, CDI",,FULL REMOTE Senior Data Scientist H/F - CDI,Jellysmack,- Levallois-Perret (92),"Nous continuons de recruter et avons adapté notre processus de recrutement. Tous nos entretiens, ainsi que l’onboarding, se déroulent désormais en full remote.
Cette offre d'emploi est proposée en FULL REMOTE
Jellysmack est une entreprise spécialisée dans la création de contenus vidéos originaux sur les réseaux sociaux. Avec plus de 3 milliards de vues par mois, Jellysmack a connu une ascension fulgurante, ne cesse de grandir et ambitionne de devenir le leader mondial dans son domaine. La recette de ce succès repose sur la qualité de nos contenus, mais aussi sur la technologie opérant en arrière-plan. Jellysmack a développé une suite d'outils propriétaires, propulsés par l'IA, permettant à nos équipes de contenu de publier, s'inspirer, comprendre la trend, analyser les résultats, mais bien plus encore, des outils qui analysent le contenu en ligne, les réactions des gens devant ce contenu, et déterminent ce que sera la tendance demain.
Après plus de 2 ans de développement technique, Jellysmack propose une technologie unique articulée autour de 3 produits qui visent à optimiser la création et la distribution sociale de vidéos.
L'équipe Tech œuvre pour la mise en place d’outils utilisés en interne par les équipes contenu afin de déterminer les sujets qui buzzent, les aider dans la création de contenu, suivre les performances des vidéos internes etc... en injectant dans chacun de ces produits une dose conséquente d’algorithmie, de statistiques et de machine / deep learning.
En lien direct avec le Head Of Data (basé en Corse), vous serez amené à travailler sur différentes problématiques - prioritairement axées autour du NLP - et sur des projets de taille très différentes, impliquant d’importantes quantités de données (plusieurs centaines de millions de vidéos stockées en base à date avec leur métadata textuelles, plus de 21 milliards de commentaires...).
Au sein d’une équipe de sept data scientist, vous serez le référent de l’équipe sur ces sujets d’analyse et de compréhension du langage et vous aurez un rôle consultatif.
Missions principales
Passer d'une problématique métier à un algorithme de data science
Passer d'un POC à un algorithme en production
Vulgariser un algorithme à l'état de l'art et être référent de l'équipe Data Science
Etre autonome sur les outils comme Git, avoir déjà travaillé sous docker - idéalement sous AWS
Quelques exemples de sujets :
Analyse de sentiments sur les commentaires des vidéos
Extraction de topics à partir des titres, descriptions, commentaires des vidéos
Catégorisation de vidéos en thématique à partir de l’ensemble des éléments textuels dont nous disposons
Génération automatique de titre/tag de vidéos...
Création d’un algorithme d’identification des meilleurs créateurs sur une thématique donnée
Analyse de vidéos (contenu et metadata) pour mieux comprendre la rétention des utilisateurs
Optimisation de coût sur l’acquisition de fans
Génération automatique de montage de vidéos...
Profil recherché
Docteur en computer science ou diplômé d’une maîtrise en data science, vous disposez d’au moins 5 ans d’expériences,
Une autonomie sur le passage en production d’algorithmes sera indispensable,
Vous êtes pédagogue sur la transmission de votre savoir,
Vous avez un très bon niveau de SQL (MySQL et PostgreSQL).
Avantages :
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
full remote senior data scientist h/f - cdi ou similaire: 1 an (Souhaité)"
Levallois-Perret (92),,,DATA SCIENTIST / LABORATOIRE INTELLIGENCE ARTIFICIELLE (H/F),Axys Consultants,- Levallois-Perret (92),"Pour promouvoir auprès de nos clients la mise en œuvre de solutions innovantes dans le domaine de l’Intelligence Artificielle (IA), Axys Consultants recrute pour son Laboratoire IA, des Data Scientist dont les principales missions seront les suivantes :

Identifier les besoins des différents métiers et entités en termes d’analyse et de visualisation de données structurées et/ou non structurées.
Analyser des données complexes, structurées et/ou non structurées.
Réaliser des modèles et algorithmes complexes ainsi que des analyses prédictives en utilisant des techniques avancées de data science (machine learning, deep learning, statistique avancée).
Analyser la performance et la robustesse de ces modèles pour une optimisation continue.
Modéliser les résultats afin de fournir des visualisations pertinentes.
Maintenir une veille scientifique active dans les domaines du Machine Learning et du Deep Learning appliqués aux données structurées et non structurées.

De formation supérieure (Bac+5 : Ingénieur, Master ou équivalent) vous avez au minimum 3 ans d’expérience dans le domaine Data Science, une bonne connaissance en Data Integration/Data Modeling/Data Visualisation ainsi qu’une maîtrise avérée dans le développement d’algorithmes de machine learning/deep learning et l’analyse de données.

Vous êtes mobile (France et international) avec une maîtrise professionnelle de l’anglais.

Votre contact RH pour les candidatures : sarah.gebeli@axys-consultants.com"
Paris (75),CDI,,CONSULTANT DATA SCIENTIST - H/F,Talan,- Paris (75),"Vous êtes reconnu pour vos compétences...
Connaissance de l’écosystème Hadoop, voire des distributions suivantes : Hortonworks, Cloudera
Connaissance de Spark, MApReduce
Connaissance de bases de données NoSQL du type Hbase, MongoDB, Cassandra
Connaissance d’outils d’analyse statistique R, SAS
Connaissance en programmation Java/Python serait un plus
Capacité à appréhender le contexte projet
Connaitre le cycle de vie du projet
Votre entourage vous décrit comme...
A l’écoute
Ayant un fort esprit d’équipe et de l'humilité
Autonome
Motivé et dynamique
Bon communiquant
Ayant une bonne capacité d’adaptation
Ayant un sens du service développé
Ensemble réalisons de nouveaux projets Talantueux
Afin de répondre aux besoins Big Data de nos clients dans la région Ile de France, nous recherchons des consultant(e)s junior(e)s ou confirmé(e)s Data Scientist.
En fonction de votre profil, vous serez amené(e) à prendre en charge les actions suivantes:
Conception et analyse techniques
Développement, tests unitaires et tests d’intégration
Intégration et rédaction des cahiers de test et des documents techniques
Veille technologique
Participer à la vie de l’équipe Data Management"
Paris 16e (75),,,DATA SCIENTIST,InnoValeur,- Paris 16e (75),"Vous êtes une licorne et avez l’esprit startup ? Vous cherchez une structure où l’on fait les choses sérieusement mais on ne se prend pas au sérieux ? Vous souhaitez participer à des projets ambitieux et évoluer sur une variété de problématiques ? Vous avez l’esprit de service et une vision en plus de vos compétences technologiques ? Vous cherchez l’excellence et à rester à la pointe de votre domaine ? Vous êtes animé par l’esprit d’équipe et souhaitez évoluer dans un parcours Fast Track ?

Nous cherchons des Data Scientists capables de comprendre les enjeux métier de nos clients et de les traduire en solutions concrètes et pragmatiques.

VOTRE PROFIL

Vous avez au moins 7 ans d’expérience avec un profil mixte combinant la statistique, la Data Science, et idéalement le développement d’applications.

Vous avez une excellente maîtrise des mathématiques, statistiques, et algorithmes.

Vous êtes expert sur les méthodes d’exploration et d’analyse des données, et en maitrisez les problématiques architecturales.

Vous avez une bonne connaissance en réseaux de neurones, intelligence artificielle, machine learning, et apprentissage supervisé et non supervisé.

Vous êtes familier avec les principaux outils du marchés et en maîtrisez au moins deux parmi Spark MLlib, Python, Scikit-Learn, TensorFlow, Watson, H2O, R, SAS, SPSS,…

Idéalement vous avez une expérience autour des technologies Big Data, NoSQL, et DataViz, ou savez du moins comment en exploiter les données.

Idéalement vous avez déjà encadré des équipes et avez une expérience probante dans le domaine du conseil.

Une spécialisation sectorielle dans la banque-assurance, les FMNG et retail, le pharmaceutique, ou la logistique sera valorisée.

VOUS RESPONSABILITES

Identifier les problématiques de nos clients et définir les modèles adéquats.
Récupérer et exploiter les données pertinentes provenant de sources variées
Modéliser les données et développer des algorithmes et scénarios
Réaliser des POC pour nos clients et assurer le passage en production
Interagir avec nos équipes d’architectes Big Data et consultants en innovation pour exploiter les leviers de création de valeur et prendre les meilleures options.
Assurer un suivi quotidien avec nos clients pour appréhender leurs besoins et être force de proposition.
Selon le contexte, mettre en œuvre de façon autonome les solutions et/ou encadrer les équipes pour les phases d’implémentation."
Issy-les-Moulineaux (92),,,Data Analyst H/F - Dr Pierre Ricaud,Groupe Yves Rocher,- Issy-les-Moulineaux (92),"Réf: 76976
Lieu: FR - Issy-les-Moulineaux, FR
Type de contrat: CDI / Unlimited Term
Marque: Docteur Pierre Ricaud
Equipe: DPR/ID PARFUMS
Data Analyst H/F - Dr Pierre Ricaud
Le Groupe Rocher est un groupe familial rentable, indépendant et animé par un esprit ""d'entrepreneurs-créateurs"".
Le Groupe Rocher ce sont 10 principales marques au service de la beauté et du bien-être : Yves Rocher, Petit Bateau, Stanhome, Kiotis, Dr Pierre Ricaud, ID Parfums, Daniel Jouvance, Flormar, Sabon et Arbonne
40 millions de femmes font confiance à la qualité et à la performance des produits élaborés par les marques du Groupe ; soit plus de 500 millions de produits délivrés par an.
Docteur Pierre Ricaud et Daniel Jouvance, deux marques emblématiques du Groupe Rocher, groupe de cosmétiques français, sont expertes en soin du visage et proposent depuis plus de 30 ans une offre experte et accessible à plus de 3 millions de femmes en Europe.
Le site Ricaud.com a été élu meilleur site E-commerce en Beauté en 2018 (sources FEVAD et source Capital).
Dans un contexte d’accélération digitale forte, la data a été identifiée comme l’un des piliers sur lesquels nous souhaitons activer notre transformation.
Dans ce cadre, nous recherchons un(e) :
Data Analyst - Dr Pierre Ricaud H/F
MISSIONS
A bord de la team Intelligence Client, vous serez amené à travailler au quotidien avec les équipes commerciales & marketing de la marque Dr Pierre Ricaud, mais aussi avec différents acteurs IT groupe et partenaires externes. Vous participerez activement à l’accélération digitale de la marque et plus particulièrement aux projets de transformation data.
Votre mission sera articulée suivant quatre axes :
Etudes : développement de la connaissance client au travers des analyses de comportement sur l’ensemble de nos données CRM, DMP, web, avis produits, réseaux sociaux
Reportings : refonte des outils existants, mise à jour des reportings et réalisation des analyses de performance
Activation : ciblages des actions Marketing et segmentations
Projets : projets de transformation data (nouvelle plateforme data GCP, CRM personnalisé, refonte de la segmentation, refonte des reportings)
Vous serez le garant de la qualité des éléments fournis. Vos travaux feront bouger les lignes et vous saurez les présenter avec impact, restituer simplement des travaux complexes, mettre en avant la valeur pour nos clientes et nos marques.
PROFIL :
Nous recherchons avant tout une personnalité pour compléter l’équipe et venir grandir avec nous.
Vous êtes :
Issu(e) d’une formation spécialisée en Statistiques / Analyse de données / Data Mining / Big Data
A l’aise avec SQL, R, Python, Excel et pourquoi pas Big Query ou souhaitez justement gagner en compétences sur ces outils
Réactif(ve), rigoureux(se), proactif(ve) et doté(e) d’un bon esprit d’analyse et de synthèse
Curieux(se), vous aimez la data et avez une appétence pour le digital, l’e-commerce, les problématiques CRM, marketing et expérience client
Vous avez un bon esprit d’équipe : vous cherchez des collègues dynamiques, un management qui vous guidera et avez envie de travailler dans une ambiance saine, fun et transparente
Envie de faire partie de la team ? Alors envoyez nous votre candidature !
Cette offre est ouverte aux personnes en situation de handicap."
Paris 18e (75),42 000 € par an,,DATA SCIENTIST-ENGINEERS,Axance,- Paris 18e (75),"MISSIONS
LES MISSIONS DU Data scientist-engineer
Vous prendrez en charge le développement d’algorithmes de Machine Learning pour nos
clients et sur nos projets internes,
Vous explorerez et structurerez diverses sources de données afin de les exploiter pour
des traitements de Machine Learning ou des rendus visuels,
Vous assurerez le déploiement du code livré à toutes les étapes de la production d’une application (du POC à la mise en production),
Vous devrez être curieux et flexible au regard des architectures et environnements proposés, nous travaillons aussi bien sur Hadoop/Spark que sur AWS (architecture S3, lambda), ou des environnements Python/R voire ELK),
Vous assurerez la documentation et la qualité du code livré,
Vous participerez aux séances R&D du pôle Data,
Vous devrez être force de proposition dans nos projets internes et auprès de nos clients.
Notre environnement technique
LE CADRE DU Data scientist-engineer
Développement : Python (Scala/PySpark, Pandas, Sklearn, NumPy, TensorFlow/Keras).
Technologies Big Data : Hadoop, Yarn, Spark, Pig, Morphline.
Traitement et manipulation de données : S3, SQL, CSV, JSON, Parquet.
Base de données NoSQL (MongoDB, Elasticsearch, Hive, HBase).
Architectures Big Data : Hadoop, ETL.
Outils : Jupyter/IntelliJ, Git, Docker, Zepelin.
Algorithme : Machine Learning (MLlIb), Deep Learning, Apprentissage (supervisé, nonsupervisé, semi-supervisé).
NOS PROJETS
LES CHALLENGES DU DATA SCIENTIST-ENGINEER
Concernant nos projets, nous privilégions les réels challenges techniques et fonctionnels.
Parmi nos clients nous avons la chance de compter : La FNAC, Darty, Ditto Bank by Travelex, AirLiquide, Accor, OUI.sncf, Carrefour, Adecco, Le Conseil National des
Barreaux, et bien d’autres.
La confiance qu’ils nous accordent nous permet de mettre en place les technologies les plus récentes et portées par la communauté, d’implémenter les architectures les plus adaptées à leurs besoins et de réaliser avec beaucoup de liberté les choix techniques les
plus avancés.
LE POSTE
LES DéTAILS DU POSTE
Temps de travail : Temps plein.
Rémunération : à partir de 42 k€ + Tickets restaurant + 50% titre de transport.
Début : Dès que possible
PROFIL
LE DATA SCIENTIST-IDéAL…
De formation Bac+5 en informatique, Big Data, Data Science, Statistiques, Machine Learning ou Mathématiques appliquées, tu sais faire preuve de rigueur et d’esprit d’analyse, tu es réactif et as le sens de l’écoute et du travail d’équipe.
Tu souhaites prendre part à des projets variés et innovants, dans un environnement Big Data
/ Data Science afin de progresser techniquement et prendre part au démarrage de divers projets.
De plus, tu sais prendre du recul sur tes réalisations et celles de tes collègues, ainsi que proposer et mettre en place des améliorations.
Nous recherchons des personnes ayant déjà 2/3 années d’expérience en Big Data / Data Science et qui ont l’envie d’intervenir sur des projets ambitieux et de partager leur passion.
Alors si tout ceci te correspond, si tu souhaites progresser et produire, apprendre et partager, rejoins-nous !
À PROPOS
Axance Technology, est l’équipe experte en technologie d’Axance. Au sein d’un collectif de 350 professionnels experts du digital, nous imaginons et concrétisons des produits & services performants dans la durée aux côtés de designers, product owners/managers et d’experts data.
Notre engagement ? Agir positivement sur la transformation de la culture et de l’organisation de nos clients par la transmission de nos savoir-faire.
L’agilité et les bonnes pratiques de développement sont au cœur de notre ADN, que nous intervenions au sein des équipes de nos clients ou en feature teams depuis notre studio parisien."
Paris (75),CDI,,Data Scientist (F/H),Calypse Consulting,- Paris (75),"s
Traiter les données, structurées ou non structurées
Contrôler la qualité des données, détecter des patterns, des outliers
Proposer et mettre en pratique les modèles statistiques (régressions…) ou de datascience (machine learning…) pour répondre à des enjeux métier
Collaborer avec les équipes technique et métier pour définir les besoins et expliciter les résultats
Restituer les résultats (rapports, présentations…)
Mettre en œuvre et développer des algorithmes et des outils en Python ou R, en vous appuyant sur les librairies statistiques et de datascience associées

Profil
Expérience d’au moins 2 ans sur des fonctions similaires
Connaissances en Biologie Computationnelle et Statistique
Expérience avec R, MatLab ou/et Python
Anglais oral obligatoire
Bac+5 minimum
Capacité d’autonomie et doit être orienté solution

Vous aspirez à une progression rapide de carrière ?
Devenez Data Scientist chez Calypse ! Ainsi, vous profiterez de :
Notre réseau d’industries de santé
Formations sur mesure
Un accompagnement personnalisé (missions adaptées et évolutives)
Calypse est une aventure entrepreneuriale depuis 2015. Notre objectif est de redéfinir avec vous le métier Data Scientist de demain (C’est vrai que c’est ambitieux mais on y croit vraiment !)."
Nanterre (92),"Temps plein, Intérim, CDD",,Data Analyste (H/F),AXA FRANCE,- Nanterre (92),"Dans le cadre de sa campagne d'Alternance, AXA recrute un Data Analyste (H/F) en Alternance.

Au sein de l’équipe « Data et outils connaissances clients » et sous la responsabilité de votre tuteur, vos missions seront les suivantes :

Contribuer à la construction d’une vision 360 client et notamment de l’information de la multi-détention en produits.
Vision prédictive du client « best next offer » : prédire ce que le client pourrait souscrire à un produit.
Développement d’algorithmes d’optimisation et prédictifs sur la connaissance client.
Construction d’indicateurs (détention, multi-équipement, rétention, résiliations, Cycle de vie, ...).
Segmenter les usages et les moments de vie de nos clients.
Enrichir nos bases clients par des données issues de l’open data.
Générer automatiquement des tableaux de bord pour les force de ventes.
Participer aux travaux de réflexion sur les techniques novatrices de Machine Learning et de Big Data.
Partage de connaissance au sein de l’équipe mais également.
Qualifications
Vous souhaitez réaliser une Alternance au sein d’AXA et vous préparez un Master avec une spécialité en Data Science.

Vous avez des connaissances en Data science : machine learning (Arbres de décision, boosting, Séparateurs à vaste marge, Forêts aléatoires…), traitement et analyse de données (classification, text mining).
Vous maîtrisez SAS, SQL SERVERNET, C#, R, Python.
Vous avez une capacité d’analyse et de recherche.

Si vous êtes une personne curieuse, dynamique, autonome, rigoureuse, Rejoignez-nous !

Poste basé : Nanterre
Durée de l'Alternance : 12 Mois
Contrat Privilégié : Apprentissage
Rythme souhaité : Jour
Date de début : Septembre 2020


A propos d'AXA
Aimeriez-vous vous lever chaque jour motivé(e) par une mission inspirante et travailler en équipe pour permettre de protéger les personnes et leurs proches?
Chez AXA nous avons l’ambition de mener la transformation de notre métier. Nous cherchons des personnes talentueuses ayant une expérience diversifiée, qui pensent différemment, et qui veulent faire partie de cette transformation passionnante en challengeant le statu quo et faire d’AXA – marque globale leader et une des sociétés les plus innovantes dans notre secteur – une entreprise encore plus performante et responsable.
Dans un monde en perpétuelle évolution et avec une présence dans 64 pays, nos 165 000 salariés et distributeurs privilégiés anticipent le changement pour offrir des services et solutions adaptés aux besoins actuels et futurs de nos 107 millions de clients.

Pourquoi nous rejoindre ?
Victime ou témoin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination à : service.discriminations@axa.fr"
Paris (75),"Temps plein, CDI",,Data Scientist H/F,AI & DATA,- Paris (75),"A.I.D recherche aujourd'hui des DataScientist expérimentés ( 2 ans d'expérience minimum) avec une appétence pour le Big Data.
Nos consultants aident les entreprises à tirer le meilleur parti des données, à mettre en place des solutions opérationnelles, à identifier et mettre en œuvre les projets liés à la transformation digitale.
Il s'agira d'intégrer notre Pôle DATASCIENCE, constitué d'une trentaine de Data Scientists.
Sur ce poste, vous serez amené à intervenir pour de grandes entreprises sur des projets à forte valeur ajoutée :
Vous aurez en charge des études menées le plus souvent pour des besoins marketing et CRM (fidélisation, recrutement, attrition, appétence, valeur client, performance commerciale… ) en réalisant :
*= > segmentations, scorings, études de comportement clients, mesures de performance, estimations de potentiels, analyses d’association de produits, des traitements d’enquêtes, etc.
Vous traiterez des données variées : vie des contrats, données d’achat / de consommation, actions et réactions de marketing direct, réclamations client, utilisations des sites web et applications mobiles.
Sur opportunité de mission, vous pourrez monter en compétences sur les outils de Big data analytics et l’analyse des parcours clients
AID, partenaire de nombreuses grandes entreprises françaises depuis plus de 40 ans, est une entreprise innovante qui utilise des technologies récentes. Vous collaborerez avec des data scientist et des data manager.
L’AID Academy vous fera bénéficier de ses formations les plus innovantes, et vous serez amené vous-même à animer des séminaires ou formations pour nos clients ou collaborateurs.
De formation supérieure en statistiques et mathématiques , vous justifiez d’au moins 2 année d’expérience acquise dans le traitement des données et les études statistiques, idéalement en société de services, dans un département de type « connaissance client » ou R&D.
Vous avez impérativement déjà pratiqué la programmation R (dont R* shiny) et PYTHON* ( idéalement d’autres logiciels comme SPSS Modeler, SAS, JMP).
Vous maîtrisez le requêtage en SQL.
Une première expérience avec les technologies Big data [spark (sparkr-sparklyr,Pyspark), hadoop, hive] ou des méthodes d’analyse de séquences serait un plus.
Vous souhaitez vous investir dans des projets challengeants, monter rapidement en compétences, avec la possibilité de gagner en responsabilités, ce poste n'attend que vous.
La société est depuis quelques années en pleine croissance et cultive son esprit start up et son ambiance conviviale. Baby foot, table de ping pong, workshops internes et afterworks font partie de nos rituels d'entreprise.
Vous baignerez alors dans un environnement de travail idéal pour développer votre créativité et prendre des initiatives.
Je vous invite à consulter notre site et nos réseaux sociaux (Cf ci-dessous) et à revenir vers moi pour échanger sur nos opportunités .
www.aid.fr
Type d'emploi : Temps plein, CDI
Expérience:
data scientist h/f ou similaire: 1 an (Souhaité)"
Boulogne-Billancourt (92),"Temps plein, Stage",,Stage Data Scientist,Reezocar,- Boulogne-Billancourt (92),"Reezocar est une start-up « made in France » qui facilite la recherche et sécurise l’achat de voitures d’occasion en France et en Europe grâce à un site qui regroupe plus de 8 millions d’annonces (Rien que ça !).
En à peine 5 ans, la société a réalisé plusieurs levées de fonds et compte déjà des milliers de clients. Notre forte croissance nous a permis de doubler nos effectifs chaque année: aujourd’hui nous sommes 90 collaborateurs dont la moyenne d’âge tourne autour des 30 ans.
REEZOCAR a remporté le prix de la meilleure startup lors du challenge de Sofinco, concours ouvert aux entreprises innovantes de moins de cinq ans.
A taille humaine, il fait bon vivre dans ces locaux dotés de deux grandes terrasses avec une ambiance et un cadre de travail unique (BBQ sous le soleil, ptit déj, activités team building).
Travailler chez REEZOCAR c’est intégrer le leader du marché de voitures d’occasion de demain et c’est vivre une aventure incroyable aussi bien professionnellement que personnellement !

« Les records sont fait pour être battus ! »
Alors si tu acceptes, nous te proposons de battre les records de tout Data Scientist.
En tant que Data Scientist, tu auras pour missions :
D’analyser les données à l’aide d’outils statistiques et de Machine Learning
D’étudier le marché européen des véhicules d’occasion
D’identifier les flux d’utilisateurs
De mettre en corrélation les données reçues
De créer des typologies de profil d’utilisateur présent sur notre site internet
De produire des rapports et visualisations pour nos « super » clients

Pour savoir si tu es le « Einstein » des Datas Scientists : Tu pratiques plusieurs « framework » tels que Panda, Numpy, Scikit, Python, Spark ? Tu aimes travailler sur des machines de guerre ? Tu es prêt à travailler dans une start-up unique ?
Nous recherchons un(e) passionné(e) d’analyse de la data. Si tu souhaites pouvoir travailler sur des projets unique en tant que data scientist dans une structure en pleine expansion et acquérir d’avantages de responsabilités.
Nous adorons notre job et nous aimons travailler avec des personnes smarts et autonomes qui viennent avec plaisir au bureau tous les jours. #happinessatwork
Chaque jour est un nouveau défi chez Reezocar et chaque jour est une nouvelle occasion d’apprendre."
La Défense (92),Stage,,Stagiaire Data Scientist – Economic Advisory (H/F),Deloitte,- La Défense (92),"Stage long (6 mois) à pourvoir dès que possible

L'activité Financial Advisory de Deloitte accompagne ses clients dans la réalisation de leurs projets stratégiques en vue d'améliorer leurs performances financières et organisationnelles. Ainsi, vous intervenez auprès de nos clients nationaux et internationaux présents dans les secteurs de l'industrie, des services, des institutions financières ou des fonds d'investissement sur des opérations de fusions-acquisitions, de restructuration, de conseil financier, de due-diligence, d'évaluation, de gestion des litiges et d'audit de fraudes.

L'activité Economic Advisory de Deloitte regroupe une solide équipe d'économistes et de data scientists issus du cabinet d'expertise économique Microeconomix. Les missions traitées pour nos clients concernent une grande variété de travaux d'analyse économique et d'analyse de données appliquées au monde de l'entreprise : nos économistes interviennent en tant qu'experts dans d'importants dossiers du droit de la concurrence (opération de concentration, cartel, abus de position dominante), en matière d'évaluation des préjudices économiques, sur des sujets de régulation sectorielle et de modélisation des industries de réseau ainsi qu'en matière d'économétrie et de data science appliquées aux stratégies d'entreprises.

En rejoignant l'équipe Deloitte Economic Advisory, vous interviendrez en tant que Data Scientist lors de missions de conseil ou d'expertise économique appliquées aux stratégies d'entreprises.

Au sein d'une équipe dynamique et en forte croissance, vous serez amené(e) à :
Proposer des solutions innovantes de traitement de données, de modélisation et de visualisation dans le cadre de missions de conseil en stratégie ;
Utiliser les outils et techniques d'analyse quantitative de données, des statistiques et de l'économétrie appliquées aux problématiques de l'entreprise ;
Concevoir et déployer des interfaces de visualisation, de reporting et d'aide à la décision ;
Elargir vos horizons professionnels en travaillant en France et à l'étranger au sein d'équipes pluridisciplinaires réunissant des spécialistes en provenance de nombreux pays.
Votre parcours :
En rejoignant Deloitte, vous aurez l'opportunité de développer un set de compétences, partagées avec notre réseau international, et structurées autour des dimensions suivantes : leadership, métier et spécialité. Grâce aux missions variées auxquelles vous participerez et au programme de formations proposé, vous pourrez renforcer progressivement ces compétences, en acquérir de nouvelles et progresser ainsi au sein de notre firme.

Votre Profil
Etudiant(e) en dernière année d'une grande école ou d'un Master 2 mathématiques appliquées / statistiques avec une spécialisation en data science, vous maîtrisez le langage R et les principaux packages pour l'analyse de données (i.e. tidyverse) et êtes motivé(e) par le développement d'outils d'analyse plus puissants (e.g. création de packages, Shiny apps, etc.).
La maîtrise d'autres langages (Stata, Python, SAS) est un plus.
Vous êtes rigoureux(se), organisé(e), autonome et d'un naturel curieux.
Vous appréciez le travail en équipe.
Vous parlez et rédigez couramment en anglais et en français."
Levallois-Perret (92),"Temps plein, CDI",,Senior Data Scientist H/F - CDI (Levallois/Corte),Jellysmack,- Levallois-Perret (92),"Jellysmack est une entreprise spécialisée dans la création de contenus vidéos originaux sur les réseaux sociaux. Avec plus de 3 milliards de vues par mois, Jellysmack a connu une ascension fulgurante, ne cesse de grandir et ambitionne de devenir le leader mondial dans son domaine. La recette de ce succès repose sur la qualité de nos contenus, mais aussi sur la technologie opérant en arrière-plan. Jellysmack a développé une suite d'outils propriétaires, propulsés par l'IA, permettant à nos équipes de contenu de publier, s'inspirer, comprendre la trend, analyser les résultats, mais bien plus encore, des outils qui analysent le contenu en ligne, les réactions des gens devant ce contenu, et déterminent ce que sera la tendance demain.
Après plus de 2 ans de développement technique, Jellysmack propose une technologie unique articulée autour de 3 produits qui visent à optimiser la création et la distribution sociale de vidéos.
L'équipe Tech œuvre pour la mise en place d’outils utilisés en interne par les équipes contenu afin de déterminer les sujets qui buzzent, les aider dans la création de contenu, suivre les performances des vidéos internes etc... en injectant dans chacun de ces produits une dose conséquente d’algorithmie, de statistiques et de machine / deep learning.
En lien direct avec le Head Of Data (basé en Corse), vous serez amené à travailler sur différentes problématiques - prioritairement axées autour du NLP - et sur des projets de taille très différentes, impliquant d’importantes quantités de données (plusieurs centaines de millions de vidéos stockées en base à date avec leur métadata textuelles, plus de 21 milliards de commentaires...).
Au sein d’une équipe de sept data scientist, vous serez le référent de l’équipe sur ces sujets d’analyse et de compréhension du langage et vous aurez un rôle consultatif.
Missions principales
Passer d'une problématique métier à un algorithme de data science
Passer d'un POC à un algorithme en production
Vulgariser un algorithme et être référent de l'équipe Data Science
Etre autonome sur les outils comme Git, avoir déjà travaillé sous docker - idéalement sous AWS
Quelques exemples de sujets :
Analyse de sentiments sur les commentaires des vidéos
Extraction de topics à partir des titres, descriptions, commentaires des vidéos
Catégorisation de vidéos en thématique à partir de l’ensemble des éléments textuels dont nous disposons
Génération automatique de titre/tag de vidéos...
Création d’un algorithme d’identification des meilleurs créateurs sur une thématique donnée
Analyse de vidéos (contenu et metadata) pour mieux comprendre la rétention des utilisateurs
Optimisation de coût sur l’acquisition de fans
Génération automatique de montage de vidéos...
Profil recherché
Docteur en computer science ou diplômé d’une maîtrise en data science, vous disposez d’au moins 5 ans d’expériences,
De l'autonomie vous sera demandée sur le passage en production d’algorithmes,
Vous êtes pédagogue sur la transmission de votre savoir,
Vous avez un très bon niveau de SQL (MySQL et PostgreSQL).
Avantages :
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
senior data scientist h/f - cdi (levallois/corte) ou similaire: 4 ans (Souhaité)"
Paris (75),CDI,,Data Scientist h/f- Paris- Cdi,Robert Half France,- Paris (75),"A propos de notre client
Notre client est une start-up made française de 90 collaborateurs.
En 5 ans, ils ont réalisé 3 levées de fonds dont la dernière d'environ 10 millions en 2018.
Cette startup a développé une solution « clé en main » facilitant la recherche et sécurisant l'achat de véhicule d'occasion en France et en Europe.
Ils répertorient 8 millions d'annonces de vente de véhicules d'occasion sur leur plateforme et propose la seule solution positionnée 100% côté acheteur.
Travailler pour notre client, c'est intégrer le leader du marché de la voiture d'occasion et vivre une aventure incroyable aussi bien professionnellement que personnellement !
Missions
En tant que Data Scientist, vous aurez pour missions :
D'analyser les données à l'aide d'outils statistiques et de Machine Learning
D'étudier le marché européen des véhicules d'occasion
D'identifier les flux d'utilisateurs
De mettre en corrélation les données reçues
De créer des typologies de profil d'utilisateur présent sur notre leur internet
De produire des rapports et visualisations
Profil du candidat
Formation et compétences
Le/la futur(e) Data Scientist devra être un(e) expert(e) de Python et ses modules : Panda, Numpy et Scikit. La maîtrise d'autres frameworks est un plus.
3/4 années d'expérience sont requises pour ce poste.
Ils sont à la recherche de passionné(e)s de la data désireux d'apprendre et d'apporter leur expertise à l'équipe Data.
Avantages et conditions
Salaire : 50k annuel brut"
Paris 2e (75),CDI,45 000 € - 50 000 € par an,Data Engineer,HireFirst,- Paris 2e (75),"Le client final
- Plateforme spécialisée dans l’estimation immobilière, plusieurs produits sont développés (cartes, indices d’évolution, estimations, analyse de l’offre et la demande … - 240 personnes en tout, 50 personnes en R&D, dont une équipe dédiée à la recherche et la modélisation. - 2 équipes Data : Data scientist/chercheurs et Data engineer.
Votre mission
En tant que Data engineer vous intégrez une équipe de 5 personnes. Vous travaillez avec des Data scientist orientés recherche et optimisation algorithmique. (Chacun a son domaine : économétrie, mathématiques, machine learning, computer vision etc…) sur les moteurs de modélisation du marché de l’immobilier. De votre côté, votre rôle sera de : - Fournir des données propres et de qualités aux Data scientists - Concevoir puis industrialiser les modèles - Créer des pipelines de données pour le traitement automatique de grosses volumétries de données
Votre profil
- Une expérience en tant que Data engineer - Bonnes compétences en Python et dans le traitement de grosses volumétries de données - Des compétences en en dataviz et/ou en cartographie seront aussi appréciées
Environnement technique
- Python (Celery, Numpy, Scipy et Pandas, ...) - PostgreSQL - PostGIS - Couchbase - Redis - Docker - Grafana"
Châtillon (92),"Temps plein, CDI",,DATA SCIENTIST H/F,Groupement Les Mousquetaires,- Châtillon (92),"Un plan de transformation ambitieux est lancé au sein du Groupement des Mousquetaires avec un horizon de 5 - 7 ans. Ce plan se compose d’un ensemble de programmes stratégiques et de projets qui touchent l’ensemble du système cœur de métier des enseignes. La Data est un programme à part entière de ce plan transformation et est piloté par le département Data Lab de la Stime que vous intégrerez.
En effet, le Data Lab a la responsabilité de l'ensemble des projets BI et Data pour les enseignes et les fonctions d'appui du Groupement (Intermarché, Netto, Supply Chain, Immo Mousquetaires, ...)

En tant que Data Scientist, vos missions principales seront de :
Structurer et piloter la montée en compétences analytiques et data science au sein du Groupement
Fournir des recommandations stratégiques et prédictives permettant aux différentes Directions du Groupement sur la base du patrimoine de données existantes, et son croisement éventuel avec des données externes afin de mieux tirer les enseignements des actions réalisées : performances passées, facteurs d’influence et d’affiner leurs choix stratégiques et leurs tactiques commerciales
Construire des services à valeur ajoutée en s’appuyant sur les algorithmes et traitements Data à l’état de l’art, ou sur des développements spécifiques internes

Autres missions:

Participer à la structuration et au pilotage de l’équipe Data Science, dans le cadre défini par le Data Lab : interactions avec les autres directions, méthodes et outils, ressources clés à mobiliser (data miners, data analysts, data scientists), choix d’internalisation ou d’externalisation des activités et algorithmes :

Cadrer les priorités des projets en cohérence avec les priorités des Directions des enseignes et des fonctions d'appui du Groupement :
Identifier les données disponibles - internes et externes, amont et aval – pour réaliser les analyses, et s’assurer du développement des outils adaptés au SI du Groupement
Etre force de proposition sur les situations où les analytics peuvent créer de la valeur pour les directions (études de prix, client, assortiments, digital), et leur proposer des analyses, et produits répondant à leurs enjeux
Cadrer les analyses (modèles d’analyses, visualisation des analyses….), piloter leur réalisation et contrôler leur qualité et pertinence au regard des enjeux des Directions
Participer au maintien en compétences de l’équipe Data Science : veille technologique, formations internes
Contribuer au déploiement une stratégie de gouvernance de la donnée
Accompagner la transformation digitale de l’entreprise
Cartographier la Data disponible et organiser les stratégies de collecte
Assurer et organiser l’accès aux données produites par l’équipe Data Science
Profil candidat
Niveau d'étude min.
Requis :
Bac + 5
Formation / Diplôme :
6 - MASTER 2
Expérience Requise :
de 5 à 7 ans
compétences techniques:
Analyses stratégiques
Analyses quantitatives/ statistiques
Data mining, Machine Learning et IA
Compétences Big Data (Spark, Python) et SQL
Data visualisation (Power BI,MicroStrategy…)
Profil:
Force de proposition,
Rigueur,
Réactivité,
Esprit analytique et de synthèse,
Aisance rédactionnelle,
Bon relationnel,
Sens de l’organisation."
Paris 10e (75),,,Data Analyst & Insights @ Paris 10 H/F,TRANSACTION CONNECT,- Paris 10e (75),"Description de l'entreprise
Transaction Connect est une start-up éditeur d'une solution omnicanale de connaissance et d'engagement clients pour les retailers basée sur les données de paiement on et offline, les technologies de l'open banking et le machine learning.
Grâce à nous, les clients des enseignes bénéficient d'une expérience shopping fluide et sans carte de fidélité, leur permettant d'être automatiquement récompensés lorsqu'ils paient avec leur moyen de paiement habituel. Fini les cartes de fidélité qui encombrent leur portefeuille et les frictions lors du passage en caisse magasin.
Nous avons a été fondé en 2016 avec un modèle économique solide qui nous a permis d'être à l'équilibre économique fin 2017. Nous sommes agréé par la Banque de France depuis 2018 et régulé par l'Autorité Bancaire Européenne.
Repéré par ELAIA en 2019 avec une levée de fonds de 1,5M d'euros, nous nous lançons à la conquête de l'Europe puis de l'Amérique du Nord.

Description du poste
Nous recherchons un(e) Data Analyst pour rejoindre notre équipe Data Insights qui a pour objectif de faire parler la donnée et faciliter les prises de décision de nos clients (shopping centers et retailers) sur leur programme de fidélité et les comportements d'achats on et off line des consommateurs. Tu travailleras de concert avec nos customer success managers, en charge de la relation avec nos clients et nos data scientists.

Ton terrain de jeu / challenges :
Comprendre le besoin de nos clients et les traduire en analyses tracking, reporting et analytics pertinents
Mettre en place des KPIs et des analyses à retranscrire sous forme de datavisualisation pour améliorer la connaissance des clients et l'amélioration continue de leurs objectifs commerciaux (programme de fidélisation clients)
Faciliter les prises de décisions des clients au travers de tes recommandations et optimiser les usages de la solution retail tech que nous éditons
Réaliser des analyses ad hoc provenant de clients ou d'équipes internes
Partager au sein des équipes internes (CSM, Sales, Operations, Data, Product) les best practices en BI, analyse et dataviz, faire progresser les pratiques internes
Développer et automatiser une suite d'analyses relatives à la fiabilité des données, aux sales opérations et aux data insights (segmentation, audience, performance de leur programme / campagne de fidélité, frein à la conversion, churn, tendances et insights consommateurs)
Développer des reportings et des dashboards utilisables et compréhensibles par nos clients, quel que soit leur niveau d'expertise ou de technicité ;
Démocratiser et donner du sens à la donnée pour l'ensemble de tes interlocuteurs et utilisateurs
Participer à l'évolution des analytics et reportings proposés à nos clients.
Tu es capable de t’intégrer à une équipe pluridisciplinaire, à la fois sur des projets opérationnels et stratégiques. Tu es reconnu par tes pairs pour ta prise de hauteur tout en portant une forte attention aux détails.

Qualifications
Bac+5 ou équivalent (business, mathématique ou école d’ingénieur)
Au moins 2 ans d’expérience en BI, data analyse, datavisualization acquise dans la practice data d’une ESN ou en cabinet de consulting spécialisé en data
Tu disposes de compétences solides en SQL et une bonne pratique de l’outil BI & analytique Tableau Sofware
Tu es passionné(e) par la data viz, les datas marketing et la démarche de conseil;
Tu as un fort état d’esprit analytique, une forte appétence pour les méthodologies et les chiffres
Autonome, tu as une forte capacité à synthétiser et à expliquer les analyses menées auprès de publics techniques et non techniques
Ta capacité à créer des outils automatisés d’analyse via des solutions standards du marché (Excel, Tableau & Google Analytics) est la bienvenue
Tu travailles en français et en anglais (Nous déployons de nouveaux clients en Pologne, Suède, République Tchèque, Espagne, Allemagne en 2020).

Nice to Have ""Le plus de ta candidature qui fera la différence"" :
Une appétence pour le retail (univers de nos clients)
Python / R

Informations complémentaires
Solide, nous préparons notre accélération en Europe post-Covid-19 et avons les moyens de notre ambition
Tu vas jouer un rôle capital pour la consolidation de notre offre BI / Dataviz
Un management expérimenté, bienveillant et ultra accessible
Une équipe jeune et dynamique prête à soulever des montagnes pour devenir un leader mondial
Un process de recrutement full remote, onboarding full remote et 100% friendly, c'est fou non :o) !"
Paris 9e (75),,,Data Scientist,Numberly,- Paris 9e (75),"Company Description
Numberly helps its customers collect, analyze and leverage their data across all marketing channels. To do this, we are more than 100 engineers (a quarter of Numberly) divided into teams with a human dimension, where we ensure that everyone develops a positive influence and can be autonomous. Our sustained growth forces us to constantly question our technical and organizational choices.
With seven offices worldwide and clients in more than fifty countries, our challenges are global.
Due to our wide range of interconnected products, our technical challenges are very varied and often complex. Our daily missions consist of processing thousands of requests per second, distributed throughout the world, operating databases of several petabytes (Big Data™), automating our entire bare-metal infrastructure, and building the digital marketing interfaces of tomorrow.

Job Description
Numberly is looking for an experienced Data Scientist to work on applied mathematics and machine learning projects and optimize our digital marketing campaigns. The role involves:
The creation and development of optimization algorithms
The realization of complex, big data studies for our clients
Participation in the creation and development of the group's product, especially algorithms using the richness of the data we collect (real-time behavioral data, demographic data, purchasing data, etc.)

Qualifications
Minimum of 3-5 years of relevant experience in data science role
Interested in research and measurement
Strong attention to detail, strong organization skills
Passionate about data
Strong interest in digital marketing and relationship marketing
Interest in working for a wide range of clients on advanced research subjects
Excellent machine learning and applied maths skills
Knowledge of Hadoop, Python, SQL Server, MongoDB, Matlab a plus
Strong motivation to work in a fast-growing, international company

Additional Information
Even with 500 people we like to spend time together!
Participate to “Happy Meetings’” where we share the Group’s news with everyone from around the world
Get to know your “Jedi Master”, your ‘go to guy’ when you arrive
Go to yoga classes, cross-training, barbecues, internal parties...
Find the most incredible fancy costume for the next party"
Paris 2e (75),,,Consultant Data Scientist (H/F) - CDI,MYDRAL,- Paris 2e (75),"Sous la supervision du Directeur Conseil, vos tâches seront les suivantes :
Animer des ateliers client
Modéliser des processus métiers / Comportements à partir des données sourcées
Créer des KPIs et Dashboards prédictifs pour le métier
Comprendre les besoins métier et proposer des solutions idoines
Mise en place des workshops sur les conclusions tirées des analyses, etc.
Participer à des projets d’enablement des projets Marketing, de création de contenus / events / webinars sur des sujets liés à la Data ;
Utiliser des outils tels que Tableau ou DataRobot ;
Développer des algorithmes et des régressions logistiques de Machine Learning ;
Participer à l’élaboration, au développement, au test et à l’optimisation des modèles de prédiction et de recommandation ;
Utiliser des méthodes ML adaptées aux grosses volumétries (out-of-core online learning.) ;
Participer à l’intégration des algorithmes au sein d’applications dites d’Intelligence Artificielle (DataRobot) ;
Participer à des projets clients avec un binôme ou en groupe.

Passionné de la Data et diplômé d'un BAC+5 en Ecole d’ingénieur (EISTI, Polytech, Télécom Paristech, MIAGE, etc.)
Expérience d’au moins 3 ans (hors stage et alternance) sur Tableau Software avec de fortes compétences en modélisation (Analyse de données, modélisation statistique…) et réalisation d’applications décisionnelles.
Vous avez de bonnes connaissances techniques sur les outils de Data Preparation, de Data Science, de Stockage de la donnée et de Data visualisation, etc.
Vous avez développé un fort sens du service, un bon relationnel avec vos clients et la rigueur nécessaire au succès de vos projets.
Qualités indispensables pour réussir chez Mydral : smart, réactif, autonome, rigoureux, fiable, organisé et SYMPA !
Vous vous reconnaissez dans cette description ? Oui ?! Nous avons une place pour vous !"
Paris (75),,,Data scientist (h/f) - Paris,Maisons du Monde,- Paris (75),"Le programme data du groupe Maisons du Monde a presque quatre ans déjà, et se compose d’une trentaine de personnes (data scientists, data analysts, data engineers, web analysts). Les cas d’usages à développer vont du marketing digital (CRM, acquisition trafic, personnalisation/recommandation) à la supply chain, avec une activité R&D sanctuarisée.
L’infrastructure data, développée dans l’équipe, est basée sur Google Cloud Platform. Les résultats sont là : nous sommes mis en avant par les équipes Google quant à l’usage de leurs outils cloud !
Dans une ambiance jeune et dynamique, où le travail d’équipe est mis en valeur, nous recherchons un(e) Data Scientist pour travailler sur toutes les problématiques liées à la supply chain.
Vous participez activement à la vie de l’équipe en collaborant étroitement avec les data scientists, data engineers et data analysts. Les missions seront variées (structuration de la chaîne Big Data, Dashboarding, Analyse Ad Hoc, R&D sur le Machine Learning) et demandent une grande rigueur.

Missions :
Vous êtes impliqué(e) dans l’engagement de l’équipe au quotidien et faites tout pour l’aider pour délivrer des fonctionnalités en continue ;
Vous travaillez en étroite relation avec notre responsable data science pour aider à la création des algorithmes nécessaires pour les cas d’usages développés pour les équipes métier ;
Vous mettez en place les nouveaux flux d’entrée et de sortie au sein de la plateforme data, et irez jusqu’au modeling et à l’activation de la donnée ;
Vous assurez le delivery, et êtes constamment en veille sur les nouvelles technos.
Environnement Technique
Google Cloud Platform ;
Big Query, SQL-like, Dataflow ;
Python ;
ML & DL, Tensorflow ;
Docker, Kubernetes, Airflow ;
Qlik Sense ;
Et tout autre outil que vous jugerez pertinent !
Poste basé à Paris, 55 rue d'Amsterdam (8ème)

De formation supérieure en école d’ingénieur/université (niveau Bac+5 ou plus), vous possédez au minimum une première expérience professionnelle (stage/alternance acceptés) dans un programme data.

SAVOIR-FAIRE
Vous avez déjà appliqué les technologies Big Data en production sur de fortes volumétries de données. Vous maitrisez le développement en Python ;
Vous avez la capacité à maintenir la chaîne Big Data, de la récupération de la donnée jusqu’à son exploitation finale ;
Une bonne culture des problématiques liées à la supply est un plus (lead time, taux de rupture, …)
SAVOIR-ETRE
Vous avez l’esprit d’équipe et êtes impliqué(e) dans votre travail au quotidien ;
Vous êtes curieux (se), rigoureux (se), structuré(e) ;
Vous avez hâte de proposer des améliorations, les partager et les prioriser avec vos collègues ;
A l’externe, vous participez à des évènements de l’univers Big Data (meetups, conférence, etc.)."
Levallois-Perret (92),"Temps plein, CDI",45 000 € - 70 000 € par an,Data Scientist H/F,AGYLL SAS,- Levallois-Perret (92),"Description de l'entreprise
La société, rattachée à un grand groupe de plus de 20.000 collaborateurs, possède et conduit des analyses sur la plus puissante (et unique) base de consommateurs représentatifs de la population française. Cette dernière fait partie du top 3 des bases consommateurs omnicanales les mieux qualifiées au monde.
Les services et accompagnements proposés permettent notamment aux Marques de :
A partir de leurs données internes, d’approfondir le profil de leurs clients ou prospects à partir de données de consommation qu’elles ne possèdent pas, et donc de communiquer de façon plus pertinente et adopter une démarche bien plus proactive
Accéder à des études et programmes consommateurs permettant de développer la stratégie de conquête ou de fidélisation, tout en optimisant le ROI des campagnes
Analyser, prédire, approfondir des comportements de consommation, mener des campagnes d’acquisition sur des cibles appétentes aux produits et/ou services de la Marque
Description du poste
Dans le cadre du renforcement de l’équipe DBA & Analytique, la société recherche un profil Data Scientist pouvant répondre aux missions et avec les compétences décrites ci-après. Vous souhaitez travailler sur des volumes de données et des approches analytiques très riches, participez à une aventure où votre contribution sera à l’origine des orientations de demain, aimez les challenges et être acteur de vos propres démarches analytiques et pas seulement spectateur, alors ce poste est fait pour vous !
PRINCIPALES MISSIONS
· En adéquation avec les orientations stratégiques, réflexions la Stratégie de Connaissance Client 360° et le déploiement des démarches analytiques
· Développement de la Customer Intelligence : mise en place de profiling, segmentations/classifications, scoring et de façon plus générale, toute approche mathématique/statistique valorisant la richesse des informations disponibles et mettant en avant des leviers business différenciant
· Développement de la Business Intelligence : alimentation et enrichissement d’outils ou interfaces dédiée aux insights analytiques à destination des opérationnels et décisionnaires – incluant l’activité de comptages et sélection de cibles appétentes
· Activité de R&D via l’exploitation de techniques avancées et innovantes
PROFIL RECHERCHE / COMPETENCES :
· Niveau 4 ou 5ème année d’études, spécialisations statistiques/mathématiques, data science, DBA spécialisé ou tout autre formation ad hoc
· 3 ans d’expérience professionnelle minimum
· Aptitude à comprendre et « jongler » avec de grosses bases de données, avec une sensibilité « business oriented »
· Customer Intelligence : expérience en modélisations statistiques (scoring, classification, etc.), méthodologies descriptives et prédictives. Les approches par IA et analyses sémantiques seraient un plus
· Business Intelligence : expérience en alimentation de solution de data visualisation & reporting
· Compétences techniques : déploiement de scripts SQL (PostgreSQL impératif, MySQL, SQL Server…), Python, R, solutions d’Analytics et tout autre outil nécessaire au data management et aux analyses statistiques avancées
· Aptitude à vérifier, confronter, consolider, sécuriser les résultats des analyses et KPIs produits avant tout déploiement
· Esprit d’équipe, curiosité, réactivité, autonomie et force de proposition
· Fort intérêt pour les nouvelles technologies et les innovations
CONDITIONS :
Contrat en CDI
Salaire selon profil
Localisation - Paris (Pont de Levallois)
Industrie : Médias et communication
Type d'emploi : Temps plein, CDI
Salaire : 45 000,00€ à 70 000,00€ /an
Expérience:
data scientist h/f ou similaire: 3 ans (Requis)
Télétravail:
Oui"
Boulogne-Billancourt (92),"Temps plein, CDI",,Docteur R&D – Intelligence Artificielle / Data Scientist – REZ,RD2 CONSEIL,- Boulogne-Billancourt (92),"RD2 Conseil est un cabinet de recrutement spécialisé sur la recherche de jeunes docteurs pour les besoins en R&D des PME innovantes et entreprises privées, souhaitant se doter de compétences scientifiques pointues et de réelles ressources humaines en matière d’Innovation.
Nous recrutons actuellement un(e) Docteur (H/F) en Data Science / Intelligence Artificielle.
Notre client est une startup innovante basée à proximité de Paris, ayant pour activité de faciliter la recherche et sécuriser l’achat de véhicules d’occasion partout en Europe. Pour cela, elle a développé un moteur de recherche permettant d’agréger les annonces automobiles d’un grand nombre de sites européens.
L’entreprise compte 90 personnes (ingénieurs développeurs, commerciaux et conseillers) et est en forte croissance.
Dans le cadre d’un remplacement au sein de l’équipe R&D (3 personnes), en tant que Docteur en Informatique, vous mettrez en œuvre des techniques de Machine Learning et / ou Traitement Automatique du Langage (NLP) pour permettre d’extraire et fournir des informations pertinentes sur les véhicules et les utilisateurs quel que soit le site, et donc la langue (allemand, italien, espagnol…) utilisée.
Vous interviendrez par exemple sur :
La recommandation de véhicules selon les cahiers des charges et les profils des utilisateurs
L’identification des utilisateurs (et des comportements utilisateurs) à recontacter selon leurs historiques de navigation, l’analyse de leurs profils, …
Le développement d’une cote des véhicules en temps réel basée sur les données recensées par la société
Le matching des annonces avec les fiches techniques des véhicules (analyse textuelle, identification de mots clés, …)
Nous cherchons un candidat disposant en particulier des compétences suivantes :
De formation initiale en Informatique, vous avez une maîtrise forte des méthodes d’extraction et analyse de données, en particulier au moyen d’algorithmes d’Intelligence Artificielle
Une expertise sur les données textuelles par des méthodes de Traitement du Langage Naturel / NLP sera particulièrement appréciée
Vous maîtrisez également la programmation informatique permettant de concevoir, d’’implémenter les solutions sur des données volumineuses et les tester à grande échelle (en particulier Python)
Vous êtes travailleur, avez le goût du travail en équipe et souhaitez évoluer dans un environnement startup, exigeant en termes d’investissement mais où l’ambiance est particulièrement conviviale et les possibilités d’évolution et de prises de responsabilités nombreuses.
Vous avez envie d’apprendre de nouvelles technologies et travailler sur des problématiques concrètes.
Si vous pensez être cette personne, que vous êtes titulaire d’un Doctorat et n’avez jamais été embauché en CDI après l’obtention de votre thèse (contrainte impérative pour respecter les critères du CIR), nous vous invitons à nous faire parvenir votre CV et lettre de motivation par mail sous la référence REZ.
Statut : Cadre
Type d'emploi : Temps plein, CDI
Expérience:
docteur r&d – intelligence artificielle / data scientist – rez ou similaire: 1 an (Souhaité)
Télétravail:
Temporairement en raison du COVID-19"
Courbevoie (92),,,DATA SCIENTIST,Aquila Consulting,- Courbevoie (92),"NOTRE MISSION
En tant que spécialiste reconnu, Aquila Data Enabler accompagne et conseille ses clients sur la Data Science et
l’intégration Big Data, principalement au sein des Labs R&D.
Notre positionnement est celui de la Recherche Opérationnelle. Aquila Data Enabler est une structure qui répond avec
réactivité, transparence et proximité aux besoins de ses clients en les aidant à faire les bons choix, et à les mettre en oeuvre
avec efficacité.
POSTE PROPOSE
Au sein du Lab interne d’Aquila Data Enabler, vous travaillerez sur plusieurs projets, en tant que Data Scientist
(F/H).

Vos missions seront :

ü Accompagnement des clients pour l’émergence des besoins centrés sur la donnée
ü Etude de la problématique posée, diagnostic de la situation et des données disponibles, préparation des données
ü Proposition de méthodes de modélisation des problèmes opérationnels, conception d’algorithmes de classification,
modélisation, prévision et optimisation
ü Validation des modèles, mise en place d’indicateurs pertinents, étude des résultats, recommandations.
ü Conception d’outils d’analyse et de data-visualisation

Vous aborderez des questions stratégiques et opérationnelles complexes, auxquels vous pouvez apporter des réponses grâce à
votre bagage technique (data mining et visualisation de données techniques, l'analyse graphique, l'analyse statistique, le machine
learning / deep learning, etc).

Les projets pourront être orientés en fonction de vos compétences : traitement du signal, traitement d’image, text mining, etc. Votre
challenge sera de proposer de nouvelles façons d'aborder les problèmes de nos clients par la réappropriation de leurs données.

Vous serez également responsable du pilotage de ses projets (définition de périmètre, planning et respect des délais,
coordination avec les autres départements).

De même, vous pourrez avoir des missions commerciales (réunions et présentations clients, workshop, etc) et des missions de
veille (rédaction d’articles sur les projets Aquila en cours, etc).

Cette mission est basée sur Courbevoie, à pouvoir ASAP.
VOS QUALIFICATIONS
Ingénieur Data Scientist diplômé Bac +5 / Doctorat, les algorithmes sont vos meilleurs amis et le réseau de neurones n’a plus
de secret pour vous !
Vous êtes passionné par la recherche, mais en même temps vous êtes attiré par le fait de travailler sur de vraies
problématiques opérationnelles au sein d’entreprises grands comptes.

Vous avez une première expérience en tant que Data scientist : en CDI, thèse ou stage.

Idéalement, comme outils, vous maîtrisez Python et R.

Enfin, vous avez la pêche, le smile attitude, assez pour prétendre de faire partie de l’Aquila Team !

Si vous vous reconnaissez dans cette description, n’hésitez pas à nous envoyer votre candidature, nous serons ravis de faire
connaissance autour d’un café !

ENVIE DE REJOINDRE NOTRE EQUIPE ?
Merci de nous envoyer votre CV et lettre de motivation à jobs@aquiladata.fr
Pour un traitement interne plus rapide, veuillez nommer vos documents comme suit : Prénom Nom_CV ou CL. N'hésitez pas
à ajouter tout document divers pouvant supporter votre demande. Nous veillerons à examiner votre demande et à vous
répondre dans les 48h."
Paris (75),Stage,,Stage - Data Lab AMF - Projet sur l'intelligence artificielle H/F,AMF,- Paris (75),"Informations générales

Entité de rattachement

L'Autorité des marchés financiers, autorité publique indépendante, est le régulateur de la place financière française. Nos 500 collaborateurs veillent à la protection de l'épargne, à l'information des investisseurs et au bon fonctionnement des marchés financiers.
Rejoindre l'AMF, c'est également s'ouvrir à un monde d'opportunités humaines et professionnelles. Nous avons à cœur d'accueillir, accompagner et développer les talents d'aujourd'hui et de demain.

Référence

2020-46

Votre contexte
Description du contexte

La Direction des Systèmes d’Information (DSI) compte une quarantaine de collaborateurs et organisée en unités :
Unité Data & BI : potentialisation des données des différentes directions de l’AMF à l’aide de l’intelligence artificielle. Valorisation de la donnée à travers la BI. Pilotage du Data Lab de l’AMF.
Unité Référentiels et Processus Métiers
Unité Devops Infrastructure Intégration et Sécurité
Unité Digital Workplace
Unité Outils de gestion Interne
Unité Architecture d’Entreprise
Le(a) stagiaire sera intégré(e) au Data Lab et rattaché à l’unité Data et BI.
Votre mission
Métier

Fonctions supports
Intitulé du poste

Stage - Data Lab AMF - Projet sur l'intelligence artificielle
Contrat

Stagiaires écoles
Description de la mission

Le Data Lab propose un stage de veille et prédiction pour réaliser des expérimentations en intelligence artificielle / Machine Learning avec différentes Directions de l’AMF.
Le stagiaire, avec l’aide de son tuteur (le responsable de l’unité Data & BI) et des autres data scientists du Data Lab, devra réaliser la mise en œuvre des expérimentations Proof Of Concept (POC) et/ou des Minimum Viable Products (MVP) en respectant la démarche projet en vigueur au sein du Data Lab de l’AMF.
Le stage se décline comme suit : Exploration/exploitation/mise en qualité de la donnée; Modélisations optimisées (en Python) descriptives/prédictives et NLP et/ou graph mining (optionnel : intégration dans un environnement cloud et/ou Devops); Industrialisation des modèles développés et validés par l'AMF dans un contexte Cloud et/ou Devops (optionnel); Rôle de Scrum Master sur une des expérimentations.

Profil

Etudiant(e) en école d'ingénieur avec une spécialisation en Datascience, en intelligence artificielle et/ou en statistiques/mathématiques appliquées aux datasciences.

Vous avez des connaissances en :
en développement de modèles en Python
en Devops et/ou Cloud (Azure ou AWS ou Google Cloud Plateform)
en modélisation mathématiques (apprécié)
en gestion projet innovants (Agile SCRUM, Lean Startup) (apprécié)

Vous êtes reconnu(e) pour les compétences suivantes:
Force de proposition
Organisation
Rigueur
Adaptabilité
Autonomie

Durée et disponibilité:
6 mois à partir de juin/ juillet 2020.
Localisation du poste
Localisation du poste

Ile-de-France, Paris (75)
Lieu"
Paris 15e (75),,,Data scientist,FABDEV,- Paris 15e (75),"FABDEV est une jeune entreprise innovante en forte croissance spécialisée dans le développement de solutions en Python : plateformes web complexes (API, temps réel, …), analyse de données, machine learning. Nous mettons les dernières technologies du web et du développement informatique au service de l'automatisation et de la simplification de process pour les entreprises. Python est notre langage de prédilection : il est beau, puissant, polyvalent ; et son utilisation est en forte croissance. Nous sommes deux fondateurs : Claire Protin (ESSEC 2014) et Lucas Berbesson (Supélec 2014). Parmi nos clients : RTE, Eqiom, Fabernovel, Engie, Magis-Maths, Renault, Valeo ... et d'autres à venir !
Votre poste
Nous sommes aujourd’hui à la recherche d’un Data Scientist qui nous rejoindra pour travailler sur des problématiques Data. Vous serez amené(e) à traiter des problématiques d’analyse de données, de machine learning pour nos clients grands comptes.
En terme de format et si l’exercice vous plaît, vous pourrez animer des formations et Workshops d’acculturation à la Data Science et au Machine learning.
Nous sommes constamment à l'écoute de nouveaux projets data, vous pourrez proposer de nouvelles idées, travaillerez en autonomie sur vos projets, mais serez encadrés et guider dans leur réalisation. Nos bureaux sont situés dans le 15ème arrondissement, métro Sèvres-Lecourbe/Volontaires.

Votre poste
Savoir faire du Python
Etre un Jedi en Pandas/Seaborn/Scikit-learn/Tensorflow
AWS ou Google Cloud
Etre sympa
Savoir gérer une machine linux
Aimer la pédagogie


Rémunération, attractive, selon profil.
Pour candidater merci d'envoyer un mail à claire.protin@fabdev.fr avec un lien git, un exemple de projet, ou juste quelques mots convaincants !"
Courbevoie (92),CDI,,Data Analyst H/F,DIANE CONSULTING,- Courbevoie (92),"Diane Consulting est un cabinet de conseil à taille humaine créé il y a 11 ans et spécialisé dans le domaine de la Data.
Nous accompagnons des grands groupes sur la conception, l'audit, le développement de solutions BI & Big Data: Société Générale, EDF, Arval Trading, Saint Gobain, ClearChannel, RATP, ...
Dans le cadre de notre développement, nous recherchons un Data Analyst H/F pour accompagner notre développement chez un de nos clients.
Les compétences requises pour la mission sont
Développement et administration de bases de données Oracle
Développement et maintenance de traitements ETL
Rédaction de spécifications
Modélisation de datamart
Profil :
Minimum 2 ans d’expérience dans le domaine
Connaissance SQL / ETL / Dataiku / Python / BI
Analyse de données
Compétence rédactionnelle
Lieu: Courbevoie
Type d'emploi : CDI
Expérience:
Data Analyst H/F: 3 ans (Requis)"
Paris (75),,,Data Analyst (F/H),Novencia,- Paris (75),"Contexte
Data is fuel ! Quelle que soit la façon dont elle est structurée, la data n’est plus l’apanage des SI… mais bien au cœur des activités et des Métiers. Aujourd’hui, de nombreuses entreprises ont besoin d’être accompagnées dans la gestion de leurs données afin de s’en servir à bon escient. La manipulation de la data est devenue une équation à plusieurs inconnues où Objectif = (Technique X Data) + (Outil X Data) … Vous l’aurez compris, pour résoudre l’équation, il devient urgent pour les organisations d’être conseillées par des spécialistes des données numériques.
Data Analyst depuis 3 ans, vous êtes à la recherche de nouveaux défis. Bouclez votre ceinture, la suite est pour vous !
Compétences
AYANT LES COMPÉTENCES EN
DataViz Python R SAS SQL Statistiques
Profil
Carnet de route
Nos 35 référencements et bien d’autres à venir offrent un large champ de possibles !
Évidemment, nous privilégions les environnements innovants et donc organisés autour de méthodologies Agile.
Quelques exemples de missions :
DataVisualisation : Création de dashboards interactifs pour suivre le parcours patient au sein d’un établissement de santé (Santé)
Création d’un outil d’aide à la décision pour l’évaluation du risque des aéronefs (Sécurité aérienne)
Mise en œuvre des outils de lutte contre la fraude pour les activités de BFI (Finance de marché)
Analyses du comportement client à des fins d’optimisation des opérations commerciales (Marketing opérationnel)
Votre rôle
Contrôler la qualité des données, détecter des patterns, des outliers
Mettre en place des segmentations client
Concevoir les datamarts
Proposer et mettre en pratique les modèles statistiques (régressions…) adaptés pour résoudre les problématiques métier
Collaborer avec les équipes technique et métier pour définir les besoins et expliciter les résultats
Restituer les résultats (rapports, présentations…)
À vous de choisir. Chez NOVENCIA, chaque consultant a le choix de sa mission et décide de la façon dont il souhaite évoluer.
De la technique et de la personnalité
Explorateur : part à la recherche de données sur des terres inconnues
Caricaturiste : reformule, vulgarise, schématise
Fin limier : trouve les meilleures solutions
Curieux : ne passe pas à côté d’une information essentielle
Sportif : aime relever des challenges en équipe
Voyant : prédit le comportement client
Calculateur : aime les chiffres
Jongleur : SAS / R / Python
Bilingue : passe aisément du français au langage statistique
Avancer en équipe
NOVENCIA, c’est avant tout un projet collectif.
Validation par un pair. Après les formules d’usage du premier entretien, vous rencontrez un de nos consultants lors d’un second échange pour qu’il puisse appréhender votre niveau technique et vous en dire plus sur l’écosystème de NOVENCIA. (C’est souvent là que tout bascule…).
Partage d’expérience. NOVENCIA compte 7 communautés : Partners – Finance/ Prodigi – Agile / Craft / ActiveViam / UX@Scale / Data / GDPR, dont le fonctionnement est indépendant. Dotées de leur propre budget, elles sont libres de récolter et diffuser des informations. L’objectif : encourager la veille technique et l’évolution professionnelle.
Expertise. Meet-up, webinar, articles, vidéos…Au-delà d’un objectif purement professionnel, technique ou fonctionnel, NOVENCIA vous donne la possibilité de vous exprimer. Environ 80 événements annuels sont organisés. Autant d’occasions pour un collaborateur de se dépasser. Crédibilité et notoriété du parcours sont donc au rendez-vous !
Formation sur mesure. NOVENCIA possède son propre centre de formation. Technique ou fonctionnelle, les formations proposées sont, pour la plupart, certifiantes.
Suivi personnalisé. Qu’elle soit personnelle ou professionnelle, votre évolution est notre priorité. C’est pourquoi nous avons créé les Instants RH et Objectifs Carrière. Vous l’avez compris, chez NOVENCIA on ne lâche rien !
Notre objectif commun : co-construire votre carrière en fonction de vos aspirations et de vos compétences.

S’engager en faveur du handicap c’est garantir l’égalité des chances dès le recrutement.
À compétences égales, nos postes sont ouverts aux personnes en situation de handicap."
Issy-les-Moulineaux (92),"Temps plein, CDI",,DATA ANALYST H/F,Groupement Les Mousquetaires,- Issy-les-Moulineaux (92),"ITM Alimentaire International, branche alimentaire du groupement les Mousquetaires recherche un(e) Data Analyst pour rejoindre son service Data au sein de l’équipe Data science.

Vous devez sûrement nous connaitre au travers des enseignes Intermarché et Netto ! D’ailleurs savez-vous qu’Intermarché revendique un positionnement unique et très engagé ? Celui de Producteurs & Commerçants responsables ! #SANTE #ENVIRONNEMENT #SOCIETE #PLAISIR

Parce que Mieux Manger c’est d’abord Mieux Produire, depuis 50 ans l’innovation est au cœur de nos stratégies et de nos valeurs. Ce que nous voulons, c’est aider les français à manger mieux tous les jours pour une vie pleine de santé !

Alors rejoingnez la Data Factory Intermarché/Netto, née de l’ambition partagée avec Accenture et Microsoft de transformer la chaine de valeur de l’écosystème alimentaire français. Les bénéfices du Cloud Azure de Microsoft et ses technologies d’Intelligence Artificielle, telles que le Machine Learning, la Data Visualisation ou encore la Computer Vision vont nous permettre de proposer une offre personnalisée tant au niveau de chaque point de vente qu’au niveau de chaque consommateur.

Partant(e) pour l’aventure ?

Concrètement quelles seront vos missions ?

Vous accompagnez la montée en compétences analytique de nos directions métier sur le pilotage et la gestion de leur activité en les aidant à mettre en place les reportings & data visualisation adaptée à leurs problématiques.
Vous assurez une veille et un retour critique sur la qualité des données par le challenge constructif des données que vous manipulez.
Vous collectez, avec l’aide des Product Owners et des Data Scientists, les besoins des métiers en analyse et en gestion des données.
Vous apportez progressivement votre expertise analytique sur un domaine métier et un périmètre de données.
Vous assurez la construction et la captation des indicateurs de performance des projets analytics.

Profil candidat
Niveau d'étude min.
Requis :
Bac + 5
Formation / Diplôme :
6 - MASTER 2
Expérience Requise :
de 3 à 4 ans
Compétences :
Qualités d'écoute et relationnelles , Disposition de déplacements , Capacité d'analyse et synthese , Esprit d'équipe
Qu’est-ce que vous pourriez nous apporter ?

Passionné(e) de chiffres et de statistiques, vous aimez autant la Data que faire parler vos coéquipiers pour comprendre leur besoin. Vous avez à cœur de comprendre les problématiques business et vous êtes force de proposition.

Diplômé(e) d’un Bac+5, vous possédez une expérience de plus de 2 ans dans le consulting ou de plus de 3 ans au sein d’une équipe Data/Analystics.

Envie d’une expérience enrichissante au sein d’une entreprise dynamique ? Rejoignez-nous dans les locaux de Microsoft France à Issy les Moulineaux (92). Tu auras également la chance de connaitre les 83 hectares verdoyants du Parc de Tréville (près d’Evry dans le 91) car des déplacements sont prévus une fois par semaine."
Courbevoie (92),,,Data scientist F/H,autobiz,- Courbevoie (92),"Créée en 2004, autobiz est une start-up innovante, leader sur le marché de la cotation automobile. L’analyse des données « big data » lui a permis de mettre en place une gamme d’outils internationaux pour développer le business VO (véhicules d’occasion) des professionnels de la distribution, de la location et de l’assurance automobile.
Aujourd’hui basée à La Défense (92), autobiz dispose également de bureaux à Berlin, à Valence (Espagne) et Milan.
Début 2017, le groupe PSA a choisi d’entrer au capital d’autobiz avec une participation minoritaire. Cette collaboration renforce la position d’autobiz sur le marché automobile à l’international et lui permet de développer de nouvelles solutions au quotidien.
Pour plus d'informations : http://corporate.autobiz.com

Vous venez de soutenir votre thèse de doctorat et recherchez votre première expérience?

En qualité de Data Scientist, vous participez à l’élaboration et au suivi des nombreux projets afin d’aider le pôle Data à se développer.
A cet effet, vous serez amené(e) à interagir avec l’ensemble des parties prenantes de l’entreprise : équipes tech, commerciales, consulting, direction, etc.

Vos missions principales :

1. Contribuer au développement du Pôle Data

Rédaction des cahiers des charges.
Architecture base de données.
Analyse des données automobiles pour plusieurs pays (15 millions d’annonces mensuelles).
Élaboration de nouveaux KPIs de vérification (Crawl, Data brute, Data traitée);
Automatisation des process actuels .
Force de proposition dans le traitement de données .
Développement de nouveaux produits (Modèles statistiques, modèles mathématiques de traitement de données, modèles approximatifs….).

2. Participer au bon fonctionnement et au développement de l’entreprise
Vous vous intéressez à la vie d’autobiz et à son marché.
Vous savez vous intégrer dans l’équipe et plus largement au sein d’autobiz.
Vous développez une attitude professionnelle (innover, suggérer, conseiller, valoriser).
Vous aimez la recherche appliquée et utilisez l’informatique pour manipuler des bases des données en utilisant des méthodes statistiques.

De formation Bac +8, vous venez de soutenir votre thèse et êtes docteur.
Vous êtes à la recherche de votre 1ère expérience professionnelle.

Vous êtes motivé(e) pour intégrer une structure à taille humaine en fort développement dans laquelle vous investir pleinement. Vous avez idéalement réalisé des stages dans le domaine du data mining, texte mining, recherches d’informations sur le web, intelligence artificielle…

Compétences demandées :
Maîtrise du SQL et de la modélisation des données.
Maîtrise des langages de programmation (PHP, R ou Python, Shell).
Maîtrise des algorithmes de traitement de masse de données.
Maîtrise de l’anglais opérationnel.
Connaissance des langages Perl, Ajax, Java script et/ou Awk serait un plus.
Connaissance des outils de pilotage de projet serait un plus."
Paris 10e (75),Stage,,STAGE 2020 - Analyse des parcours clients - Big Data (F/H),Parrot Drones,- Paris 10e (75),"Vous avez toujours rêvé d'intégrer un groupe agile ? en voilà un, et pas des moindres ! Les projets de Parrot sont innovants, techniques, difficiles à réaliser et en un temps record. C'est ça la beauté d'un esprit startup !

Nous avons l'ambition, vous n'avez pas froid aux yeux, rejoignez-nous !

Fondée en 1994 par Henri Seydoux, Parrot conçoit, développe et commercialise des produits sans fil de haute technologie à destination du grand public et des grands comptes. L'entreprise s'appuie sur une expertise technologique commune et son développement se concentre aujourd'hui sur les drones civils avec des quadricoptères de loisirs et des solutions destinées aux marchés professionnels.

L’équipe Big Data est responsable de la mise en place et de l’exploitation des données partagées par nos clients en vue de l’amélioration de nos services et de nos drones. Notre rôle est transverse et nous intervenons auprès de plusieurs départements
.
Le stage propose d’étudier les parcours des clients dans leur utilisation de l’application Freeflight à partir de données anonymes.

Missions :

La mission se décomposera en plusieurs phases, la première consistant à indexer en base de données des informations sur les parcours de l’utilisateur dans l’application, la deuxième à les exploiter.

Se former aux outils logiciels, recherche documentaire
Définition, développement d’un proof of concept, présentation
Indexation des métadonnées en vue des analyses de parcours client
Développement d’indicateurs et de profils types à partir d’algorithmes analytiques ou de machine learning

Profil :
Formation :
Scientifique, école d’ingénieur - ingénieur Data Sciences
Niveau d’études : BAC + 5

Compétences technique :
Indispensables : Linux, Python
Souhaitées : GIT, jenkins, elasticsearch

Qualités requises :
Autonomie; Rigueur ; Communication

Un très bon niveau d'anglais est souhaité pour le poste (échange régulier à l'écrit et à l'oral)."
Nanterre (92),"Temps plein, CDI",,Consultant Data Scientist Confirmé (H/F),GROUPE HLI,- Nanterre (92),"Qui sommes-nous ?
Flexibilité d’une entreprise à taille humaine et solidité économique, le Groupe HLi, créé en 1985, vous offre l’appui de 170 collaborateurs en France et à l’international.
Le pôle Analytics du Groupe HLi, spécialiste en data science et intelligence artificielle, intervient sur des projets variés : risque management, AgroTech, connaissance clients, maintenance prédictives, optimisation de performance d’équipes, scores de fraude, etc….
Nos outils fétiches : R, Shiny, Python, SAS, ElasticSearch …
Ce que nous vous proposons :
Une société à taille humaine à l’écoute de vos propositions
Une évolution professionnelle qui suit vos aspirations
Une intégration rapide grâce à la mise en place d’événements internes (soirées et déjeuners d’entreprise, présentations et retours d’expérience) et au suivi de proximité…
Et aussi : notre Lab HLi, de nouveaux locaux, une équipe dynamique, des projets innovants et originaux...
N’attendez plus, rejoignez-nous !
Description du poste :
Vous intégrerez le pôle analytics – big data du Groupe HLi, composé d’experts data scientist qui interviennent principalement sur des projets stratégiques pour le compte de grandes entreprises ou au sein de notre pôle R&D.
Au sein du pôle analytique, vous participerez à :
L’accompagnement et au conseil de projets data science pour les clients grands comptes.
La réalisation de solutions data science du Groupe HLi commercialisées sur le cloud.
Les principales étapes des projets sont :
Accompagner le client dans la formalisation de sa problématique,
Cadrer le projet et réaliser l’approche méthodologique,
Réaliser les solutions /outils d’aide à la décision : recherche des sources de données pertinentes, modélisation (machine /deep learning), réalisation d’API, industrialisation des modèles,
Synthétiser et présenter les résultats (Data visualisation / PowerPoint).
Vous interviendrez sur les phases suivantes :
Extraction, contrôle et transformation de données structurées et/ou non structurées
Construction des algorithmes prédictifs :
Analyse de données structurées et/ou non structurées
Modélisation statistique : modèles de régressions, algorithmes de machine learning, séries temporelles, détermination de profils, recherche opérationnelle…
Restitution des résultats et industrialisation :
Mise en place d’interfaces de data visualisation (cartographies dynamiques, tableaux de bord…)
Réalisation de documents de synthèse et benchmark des méthodes mobilisées.
Description du Profil :
Titulaire d’un BAC+5 ou plus à dominante mathématiques, d’une formation grande école.
Vous disposez de 3 ans d’expérience minimum et savez manipuler les données sur SAS, R, Shiny, Python …
Vous disposez d'un bon relationnel, l’esprit d’équipe et êtes curieux.
De plus , la maîtrise de l’anglais serait appréciée.
Type d'emploi : Temps plein, CDI"
Paris (75),CDI,,Data scientist user behaviour H/F,Se Loger,- Paris (75),"Nous recherchons un data scientist référent sur la connaissance et la prédiction des projets immobiliers de nos utilisateurs.

Rattaché(e) au responsable data du Groupe, nous souhaitons une personne qui aime se prendre la tête avec les données en ayant à cœur de lui donner un vrai sens business. Les données que nous avons sont très riches et vous permettront de vous éclater dans un domaine qui nous touche tous et tout au long de notre vie, l'immobilier !



Vous utilisez et enrichissez les données pour comprendre le projet immobilier et le profil de nos utilisateurs en analysant leurs comportements sur nos sites et applis (données CRM, données de tracking).
Vous construisez et mettez en place des modèles prédictifs permettant de segmenter nos utilisateurs.
Vous contribuez aux projets d'amélioration ou de refonte des sites, applis, du CRM, des offres régie, ou des offres BtoB proposés par SeLoger en apportant des insights data utilisateurs et/ou en exprimant des besoins de collecte de données.
Vous mettez en en place les tableaux de bord dataviz permettant de piloter les principaux KPIs utilisateurs.
Vous contribuez à la montée en compétence des équipes data sur les outils et techniques liées au Big Data.
Vous contribuez à la construction de l'écosystème IT Big Data du Groupe en lien avec l'équipe IT.
Profil
De formation master ou école d'ingénieurs avec un focus datascience, mathématiques, statistiques vous avez 2-3 ans d'expérience en analyse et prédiction de comportements, idéalement dans un contexte marketing ou digital (consulting/agence, techno data ou pub, e-commerce, entertainment, médias, …)
Vous avez d'excellentes capacités analytiques, de la préparation des données à la restitution des résultats.
Vous êtes à l'aise dans la restitution orale et écrite des analyses et des algorithmes, notamment vis-à-vis d'audiences business.
Vous avez une forte sensibilité pour le marketing et savez orienté vos sujets avec une vision ROIste

Techniquement ?
Vous pratiquez les principales techniques de Machine Learning supervisées : régression, arbres et modèles ensemblistes, neural networks. Une expérience de l'analyse de séquences (HMM, LTSM, …) est un plus.
Vous êtes autonome dans l'accès et la manipulation des données structurées ou non (SQL, Hive, Spark/mapreduce, Python, R, …) et dans le développement d'algorithmes.
Vous êtes familier des outils de dataviz (Tableau, Qlik, D3.JS,…) et la pratique des outils de webanalytics serait très appréciée (Omniture, Google Analytics, AT Internet, …).
Localisation du poste
Localisation du poste
Ile-de-France, Paris (75)
Lieu
65 rue Ordener Paris
Critères candidat
Niveau d'expérience min. requis
de 2 à 5 ans"
Boulogne-Billancourt (92),CDI,,Data Scientist F/H,DEGETEL,- Boulogne-Billancourt (92),"Dans cette logique et afin de renforcer notre communauté du Digital Performance, nous cherchons une nouvelle pépite en qualité de : Data Scientist:

Pour :
Définir une modélisation statistique ;

Identifier les outils d’analyse à utiliser pour collecter les données, parfois les construire ;

Étudier les données ;

Synthétiser les résultats dégagés et les rendre exploitables facilement.

Audit des solutions et des outils, évaluation des prestataires et solutions

Enrichissement des bases de données tout en satisfaisant les exigences de qualité des données recueillies.

Conception et mise en œuvre des outils pour la réalisation et le fonctionnement de la DATA Warehouse

En qualité de consultant Degetel, vous êtes amené à intervenir en régie, intégré aux équipes de nos clients, et dans différents secteurs d’activités (industrie, banque, assurance, média, e-commerce…)

Nos missions longues (de 1 à 3 ans) sont situées à Paris petite couronne et en proche banlieue.

Profil recherché Ayant :
De formation supérieure (BAC +5ou Doctorat avec un profil scientifique)

Une expérience de 1 ans minimum en tant que data scientist

Multiples compétences scientifiques (mathématiques, statistiques, modélisation, analyse de données

Des connaissances ou une maitrise technique (Big data, python, hadoop, spark, scala..) et un plus

Travaillé en méthodologies Agile (Kanban, Scrum)
Entreprise Degetel ?

Degetel et le digital ont en commun bien plus que des consonnes : ils partagent le même ADN.

En plus de 20 ans d’histoire, Degetel n’a eu de cesse d’accompagner ses clients dans leur transformation digitale. Nous leur faisons bénéficier de notre parti pris d’innovation, fruit de notre R&D et de notre expérience multisectorielle. Nous anticipons à leur profit les évolutions des technologies, des usages et des tendances."
Issy-les-Moulineaux (92),CDI,,Data Analyst Connaissance Clients,Le Groupe La Poste,- Issy-les-Moulineaux (92),"MISSION
La Branche Numérique du Groupe la Poste recherche un Data Anayste Connaissance Clients, dont les missions sont de :
Constituer une base de données centralisant les données des clients particuliers, professionnels et entreprises du groupe La Poste.
Personnaliser la relation client et proposer des parcours fluides et omnicanaux.
Contribuer à l'amélioration de la pertinence des offres et des services en proposant, aux clients, la meilleure offre, au meilleur moment, par le meilleur canal.
Contribuer au développement de services pour étendre nos activités.
Asseoir les activités du Groupe La Poste dans la durée, sans intermédiation de l'accès à la connaissance de nos clients particuliers, professionnels et entreprises
Analyser les données et partager cette connaissance avec les différentes branches et l'exploiter dans le respect des règles liées à la « privacy »
Devenir un acteur reconnu de l'économie de données
Faire de la connaissance client le levier de la performance de chacune des branches du Groupe.
Dans ce contexte, le/la Data Analyst Connaissance Clients a pour mission de développer la connaissance transverse et multicanale des clients particuliers & professionnels du Groupe via la production d'analyses statistiques fondées sur les données collectées dans toutes les Branches et Filiales.
PROFIL
Le Data Analyst Connaissance Clients devra mettre en place des indicateurs clé et des études trans-branches, aboutissant à des préconisations et des leviers de développement business pour le groupe. Il contribuera ainsi au déploiement de la connaissance clients Groupe et à sa diffusion auprès des différents acteurs.
Il devra proposer les bonnes méthodologies et faire preuve de pédagogie, pragmatisme, sens client et business et apporter des réponses aux problèmes métiers des différents services
FORMATION ET EXPÉRIENCE
Titulaire d'une formation supérieure en Statistiques / Econométrie / Informatique Décisionnelle, orienté outils de la Datascience et Marketing Client
4 ans d'expérience en exploitation statistiques de données clients (Datamining/Etudes statistiques), idéalement au sein de directions Marketing ou CRM
Maîtrise du langage SQL
Connaissance des outils Dataiku ou Tableau, et des langages tels R, Python et Spark .
Curiosité, pédagogie, aisance relationnelle et rédactionnelle"
Paris (75),CDI,,Data Scientist (H/F),Le Lynx,- Paris (75),"Chez LeLynx.fr, la data est utilisée au quotidien par l’ensemble de l’équipe pour le suivi des résultats et l’aide à la prise de décision.
Dans ce contexte, vous serez en charge de l’analyse de notre expérience client et de son impact business.
Vous participerez à la mise en place d’un projet d’amélioration du service LeLynx.fr basé sur du machine Learning, notamment :
choix des modèles statistiques à utiliser ;
automatisation des modèles ;
optimisation des modèles ;
intégration de nouveaux indicateurs dans les modèles.
Vous serez amené.e à :
publier des tableaux de bord sur notre outil de BI et à produire des études de données pour les différents services business ;
mettre à jour des modèles statistiques existants ;
proposer de nouveaux modèles ;
animer régulièrement des formations cross service pour faire vivre la culture data au sein de l’entreprise.
Enfin, vous êtes le garant du bon fonctionnement de processus récurrents tels que le processus d’intégration des données partenaires suite à l’envoi de données de facturation.
De manière générale, en tant que membre de l’équipe Data, vous serez une référence concernant l’accès aux données, leur compréhension et leur analyse, auprès de l’ensemble de l’équipe LeLynx.fr.
Profil recherché
Vous êtes diplomé.e d’une formation de l’enseignement supérieur avec spécialisation en machine learning. Vous possédez une première expérience en entreprise en tant que Data Scientist.
Vous êtes à l’aise avec les outils ou langages suivants :
R ou Python pour les modèles statistiques
SQL pour l’extraction de données
Tableau Software pour l’analyse et la visualisation de données
Vous serez amené.e à échanger avec les différentes entités du groupe Admiral (en Inde, au Royaume- Uni, en Espagne). Dans ce contexte, votre niveau d’anglais est opérationnel, à l’écrit comme à l’oral. Vous êtes rigoureux.se, force de proposition et pédagogue.
Modalités :
Le poste est basé à Paris 19ème, le long du canal de l’Ourcq (concours de pétanque et piqueniques à foison l’été).
Nous proposons des fruits, du café et du thé à volonté, ainsi que des sorties mensuelles (expos, bars, activités team building…), bref, tout ce qu’il faut pour que vous soyez le plus heureux possible.
Date de démarrage : Lundi 4 mai
Rémunération : Selon profil
Mutuelle, carte déjeuner & remboursement transports à hauteur de 50%
Informations complémentaires
Type de contrat : CDI
Date de début : 04 mai 2020
Lieu : Paris, France (75019)
Expérience : > 2 ans"
La Défense (92),CDI,,Docteur Data Scientist,Kaisens Data,- La Défense (92),"Nous disposons aujourd'hui d'un ensemble de données qui restent insuffisamment exploitées : il peut s’agir du comportement des utilisateurs du site web, du tracking à partir de newsletters, des informations issues des systèmes d’informations.
L’objectif du recrutement d’un(e) Docteur Junior vise à pouvoir collecter ces données, les regrouper / classifier dans des systèmes de gestion de bases de données, et les traiter par des méthodes d’apprentissage automatique (Machine Learning) pour permettre une meilleure exploitation de ces données. En particulier, l’objectif est de mettre en place des systèmes de recommandation pour améliorer les solutions du marketing digital (identification des produits à valoriser, accompagnement au processus d’achat des utilisateurs web, réponses adaptées en fonction du comportement et de la classification des utilisateurs).
Profil recherché
Dans ce contexte, nous cherchons un candidat disposant en particulier des compétences suivantes :
· Maîtrise des algorithmes de Machine Learning (supervisés et non supervisés)
· Data Science : collecte, traitement et analyse de données
· Connaissances des outils Big Data (Spark)
· Maîtrise des langages de programmation permettant d’implémenter les méthodes et algorithmes imaginés (Python, Scala, Java)
· Des connaissances sur la stack web (Node.js, React) seront particulièrement appréciées
· La personne que nous souhaitons recruter devra impérativement être titulaire d’un Doctorat.
Quelles sont les qualités importantes pour ce poste ?
· Autonome et proactif
· Intérêt pour les métiers du marketing digital
· Esprit entrepreneurial, capable de travailler au sein d’une petite équipe
· Ouvert, pédagogue, sympathique
· Pragmatique
Kasiens Data recherche des collaborateurs engagés et dynamiques pour intégrer une équipe jeune.
Type d'emploi : CDI
Expérience:
docteur data scientist ou similaire: 1 an (Souhaité)"
Paris (75),,,Data Scientist (H/F),MFG Labs,- Paris (75),"Ce que l’on vous propose
Dans un contexte de partage, de challenge continu et de veille où vous pourrez monter en compétences et vous épanouir vous :
Échangerez avec le client pour comprendre ses objectifs business
Proposerez des formulations mathématiques de problèmes concrets
Vous servirez d’analyses exploratoires et de méthodes d’apprentissage non supervisé pour dégager des tendances et tirer des enseignements provenant de datasets
Appliquerez des algorithmes statistiques / de machine learning pour aider à la prise de décision
Analyserez les résultats de modèles et les communiquer à tout type d’audience (aussi bien technique que non technique)
Prototyperez des algorithmes et collaborer avec nos ingénieurs pour les déployer en production
Ferez de la veille académique afin de rester à la pointe de l’état de l’art et partagerez les découvertes avec le reste de l’équipe
Pour vous épanouir sur ce nouveau poste, nous vous accompagnerons dans votre parcours d’intégration, de formation et dans le suivi de votre carrière.
Votre profil
Vous avez le goût pour le travail bien fait, êtes rigoureux et vous souhaitez vous investir dans des projets dont vous serez fier(e). Vous possédez :
Une formation en Informatique, Mathématiques Appliquées ou Statistiques
Une compétence analytique (statistiques, machine learning et programmation)
Une capacité à communiquer de manière claire et efficace
Une capacité à comprendre les problèmes et y proposer des solutions
Une volonté d’appliquer ces compétences dans un contexte business
Une forte envie d’apprendre
De la rigueur, de l’organisation et de la curiosité
Un français courant et un bon niveau d’anglais
De plus, vous possédez également les compétences techniques suivantes :
Compréhension des concepts de base du machine learning et connaissance d’algorithmes spécifiques
Compétence mathématique, particulièrement en statistiques (descriptive et inférentielle)
Maîtrise d’outils adaptés à la data science (Python, R) et des librairies associées (pandas, scikit-learn, dplyr, ggplot2, …)
Compréhension des algorithmes informatiques et structures de données classiques
Les plus :
Maîtrise du SQL
Expérience avec des outils de visualisation (de préférence Tableau)
Détails de l’offre
Poste à pourvoir dès maintenant
Temps plein
Lieu de travail : Paris
Vous vous reconnaissez dans cette annonce ? N’hésitez pas à nous contacter et partager votre profil, nous serons ravis d’échanger avec vous."
Paris 16e (75),CDI,,Explorateur Data Scientist - Santé (Paris) F/H,ALCIMED,- Paris 16e (75),"Le poste à pourvoir

Un voyage de mille lieues commence toujours par le premier pas, et ce premier pas, c’est peut-être vous : Vous embarquez à bord d’Alcimed pour travailler sur le futur de la santé !

Dès votre arrivée, vous travaillez au croisement des innovations santé et de la data. Les missions durent en moyenne quelques mois et sont très variées : nouveaux produits/services, nouveaux business models, nouveaux parcours utilisateurs… Un maître mot, pas de routine !

Le vrai plus de votre mission ? Vous êtes au contact direct de nos clients pour les aider à avancer et à façonner le monde de demain.

Les avantages, pour finir !

Un beau package de rémunération selon votre expérience.

Le plaisir de prendre part à un projet fun et d’intégrer une équipe pa

ssionnée par son métier ... et qui

ne se prend pas au sérieux.

Pour rejoindre la flotte, c’est maintenant à vous de nous convaincre !
Profil recherché Les compétences requises

Doté d’une réelle appétence pour les sujets d’innovation et le secteur de la santé, vous cherchez à donner un sens à votre carrière.

Vous êtes passionné par les

solutions algorithmiques et d’architectures Big Data (

bonnes bases en développement comme Python et SQL), vous avez de solides bases théoriques et une première expérience pratique en data science ou architecture de données…

Vous êtes diplômé d’une école d’ingénieur ou master en data science.

Chez nous, on n’explore pas en solo, il faut aussi avoir le goût du travail en équipe.

Comme tout explorateur qui se respecte, vous êtes curieux(se) et vous êtes bilingue en anglais.

Il n’y a pas qu’un Christophe Colomb qui sommeille en vous, il y a aussi un Bill Gates : vous avez un fort esprit entrepreneurial.
Entreprise La vocation d’Alcimed est d’aider les industriels à innover et à créer de nouveaux business en les accompagnant dans l’exploration et le développement de leurs terres inconnues : nouvelles technologies, nouvelles offres marchés, nouveaux business models, nouvelles géographies, nouvelles manières d’innover, prospective… Nous sommes aujourd’hui une équipe de 200 Alcims répartis entre 8 bureaux en France, en Europe, aux USA et à Singapour et nous avons l’ambition de construire une équipe de 1000 personnes d’ici 10 ans."
La Défense (92),CDI,,INGENIEUR BIG DATA ANALYTICS - F/H,Ingeniance,- La Défense (92),"Contexte :
Notre client est une banque de financement, d'investissement et de services, qui développe également une offre originale en matière de gestion du poste clients.
Chez INGENIANCE notre Lab � BigData Analytics �, est un véritable terrain d'expérimentation de mise en place de cluster hadoop, de montée en compétence sur des architectures d'applications distribuées (Lambda, Smack, Microservices). Ce dispositif permet à nos collaborateurs de maîtriser des outils tels que Spark, Kafka, Elasticsearch, Hbase, Hive, Cassandra.

Notre Lab permet également de créer des modèles Machine Learning (classification, régression, clustering) avec Spark-Mllib, Tensorflow, Sickit-learn.
Missions:

Chez INGENIANCE :
Participer à la veille technologique au sein de nos communautés,
Être accompagnés avec nos éléments référents, experts dans le domaine
Conseiller nos clients sur les produits du marché
Participer au développement de nos événements techniques internes (Speed training, Meetup) et externes

Chez nos clients :
Intervenir dans des environnements en transformation notamment sur les sujets du Big Data. Voici une liste indicative des activités qui pourraient vous être confiées:
Analyser les besoins clients et formaliser des Use Cases clients,
Participer activement à la conception et à la réalisation des solutions Big Data,
Développer une approche analytique ou machine learning en fonction du besoin,
Développer des solutions d'ingestion de données depuis des sources multiples pour les déverser dans un data lake : Nifi, Sqoop, Kafka, etc.
Passer de la donnée brute à de la donnée propre (inférer les schémas de données, nettoyer et normaliser les données, publier les données)
Consolider les données au fur et à mesure de leur alimentation récurrente dans le data lake.
Exploiter les résultats pour atteindre la finalité business : exposition de business view, réintégration des résultats dans le SI, etc.
Mettre en place et garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de développement et d'industrialisation (documents, tests unitaires / intégrations / fonctionnels, commentaires, versionning, etc.)
Environnement:
Horton Works, Cloudera, Spark, NoSQL
Profil recherché:
Vous êtes passionné(e) d'innovations technologiques, désireux de partager vos compétences au sein d'une équipe en recherche d'excellence.
Vous disposez d'une bonne première expérience en big data, gestion des bases de données NoSQL et maîtrisez les environnements Hadoop du type Hortonworks, Cloudera, Spark, etc.
Vous êtes reconnu(e) pour votre énergie, votre pertinence, votre polyvalence, votre curiosité et votre capacité à mener à bien des projets.
Vous avez un bon sens de la communication et avez des capacités affirmées d'analyse et de synthèse et êtes à l'aise en anglais, tant à l'oral qu'à l'écrit.
INGENIANCE est une société jeune et dynamique qui stimule l'innovation et la transformation digitale par l'accompagnement de ses clients dans leurs projets liés aux nouvelles technologies.

Spécialiste des secteurs Banque, Finance et Assurance, INGENIANCE est également une entreprise technology-oriented qui offre une expertise multi-sectorielle autour du Big Data, du développement informatique, de la Blockchain et de la philosophie DevOps.

Ceci permet à INGENIANCE de se positionner comme une entreprise leader du marché financier et avant-gardiste des technologies disruptives."
Massy (91),,,Data scientist dans le domaine des risques de crédit,Crédit Agricole Consumer Finance,- Massy (91),"Qui sommes nous ?

Crédit Agricole Consumer Finance est un acteur majeur du crédit à la consommation en Europe. Filiale du groupe Crédit Agricole, elle apporte son expertise du crédit à la consommation en mettant à disposition de ses clients et partenaires des offres adaptées et innovantes.

La mission que l'on propose

Vous rejoindrez le Pôle Données et Reporting de l’équipe Projets Risques et Règlementaires au sein de la division Risk Management Groupe dont la mission principale est la mesure, la surveillance et le contrôle des risques du Groupe CA CF présent dans de nombreux pays en Europe ainsi qu’en Chine et en Afrique du Nord. Vos principales missions sont de mettre en place des indicateurs clés pour le pilotage de l’activité risque et de maintenir en condition opérationnelle le SI de la direction Risk Management Group. Ce sera l’occasion pour vous de découvrir la réglementation appliquée à notre secteur d’activité et de vous familiariser à la maîtrise du risque de crédit tout en évoluant dans un univers technique où la donnée risque est l’élément central.

En lien avec les services IT, les experts métiers risque et finance, vous aurez pour missions principales :
L’extraction et le traitement de bases de données
La mise en place des indicateurs de pilotage de l’activité risque : à travers des reporting dont le besoin est exprimé par des experts métiers ;
La conception, l’automatisation et l’amélioration de la production des reporting ;
Mise en place des contrôles sur les données tout au long du cycle de production ;
L’analyser des données nécessaires à la production des indicateurs et reporting;
La qualification des indicateurs et reporting produits;

#Ta formation

Bac +4/5
Spécialisation : Data, informatique
École de commerce, Ecole d'ingénieur, Université

#Tes compétences

Connaissances solides en bases de données relationnelles et en développement
Goût du challenge
Rigueur
Réactivité

Outils informatiques : SQL, SAS, Python

Langues : Anglais

#Nos pré-requis

Capacité d'analyse
Pro-activité"
Paris 8e (75),CDI,,Data Analyst BI F/H,CAPFI VITA DATA,- Paris 8e (75),"Vous accompagnerez nos clients sur la conception et la mise en œuvre de leurs projets de Data

Management, Data Analyse et/ou Data Visualisation.

Selon les projets, vous pourrez intervenir sur les phases suivantes :

Recueil des besoins métiers
Acquisition, Traitement et Exploration de données
Travaux sur la Qualité des données
Conception/développement/structuration des entrepôts de données et datamarts
Réalisation d’études statistiques
Identification des indicateurs de pilotage et réalisation des outils de Datavisualisation,
Support technique et fonctionnel auprès des utilisateurs
Profil recherché Diplômé d’une école, d’un Bac+5 en Statistiques, Informatique Décisionnelle ou Big Data, vous avez une expérience significative en tant que Data Analyst

Vous maîtrisez l’un des outils suivants :
Power BI (Desktop, Report Server, DAX), connaissant la suite Microsoft BI (SSIS, SSAS, SSRS)
Tableau
QlikView et Qlik Sense
Entreprise Capfi VITADATA est la start-up du groupe Capfi spécialisée en Data Science et Big Data.

Capfi VITADATA accompagne ses clients grands comptes sur des projets data avec comme

objectifs de:
Transformer leurs données en intelligence métier
Construire de manière contrôlée et évolutive leurs outils décisionnels et Big Data.
Nous répondons aux problématiques analytiques des Directions Marketing, Digital et Risques de nos

clients des secteurs Banque/Assurance, Energie, Laboratoire, Retail, Media, Telecom...

Et accompagnons les Directions des Systèmes d’Information sur leurs projets de développements en

mode agile."
Paris 15e (75),,,Data Scientist H/F,EOS France,- Paris 15e (75),"Le groupe EOS, filiale à 100% du groupe allemand OTTO, présent dans 26 pays, est l’un des leaders internationaux de la gestion et de l’acquisition de créances. EOS France propose une gamme complète de services à ses clients institutionnels dans les domaines de la banque, du crédit, de l’énergie, de la téléphonie…
Evoluant dans un univers hautement technologique, et dans un contexte de croissance soutenue, EOS investit en propre chaque année plusieurs centaines de millions d’euros dans des portefeuilles de créances de toutes natures (créances immobilières, créances bancaires, crédit conso, téléphonie et énergie entre autres) . Pour évaluer et gérer les portefeuilles de créances, EOS s’appuie à la fois sur des techniques de modélisation et de scoring pour les portefeuilles de créances multiples et sur une approche juridique du crédit et de l’immobilier pour les portefeuilles de créances plus granulaires.
EOS France compte 550 collaborateurs, répartis sur 4 sites en Métropole, Paris, Nantes, Pau et Lille et 2 sites à l’international, à l’Ile Maurice et Tahiti.

Le département Finance, Statistiques et Contrôle de gestion est au cœur du processus d’acquisition de portefeuille de l’ensemble du groupe EOS France.
Intégré(e) au sein d’une équipe qui vous offre des responsabilités et des perspectives d’évolution, vos principales missions seront :
Participer au pricing des portefeuilles de créances : construction de modèles financiers sur 15 ans, utilisation des performances des portefeuilles comparables déjà détenus par EOS, sur tout type de créances (performing / non performing loans, secured / unsecured …)
Développer des modèles pour optimiser les process de traitement opérationnels et forecaster les flux financiers
Réaliser des études, analyses et développement de tous types d’instruments d’aide à la décision, destinés à nos clients, à la Direction Générale, aux entités du groupe.

Profil recherché :
Vous êtes diplômé(e) d’une école d'Ingénieur option Statistiques et vous possédez les qualités suivantes :
Vous êtes rigoureux(se), méthodique, organisé(e) et autonome
Vous maîtrisez les bases de données
Vous êtes curieux(se) et disposez d'une grande capacité de travail
Vous connaissez les méthodes statistiques (bases de données et modélisation)
Vous maîtrisez l'anglais à l'oral et à l'écrit
Vous avez une bonne maîtrise des logiciels Python, SQL et R"
Neuilly-sur-Seine (92),"Temps plein, CDI",,Consultant confirmé Data & Analytics,Grant Thornton,- Neuilly-sur-Seine (92),"Contrat :CDI
Temps de travail :Temps plein
Expérience :De 2 à 5 ans
Niveau d’études :Master, DESS, DEA, Bac+5
Votre mission chez Grant Thornton France :
Analyse de données, recherche de fraude, solutions de contrôle continu, Machine Learning, Big Data…
Au sein de Grant Thornton, 6e cabinet national d’audit et de conseil, nous recrutons aujourd’hui, dans le cadre du développement de notre équipe dédiée au conseil Business Risk Services, un Consultant Confirmé, pour une durée indéterminée.
Les principales missions du consultant seront les suivantes :
Mise en place d'outils de contrôle en continu (datamining, audit management et autres)
Déploiement de systèmes de management intégrés des risques et de la conformité (contrôle interne, lutte contre la fraude, Sapin 2, GDPR...),
Investigations informatisées / digital forensic (analyse de fraude, contentieux, assistance aux perquisitions...).
Contribuer au développement de l’entité Business Risk Services en participant à des projets internes
Pour ce faire, le consultant bénéficie des qualités suivantes : autonomie, proactivité, fort intérêt pour l’analyse de données, capacités rédactionnelles, analytiques et synthétiques, aisance orale, rigueur…
Profil de candidat recherché :
Vous êtes diplômé d’une formation d'Ecole d’Ingénieur, idéalement complétée par une spécialisation en gestion, vous souhaitez rejoindre une équipe en croissance.
Désireux de rejoindre un cabinet en croissance, vous êtes impliqué et disposez d'une expérience d’au moins deux ans acquise en entreprise. Doté d’un excellent relationnel, voussouhaitez travailler au sein d’équipes pluridisciplinaires. Vous êtes curieux, motivé et avez une grande capacité d’adaptation.
La connaissance des outils et techniques d’analyse de données (SQL, Google Big Query, ACL, Data Studio, Python, Power BI, etc.) est un plus.
Vous maîtrisez l'anglais dans un environnement professionnel.
Site de Grant Thornton : https://www.grantthornton.fr/fr/
A compétences égales, travailleurs en situation de handicap bienvenus !"
Paris (75),,,Explorateur Data Scientist – Santé,Alcimed,- Paris (75),"Vous êtes passionné(e) par l'innovation et le secteur de la Santé ?
Alcimed voit le jour en 1993, avec la vocation d’explorer et de développer les terres inconnues. Nous sommes plus de 200 explorateurs à avoir embarqué dans l’aventure et nous accompagnons au quotidien nos clients industriels, pour les aider à innover et à créer de nouveaux business, depuis nos huit camps base en Europe, aux USA et à Singapour.
Notre rêve ? Construire une communauté de 1000 explorateurs.
Le poste à pourvoir
Un voyage de mille lieues commence toujours par le premier pas, et ce premier pas, c’est peut-être vous : Vous embarquez à bord d’Alcimed pour travailler sur le futur de la santé !
Dès votre arrivée, vous travaillez au croisement des innovations santé et de la data. Les missions durent en moyenne quelques mois et sont très variées : nouveaux produits/services, nouveaux business models, nouveaux parcours utilisateurs… Un maître mot, pas de routine !
Le vrai plus de votre mission ? Vous êtes au contact direct de nos clients pour les aider à avancer et à façonner le monde de demain.
Les compétences requises
Doté d’une réelle appétence pour les sujets d’innovation et le secteur de la santé, vous cherchez à donner un sens à votre carrière.
Vous êtes passionné par les solutions algorithmiques et d’architectures Big Data (bonnes bases en développement comme Python et SQL), vous avez de solides bases théoriques et une première expérience pratique en data science ou architecture de données…
Vous êtes diplômé d’une école d’ingénieur ou master en data science.
Chez nous, on n’explore pas en solo, il faut aussi avoir le goût du travail en équipe.
Comme tout explorateur qui se respecte, vous êtes curieux(se) et vous êtes bilingue en anglais.
Il n’y a pas qu’un Christophe Colomb qui sommeille en vous, il y a aussi un Bill Gates : vous avez un fort esprit entrepreneurial.
Les avantages, pour finir !
Un beau package de rémunération selon votre expérience.
Le plaisir de prendre part à un projet fun et d’intégrer une équipe passionnée par son métier … et qui ne se prend pas au sérieux.
Pour rejoindre la flotte, c’est maintenant à vous de nous convaincre !"
Vitry-sur-Seine (94),CDI,,Data scientist f/h,Franprix,- Vitry-sur-Seine (94),"Description de l'organisation

Avec plus de 900 magasins en France, le réseau Franprix connaît une forte croissance à Paris, en région parisienne, et se développe maintenant dans les grandes villes de France à travers son ambitieux projet d'expansion.
Ancrés au cœur de la vie de quartier, nos magasins proposent des services d'ultra-proximité ainsi qu'une gamme de produits étendue et adaptée aux habitudes de consommation. Notre priorité : satisfaire le client au quotidien !
Toutes nos équipes sont mobilisées pour donner vie à ce grand challenge collectif. Vous avez envie de vous y associer, rejoignez-nous pour faire partie de l'équipe des « épiciers d'aujourd'hui ».

Mission

Contexte :
L'équipe data science est spécialisée dans l'accompagnement des directions de Franprix pour les aspects analytics et data, sur 3 volets :
conseil data-driven auprès des différentes directions de l'enseigne (geomarketing, scoring et clusterisation de points de vente / clients, recommandation d'assortiments, de stratégie tarifaire, horaires d'ouverture, accompagnement à la performance des franchisés, …)
impulsion de projets transverses de fiabilisation et de valorisation des données
mise en place de l'accès aux données de reporting opérationnel et stratégique lorsqu'il nécessite des traitements qui ne sont pas pris en charge par les équipes datawarehouse / CDG
La spécificité de l'équipe data science Franprix réside dans ses domaines d'intervention dépassant le périmètre habituel de la business intelligence et des métiers du numérique : nous développons une approche personnalisée et quantitative d'analyse de l'existant et d'optimisation des performances.
Dans ce contexte, l'équipe data science recherche un data scientist jeune diplômé.

Missions :
participer à la mise en place et à la maintenance d'une infrastructure de mise à disposition des données et rapports aux équipes métiers
accompagner et former les utilisateurs métier aux réflexes analytiques et à l'usage des données enseigne
contribuer aux activités de conseil data de l'équipe en apportant ses compétences en développement des outils data engineering et de data science de l'équipe
proposer/contribuer à des études d'optimisation des performances de l'enseigne
Profil souhaité

Du fait de la variété de nos domaines d'intervention et de nos interlocuteurs, nous privilégions des profils certes techniquement complets mais ayant également les qualités requises pour notre activité de conseil interne. Au-delà donc de compétences techniques avérées, nous recherchons des capacités de communication et de pédagogie, de compréhension et d'interrogation des besoins métier, ainsi que des réflexes de management de la connaissance.
Programmation data, visualisation : Python, Numpy, Pandas, SQL, Jupyter, Matplotlib, Plotly
Apprentissage machine : Scikit-learn, Keras, Tensorflow
Autonomie et force de proposition
Goût prononcé pour l'innovation et l'expérimentation, curiosité
Une sensibilisation aux problématiques métier d'une enseigne de GSA serait appréciée
Poste
emploi
Poste basé à VITRY (France)"
Paris (75),"CDD, CDI",,Data Scientist,Heetch,- Paris (75),"ℹ️Important note before applying
For this role we are only considering candidates located in Paris or near Paris (+ 1h -) so they can come to the office, we’re cool to have you work a couple of days from home as well.

Data Science Team @Heetch

Deep learning, hyperparameter tuning, parallel computing? Let’s first get the buzzwords out of the way, at Heetch we care about maximizing the impact rather than hype. For us, a data scientist’s main strength lies more in their capacity to proactively seek out stakeholders and build relationships with them.
Our team’s mission is to provide valuable data insights to Product squads in order to help them understand what is going on, discover opportunities and take impactful decisions that will later on improve the whole experience for both our drivers and passengers.

Our team's values

Transparency: We discuss everything openly within the team. Our 'Speak up' culture is strong.
Learn from failures: It's ok to fail, learn from it and try again.
Experiment things: Being free is part of our DNA, we can try things as long as it brings value.
Caring is sharing: We believe in continuous learning and want you to be proud of what you've learned/built. Sharing is a natural part of the process.

What are the challenges Data Scientists face at Heetch?

Navigate through thousands of different datasets.
Identify hidden business opportunities proactively.
Motivate and/or automate data-driven decision-making.
Improve our rules and processes around data quality standards.
Work in one of the most competitive industries with a challenger status.

What will you do?

Inside a cross-functional team you will become an expert in your domain’s data.
Influence the team roadmap and priorities via product and business analysis.
Design experiments such as A/B tests.
Develop and present business intelligence dashboards.
Work alongside developers, designers, product managers.
Uncover hidden opportunities for growth and efficiency for Heetch.

Does it sound like you?

You have some data manipulation experience (regardless of languages and tools).
You create clear and powerful data visualizations (dashboards, presentations...)
You can communicate effectively with colleagues from various backgrounds and technical levels.
You enjoy specifying data manipulation pipelines to extract value for the company, whether it’s in the form of code, query languages, visual tools or documentation.
You want to steer the company in the right direction in terms of data quality standards.
You are fluent in English (it’s the language we use within the company, because hey we’re an international team )

What's next?

If your application is selected, the process will be composed of 4 steps:
1. Interview with a Technical Recruiter (45mn).
2. Take home assignment (~5 days deadline).
3. Interview with your future Data Science Manager (1h).
4. Half day on site (Paris) to meet your future teammates and stakeholders.
Heetch embraces diversity and equal opportunity for everyone We provide a safe and inclusive work environment. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills.
For non-European citizens, a valid working visa for France is required to be eligible for the role.

Heetch SAS is collecting your personal data (identity, contact details, academic background, professional experience and optionally a covering letter) for the processing of your application to our job offer, based on your consent.
Your personal data will only be accessible to our hiring team, our co-founders, and the manager of the position you are applying to. In addition, data are stored by our processor in order to use its applications tracking system. Your data may be stored outside of the EU/EEA but are protected by appropriated safeguards.
Your data are stored for a maximum duration of two years. If we do not reply to your application, you allow us to store your data during this term in order to potentially contact you for another position within our company or affiliates and subsidiaries.
You have a right to access to your data, to rectify them, under some conditions to erase them, and to limit the processing. Also, you have a right of portability on your data. In addition, you may revoke your consent and we shall stop processing your data. Eventually, you have a right to define directives about the fate of your data if your death should occur.
For more information about your rights, please see our privacy policy."
Hauts-de-Seine,CDI,48 000 € - 60 000 € par an,Data Scientist,PROFILE RESEARCH,- Hauts-de-Seine,"Rôle & Mission
Au sein de la Direction des Process, des Systèmes d’Information et du Numérique (DPSIN), nous recherchons un/une Data Scientist dans le but de constituer son équipe Big Data. Il/elle sera chargé(e) d’accompagner le Chef de Projet Big Data sur les activités suivantes (non exhaustives) :

Compréhension des enjeux stratégiques et accompagnement des métiers dans l’expression de leurs besoins,
Étude et identification des données de l’entreprise et des données externes qui permettront de répondre à ces enjeux,
Détermination des techniques d’analyse et élaboration des algorithmes correspondants,
Participation à la définition de l’architecture logicielle et technique des solutions à mettre en place,
Spécification et développement des visualisations adaptées à la restitution des résultats,
Communication et explication des résultats de ses analyses,
Veille sur les technologies liées à la Data Science.
Nos locaux sont situés à Issy-Les-Moulineaux. Des déplacements à l’international sont à prévoir (1 tous les 2 mois).
Profil recherché
Nous recherchons une personne diplômée d’école d’ingénieur ou disposant d’un diplôme similaire, spécialisée en informatique, en statistiques ou en mathématiques appliquées et justifiant d’une expérience significative (autonome sur la gestion des problématiques Big Data). Cette personne devra posséder un solide bagage autour de l’innovation et de la donnée.

Compte tenu de la dimension internationale du groupe, l’anglais courant est indispensable, ainsi qu’une capacité d’adaptation permettant d’évoluer favorablement dans un contexte multiculturel.

Une expérience à l’international ainsi que dans les secteurs d’activités du transport et/ou de la logistique seraient de sérieux atouts.

COMPETENCES RECHERCHEES

Afin d’atteindre les objectifs qui lui sont assignés dans le cadre de ses missions, le/la Data Scientist devra démontrer les compétences suivantes :

Savoirs-être :
Curiosité intellectuelle
Bon relationnel
Travail en équipe
Capacité d’adaptation
Capacités de vulgarisation et de communication
Compétences techniques :

Indispensable :
Solides connaissances en analyse et modélisation de données (probabilités, statistiques…),
Maitrise des techniques d’exploitation de la donnée, avec une expérience sur des technologies Big Data (Hadoop, Spark, …)
Bonne connaissance des langages de programmation Python et/ou R
Bon niveau de SQL (idéalement sur Teradata)
Atout :
Connaissance d’un ou plusieurs ETL (Extract, Transform & Load)
Connaissance d’un outil de visualisation de données (idéalement Tableau software)
Connaissance des environnements Linux"
Montigny-le-Bretonneux (78),,,Data Analyst / Scientist (H/F),Alltricks,- Montigny-le-Bretonneux (78),"Alltricks poursuit son ascension vers les sommets du e-commerce français du vélo, du running et de l’outdoor. Pour continuer sa croissance, renforcer son excellence opérationnelle et partir à l’assaut de l’Europe, Alltricks cherche son futur Data Manager (H/F) !
TES MISSIONS
Au contact quotidien de toutes les équipes d’Alltricks et de la direction, le Data Analyst / Scientist est responsable du flux de data entre les sources de données internes/externes et le logiciel de business intelligence (Power BI). C’est lui aussi le principal consommateur de data puisqu’il réalise et diffuse les données et analyses au sein de l’entreprise.
Chez Alltricks, le principe du poste est d’intervenir là où la data peut améliorer l’expérience client ou simplifier les processus.
Les activités du Data Analyst couvrent trois domaines à développer avant de former une équipe :
Data Engineering – Population / Exploitation de la base de données de BI
Collecte de données depuis toutes les sources (BDD de l’ERP et du Site, mails, API…),
Organisation des flux et de la séquence de chargement,
Définition et calcul des KPIs métiers,
Evolution de la base et des outils en collaboration avec les équipes IT.
Data Analysis – Etudes / Aide à la décision
Suivi des KPIs, élaboration d’alertes automatiques et d’outils de suivi des processus,
Reporting opérationnel : mesures d’efficacité/efficience de l’entreprise et des processus, étude du catalogue, suivi des coûts, suivi des achats et des stocks, mesures de productivité,
Reporting commercial en collaboration avec la direction et le Business Analyst : suivi des ventes, optimisation des achats, études de la clientèle, étude des campagnes marketing et commerciales, pricing.
Data Science – Automatisation / Classification / Prévisions
Automatisation des processus internes,
Segmentation de la base clients, étude du parcours d’achat et propositions de parcours clients,
Prévisions du volume d’affaire,
Développement de l’utilisation du Machine Learning et de l’Intelligence Artificielle.
TON PROFIL
Tu es de formation Bac+5.
Touche à tout, tu as un goût prononcé pour l’algorithmie et l’analyse de données.
Bon communicant(e), tu souhaites t’épanouir dans un poste à mi-chemin entre technique et business.
Tu sais aussi être à l’écoute et êtes créatif pour proposer rapidement des solutions techniques.
LES + POUR NOUS CONVAINCRE
Tu as une sensibilité e-commerce (acheteurs online compulsifs acceptés)
Tu as envie de participer à un projet ambitieux dans un environnement en croissance permanente et d’en relever les challenges
Tu aimes travailler dans la joie et la bonne humeur
QUI SOMMES NOUS ?
En 2008, Gary Anssens s’est lancé le pari de créer une entreprise 100% française spécialisée dans la distribution d’articles de sport. Tout d’abord experte dans le cycle, l’entreprise s’est diversifiée dans les domaines du running en 2015 et des sports outdoor en 2017. Notre objectif ? Proposer le plus large catalogue de ces disciplines au meilleur prix. Et voici le résultat : Alltricks.fr a été classé meilleur site e-commerce dans sa catégorie par le magazine Capital en 2019, et on n’est pas peu fier !
Notre camp de base est situé à Montigny-le-Bretonneux, à 30 minutes de Paris, et la partie logistique à Châteaudun en Eure-et-Loir. Nous proposons de même 2 magasins proches de la région parisienne et détenons 1 franchise dans le sud de la France.
Composée d’une équipe jeune et passionnée, évoluant dans une ambiance conviviale, Alltricks c’est plus de 140 collaborateurs qui font de la satisfaction client leur priorité au quotidien. 3 grandes valeurs sont partagées lors de cette aventure : la passion, l’innovation et la cohésion (PIC).
Les Alltricksiens/Alltricksiennes te proposent :
Des sorties sportives quelle que soit la météo : sessions running le midi, sorties VTT ou vélo de route le soir, balades en Stand Up Paddle sur le lac de Saint-Quentin-en-Yvelines… Mais aussi des afterworks au bloc d’escalade à 2 pas du bureau ou courses-poursuites sur la pumptrack qui trône au centre de l’openspace … Bref il y a de quoi faire !
Des remises staff exceptionnelles toute l’année (encore mieux que les soldes !)
Une Alltricks Academy tous les mois dédiée à l’intervention d’hommes et de femmes inspirants, avec lesquels tu pourras échanger sur différentes thématiques : innovation digitale, levée de fonds, engagement et responsabilité sociétale, entrepreneuriat, made in France, e-commerce…
Des défis en tout genre 1 fois par mois : concours du meilleur pâtissier, compétition de ping-pong, de Mario Kart, initiation à la Slackline etc…
Des locaux proches de nombreux parcs et lacs (en étant seulement à 30 minutes de Paris),
Et une équipe passionnée et dynamique qui se fera un plaisir de t’accueillir.
MODALITÉS DE L’OFFRE
Poste basé à Montigny-le-Bretonneux (Saint-Quentin en Yvelines).
30 minutes de La Défense et à 25 minutes de Montparnasse !
CDI – 39h – Rémunération selon profil
CV et lettre de motivation à envoyer à recrutement@alltricks.com"
La Garenne-Colombes (92),"Temps plein, Stage",800 € - 1 100 € par mois,Quantitative Analyst,ExpertEye,- La Garenne-Colombes (92),"Quantitative Analyst (Internship)
Context
ExpertEye offers a range of research and financial products that help companies in the automotive and leasing sector monitor risks and maximize profits. Our ccustomers, all over Europe, use interactive web-based reporting tools to track their competitive position, identify market movement and benchmark against their own data. Over its 15 years of existence, the company developed a strong expertise.
While working closely both with the Operation Director located in La Garenne Colombes (92250) and with the rest of the team located in the UK, you will maintain and develop ExpertEye’s data infrastructure to support the development of new financial products.
Main Activities
Concretely, you will use SAS, Python and Excel/VBA to perform following tasks :
- Develop and run data compilation process on SAS to build internal dataware (multiple inputs standardized)
- Develop statistical models (regressions, linear optimization, PCA..) on SAS to follow and forecast used car prices evolution.
- Build Machine Learning models to forecast vehicles residual values
- Develop diverse python algorithms to map the data through advanced text mining methods
- Perform ad-hoc pricing studies and build reports for the industry (Leasing Companies and Car Manufacturers)
- Coordinate technical tasks with the Operation team in the UK
Skills / Profile
- Master’s degree in Mathematics, Statistics, Finance or Computing Sciences.
- Good skills in SAS, SQL, VBA, preferably also in Python.
- Fluent French and English level required.
- Strong analytical skills & ability to take initiatives
Job Interest
This position offers an opportunity to work in an international context while being close to operational issues. You will expand your analytical skills and develop a real pricing and car knowledge. You will improve your communication skills through regular contacts with the teams located in Europe. The working environment is flexible and relax. If you are passionate by data crunching and if you like cars on top, the job is made for you!
Job Types: Full-time, Internship
Salary: 800.00€ to 1,100.00€ /month
Experience:
quantitative analyst ou similaire: 1 year (Preferred)
Language:
English (Required)
Work Remotely:
Yes"
La Défense (92),CDI,,Data Analyste dans le domaine des transports et de la logistique F/H,Orange,- La Défense (92),"La croissance très importante des volumes de données transitant sur le réseau est à la fois une contrainte pour le dimensionnement des infrastructures et une opportunité de création de valeur pour l'opérateur. Aujourd'hui de nombreux services existent liés à l'analyse de la mobilité basée sur l'exploitation anonymes des données de fonctionnement du réseau.
Ces services nécessitent la conception et la mise en oeuvre de nouvelles technologies, de nouveaux algorithmes et de nouveaux modèles liés à la fois au monde des télécommunications, de l'informatique, de la recherche opérationnelle, de la géomatique.
Dans le cadre de sa croissance dans le domaine du transport et de l'aménagement du territoire, l'équipe Flux Vision d'Orange Business Services recherche une personne ayant une expérience significative dans l'un de ces domaines et dans l'analyse de données.
Description de la mission:
Au sein de l'équipe offres sur mesures, votre rôle consistera à analyser les besoins métier des clients potentiels de la solution Flux Vision dans les domaines du transport et de l'aménagement du territoire et à mettre en oeuvre une solution technique permettant de répondre à ces besoins en collaboration avec d'autres data analystes et des équipes de développement.
Vos principales activités seront :
L'analyse des besoins des clients sur les offres Flux Vision dans les domaines du transport et de l'aménagement du territoire
La production de modèles et de référentiels métiers sur ces offres
L'analyse, la représentation et la qualification des résultats
La participation à la spécification et la qualification de nouvelles fonctions métier à automatiser dans l'offre Flux Vision
La participation à la relation client
Le travail en coordination avec les équipes de développement et les équipes d'exploitation
about you
Vous êtes titulaire d'un Bac+5 master ou école d'ingénieur dans le domaine de l'analyse de données, des transports, de la planification. Vous avez une expérience significative dans la mise en place ou l'analyse de modèles de mobilité ou d'optimisation de la planification. Vous avez idéalement de l'expérience dans le développement ou le prototypage sous Python.
Dynamique, doté(e) d'un bon relationnel, vous aimez travailler en équipe. Vous souhaitez intégrer une structure qui saura être à l'écoute de votre potentiel et qui vous permettra d'évoluer, alors envoyez sans plus attendre votre candidature.
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Paris 9e (75),Stage,,Data Analyst - Corporate Financial Planning & Analysis Intern,Criteo,- Paris 9e (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

Overall

As Criteo’s business scales ever faster, the Financial Planning and Analysis (FP&A) team is strongly engaged in providing both analytical input to important strategic decisions as well as assisting business leaders with all finance-related matters. This includes developing financial forecasts and analysis, generating internal management reports and monitoring key performance indicators. We also provide decision support and conduct financial reviews on a wide range of business topics. As part of the Finance department, FP&A is actively involved in implementing and promoting locally the processes that support business needs and the Criteo organization. The role will be based in Paris and its scope worldwide.

Enjoy our very international and dynamic environment in a dynamic internet company, led by a worldwide team of trend-setting professionals
Unique opportunity to participate in a major processes and tools upgrade, from SME practices to multinationals’ standards

Based in our offices in Paris, you will support the FP&A Corporate team on the following missions:
What You Will Do
Extract truthful insights from data to support the Corporate FP&A Team on data analytics and KPI production
Support quarterly forecasting and monthly reporting processes
Develop internal tools to automate and streamline routine work and existing processes to improve overall efficiency
Assisting the team with ad-hoc reports, data analysis, presentation and projects.
Help to develop and evaluate new financial reporting and KPIs analysis in order to support Management’s business decisions

Who You Are
Bachelor’s degree (Bac +5 – business /engineering school) with strong analytical skills
You have strong analytical, problem solving and critical thinking skills
You have solid Excel experience
SQL and usage of data analysis tools and techniques is a strong plus
Knowledge of SAP reporting will be helpful
Quick learner, pro-active and well organized
Ability to work well individually as well as in a team environment
Excellent communication skills in both French and English

Why You'll Love Us
We are innovative, passionate, driven and adaptable
Our core values are at the heart of who we are: we have a spontaneous and vibrant culture and we truly believe in team spirit and collaboration
Competitive compensation
No suits here, adopt your style
Career advancement opportunities
A large community of interns and apprentices to create your own small network

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Paris (75),,,Data Scientist,CAST Software,- Paris (75),"Data Scientist - France / Paris
CAST est le leader du marché de la Software Intelligence.
Sa technologie unique permet d'analyser en profondeur la structure et le fonctionnement interne des systèmes logiciels complexes, avec une précision comparable à celle d’une IRM.
Il fournit automatiquement des renseignements précis et exploitables sur les applications logicielles : architecture , liste des défauts critiques et failles, grades de qualité ou sécurité, et révèle les composants open source ainsi que leur aptitude à migrer vers le cloud.
Des centaines d'entreprises font confiance à CAST pour prendre des décisions critiques , définir avec confiance la trajectoire de modernisation de leurs applications et accroître la résilience, la qualité et la sécurité de leurs logiciels.
CAST opère à l’échelle mondiale avec des bureaux en Amérique du Nord, en Europe, en Inde et en Chine. Les meilleurs cabinets de conseil, Entreprises de Services du Numérique et fournisseurs de solutions Cloud s'appuient de plus en plus sur CAST pour une plus grande objectivité et des actions de transformation plus rapides.
CAST, éditeur de logiciels, numéro un mondial de l'analyse et de la mesure logiciel (code, architecture, transactions, structure de données …) recherche un Data Scientist qui sera rattaché(e) à l’équipe analyseurs de code source.
En tant que Data Scientist, vous avez les responsabilités suivantes :
Identifier les champs d’applications possibles de manière non exhaustive :
l’application de technique d’analyse de langues naturelles à l’analyse du code source
l’extraction de « topics » fonctionnels et techniques à partir de code source
l’architecture recovery
Proposer et réaliser des pilotes
Accompagner la mise en œuvre et le déploiement en production.
L’objectif est donc d’appliquer des approches nouvelles et non classiques en analyse de code afin d’extraire de l’information pertinente.
Basé à Meudon, 92 (tramway T2 :15 minutes depuis la défense, 12 minutes depuis la Gare Montparnasse), vous intégrez une équipe de 15 personnes au sein des analyseurs de code source.
Pourquoi CAST ?
Ce poste vous permet de travailler au cœur de notre produit phare : le logiciel CAST AIP au sein d’une R&D de pointe, solidement établie.
Dans un cadre de travail convivial, intégré au plus important centre de R&D en analyse et mesure logiciel au monde (160 personnes en développement, tests, support et intégration, réparties sur 3 sites : Paris, NYC, Bangalore), Vous profitez de 25 ans d’expertise en ingénierie logicielle.
CE QUE NOUS RECHERCHONS :
Une personne ayant des connaissances/expérience en data science et machine learning
Maitrise d’au moins un langage de préférence Python
A PROPOS DE L’EQUIPE
Nous développons des analyseurs de code source sous forme de plugins à la plateforme CAST AIP.
En relation étroite et directe avec les utilisateurs, nous leur livrons, en continu, ce qui répond en priorité à leurs besoins immédiats.
Dans un esprit Lean et eXtreme Programming :
nous nous imposons le moins de process inutile
nous écrivons la documentation utilisateur
nous remercions nos testeurs d’avoir trouvé des bugs, qui viennent ensuite remplir notre base de tests unitaires.

Apply for this opening"
Neuilly-sur-Seine (92),CDI,,Data Scientist H/F,JCDecaux FR,- Neuilly-sur-Seine (92),"Au sein de la nouvelle Direction Data, chargée de l'exploitation et de la valorisation des données à travers le groupe, nous recherchons un Data Scientist H/F pour intégrer une équipe dynamique en forte croissance composée de Data Engineers, Data Scientists, Data Analysts.

Au quotidien vous serez amené à :

Désigner et créer des algorithmes, construire des modèles, prototyper les solutions imaginées sur des données hétérogènes et mondiales ;
Travailler en équipe avec les Data Scientists de la Direction Data ;
Identifier de nouvelles sources de données pertinentes, proposer des use cases innovants ;
Interagir étroitement avec les Data Engineers de la Direction Data et de la DSI pour l'intégration, mise en production des outils et algorithmes ;
Développer vos prototypes directement sur notre plateforme Big Data.

Vous aurez la chance de participer à la mise en place de cette Direction, et interviendrez sur l'ensemble de la chaine Data à nos côtés.
Profil
Amoureux de la Data, passionné par ses utilisations, avec un esprit innovant et autonome. Vous cherchez à relever un défi et êtes motivé par les challenges en perspective.

De formation Bac +5 minimum de type école d'ingénieur, vous avez au moins une expérience préalable dans le traitement de données en industrie, avec le développement d'algorithmes sur une infrastructure Big Data.

Vous avez une connaissance des modèles de Machine Learning aussi bien théorique que pratique, et avez le désir d'approfondir ces compétences.

Compétences requises :

Connaissance pointue en Machine Learning, Artificial Intelligence, Econométrie avec des expériences d'utilisations sur données réelles ;
Capacité reconnue à travailler avec les langages tels que Java, Python, Scala, etc. et sur les infrastructures Big Data ;
Compréhension fine des enjeux business ;
Habilité à communiquer sur les algorithmes et les applications développées à des non experts (anglais & français) ;
Force de proposition et esprit innovant ;
Expérience de travail en équipe.

La maîtrise de l'anglais est indispensable pour ce poste à dimension internationale.
Localisation du poste
Localisation du poste
France, Ile-de-France, Neuilly
Critères candidat
Niveau d'études
Bac +5 et plus
Diplôme
DESS / DEA / Master
Niveau d'expérience global pour le poste à pourvoir
1ère expérience (de 1 à 3 ans)"
Levallois-Perret (92),CDI,,Consultant confirmé Data Scientist – H/F,Micropole,- Levallois-Perret (92),"WIDE est une agence digitale de marketing relationnel qui intègre les expertises fondamentales liées à l’Expérience Client : conseil stratégique, Data Science, CRM, Design/UX, conseil et production techniques.
Pour accompagner notre croissance, nous recrutons des Consultants Confirmés Data Scientists.
Pour WIDE, la connaissance client à travers la Data Science est au cœur de l’expérience client/Visiteur. Nos Data Scientists ont donc un rôle essentiel pour accompagner nos clients sur des projets digitaux et data d’envergure.
Vos missions :
Au sein d’une équipe jeune, motivée et solidaire encadrée par des experts en Data Science, nos Data Scientists travaillent sur des projets innovants allant de la modélisation au Big Data en passant par le web analytics, le text mining ou l’analyse de parcours client.
Vous serez ainsi amené à échanger avec les différentes équipes de l’agence (Digital, CRM, Création …) afin de garantir une utilisation efficace des études réalisées pour nos clients.
Vous accompagnerez nos clients en autonomie sur les problématiques suivantes :
La réalisation opérationnelle de projets orientés Connaissance Client et Data Science : préparation des données, constructions de scores et de segmentations, réalisation d’études et analyses des différents résultats.
Mesurer l’efficacité des différentes actions marketing et digitales mises en place.
Contribuer à l’expérimentation de l’utilisation de nouvelles données (non structurées, sociales, log webs…).
Rédiger des premiers niveaux de recommandations opérationnelles suite aux différentes études effectuées.

Votre profil :
Vous justifiez d'une expérience minimum de 4 ans sur un poste similaire.
A l’aise avec les nouvelles technologies, vous avez une expérience d’au moins 2/3 ans, dans le domaine du conseil ou chez un client, au cours de laquelle vous avez eu l’occasion de participer à des projets liés à l’exploitation de la donnée.
Vous maîtrisez les principales techniques Datamining (Analyses factorielles, Typologies, Arbres de décision, Régression logistique, Radom Forest, Séries temporelles...).
Vous connaissez a minima un ou plusieurs outils/langages statistiques : SAS, R, Python
Vous avez le goût du travail en équipe, et êtes dynamique, autonome, organisé et rigoureux.

Vous disposez d’un niveau d’anglais opérationnel, à l’oral comme à l’écrit.
Vous êtes bien sûr passionné par le digital et êtes en veille permanente sur les évolutions du marché.
Vous savez être force de proposition et avez une vraie volonté de travailler sur des projets stratégiques.
Depuis 2015, Le Groupe Micropole est labellisé Happy Trainees et happy at Work for Starters.
En 2018, le Groupe est une nouvelle fois propulsé dans le top 10 des entreprises françaises où il fait bon démarrer sa carrière !
#LI-CD1"
Paris (75),CDI,,Consultant Data Science F/H,OCTO Technology,- Paris (75),"Vous êtes persuadé que la Data Science est un outil puissant pour adresser des problématiques métier complexes, et ainsi aider nos clients à créer davantage de valeur. Rejoignez-nous !
Profil recherché
F/H
Vous êtes diplômé de l’enseignement supérieur avec une spécialisation mathématiques appliquées, statistiques, économétrie, recherche opérationnelle, data science, etc.
Vous maîtrisez les familles d’algorithmes de Data Science et les principales implémentations.
Vous avez des compétences éprouvées en programmation orientée data (Python et/ou R)
Votre démarche conseil vous permet d’être force de proposition et d’apporter de la valeur ajoutée à nos clients.
Vous avez démontré de vraies capacités d'analyse, de synthèse, d'écoute et de communication. Vous êtes capables d’expliquer simplement des modèles et des résultats complexes.
Vous êtes reconnu par vos pairs comme étant rigoureux, curieux et autonome.
Détails de l'offre
Type de poste : CDI
Lieux : Paris, Île-de-France (FR)
Descriptif du poste
En tant que Consultant au sein de notre équipe Data Science & Advisory, vous serez amené à :

Accompagner nos clients dans l’émergence et le cadrage de cas d’usage métier adressables par la donnée.
Identifier et implémenter les approches scientifiques et analytiques pertinentes (solutions basées sur des règles métier, des algorithmes de Machine Learning, de l’optimisation sous contraintes, …) permettant d’adresser au mieux les problématiques métier dans une logique de création de valeur pour nos clients.
Partager et communiquer sur les résultats de vos travaux en interne et auprès du client.
Participer à la mise en production des cas d’usage dont la valeur aura été démontrée.
Participer à la rédaction des réponses à appels d’offres et aux soutenances d’avant-vente.

En intégrant OCTO, vous rejoignez un écosystème capable d’adresser toutes les problématiques autour de la data, de l’émergence de cas d’usage à leur mise en production.

Mais ce que nous cherchons avant tout, ce sont des personnalités qui enrichiront OCTO. Nous les reconnaissons à leur volonté de participer à l’amélioration de la vie de l’entreprise, de construire la vision et les offres de demain, de partager leurs connaissances pour faciliter la montée en compétences réciproque. De rejoindre, enfin, une communauté qui n’a pas peur d’affirmer sa différence."
La Défense (92),CDI,,DATA SCIENTIST CONFIRME- F/H,Ingeniance,- La Défense (92),"Contexte :
Pour soutenir le développement de solutions numériques, le service de transformation digitale d'un de nos clients lance un programme de transformation:
Fournir de nouveaux services à la clientèle, basés sur l'utilisation d'analyse des données prédictives ou prescriptives, d'intelligence artificielle et de capacités de distribution innovantes.
Soutenir le processus de prise de décision (finances, risques, marketing, ...) et l'amélioration de l'expérience client
Optimiser les processus opérationnels : Faciliter la communication avec des partenaires externes et des régulateurs
Au sein du programme Smart Data, l'équipe Data Research a pour objectifs:
Intervenir en amont sur les POC/MVP pour réaliser des études de faisabilité basée sur les données disponibles pour établir des modèles validant les hypothèses de l'initiative.
Participer à la réalisation de solution au sein des équipes agiles en charge de la mise en oeuvre des MVP
Mener en tâche de fond des études exploratoires sur la donnée disponible, éventuellement enrichie de données externes pour détecter des opportunités pouvant constituer une 'Business Value'
et donc pouvant inspirer de nouveaux Uses Cases
Assurer l'activité de modèle management pour garantir une cohérence entre les différents modèles implémentés au sein du programme Smart Data, documenter les modèles utilisés, diffuser les bonnes pratiques.
Assurer une veille technologique en data science

Missions:

L'équipe veut se renforcer avec un Data Scientist dont les objectifs seront de valoriser les données du métier à travers les actions suivantes:
Travailler avec les métiers pour bien comprendre les use cases proposées par les métiers, les objectifs attendus et établir les critères de succès,
L'identification auprès des métiers, des data sources qui permettront d'alimenter les uses cases
Processing, nettoyage et vérification de l'intégrité de la donnée utilisée pour l'analyse.
Développer des algorithmes de classification, de prédiction ou des analyses basées sur les données à disposition.
Travailler à rendre les résultats des modèles compréhensibles par le métier
Packager et documenter les modèles
Respect des exigences de sécurité et de conformité.
Partager ses connaissances sur le domaine d'expertise au sein de l'équipe
S'inscrire quand ce sera nécessaire au sein d'équipes agiles(Scrum) pour y apporter son expertise
Profil recherché:
Niveau de formation Bac + 5
Expérience professionnelle 3 ans minimums
Expérience dans la fonction 2 ans
Très bonnes compétences en data science, mathématiques et en statistiques.
Maîtrise des algorithmes de machine learning: Scikit-Learn, TensorFlow, etc.
Maîtrise des langages de programmation et d'analyse de données Python et R
Maîtrise de la stack HADOOP et de son écosystème
Bonne connaissance des réseaux de neurones et d'intelligence artificielle
Maîtrise des bases de données SQL et no-SQL
Maîtrise des outils d'analyse de données ELK
Maîtrise des outils de data visualisation: Kibana, Tableau, Power BI, etc.
Connaissance des frameworks NLP: NLTK Google Cloud NLP API
Anglais courant: nombreuses réunions et call en anglais


INGENIANCE est une société jeune et dynamique qui stimule l'innovation et la transformation digitale par l'accompagnement de ses clients dans leurs projets liés aux nouvelles technologies.

Spécialiste des secteurs Banque, Finance et Assurance, INGENIANCE est également une entreprise technology-oriented qui offre une expertise multi-sectorielle autour du Big Data, du développement informatique, de la Blockchain et de la philosophie DevOps.

Ceci permet à INGENIANCE de se positionner comme une entreprise leader du marché financier et avant-gardiste des technologies disruptives."
Paris (75),CDI,,DATA SCIENTIST,Nextedia,- Paris (75),"Véritable Data Scientist, vous analysez et exploitez tous types de données pour le compte de nos clients (données transactionnelles, digitales, CRM, Produits, Open data…).
Vous développez des algorithmes sur mesure adaptés aux enjeux business de nos clients.
Vous déployez les méthodes de Machine Learning pour répondre aux objectifs marketing.
Vous travaillerez sur les domaines suivants :
Segmentation clients
Analyse des parcours clients omnicanal, des cycles de vie
Moteurs de recommandations produits
Modèle de repricing (Yield management)
Scores prédictifs (attrition, appétence, repeat business…)
Modèle d’attribution et de contribution des canaux de conversion
Vous restituez les résultats à nos clients dans le respect des engagements de qualité et de délai.
PROFIL
De formation supérieure en statistiques, avec minimum 5 ans d’expérience dans des fonctions similaires :
Vous maîtrisez les méthodes statistiques et leurs applications opérationnelles, ainsi que les principaux outils statistiques du marché comme R, Python…
Curieux, vous êtes capable d’appliquer les méthodes statistiques de Data Science pour répondre aux enjeux marketing et business de nos clients"
Paris (75),CDI,,Data Science Consultant,Nova Consulting,- Paris (75),"CDI
Nova Consulting :
Créée il y a 12 ans, Nova Consulting est une « Boutique » de Conseil en Stratégie, spécialisée dans l’analyse de la performance et l’optimisation
de la rentabilité des investissements dans des secteurs dotés d’une forte part d’irrationnel et d’émotion : la Culture, le Sport, le Tourisme et les
Marques. Le cabinet accompagne chaque année sur des problématiques diverses une quarantaine de directions générales de groupes du CAC
40 ou de marques de niches emblématiques de grandes institutions culturelles, sportives ou touristiques et de collectivités locales.
Depuis sa création, le Cabinet a développé une expertise ainsi que des méthodes quantitatives et statistiques reconnues dans ces quatre
secteurs, dont la combinaison permet la conception de stratégies « sur-mesure », à la fois innovantes et rentables. Nova Consulting accompagne
tous ses clients avec le même niveau d’exigence et d’engagement, depuis la phase de définition de leur stratégie jusqu’au pilotage de sa mise
en œuvre.
Le cabinet est en très forte croissance (> 40% par an depuis sa création) : le succès du développement de Nova repose sur une fidélité
remarquable de ses clients (78% de son CA est réalisé par des clients de plus de 3 ans) et une expertise sectorielle unique qui permet une
conquête très forte (71% de succès sur proposition commerciale depuis 2 ans).
Pour soutenir cette croissance et son ambition, Nova est structuré autour de 4 principaux managers associés :
Un Président (25 ans d’expérience : L’Oréal, BCG, Havas)
Un Directeur Général (25 ans d’expérience : Senior Partner au BCG)
Un Directeur Associé du Pôle Marques (22 ans d’expérience : L’Oréal, Unilever, McKinsey, Accenture Strategy)
Un Directeur Associé du Pôle Entertainment (20 ans d’expérience : Centre Pompidou)
Le Pôle « Marques » accompagne chaque année ses Clients dans la définition et la mise en œuvre de leur stratégie. Grâce à des compétences
sectorielles approfondies et des méthodologies reconnues, le pôle « Marques » aide ses clients sur différentes problématiques (Stratégie
CRM/PRM, ROI, études de marché, plan stratégique, modèles prédictifs, segmentations…).
Le cabinet a structuré en 2018 un pôle Data regroupant toutes les expertises dédiées du cabinet en vue d’accélérer la transformation de ses
clients sur ces problématiques. Vous intégrerez ce nouveau pôle composé de 2 à 3 data scientists. Votre poste présentera donc une forte
dimension intrapreneuriale avec la responsabilité de structurer ce pôle.
En lien avec les Consultants, voici les principales missions auxquelles vous participerez :
Gestion de bases de données et modélisation de modèles statistiques fiables (segmentation, scores, modèles prédictifs…)
Développement de scripts d’analyse de données en SQL et optimisation des modèles
Création de nouveaux modèles d’analyses de données
Participation au développement de nouveaux outils permettant l’automatisation des analyses et des travaux
Gestion de la qualité et de l’intégrité des données
Participation à la présentation des solutions aux clients
Au sein de l’équipe Data Science, avec une forte vision business appliqué, vous serez également en charge de :
Contribution aux initiatives de R&D Data du cabinet
Publications de travaux de recherche sur des sujets d’innovation en lien avec nos secteurs (revues spécialisées, etc.) et en lien avec
des acteurs de références sur ces problématiques (Professeurs, chercheurs, etc.)
Travail avec Nova le Lab sur des partenariats avec des start-ups et entreprises de la tech de premier rang
Contribution à des éventuels Tech Tour, Hackathon, etc.
Proposition de nouveaux business cases pour Nova le Cabinet
Profil recherché :
Ecole d’ingénieur ou de commerce de premier rang
Niveau avancé en statistiques
Bonne connaissance des outils statistiques (SPSS, R…)
La connaissance des langages de programmation (Python, SQL…) est un plus
Vous êtes passionné (e) par les nouvelles technologies liées à la Data : Business Analytics, Analyse prédictive, construction et
exploitation de base de données SQL à forte volumétrie
Vous avez idéalement une expérience de stage au cours de laquelle vous êtes intervenu (e) sur le domaine de la « Data »
Vous avez un excellent sens du travail en équipe
Date de prise de fonction : Candidature :
Dès que possible
Pour postuler, remplissez le formulaire de candidature à l’adresse
Lieu : suivante : https://www.nova-consulting.eu/offres
Paris 4ème
Nova Consulting
Rémunération : 20, rue Sainte-Croix de la Bretonnerie, 75004 Paris / site :
Rémunération très attractive www.nova-consulting.eu"
Paris 14e (75),CDI,,Consultant Data Marketing F/H,ANALYSE INFORMATIQUE DE DONNEES,- Paris 14e (75),"AI&Data recherche aujourd'hui des chef de projet Marketing avec une appétence pour la Data et le CRM.

A ce titre, nos consultants aident les entreprises à tirer le meilleur parti des données, à mettre en place des solutions opérationnelles, à identifier et mettre en oeuvre les projets liés à la transformation digitale.

Il s'agira d'intégrer notre Practice Conseil composé d'une dizaine de personnes passionnées ""data driven"", technophiles et dynamiques.

Sur ce poste, vous serez amené à intervenir pour de grandes entreprises sur des projets à forte valeur ajoutée :

CRM Analytique : collecte et analyse des données clients
CRM onboarding
Marketing & Fidélisation : parcours et expérience client, roadmap data de la transformation digitale, intégration des besoins métier dans le marketing opérationnel... .
Conseil technologique : conduite du changement, accompagnement des évolutions technologiques des directions marketing, aide au choix d’outils… .
P.O.C. : définition des besoins métier, hiérarchisation, accompagnement à la mise en oeuvre, bilan.
Profil recherché De formation supérieure en statistiques et mathématiques, vous justifiez d’au moins 2 années d’expérience acquises dans le traitement des données et les études statistiques, idéalement en société de services, dans un département de type « connaissance client » ou R&D.

Vous avez impérativement déjà pratiqué la programmation R (dont R shiny) et PYTHON (idéalement d’autres logiciels comme SPSS Modeler, SAS, JMP).

Vous maîtrisez le requêtage en SQL.

Une première expérience avec les technologies Big data spark (sparkr-sparklyr,Pyspark), hadoop, hive, ou des méthodes d’analyse de séquences serait un plus.

Vous souhaitez vous investir dans des projets challengeants, monter rapidement en compétences, avec la possibilité de gagner en responsabilités, ce poste n'attend que vous.

La société est depuis quelques années en pleine croissance et cultive son esprit start up et son ambiance conviviale. Baby foot, table de ping pong, workshops internes et afterworks font partie de nos rituels d'entreprise.

Vous baignerez alors dans un environnement de travail idéal pour développer votre créativité et prendre des initiatives.

Je vous invite à consulter notre site et nos réseaux sociaux (Cf ci-dessous) et à revenir vers moi pour échanger sur nos opportunités.
Entreprise AI&Data, Agence Data et Datascience

AI&Data possède trois domaines d'expertise : Datascience, CRM et Big data.

1er hébergeur de bases de données marketing et de datalakes en France cumulant plus de 220 millions de clients et plus de 45 milliards d’interactions.

AI&Data offre une chaine de valeur complète autour de l’analyse, du traitement, de l’exploitation et de la transformation des données en performance marketing.

Opérant des données clients dans plus de 12 pays, AI&Data travaille avec les plus grands des secteurs des télécoms, de l’énergie, de la banque, de l’ hôtellerie, des jeux et des loisirs."
Paris (75),CDI,,CDI - Data Scientist - Stratégie Data et IA (H/F),BPCE SA,- Paris (75),"Le Groupe BPCE, deuxième groupe bancaire en France, s’appuie sur deux réseaux de banques commerciales coopératives, autonomes et complémentaires : celui des 14 Banques Populaires et celui des 16 Caisses d'Epargne. Il est un acteur majeur de la banque de grande clientèle, de la gestion d’actifs et des services financiers avec NATIXIS.
Le Groupe BPCE compte 31 millions de clients et bénéficie d’une large présence en France avec 7 800 agences, 106 500 collaborateurs et plus de 9 millions de sociétaires.
BPCE SA, l’organe central commun aux Caisses d’Épargne et aux Banques Populaires, est en charge de la stratégie, de la coordination et de l’animation du groupe.

Poste et missions
Au sein du Pôle Digital & Data, vous rejoindrez la nouvelle direction Stratégie Data et IA dont fait partie le département Data Science.
L’équipe Data Science est garante des principes et de la cohérence d’ensemble, elle a une fonction d’orchestration et contribue aux projets data multi-acteurs.
Rattaché(e) au responsable du département Data Science de la direction Stratégie Data et IA, en intéraction forte avec les différents acteurs de la Data du Groupe et avec les Business Owners des produits (métiers), vous aurez pour missions de :
Contribuer à l’identification des besoins et des problématiques des directions métiers,
Intervenir directement, en lien avec les Métiers, sur des projets de Data Science pour définir des orientations méthodologiques ou valider des choix d’approche,
Interagir avec les équipes IT, en tant que client de plateforme et outils Big Data (expression des besoins associés à l’outillage data science) et en tant que contributeur à l’industrialisation des projets,
Mener des actions de recherches sur des technologies de pointes, de nouvelles sources de données et prototyper des solutions « sur étagère » au service des entités du Groupe,
Réaliser une veille active à des fins de R&D (à la fois sur les outils et les méthodes de data science), dans le cadre des partenariats et de manière directe.

Profil et compétences requises
Fort d’une première expérience d'au moins 2 ans en tant que Data Scientist, vous maîtrisez les langages et outils suivants :
Python, R, Java…,
Librairies de machine learning (Scikit-learn…) et manipulation de données (Pandas…),
Langage de calcul distribué (Spark, Hive…) en environnement Hadoop,
Outils de DataViz.
Vous connaissez également :
Les techniques de machine learning de segmentation et de prédiction,
Les méthodes de développement informatique,
Une expérience en analyse sémantique ainsi que la connaissance des problématiques propres au secteur bancaire serait des plus.
De plus, vous appréciez travailler en équipe sur des projets multidisciplinaires. Vous êtes reconnu pour votre capacité à communiquer de manière pédagogique sur des sujets complexes."
Paris (75),CDI,70 000 € par an,Data Engineer Machine Learning – Marketplace - H/F,WAKE IT UP,- Paris (75),"Amazon-machine-learning / Java / Scala / Spark / Python
Data Analyst, Data Engineer, Big Data Developer / CDI / Environ 70k€ / 7+ / Paris

Le poste
• Créé dans les années 2000, ce groupe mondial est un des leaders des Marketplaces au niveau international. La société possède plus de 15 Marketplaces. • Au sein de leur DSI, ils ont une équipe DATA qui représente le cœur des tous les sites Web et ce sont les spécialistes Data pour tous les sites du groupe. • En tant que membre de cette équipe Data de 12 personnes, vous travaillez sur la construction from scratch de Solutions Data pour analyser le comportement du consommateur sur chaque site en prenant en compte les problématiques de volume des données, de performance, de scalabilité et surtout les problématiques liées aux données privées.
Les responsabilités
Le challenge est donc de créer des solutions adaptées à chaque étape dans le parcours de l’utilisateur, par exemple un « Data Processing Solution » qui gère plus de 900 millions d’événements au niveau mondial par jour tout en respectant la vie privée des utilisateurs et la sécurité des données échangées sur la plateforme.
Vous travaillez de près avec des Data Scientists et des Machine Learning Engineers, vous partagez vos connaissances. Vous intervenez sur tous les sujets autour du Machine Learning et la création des algorithmes autour de la reconnaissance visuelle (de photos par exemple).
Vous développez et implémentez des algorithmes qui répondent aux problématiques soulevées. Vous faites des POCs, vous contribuez à l’amélioration continue du produit actuellement encore au démarrage.
La stack • Spark, Kafka, Kafka Streams, Scala • Big Data NoSQL databases (S3, Hive, Redshift, Cassandra) • Cloud AWS • Agile • SOLID, TDD
Pourquoi venir chez nous?
Ce que WakeITUp (Cabinet d'experts en Recrutement Tech - CDI- Clients finaux uniquement: www.wakeitup.tech) aime: • Travailler dans un Groupe International, dans le domaine du Web et du Fort Trafic • Faire partie d’un des groupes Web parmi les plus puissants en France ! • Etre parmi les meilleurs Data Engineers et Data Scientists au niveau international et apprendre d’eux, avoir la chance de travailler dans un environnement créatif et de partage • Les locaux au top, le beau rooftop parisien et l’équipe humaine et passionnée."
Paris (75),"Intérim, Stage",,DATA SCIENTIST INTERN,Data&Data,- Paris (75),"JOB DESCRIPTION
Mission
As a data scientist at Data&Data, your responsibilities will include:
Enhancing our crawling and scraping algorithms.
Untangling APIs of social media and marketplaces from around the world.
Designing algorithms for processing and analyzing data.
Scaling our architecture to process more bytes at ever-faster rates.
Implementing a bulletproof strategy for testing and maintenance.
Developing internal monitoring or productivity tools.
PREFERRED EXPERIENCE
You:
Have 1+ years of experience with a scripting or OO language, ideally Python.
Master SQL queries, and feel at ~ in a Unix terminal.
Have previous experience working with startups.
Are driven, with strong interpersonal, analytical and problem solving skills.
Are well rounded, proactive, can multitask and ship top quality code on time.
Bonus skills:
Big data, cloud or NoSQL technologies (Hadoop, MS Azure, Neo4j, etc.).
Applied machine learning or computer vision.
Having worked with startups or agile teams..
Fluency in a language other than English or French (East Asian languages in particular).
Mad foosball skills and a strong sense of humour.
Why join us?
Challenges: never short of those, you’ll have the opportunity to apply many skills.
Responsibilities: expect your first release into production on week one.
Work life: flexible hours, flat hierarchy, casual Fridays everyday.
Team: a small, cohesive and dynamic team, that wants to make a dent in the universe.
Diversity: Unix or OS X? Choose your gear. We welcome diversity. (Seriously though, we do.)
Location: Station F The largest startup incubator. Parsi 13 Disct.
ADDITIONAL INFORMATION
Contract Type: Internship (Between 4 and 6 months)
Start Date: 02 January 2020
Location: Paris, France (75013)"
Paris (75),Stage,,Intern Data Analyst,Seelk,- Paris (75),"About Seelk

Seelk is the first tech agency dedicated to Amazon in Europe.

We empower brands with sharp expertise and cutting-edge technology to help them achieve sustainable business success on the Amazon ecosytem globally. Based on a unique SaaS platform that analyses all business drivers on Amazon, our team of Experts supports brands from kick-starting their businesses to activating Retail Media strategies on the various marketplaces worldwide.

With a team of 45 people, Seelk now supports over fifty leading brands including: Lacoste, Devialet, Tefal, Bic, OPI, Mondelez, Playmobil, Beaba, Vilebrequin...

We are growing fast and are looking for the best talents to seize the ocean of opportunities before us:

1. Strengthen our leading position in France
2. Expand our business in Europe by opening 4 internationals offices in the next 12 months
3. Leverage maketplace data to create insightful growth strategies for our clients

As a Data Analyst, you’ll be at the forefront of the value Seelk delivers to its clients through understanding how their business perform on Amazon. You’ll set up the Reporting Suite by understanding Amazon KPIs, their contribution to brands’ growth and how they need to be articulated and displayed to deliver compelling insight to Client Strategist and our Client’s stakeholders.
Your objectives at Seelk :
Map, understand perfectly and train the team on Amazon business drivers and KPIsBuild, maintain and upgrade the Seelk reporting tools suite included managing connected databases
Produce Monthly Business reviews & support Client Strategists in the brands’ performance analysis & recommendations identification
Collaborate with the Product (SaaS) team to influence its roadmap based on internal & market identified needs
What will you do to get there ✍️ :
Produce best in class brands performance analysis & reporting reflecting Seelk’s pioneer Amazon (and E-commerce) expertise and reporting assets
Support the consulting team and help them shine in front of clients through uncovering brands growth levers and sharp analytical frameworks
Contribute to Seelk’s SaaS product development & adoption through collaboration with the product team and influence on its roadmap
You are the one if :
You have strong analytics skills (SQL master, Python or any other coding language is a +)
You are a DataViz champion (Power BI, Tableau, Google Data studio, Looker, etc…)
You Know how to turn data into insight, recommendations & storiesCross Team collaboration
You are Fluent English
You search an end-of-study internship

Join the adventure :
An ultra stimulating work environment in contact with high-level customers
Possibilities of multiple evolutions, on different positions and internationally
Competitive salary, based on experience
50% contribution on your public transport fees
Alan for your Health Insurance and Payfit for Payroll Management
Gym and restaurant in the building
And much more …
Recruitment Process :
Quick Phone Chat (30 min)
Test at home
Interview in visio to meet our amazing team"
Paris (75),,,DATA SCIENCE CONSULTANT PARIS,managementsolutions,- Paris (75),"France

DATA SCIENCE CONSULTANT PARIS

Paris / Graduate / Number of vacancies: 5




You will be working in key projects for leading organizations in data mining & knowledge Discovery, predictive modeling, trend modeling, Simulation models (Monte Carlo), Review of credit rating and scoring models and quant support to the business and R&D projects.

Requirements

Recent graduates or final year students from disciplines relating to Mathematics, Physics, Statistics, Econometrics or other Quantitative fields.
Postgraduate studies and/or specialised courses are an asset, especially in Data Science, Quantitative Finance or similar.
Should desirably have knowledge of modeling techniques (logit, GLM, time series, decision trees, random forests, clustering), statistical programming languages (SAS, R, Python, Matlab) and big data tools and platforms (Hadoop, Hive, etc.).
Solid academic record.
Strong computer skills.
Knowledge of other languages is desirable.
Get-up-and-go attitude, maturity, responsibility and strong work ethic.
Strong ability to learn quickly.
Able to integrate easily into multidisciplinary teams.

We Offer

The best environment to develop talent


We offer you the possibility to join a firm that provides all you need to develop your talent to the fullest:
Working in the highest-profile consulting projects in the industry,
for the largest companies, leaders of their respective markets,
alongside top industry management as they face challenges at the national and global level,
as part of an extraordinary team of professionals whose values and corporate culture are a benchmark for the industry

Ongoing training plan, with approximately 10% of business turnover spent in training

Specialist knowledge courses, external expert courses, professional skills courses, and language courses.

Last year our staff as a whole received over 250,000 hours of training, spanning more than 575 courses.

Clearly defined career plan

Internal promotion based solely on merit.
Partnership-based management model offers all professionals the opportunity to become part of the Firm’s group of partners.

Complementary experiencies

University: we maintain a close relationship with the world’s most prestigious universities.
Social Action: we organize more than 30 community support activities.
Sports Club: internal and external tournaments.




More on Management Solutions

Management Solutions is an international consulting firm whose core mission is to deliver business, risk, financial, organisational and process-related advisory services, targeting both functional aspects and the implementation of related technologies.

Discover our París office


5 Place de la Pyramide

92088 Paris

Francia

Afficher le nº de téléphone

Location

Share this job


Follow us

linkedin/management-solutions

facebook/MngmtSolutions

youtube/management-solutions

instagram/management.solutions

Mngmt_Solutions

Are you a student?

If you are in the final years of your degree, we would also like to hear from you. Management Solutions has agreements with the most prestigious universities to offer students their first experience with the business world. The Firm offers paid work experience and flexible hours with the possibility of students becoming part of the Firm upon graduation.

Other open positions in Paris

DATA SCIENCE CONSULTANT PARIS

BUSINESS CONSULTANT PARIS

NEW TECHNOLOGIES AND DIGITAL TRANSFORMATION CONSULTANT PARIS"
Paris 13e (75),CDI,,Data scientist F/H,CAISSE DES DEPOTS ET CONSIGNATIONS,- Paris 13e (75),"Description détaillée du poste

Au sein de la Direction des prêts de la Banque des Territoires, le Data Scientist sera à titre principal amené à réaliser divers études / analyses et à mettre en œuvre divers outils de machine learning. Il pourra être amené, ponctuellement et lorsque cela est nécessaire, à participer à l'activité de production de données du service. Il sera membre de la filière Data de l'EP.

Les missions à réaliser seront variées :
Mise en œuvre d'algorithmes de textmining sur les différents documents à disposition de la direction des prêts (pièce justificative des clients…) :

Extraction automatique d'informations

Classification de documents

Correction d'erreurs

Pour cela, la connaissance de différentes approches statistiques dont l'utilisation de réseaux de neurones est nécessaire. La mise en œuvre de ces techniques permettra, par exemple, de constituer automatiquement des bases de données pour fiabiliser les données de la DP et les enrichir d'informations supplémentaires.

Il participera activement au développement de services destinés aux clients de la Direction, sur la base de ce type de technologies.

Analyse de données / modèles prédictifs :
Réalisation de statistiques descriptives, de classification et d'analyse : ces travaux pourront notamment participer à comprendre les dynamiques à l'œuvre en matière d'activité, ou encore à classer les clients en fonction d'un ensemble de différents déterminants pour les cibler au mieux ;

Construction de modèles prédictifs : un ensemble de prévisions seront mises en œuvre, et des travaux visant une industrialisation des prévisions d'activité et leur amélioration ;

Travaux de collecte / croisement de base de données

La mise en œuvre de ces outils permettra, par exemple, d'éclairer les choix / analyse de la direction et de proposer des outils d'aide à la décision de type logit et forêt aléatoire.
Profil recherché Profil

De formation scientifique, vous justifiez d'une solide expérience en modélisation / mathématiques appliquées et machine learning. Vous maitrisez aussi bien les statistiques classiques que les dernières évolutions dans le domaine de l'IA et du deep learning. Vous savez mettre en œuvre des outils d'IA dans le domaine du traitement du texte, de l'image et de données plus classiques.

Vous avez une excellente connaissance de la programmation en particulier python et les librairies tensorflow, scikitlearn, pandas, numpy.

Vous êtes curieux, rigoureux, autonome, en capacité de faire des propositions innovantes et savez construire des solutions opérationnelles-industrialisables pertinentes.
Entreprise Caisse des dépôts et consignations - Banque des Territoires - Direction des Prêts

La Caisse des Dépôts et ses filiales forment un groupe public au service de l'intérêt général et du développement économique des territoires. Elle agit en appui des politiques publiques conduites par l'Etat et les collectivités locales, prioritairement pour répondre aux grands défis de société : transition territoriale, transition énergétique et écologique, transition démographique et transition numérique. Elle assure également la gestion de grands mandats publics (fonds privés, retraite, financement du logement social…) et intervient comme banquier du service public de la justice et de la sécurité sociale.

Elle est, au travers de la Direction des prêts de sa Banque des territoires, le financeur principal du secteur du logement social avec près de 80% de sa dette représentant 160Mds€ d'encours.

Au sein de la direction des prêts, le service Pilotage et Statistiques a pour mission de valoriser les données nécessaires au pilotage de l'activité de prêt, pour comprendre les dynamiques d'activité et y participer par des approches innovantes (mieux comprendre la concurrence, mieux cibler les prospects etc). Il est à ce titre Product Owner de Diapason, qui est le SI permettant d'avoir une vision 360 de l'activité globale de prêt.

Il est par ailleurs chargé de réaliser et mettre en œuvre :
Un ensemble de reportings réguliers alimentant le pilotage stratégique de l'activité ;

Les prévisions d'activité de prêt (signatures - versements), alimentant notamment la fixation et le suivi des objectifs, les PMT (BDT - Fonds d'Epargne (FE) et Etablissement Public CDC) ou encore les travaux relatifs à l'équilibre ALM des Fonds d'Epargne ;

Le développement d'approches quantitatives innovantes (économétrie - machine learning - deep learning) afin d'éclairer ou faciliter l'activité opérationnelle de prêt."
Paris 1er (75),CDI,,Data Scientist F/H,Kaisens data,- Paris 1er (75),"Kaisens Data est un éditeur logiciel spécialisée en Data Science/Big Data et Machine learning avec une branche de conseil . Nous recherchons un data scientist qui aura pour missions :

Participer à l’élaboration des modules machine learning pour des projets prédictif dans un contexte big data.
Adapter les outils de traitement statistique de données
Présenter et diffuser les résultats des études réalisées
Management d'équipe ou de projet selon sa séniorité
Profil recherché Maîtrise d'un langage d'analyse de données R, Python ou Spark et une bonne compréhension des structures de données

Bon niveau gestion des bases de données relationnel (SQL) idealement connaissance en NoSql.
Des compétences en gestion de projet seront également appréciées.
Connaissances en text mining seront très apprécies
Avantages

Un cadre de travail agréable, une rémunération selon le profil
Participation à des projets à haute valeur ajoutée avec des technologies récentes
plusieurs possibilités d'évolution de carrières
Entreprise KaisensData est un éditeur en IA avec une branche ESN spécialisé Big Data, Data Science, Text Mining et Deep Learning. Après des années de R&D, nos solutions brevetées sont sollicitées par plusieurs grandes sociétés afin de répondre à des différentes problématiques. Nous traitons le churn en temps réel, le smart pricing, la détection de fraude, le dédoublonnage de stock, la prédiction de pannes, la réduction de coûts, les campagnes marketing, l'analyse de sentiments, et plusieurs autres applications."
Paris (75),CDI,,Data scientist (H/F),FineDigit,- Paris (75),"Description
Attiré par une aventure à vocation entrepreneuriale et humaine, vous êtes dynamique et proactif. Exigent avec vous-même, votre orientation client et votre sens de la communication vous permettent d’offrir une expertise sur mesure dans l’approche de nos clients.
Vous prendrez en charge différents sujets liés aux Systèmes d’Informations, en intervenant sur les nombreuses phases des projets. Si vous souhaitez poursuivre votre expérience technique dans un environnement fonctionnel riche, au sein d’une société en devenir, n’hésitez pas et soyez audacieux !
Plus précisément, au sein d’un acteur majeur en finance de marché ou Asset Management, vous interviendrez en tant que consultant « Data Scientist/Analyst » sur l’ensemble des étapes du(es) projet(s), avec une dimension technique et métier. Les technologies utilisées sont : Python, R, Hadoop, SQL, les bases de données
De formation supérieure (écoles d’ingénieur ou universités), BAC+4/5, vous souhaitez mettre à profit vos compétences techniques autour de la « data », vous avez des connaissances en finance ou un réel intérêt pour des sujets très métier.
Votre autonomie, votre adaptabilité et votre capacité à mener plusieurs sujets en parallèle vous permettront de réussir pleinement sur les projets proposés. Grâce à votre enthousiasme et au management de proximité, vous aurez l’opportunité de contribuer au développement de l’activité avec une réelle valeur ajoutée au sein de FineDigit.
Les axes de développement de FineDigit sont
Ingénierie : MOE, MOA, et support technico-fonctionnel
Intégration : les progiciels métiers font partie intégrante des SI des acteurs de la finance, l’objectif est de maîtriser ces outils dans leur contexte métier
Innovation : la transformation digitale, le big data, la blockchain sont autant de sujets qui sont au cœur de la réflexion et de la stratégie des services financiers"
Paris (75),"Temps plein, CDI",,Machine Learning Engineer – transfer learning / data analysis,USA Recruitment,- Paris (75),"Machine Learning Engineer – transfer learning / data analysis / python / C++ / Java

We are currently working with a leading mobile phone company who are actively looking for a strong Machine Learning Engineer to join their team in Paris. You will here be givent he opportunity to work with one of the worls leading industrial labs with offices all around the world.

As a Machine Learning Researcher your responsibilities will be;

Provide advanced and transferable solutions for telecom network operation and maintenance
Perform research in Transfer learning, Time series anomaly detection and prediction and Active Learning.
Work with leading researchers in the field of Machine Learning and help impact the companies technology.

As a Machine Learning Researcher your skills will include;

PhD in relevant field, eg, Machine Learning / Deep learning / Computer Science etc
Experience in either transfer learning, multi-task learning, active learning, anomaly detection or time series data analysis
Publications in machine learning related conferences or journals;
Programming skills in either python, C, C++ or Java.

Please send a CV attached to your application or email me at os@eu-recruit.com

Machine Learning Engineer – transfer learning / data analysis / python / C++ / Java
By applying to this role you understand that we may collect your personal data and store and process it on our systems. For more information please see our Privacy Notice https://eu-recruit.com/about-us/privacy-notice/"
Paris 13e (75),,,CDI - Data Scientist - Stratégie Data et IA (H/F),Groupe BPCE,- Paris 13e (75),"Description de l'entreprise
Le Groupe BPCE, deuxième groupe bancaire en France, s’appuie sur deux réseaux de banques commerciales coopératives, autonomes et complémentaires : celui des 14 Banques Populaires et celui des 16 Caisses d'Epargne. Il est un acteur majeur de la banque de grande clientèle, de la gestion d’actifs et des services financiers avec NATIXIS.
Le Groupe BPCE compte 31 millions de clients et bénéficie d’une large présence en France avec 7 800 agences, 106 500 collaborateurs et plus de 9 millions de sociétaires.
BPCE SA, l’organe central commun aux Caisses d’Épargne et aux Banques Populaires, est en charge de la stratégie, de la coordination et de l’animation du groupe.

Poste et missions
Au sein du Pôle Digital & Data, vous rejoindrez la nouvelle direction Stratégie Data et IA dont fait partie le département Data Science.
L’équipe Data Science est garante des principes et de la cohérence d’ensemble, elle a une fonction d’orchestration et contribue aux projets data multi-acteurs.
Rattaché(e) au responsable du département Data Science de la direction Stratégie Data et IA, en intéraction forte avec les différents acteurs de la Data du Groupe et avec les Business Owners des produits (métiers), vous aurez pour missions de :
Contribuer à l’identification des besoins et des problématiques des directions métiers,
Intervenir directement, en lien avec les Métiers, sur des projets de Data Science pour définir des orientations méthodologiques ou valider des choix d’approche,
Interagir avec les équipes IT, en tant que client de plateforme et outils Big Data (expression des besoins associés à l’outillage data science) et en tant que contributeur à l’industrialisation des projets,
Mener des actions de recherches sur des technologies de pointes, de nouvelles sources de données et prototyper des solutions « sur étagère » au service des entités du Groupe,
Réaliser une veille active à des fins de R&D (à la fois sur les outils et les méthodes de data science), dans le cadre des partenariats et de manière directe.

Profil et compétences requises
Fort d’une première expérience d'au moins 2 ans en tant que Data Scientist, vous maîtrisez les langages et outils suivants :
Python, R, Java…,
Librairies de machine learning (Scikit-learn…) et manipulation de données (Pandas…),
Langage de calcul distribué (Spark, Hive…) en environnement Hadoop,
Outils de DataViz.
Vous connaissez également :
Les techniques de machine learning de segmentation et de prédiction,
Les méthodes de développement informatique,
Une expérience en analyse sémantique ainsi que la connaissance des problématiques propres au secteur bancaire serait des plus.
De plus, vous appréciez travailler en équipe sur des projets multidisciplinaires. Vous êtes reconnu pour votre capacité à communiquer de manière pédagogique sur des sujets complexes.

Job Reference: BPCE02295"
Paris (75),"Temps plein, Freelance / Indépendant",,"Belle opportunité Data Scientist, expertise en Machine, Deep Learning NLP NLU - langage python et R / Freelance",Innov and Co Diversité,- Paris (75),"Notre client souhaite renforcer l’équipe Data Science pour travailler sur différents sujets. L’équipe Data Science a besoin de renfort très rapidement pour répondre aux attentes qui lui ont été fixées. Cette équipe a besoin de profils datascientists avancés avec une expertise en Machine Learning, Deep Learning. Ces profils doivent également maîtriser le langage Python, voir R.
Détails de la prestation : Les datascientists seront en mesure d’accompagner l’équipe Data Science de notre client en étant force de proposition sur des sujets R&D identifiés par le manager de l’équipe sur une période de 90 à 150 jours (pas d’activité en Août). Un des enjeux est de permettre de démontrer la valeur ajoutée de l’équipe, en livrant des produits Data Science et des résultats de manière régulière Ces travaux auront la vertu de positionner cette équipe en centre d’excellence. Ces travaux de R&D restent néanmoins très opérationnels car il est important de démontrer que la Data Science apporte de la valeur.
L’enjeu de tous les travaux menés reste la mise en production des produits Data Science qui auront été développés. Par ailleurs, les Datascientists externes collaborent pleinement avec l’équipe Data Science sur les projets sur lesquels ils travaillent. Il y a un réel partage entre les personnes pour gagner en efficacité et en efficience.

2 profils sont souhaités

Il y a 2 sujets majeurs identifiés :
Construire un dispositif pour monitorer l’impact des verbatims sur l’Experience Client, la notoriété de la marque et la concurrence. Plusieurs sources de données sont disponibles:
Les verbatims des réseaux sociaux, Les réponses aux questionnaires de satisfaction, Les commentaires des conseillers, Les données décisionnelles (présentent dans les Legacy),
Les données de navigation web (Google Analystics, DMP Weborama)
Les données issues de la Plateforme de Services
L’objectif est de pouvoir utiliser les méthodes de Machine Learning, Deep Learning en utilisant par exemple les méthodes
Analyse de sentiments
NLP,NLU
Analyse d’impacts des sentiments/retours clients sur le business

Il sera attendu en livrable d’être en mesure de produire:
un tableau de bord de KPIs pour montrer l’impact de la concurrence
Capter ce qui est dit sur les marques , pour segmenter ces informations afin de définir une visualisation pour apporter de la valeur
Faire de ces analyses une résonance de ce qui émane du public pour faire émerger des points de ce qui fonctionne et de ce qui ne fonctionne pas, ce que les gens (futurs Clients ou déjà Clients) veulent
Soit pour modifier les processus existant en donnant des pistes de réflexions
Soit en identifiants de nouveaux besoins
Ce qui viendra nourrir les retours sur l’Expérience Client, le contenu des Edito, les messages de communication,

AOC
Travailler sur un moteur de recommandations, faisant appel à des modèles de Machine Learning et d’optimisation des Flux pour accroître les taux de transformation tout en priorisant les lead Internet sur l’Auto, la MRH et la Santé pour les Prospects d’une marque
L’objectif est ensuite de pouvoir construire un moteur de recommandations des leads à transformer entre l’Auto, la MRH et la Santé pour les prospects d’un point de vue commerciale en prenant en compte la probabilité du score technique , garantissant la valeur des prospects conquis .
Livrables : Score MRH, Santé en utilisant des données des Legacy et du digital Proposition de croisement du score d’efficience commercial et du score technique Analyse de la performance du score d’efficience commerciale (Auto,MRH, Santé) et du croisement du score d’efficience et du score technique Moteur de recommandations pour organiser la relance entre l’Auto, la MRH et la Santé

Période de 90 à 150 jours (pas d’activité en Août)"
Paris (75),Stage,,Data Scientist – Machine Learning – Artificial Intelligence,One2Team,- Paris (75),"Les missions
Contribuez à révolutionner la gestion de projet en utilisant vos connaissances en Intelligence Artificielle!
Vous aurez pour mission de :
Créer des algorithmes de machine learning (clustering, reinforcement learning).
Proposer des fonctionnalités innovantes au métier (suggestion, predictability).
Organiser la collecte des données métier : data exploration (outils et scripts).
Mettre en place et configurer des outils pour l’analyse (Hadoop, … ).

Vous jouerez un rôle important et disruptif dans l’identification et le choix des méthodes et des algorithmes qui seront utilisés.

Le profil
Formation: Bac+5 école d’ingénieur, université ou école de commerce (Data Science, Recherche Opérationnelle).
Expérience souhaitée dans l’analyse de données.

Les compétences
Compétences techniques indispensables: Maîtrise de technologies statistiques (R ou Python ou Torch ou Tensorflow ou skilearn).
Des connaissances en Machine Learning et langage Java seraient un plus."
Paris (75),,,Data Scientist,DataDome,- Paris (75),"DataDome is one of the fastest growing tech start-up in Paris. We offer a cutting edge technology, based on AI & Machine Learning, that protects in real-time eCommerce websites against advanced cyber attacks, such as credential stuffing & intensive scraping.

Today, we are proud to protect more than 10 000 domains worldwide, including TripAdvisor, The New-York Times, Carrefour, BlaBlaCar, Rakuten, Veepee, Adevinta.

Our offices in Paris & New-York gather talents coming from 10 different countries and our team is working in an highly stimulating and fascinating industry, focusing on the security and reliability of our customers sites, keeping an eye on new attacks and new technologies and making our solution as reliable, fast and scalable as possible.

Our Dashboard technical stack is mainly composed ElasticSearch for the storage, Symfony 5 & Angular 8 for our dashboards. Our infrastructure is deployed on AWS, GCP and Azure, using Docker, Ansible and Terraform, and monitored with Grafana and Prometheus.

The team:
We are looking for a Data Scientist who will be in charge of improving our detection algorithms. You will also design, implement and push them on production based on our existing technical stack.

You will be more specifically in charge of:
Extracting samples from our large traffic DataSets
Looking for new features to implement
Using our feedback loop to update model close to realtime
Moving batch detection to RealTime stream analysis
Reading state to the art research papers
Write technical papers and publish them on our tech blog

You're the perfect candidate if you :
Can argument the potential value of a research paper and implement it
Are not afraid of working on very large datasets
Have been working on ML for 3+ years
Have a strong programming background in Python, Java or Scala
Care about code quality, simplicity and performance
Have a BS/MS/PhD in a scientific field or equivalent experience

Bonus points

You are more interested in R&D than writing thousands of lines of code
You've worked at high scale with systems like Apache Kafka, Apache Flink or ElasticSearch
You have a previous experience in building your own web crawler
You understand how internet works

What we offer if you join our dream team:
A stimulating working environment with passionate individuals and a first-class R&D team creating a top-quality and innovative solution, making DataDome one of the strongest performers in the bot protection industry globally.
A joyful workplace with many events throughout the year: annual offsite, summer and Christmas parties; drinks, breakfast every Friday morning...
Amazing office located Rue de Rivoli with a 360 view of the most beautiful city in the world!
A lunchr card
A health insurance plan with excellent cover"
Paris 10e (75),,,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong

Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),,,Data Scientist H/F,Equancy,- Paris (75),"Equancy recherche un data scientist passionné pour rejoindre sa practice Data.
Au sein du pôle Data Science, nous développons et mettons en œuvre des modèles de data science dans le cadre de projets pour des directions marketing et de ressources humaines. Notre marque de fabrique est l’utilisation créative de la data science pour atteindre les objectifs des stratégies métier de nos clients, en marketing, digital, média, social et ressources humaines.
Vous pourrez participer dès votre arrivée à un passionnant projet de détection de fraude dans le secteur banque et assurance pour le compte d’un de nos clients, qui vise à mettre en production un outil de détection de fraude. La collaboration avec le laboratoire de data science de notre client offre des perspectives particulièrement intéressantes.
Profil recherché :

Vous avez une formation bac + 5 en université ou école d’ingénieur, avec une spécialisation Data Science, et 1 à 3 ans d’expérience en tant que data scientist.
Vous aimez, comme nous, travailler en Python, pandas et scikit-learn, mais n’êtes pas rebuté par R, car nous en faisons aussi dans certains projets.
Vous connaissez Spark pour le calcul distribué.
Si vous connaissez Dataiku DSS, c’est bien, nous l’utilisons sur certains projets.
Si vous connaissez Scala, c’est un plus.
Vous avez un très bon sens du relationnel et vous intéressez aussi au métier, pas qu’aux algorithmes.
Anglais et Français courants sont impératifs.
Une première expérience en fraude et/ou assurance est un atout

A propos d’Equancy Data
Nos équipes sont composées de consultants de niveau junior à manager, spécialistes et experts en data science, data engineering et analyse de performance.
L’activité est structurée autour de 3 pôles :
Data Science : nous construisons des modèles de data science (algorithmes de recommandations, modèles prédictifs, segmentations, scores, etc.) pour modéliser et prévoir des comportements clients dans le cadre des stratégies marketing, média, CRM, sociales, RH, etc. de nos clients.

Data Technologies : nous déployons et maintenons des infrastructures et applications big data, que ce soit des portails de data visualisation, des applications de Machine Learning (moteur de recommandations, catégorisations de textes, alertes fraudes, qualification d’images, etc.). Nous conseillons aussi nos clients dans les choix de technologies marketing autour de la data (MDM, DMP, gestion de campagnes, BI, etc.).

Data Performance : nous définissons les KPIs de mesure de performance des stratégies marketing, digital, media, CRM, sociale de nos clients et analysons continument les résultats pour recommander des optimisations de plans d’actions.

Conditions
Type de contrat: CDI
Date de début: dès que possible
Lieu : Paris"
Ivry-sur-Seine (94),"Temps plein, CDI",40 000 € - 50 000 € par an,Consultant Data H/F,AFTERDATA,- Ivry-sur-Seine (94),"Passionné par la data, vous cherchez à développer votre maîtrise des données dans des cas concrets ? Rejoignez-nous !
Disponibilité
Dés maintenant
AfterData
Notre plateforme de marketing prédictif en mode SaaS met l’intelligence artificielle au service des équipes business pour décupler la valeur de la data en entreprise.
La solution AfterData permet de répondre avec une précision inégalée aux principales problématiques marketing : Quel client risque de résilier ? Quel visiteur de mon site web est sur le point de commander ? Quelle nouvelle offre proposer à un client ?
AfterData est une startup de la French Tech en forte croissance. Nous sommes implantés au Village by CA à Paris et à Ivry-sur-Seine. Grâce une levée de fonds fin 2019, nous accélérer fortement notre déploiement hexagonal avant un lancement européen d’ici 2 ans.
Nos clients : de grands et très grands comptes tels que BNP PARIBAS, Energie Mutuelle, Société Générale, SOMFY, GMF, Mutuelle de Poitiers…
La mission
Vous intégrez notre équipe mixte R&D et Projets.
Epaulé par deux consultants séniors, CTO et COO AfterData, vous participez aux projets clients et vous apportez votre brique à la construction de la plateforme AfterData.
Votre objectif : manipuler les données client et externes afin d’en faire un levier de valeurs
Vos missions seront les suivantes :
Communiquer avec nos data scientists et nos clients pour mener les projets à leur terme
Participer aux ateliers métier et data
Participer à la préparation de données et à l'évaluation des modèles
Etre force de proposition sur l’amélioration de la solution et de la méthodologie
Participer à la roadmap produit
Profil recherché
Diplôme ingénieur Master 2
3 ans d'expérience dans un poste similaire
Passionné(e) de nouvelles technologies et curieux(se)
Conscient(e) des enjeurs clients, terre à terre
Vous maîtrisez le language Python, en particulier la librairie Pandas
Vous connaissez les principes du Machine Learning, principaux modèles et leurs usages.
Bonne capacité à faire le lien entre un jeu de données et sa signification dans le monde réel ! Vous savez faire preuve de créativité.
Pratique
CDI
Début : Dés maintenant
Salaire entre 40 à 50K € selon expérience
Tickets restaurants, mutuelle, pass navigo…
Paris - Ivry
Avantages :
Titre-restaurant / Panier
RTT
Participation au transport
Type d'emploi : Temps plein, CDI
Salaire : 40 000,00€ à 50 000,00€ /an
Expérience:
consultant data h/f ou similaire: 3 ans (Requis)"
Paris (75),"Temps plein, Stage",,Business & Data Analyst (Intern),Blade,- Paris (75),"Company description

After raising a total of 60 million euros in 2 years, Blade is going international in 2018 with the expansion of Shadow in Europe and in the US.

Shadow is a high-end Windows 10 PC accessible from anywhere at anytime. Thanks to our apps (Windows, Mac, Linux, Android and iOS) and to the Shadow Box, the service is available on any kind of device (laptop, smartphone, tablet, Android TV…). This way, any connected device with a screen becomes a powerful gaming or working station offering a unique experience.
Shadow’s software is frequently updated and the hardware components are improved in our highly secured data centers. No need to change your computer every few years, Shadow is the end of obsolescence!

We truly believe that Shadow represents a whole new way of using computers. Much more than a PC, Shadow is THE answer to the increasing need of computing power, mobility and hardware replacement.

Key facts:
Raised €100m since the creation of the company in 2015, backed by successful entrepreneurs & VCs :
Pierre Kosciusko-Morizet, founder of Price-minister
Michael Benabou, co-founder of Vente-privee.com
Nick Suppipat, founder of Wind Energy Holding, South-East Asia’s largest Wind Power business in 2014 ($1.9 billion valuation)
Serena Capital
Erik Maris, Founder of Messier-Maris
Only two years after its official launch (November 2017), Shadow is present in 6countries (France, Germany, UK, US, Luxembourg, Switzerland) with 70k+ users. * Two-digit growth MoM and 150+ employees in France and San Francisco
More info here in French
[https://www.lefigaro.fr/secteur/high-tech/shadow-leve-30-millions-d-euros-pour-diversifier-ses-offres-20191029] or in
US
[https://techcrunch.com/2019/10/29/shadow-announces-new-plans-for-its-cloud-gaming-platform/] media.

Job Description

As a Business & Data Analyst, you will be joining the Business Intelligence & Data pool in Paris.
You will be working with a very skilled and motivated team of people toward developing and improving the business, providing some support to help them grow, structure, rationalize, organize, follow through data intelligence, data analysis, project management, tools implementation skills. As such, the role requires a sharp, analytical mind, agile and an
entrepreneurial spirit with positive energy.

Team
You will be joining the BI & Data team and will work directly with Blade’s Head of Data & BI and top executives. You will work on a daily basis with Data, BI & Finance analysts, as well as with each department of the company.

Key responsibilities:
Being able to extract data and analyze it
Defining, implementing and measuring KPIs according to business needs
Developing models and reports using data visualization software
Participate to strategic planning exercise and fundraising process
Collaborate with many teams across the company to implement the processes and tools required to make the organization more efficient
Identify and follow up bottlenecks / quick wins around growing fast
Provide ad hoc analysis with actionable insights
Ideally: Using advanced models / algorithms to drive smarter business decisions – e.g. econometric modeling, clustering
Key skills requirement:
Fully proficient in Microsoft Office, especially Excel
Strong analytical and expression skills
Flexible and “hands-on” spirit
Ability to evolve in a fast-moving environment
Ability to conduct research, benchmark with a strong ability to summarize
Fully proficient in French & English
Ideally: familiar or (even better) proficient with programming languages (e.g.Python, R, SQL) & dashboarding software (Tableau, Power BI).
Background:
Top business or engineering school
First experience in consulting, data analytics, or banking/finance
Knowledge and interest for tech/gaming ecosystem"
Paris (75),,,GroupM | Data Scientist (H/F),GroupM,- Paris (75),"Qui sommes-nous ?

GroupM, leader mondial en conseil et en achat d’espaces publicitaires a pour activité principale l’accompagnement des annonceurs dans la promotion de leurs marques.
GroupM est présent dans 80 pays via des réseaux internationaux et travaille avec des clients de renom dans des secteurs d’activité diversifiés tels que le Luxe, l’Automobile, l’Agroalimentaire, les Services ...
En France, GroupM est présent au travers des agences KR Wavemaker, MediaCom, Mindshare, Neo et Keyade (1000 collaborateurs).


Missions :

En tant que Data scientist, vous interviendrez sur les différents projets data science, destinés à mesurer l’impact des principaux leviers marketing sur la performance des annonceurs.

Dans ce cadre, vous aurez comme missions de :

Conduire des réunions de cadrage : Prise de Briefs, définition des KPIs, étude faisabilité
Être le point central dans la collecte, l’analyse, la compréhension et l’utilisation des données
Être garant de la qualité des données provenant de différentes sources
Mener un projet de modélisation de bout en bout (Réalisation de modèles économétriques/statistiques, analyse des résultats, restitution client…)
Mettre en place des modèles de machine Learning
Assurer l’automatisation de ces modèles, notamment par l’intermédiaire de structures de récupération de données industrialisées
Participer aux projets R&D et contribution à l’innovation de nouvelles méthodes (Machine learning, modèles ad hoc
Garantir la visualisation et la communication des résultats auprès des agences et de leurs clients annonceurs
Comprendre les enjeux métiers et identifier de nouvelles opportunités business

Profil :

- Formation Bac+5 type école d’ingénieur ou équivalent universitaire avec une spécialisation mathématiques appliquées et statistiques ou/et informatique
Vous avez au moins 2 ans d’expérience dans un poste similaire
Maitrise de l’outil R/R shiny
Compétences en économétrie et datamining : Régressions, classification et clustering
Bonne compréhension des techniques de Machine Learning
Maitrise d’au moins un langage de programmation orienté objet : Python, Scala
Compétences en manipulation et gestion de base de données (SQL, no SQL)
Calcul numérique et algorithmes d’optimisation
Vous êtes dynamique, autonome et force de proposition
Vous maitrisez l’anglais, avec un goût prononcé pour le marketing et les médias"
Paris (75),,,RESEARCH ENGINEER DEEP LEARNING APPLIED TO DRUG DISCOVERY,DeepLife,- Paris (75),"JOB DESCRIPTION
Our team is developing digital twins of human cells using sequencing data. Your work is to design deep learning algorithms addressing state-of-the art challenges in genetics. Your finding will play a major part for the development of our technology.
We are looking for a candidate willing to push back boundaries in deep learning in order to disrupt the way drug discovery is performed today.
PREFERRED EXPERIENCE
Minimum qualifications:
Written / spoken fluency in English
Find relevant information and implement algorithms from academic literature - Strong background in machine learning and deep learning
Master 2, engineer degree in computer science or equivalent
Preferred qualifications:
Solid skills in applied mathematics
A real passion for AI
Experience working with large datasets using Python, Matlab, or other statistical software
RECRUITMENT PROCESS
Two meetings: One with our technical team, the other with the CEO
ADDITIONAL INFORMATION
Contract Type: Full-Time
Start Date: 01 June 2020
Location: Paris, France (75013)
Education Level: PhD and more
Experience: > 2 years
Occasional remote authorized"
Le Plessis-Robinson (92),,,Ingénieur Data Visualisation F/H,TRIMANE,- Le Plessis-Robinson (92),"TRIMANE est une société de service spécialisée dans les systèmes d’information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l’information au sein de leur entreprise. En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d’expertise de nos consultants.Nous accompagnons nos clients (CAC 40 et SBF 120) sur des prestations de Conseil, MOA et MOE, autour du traitement et l’analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique. TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d’outils d’Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique.Nous recherchons un Consultant Data Visualisation pour accompagner nos clients dans la mise en œuvre de leurs solutions décisionnelles dédiées : - Analyse des besoins en collaboration avec l’équipe métier- Rédaction des spécifications techniques- Conception, développement et documentation de la solution- Accompagnement des utilisateursEn fonction de votre expérience, vous soutiendrez l’équipe commerciale dans ses activités de qualification avant-vente (réponses à appel d’offres …).Vous êtes de formation ingénieur ou Bac + 5 avec une spécialisation en Data, Informatique, Statistique, Mathématiques. Vous disposez d'une expérience de 4 ans en environnement décisionnel (modélisation, intégration, ETL, Datawarehouse, Reporting).De nature curieuse, vous avez la volonté découvrir de nouveaux outils de Datavisulisation, en plus de celui/ceux déjà maîtrisé(s).

Vous êtes passionné par la Data et vous effectuez une veille permanente autour des sujets suivants : Data Mining, Intelligence Artificielle, Deep Learning, Machine Learning ;Langages de programmation et Scripting data science (Python, R, Java, Scala) ;Langages de requêtage (SQL, NoSQL, MDX, DAX etc.)Recherche opérationnelle et bonnes connaissances en statistiques ;Gouvernance des données ;Data Visualisation : Tableau Software, Qlik Sense, PowerBI, Tibco, Microstrategy, Oracle Data Visualisation etc. ;Bases de données relationnelles & NoSQL (MongoDB, Cassandre, Hbase,..) et langages de requête (Hive, Pig) ;Architecture technique des environnements Big Data (Hadoop, Spark, Scala, Hive…)Environnements Cloud (Microsoft Azure, Google Cloud, AWS) ;"
Paris (75),,,Ingénieur Data Intelligence F/H,TRIMANE,- Paris (75),"TRIMANE est une société de service spécialisée dans les systèmes d’information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l’information au sein de leur entreprise. En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d’expertise de nos consultants.Nous accompagnons nos clients sur des prestations de Conseil, MOA et MOE, autour du traitement et l’analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique. TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d’outils d’Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique.Au sein d’une équipe et sous la responsabilité de managers Data aguerris, vous interviendrez autour de la mise en place de solutions décisionnelles et participerez aux phases conception et réalisation des projets : Recueil de besoins, Spécifications fonctionnelles et techniques, Réalisation, Tests, Formation utilisateur, Maintenance de la solution.Vous participerez à des projets variés, de tous secteurs d’activités et vous aurez l’occasion d’appréhender les différentes composantes techniques d’un projet décisionnel : La modélisation et préparation des données,L’enrichissement de bases de données,La modélisation de Datawarehouses et de Datamarts,La création d’outils d’analyse, d’indicateurs (Cube OLAP, modélisation multidimensionnelle …),La mise en place de Dashboards BI,Vous interviendrez sur des technologies récentes : SAP BI, Informatica, Datastage, Cognos, Qlik View/Sense, Talend, Snowflake, Microsoft BI/PowerBI, SAS, Tableau Software, Microstrategy etc.Diplômé d’une école d’ingénieur ou d’un Master Data, vous êtes à l’aise sur les problématiques de traitement et d'analyse de données et vous maitrisez l’ensemble de la chaine BI (ETL, Datawarehouse, Datamart, OLAP, Reporting/Dashboarding).Vous êtes passionné par la Data et vous effectuez une veille permanente autour des sujets suivants : Data Mining, Intelligence Artificielle, Deep Learning, Machine Learning ;Langages de programmation et Scripting data science (Python, R, Java, Scala) ;Langages de requêtage (SQL, NoSQL, MDX, DAX etc.)Recherche opérationnelle et bonnes connaissances en statistiques ;Gouvernance des données ;Data Visualisation : Tableau Software, Qlik Sense, PowerBI, Tibco, Microstrategy, Oracle Data Visualisation etc. ;Bases de données relationnelles & NoSQL (MongoDB, Cassandre, Hbase,..) et langages de requête (Hive, Pig) ;Architecture technique des environnements Big Data (Hadoop, Spark, Scala, Hive…)Environnements Cloud (Microsoft Azure, Google Cloud, AWS) ;

Data"
Paris (75),,,DATA ANALYST (F/H),Acceo Consulting France,- Paris (75),"Nos clients disent apprécier notre capacité à anticiper, comprendre et mettre en application les fréquentes évolutions réglementaires. C’est grâce au travail et aux propositions de nos Consultants, qu’Acceo Consulting a pu faire reconnaître la qualité de ses interventions dans les domaines exigeants des risques, de la production bancaire et de la conformité. Avec une volonté constante d’innovation, nous proposons des méthodologies de travail qui n’attendent que vous pour continuer à évoluer.
Actuellement, au sein des équipes BIG DATA et Machine learning de notre client, grande entité bancaire, l’objectif au quotidien est d’acquérir une expertise sur l’ensemble des informations liées aux données marketing et commercial des différentes entités, c’est pourquoi nous recherchons un(e) :
DATA ANALYST (F/H)
Vos principales missions :
Mise en place d’un dictionnaire de données / catalogue, à disposition des chefs de projets et des data scientists afin de les aider, lors de la mise en place de projets BIG DATA ou machine learning.
Manipulation, analyse et mise à disposition des données collectées.
Reporting
Vous serez également en charge de toutes les demandes liées à l’exploitation des données

Votre Profil :
Issu(e) d’une formation supérieure de type BAC + 5 en informatique, statistiques ou en big data, vous avez acquis une expérience de minimum 3 ans dans le traitement et l’analyse de données dans un environnement bancaire.
Pour ce poste, ous recherchons un profil avec un très bon relationnel pouvant communiquer aisément entre les différents services et interlocuteurs.
A l’aise dans la transmission des informations, vous avez aussi une réelle appétence pour manier les données.
Bon communiquant, vous avez un sens du service développé."
Paris 8e (75),CDI,,Ingénieur Data Intelligence F/H,TRIMANE,- Paris 8e (75),"Au sein d'une équipe et sous la responsabilité de managers Data aguerris, vous interviendrez autour de la mise en place de solutions décisionnelles et participerez aux phases conception et réalisation des projets :

Recueil de besoins, Spécifications fonctionnelles et techniques, Réalisation, Tests, Formation utilisateur, Maintenance de la solution.

Vous participerez à des projets variés, de tous secteurs d'activités et vous aurez l'occasion d'appréhender les différentes composantes techniques d'un projet décisionnel :

La modélisation et préparation des données,

L'enrichissement de bases de données,

La modélisation de Datawarehouses et de Datamarts,

La création d'outils d'analyse, d'indicateurs (Cube OLAP, modélisation multidimensionnelle …),

La mise en place de Dashboards BI,

Vous interviendrez sur des technologies récentes :
SAP BI, Informatica, Datastage, Cognos, Qlik View/Sense, Talend, Snowflake, Microsoft BI/PowerBI, SAS, Tableau Software, Microstrategy etc.
Profil recherché Diplômé d'une école d'ingénieur ou d'un Master Data, vous êtes à l'aise sur les problématiques de traitement et d'analyse de données et vous maitrisez l'ensemble de la chaine BI (ETL, Datawarehouse, Datamart, OLAP, Reporting/Dashboarding).

Vous êtes passionné par la Data et vous effectuez une veille permanente autour des sujets suivants :

Data Mining, Intelligence Artificielle, Deep Learning, Machine Learning ;

Langages de programmation et Scripting data science (Python, R, Java, Scala) ;

Langages de requêtage (SQL, NoSQL, MDX, DAX etc.)

Recherche opérationnelle et bonnes connaissances en statistiques ;

Gouvernance des données ;

Data Visualisation : Tableau Software, Qlik Sense, PowerBI, Tibco, Microstrategy, Oracle Data Visualisation etc. ;

Bases de données relationnelles & NoSQL (MongoDB, Cassandre, Hbase,..) et langages de requête (Hive, Pig) ;

Architecture technique des environnements Big Data (Hadoop, Spark, Scala, Hive…)

Environnements Cloud (Microsoft Azure, Google Cloud, AWS) ;
Entreprise TRIMANE est une société de service spécialisée dans les systèmes d'information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l'information au sein de leur entreprise. En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d'expertise de nos consultants.

Nous accompagnons nos clients sur des prestations de Conseil, MOA et MOE, autour du traitement et l'analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique.

TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d'outils d'Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique."
Boulogne-Billancourt (92),,,NLP DATA SCIENTIST,MyScienceWork,- Boulogne-Billancourt (92),"Place: Boulogne-Billancourt (France)
Start: Now

MyScienceWork est une startup internationale (Paris, Luxembourg, Philadelphie) qui propose des services et outils d’identification, d’analyse et de valorisation de la production scientifique. Notre vocation est de démocratiser la science et la rendre plus compréhensible pour les décisionnaires.
Pour accompagner l’essor de notre nouvelle solution de gestion des données, nous sommes à la recherche d’un NLP Data Scientist qui renforcera l’équipe IT pour contribuer au développement de nos solutions.
Vous êtes passionnés de développement logiciel et de technologies à la pointe. Vous cherchez toujours la solution la plus innovante pour tirer le maximum des données textuelles ? Vous maîtrisez les algorithmes d’apprentissage supervisé ou non-supervisé ? L’analyse sémantique et la création de graphes de connaissances ne vous font pas peur ?
Vous souhaitez évoluer dans un environnement de travail international et centré sur l’innovation ?
Vous aimez les challenges, le travail en équipe mais savez aussi faire preuve d’autonomie et d’initiative ?
… Alors rejoignez notre équipe jeune, dynamique et ambitieuse !
MISSION
Vous aurez comme principale mission la développement et l’amélioration de nos solutions Sirius et Polaris OS ainsi que de notre site www.mysciencework.com.
En collaboration avec le Directeur R&D et le Directeur Innovation & Business Development, vous serez en charge de :
Proposer des améliorations techniques et fonctionnelles pour nos solutions.
Développer le code qui forme le backend de la solution et implémenter des algorithmes de machine learning et de fouille de données.
Mettre en œuvre des chaînes de traitement des données.
Concevoir les schémas de stockage dans les différentes bases de données NoSQL et Graphe.
Tester les applications logicielles sur une quantité importante de données.
Interagir avec les clients pour comprendre leurs besoins et éventuellement les conseiller sur le design et l’expérience utilisateur.
Collaborer avec l’équipe commerciale dans le cadre de l’élaboration des offres commerciales (cahiers des charges et appels d’offres).
PROFIL
Diplôme : bac +5 minimum (formation d’ingénieur ou équivalent universitaire), Un PhD en Intelligence Artificielle appliquée au NLP est un plus.
Langues : anglais et français,
Expérience : 5 ans minimum dans le développement de backend et d’algorithmes et idéalement dans le monde de la recherche et de l’innovation.
COMPETENCES ATTENDUES
Langages : Java, C++, Python
Frameworks : Spark, Tensorflow.
Bases de données : ElasticSearch, Neo4j, MariaDB.
Notion de test-driven (ou behaviour-driven) development.
Algorithmes d’apprentissage automatique : neural networks, clustering, semantic analysis, word2vec (et dérivés).
Capacité à développer des chaînes robustes de traitement pour le nettoyage et le mapping de données.
Création de tests unitaires.
Connaissances des technologies de crawling / scraping de données seraient un plus (Scrapy, Puppeteer).
Méthode de développement Agile + possibilité d’assumer le rôle de scrum master
Excellente capacité d’organisation, d’esprit d’initiative et de créativité.
ELEMENTS DU POSTE
Contrat : CDI
Disponibilité : immédiate
Lieu : Boulogne-Billancourt
Déplacements : Quelques déplacements en France ou à l’étranger sont à prévoir.
Salaire : Selon profils
POUR CANDIDATER
Envoyez-nous votre CV et une présentation personnelle à jobs@mysciencework.com

English
MyScienceWork is an international startup (with operations in Paris, Luxembourg, Philadelphia) that offers services and tools for the identification, analysis and valorisation of scientific production. Our mission is to democratize science and make it more coherent for decision-makers. To support the development of our new data management solutions, we are looking for an NLP Data Scientist to reinforce the IT team.

PROFILE
You are passionate about software development and cutting-edge technologies.
Are you always looking for the most innovative solution to get the most out of text data?
Do you master supervised or unsupervised learning algorithms?
Are you not afraid of semantic analysis and knowledge graph creation?
Do you want to evolve in an international work environment focused on innovation?
Do you like challenges and teamwork, but also know how to show autonomy and initiative?
If this is you, we invite you to join our young, dynamic and ambitious team!

MISSION
Your main mission will be the development and improvement of our Sirius and Polaris OS solutions as well as our website www.mysciencework.com.
In collaboration with the R&D Director and the Business Development team, you will be in charge of :
Propose technical and functional improvements for our solutions.
Develop the code that forms the backend of the solution and implement machine learning and data mining algorithms.
Implementing data processing chains.
Design storage schemes in the different NoSQL and Graphe databases.
Test software applications on a large amount of data.
Interact with customers to understand their needs and possibly advise them on design and user experience.
Collaborate with the sales team in the elaboration of commercial offers (specifications and tenders).

BACKGROUND
Diploma: at least 5 years of higher education (engineering degree or university equivalent). A PhD in Artificial Intelligence applied to NLP is a plus.
Languages: English and French,
Experience: 5 years minimum in backend and algorithm development and ideally in the world of research and innovation

SKILLS
Languages : Java, C++, Python
Frameworks: Spark, Tensorflow.
Databases: Elasticsearch, Neo4j, Maria DB.
Notion of test-driven (or behaviour-driven) development.
Machine learning algorithms: neural networks, clustering, semantic analysis, word2vec (and derivatives).
Ability to develop robust processing chains for data cleansing and mapping.
Creation of unit tests.
Knowledge of data crawling / scraping technologies would be a plus (Scrapy, Puppeteer).
Agile development method + possibility to assume the role of scrum master.
Excellent organisational skills, initiative and creativity.

Position
Contract: CDI Permanent full time contract
Availability: Immediately
Location: Boulogne-Billancourt
Travel : Some trips in France or abroad are to be expected.
Salary : According to the profile
Contact: jobs@mysciencework.com"
Paris (75),"Temps plein, Freelance / Indépendant",,URGENT DATA SCIENTIST NLP BANQUE / Freelance,EMPIRIC,- Paris (75),"Dans le cadre de ces développements, le DataLab du groupe souhaite confier à un data scientist, venant en renforcement de son équipe data science sur la partie NLP, la mission suivante :
1. Prise en main des modèles/packages développés en interne pour adresser des cas d’usage de type classification de texte (emails, verbatim) et extraction d’information (entités nommées et relations)
2. Adapter les modèles dans le cadre d’un projet avec un client interne sur un corpus métier
3. Développer et intégrer des nouveaux modèles plus performants.
4. Packager les développements pour les préparer à une mise en production

Participer dans l’équipe projet email dans la factorisation des codes et l’amélioration du produit interne.
Le data scientist sera accompagné par l’équipe data science. Il devra, par ailleurs, fournir les livrables suivants :
Documents de spécification des librairies développées.
Une description des résultats : description des expérimentations, performances, etc
Codes sources commentés et reviewés .

Présentation et partage des travaux.
Le renouvellement de la mission dépendra de l’avancement des développements.

Des revues itératives seront mises en place entre les tâches de développement et de modélisation/Analyse afin de produire de manière continue des résultats et orienter les développements.

Pré-requis :
De fortes compétences algorithmiques en apprentissage automatique
Python avancé
Connaissances solides en machine learning et deep learning
Connaissances en NLP, extraction d’information, classification de textes

Merci d’adresser vos candidatures à"
,,,DATA SCIENTIST NLP,Aquila Consulting,- Paris (75),"NOTRE MISSION
En tant que spécialiste reconnu, Aquila Data Enabler accompagne et conseille ses clients sur la Data Science et
l’intégration Big Data, principalement au sein des Labs R&D.
Notre positionnement est celui de la Recherche Opérationnelle. Aquila Data Enabler est une structure qui répond avec
réactivité, transparence et proximité aux besoins de ses clients en les aidant à faire les bons choix, et à les mettre en oeuvre
avec efficacité.
POSTE PROPOSE
Pour un client grand compte basé sur Paris, vous travaillerez au sein de leur lab sur plusieurs projets, en tant que Data
Scientist (F/H) spécialisé NLP / Text mining.

Vos missions seront :

ü Accompagnement du client pour l’émergence des besoins centrés sur la donnée
ü Etude de la problématique posée, diagnostic de la situation et des données disponibles, préparation des données
ü Proposition de méthodes de modélisation des problèmes opérationnels, conception d’algorithmes de classification,
modélisation, prévision et optimisation
ü Validation des modèles, mise en place d’indicateurs pertinents, étude des résultats, recommandations.
ü Conception d’outils d’analyse et de data-visualisation

Vous aborderez des questions stratégiques et opérationnelles complexes, auxquels vous pouvez apporter des réponses grâce
à votre bagage technique (data mining et visualisation de données techniques, l'analyse graphique, l'analyse statistique,
le machine learning / deep learning, etc).

Voici quelques exemples de problématiques NLP pouvant être rencontrées :

Chatbot
Reconnaissance automatique de la parole (chaînes télévisées, appels téléphoniques, etc)
Lecture automatique de document (documents d’identité, contrats, tableaux, etc : OCR)
Analyse de sentiments clients (à la suite d’un questionnaire, réseaux sociaux, etc)
Analyse de données exogènes (journaux, site internet, etc)
Analyse automatique de rapports humains

Vous serez également responsable du pilotage de ses projets (définition de périmètre, planning et respect des délais,
coordination avec les autres départements).

De même, vous pourrez avoir des missions commerciales (réunions et présentations clients, workshop, etc) et des missions de
veille (rédaction d’articles sur les projets Aquila en cours, etc).

VOS QUALIFICATIONS
Ingénieur Data Scientist diplômé Bac +5 / Doctorat, vous avez acquérit une spécialisation NLP / Text mining / Reconnaissance
automatique de la parole de par vos études (thèse) ou via vos premières expériences professionnelles.

Les algorithmes sont vos meilleurs amis et le réseau de neurones n’a plus de secret pour vous !

Vous êtes passionné par la recherche, mais en même temps vous êtes attiré par le fait de travailler sur de vraies
problématiques opérationnelles au sein d’une grande entreprise.
.
Idéalement, comme outils, vous maîtrisez Python et R.

Enfin, vous avez la pêche, le smile attitude, assez pour prétendre de faire partie de l’Aquila Team !

Si vous vous reconnaissez dans cette description, n’hésitez pas à nous envoyer votre candidature, nous serons ravis de faire
connaissance autour d’un café !
ENVIE DE REJOINDRE NOTRE EQUIPE ?
Merci de nous envoyer votre CV et lettre de motivation à jobs@aquiladata.fr
Pour un traitement interne plus rapide, veuillez nommer vos documents comme suit : Prénom Nom_CV ou CL. N'hésitez pas
à ajouter tout document divers pouvant supporter votre demande. Nous veillerons à examiner votre demande et à vous
répondre dans les 48h."
Paris (75),CDI,,Data Scientist,Margo Conseil,- Paris (75),"Vos principales responsabilités
Utiliser les sources de données contenues dans le Data Lake existant pour créer de nouveaux modèles quantitatifs : modèles de prédiction, apprentissage machine, intelligence artificielle, etc.

Concevoir et développer de nouveaux outils robustes de data science afin de répondre aux exigences des équipes métiers.


Vos autres activités
En parallèle de ce poste, vous assurez une veille technologique autour de la Data Science et du Machine Learning. Vous êtes attentif aux dernière nouveautés et force de proposition au sein de votre équipe.


Et après ?
Ce poste permet de maîtriser l’intégralité d’un projet en data science et est un véritable tremplin pour évoluer sur un poste impliquant des responsabilités managériales ou de gestion de projet.


Votre profil
Vous êtes issu(e) d’une grande école d’ingénieur et /ou titulaire d’un PhD en Machine Learning
Vous maîtrisez les outils informatiques Python, C++, SQL
Vous êtes familier(e) des outils / bibliothèques scientifiques : R, Matlab, numpy, pandas…
Vous êtes passionné(e) par les problématiques d’apprentissage machine et effectuez de la veille sur les innovations de la data science.


Ce que vous aimerez chez Margo
« We design career algorithms », notre promesse est porteuse des principales valeurs de notre groupe : l'esprit visionnaire et entrepreneurial de nos associés ainsi que notre politique RH focalisée sur le développement de chacun.

Nous favorisons l'évolution de nos collaborateurs, en encourageant la mobilité professionnelle et internationale pour la diversité des expériences et l'intérêt de la progression de carrière.


Engagée en faveur de l'égalité des chances, Margo vous informe que ce poste est ouvert aux candidatures de personnes en situation de handicap."
Fontenay-sous-Bois (94),"Temps plein, Freelance / Indépendant",650 € - 700 € par jour,Data Scientist confirm / Freelance,ABSIS CONSEIL,- Fontenay-sous-Bois (94),"Nous recherchons un DATA SCIENTIST/ Machine Learning au sein des équipes infrastructures.
Contribuer au développement de MVP et de data products de production.
Formaliser des problèmes business en projet de data science
Proposer des évolutions des produits existants ou de nouveaux produits
Proposer et mettre en oeuvre l’industrialisation du machine learning au sein de GTS
POCs, MVPs et data products en production
Divers livrables projets de data science, dont l’analyse du besoin
Bonnes pratiques data science
Pipeline industriels de machine learning
Contributions et utilisation de composants de data science mutualité
Techno : Hadoop / Hive / Kafka / Spark / GIT/ Agile / Linux / open Source / PYTHON
le plus important étant GIT et Python"
Paris 10e (75),,,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community

Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),"Temps plein, Freelance / Indépendant",,Data Scientist / Freelance,Lawrence Harvey,- Paris (75),"Freelance / Data Scientist / Data Science / Python/ Confirmé / Machine Learning/ IDF / Paris

Lawrence Harvey recherche pour le compte de son client un Data Scientist le rôle sera basé en région parisienne.

Freelance - Pas de sous-traitance, merci.
Démarrage : ASAP
Contrat : 6 mois
Localisation : Région parisienne

TJM négociable selon expérience

Activités principales :
Au sein d’une équipe de data scientist dans le secteur de l’énergie. Ce nouveau projet s’orientera vers le développement des algorithmes prédictifs pour la plateforme du client.

Compétences Requises :
Forte expérience sur Python
Forte expérience en Machine Learning ( Forecasting time series et clustering )
Des compétences en manipulation de data(croisement de données, analyses, mise en forme, intégration dans les bases sous forme de scripts, Python ou autres).
Profil confirmé
Capacité de penser générique à travers la spécificité des problèmes du client.

Si cette superbe opportunité vous intéresse, merci de postuler vite sur l’annonce ou de m’envoyer votre CV à (Olivia Rouhet) et je vous recontacterai le plus rapidement possible si votre profil matche avec la mission.

N’hésitez pas à partager avec votre réseau si vous connaissez des personnes qui pourraient être intéressées

Lawrence Harvey is acting as an Employment Business in regards to this position. Visit our website www.lawrenceharvey.com and follow us on Twitter for all live vacancies @lawharveyjobs"
Paris (75),,,DATA SCIENTIST COMPUTER VISION,Aquila Consulting,- Paris (75),"NOTRE MISSION
En tant que spécialiste reconnu, Aquila Data Enabler accompagne et conseille ses clients sur la Data Science et
l’intégration Big Data, principalement au sein des Labs R&D.
Notre positionnement est celui de la Recherche Opérationnelle. Aquila Data Enabler est une structure qui répond avec
réactivité, transparence et proximité aux besoins de ses clients en les aidant à faire les bons choix, et à les mettre en oeuvre
avec efficacité.
POSTE PROPOSE
Pour un client grand compte basé sur Paris, vous travaillerez au sein de leur lab sur plusieurs projets, en tant que Data
Scientist (F/H) spécialisé Computer vision.

Vos missions seront :

ü Accompagnement du client pour l’émergence des besoins centrés sur la donnée
ü Etude de la problématique posée, diagnostic de la situation et des données disponibles, préparation des données
ü Proposition de méthodes de modélisation des problèmes opérationnels, conception d’algorithmes de classification,
modélisation, prévision et optimisation
ü Validation des modèles, mise en place d’indicateurs pertinents, étude des résultats, recommandations.
ü Conception d’outils d’analyse et de data-visualisation

Vous aborderez des questions stratégiques et opérationnelles complexes, auxquels vous pouvez apporter des réponses grâce
à votre bagage technique (data mining et visualisation de données techniques, l'analyse graphique, l'analyse statistique,
le machine learning / deep learning, etc).

Voici quelques exemples de problématiques de traitement de l’image / Computer vision pouvant être rencontrées :

Lecture automatique de documents (documents d’identité, plans industriels, contrats, tableaux, etc)
Détection automatique de défauts (éoliens, panneaux solaires, etc)
Création de plans par drones
Reconstruction 3D de bâtiments via des images satellites
Tracking d’objets (de voiture, etc sur des flux vidéos en temps réel)

Vous serez également responsable du pilotage de ses projets (définition de périmètre, planning et respect des délais,
coordination avec les autres départements).

De même, vous pourrez avoir des missions commerciales (réunions et présentations clients, workshop, etc) et des missions de
veille (rédaction d’articles sur les projets Aquila en cours, etc).

VOS QUALIFICATIONS
Ingénieur Data Scientist diplômé Bac +5 / Doctorat, vous avez acquéri une spécialisation Computer vision / traitement de
l’image / télédétection via votre formation (thèse) ou bien vos premières expériences professionnelles.

Les algorithmes sont vos meilleurs amis et le réseau de neurones n’a plus de secret pour vous !

Vous êtes passionné par la recherche, mais en même temps vous êtes attiré par le fait de travailler sur de vraies
problématiques opérationnelles au sein d’une grande entreprise.

Idéalement, comme outils, vous maîtrisez Python et R.

Enfin, vous avez la pêche, le smile attitude, assez pour prétendre de faire partie de l’Aquila Team !

Si vous vous reconnaissez dans cette description, n’hésitez pas à nous envoyer votre candidature, nous serons ravis de faire
connaissance autour d’un café !

ENVIE DE REJOINDRE NOTRE EQUIPE ?
Merci de nous envoyer votre CV et lettre de motivation à jobs@aquiladata.fr
Pour un traitement interne plus rapide, veuillez nommer vos documents comme suit : Prénom Nom_CV ou CL. N'hésitez pas
à ajouter tout document divers pouvant supporter votre demande. Nous veillerons à examiner votre demande et à vous
répondre dans les 48h."
Courbevoie (92),,,Consultant Junior – Data Engineer Technology Transformation D&A,KPMG,- Courbevoie (92),"#AMilleLieuxD'EtreImmobile
Leader de l'audit, du conseil et de l'expertise comptable, KPMG France est membre de KPMG International, réseau de cabinets indépendants exerçant dans 155 pays.
Avec 200 consultants au sein de notre centre d’excellence données en France et un réseau mondial de plus de 14000 personnes, Lighthouse, notre équipe Data Analytics accompagne des grands comptes internationaux dans leurs projets de transformation centrés sur la donnée, en développant des modèles de machine learning avancés, et en aidant nos clients à mener leur transformation Data Analytics.
Pour faire face aux besoins de nos clients et accompagner notre développement, l’équipe KPMG Data & Analytics cherche à renforcer ses effectifs, et recrute un Data Engineer junior, intéressé par le développement d’applications en réponse aux besoins d’analyses de données clients, et dotés d’une forte sensibilité métier.
Notre équipe Data & Analytics travaille conjointement avec les équipes Digital et spécialistes de domaines (Finance, Cutomer, RH, Operation, Risk, etc.)
Vos missions :
Vous serez intégré(e) dans notre équipe pluridisciplinaire de consultants innovants et motivés, spécialisés sur les problématiques Data & Analytics et d’intelligence artificielle. A ce titre, vous interviendrez de façon opérationnelle sur des missions de conseil autour des sujets de stratégie, transformation, et de modélisation de données dans des entreprises data driven
Vous serez notamment en charge de participer à des missions à travers :
Le recueil des besoins de différents métiers de nos clients (Finance, Cutomer, RH, Operation, Risk, etc.) dans de multiples secteurs d’activité (Banque, Assurance, Energie, Transport, Santé, Distribution, Luxe, etc.)
La conception de cahier des charges et/ou spécifications fonctionnelles
Le développement et la mise en œuvre de solutions Data Analytics / Big Data et industrialisation des solutions sous forme d’applications full stack, souvent en cloud
La recette, documentation et maintenance des applications.
Vous aurez l’occasion de monter en compétences sur tous les aspects d’un projet « Data Driven », tout en apprenant les facettes du métier de consultant

Votre profil :
Vous êtes diplômé(e) d’une école d’ingénieur ou d’un équivalent universitaire.
Vous avez déjà montré un intérêt pour le domaine du développement applicatif intégrant une composante Data, à travers des stages, cours ou projets personnels impliquant le développement back-end et/ou front-end d’une application.
Vous avez une expérience pratique et une bonne connaissance de
o Un ou plusieurs langages de programmation analytique (Python, C#, Java, …)
o Un ou plusieurs Framework Front end (React, D3.js, ..)
o Une ou plusieurs bases de données (MySQL, MongoDB, PostGres)
o Un ou plusieurs cloud providers (Azure, AWS, GCP)
Vous avez une bonne connaissance des outils de gestion des versions (Git...)
Vous êtes familiers avec les bonnes pratiques en termes de sécurité (protocole d’accès, gestion des droits, chiffrement, etc.)
Vous avez une première expérience des environnements cloud et des technologies de virtualisation (Azure, Docker...)
Vous savez travailler avec les utilisateurs métiers et les clients et comprendre leurs besoins
Vous êtes curieux (se), autonome, entreprenant(e) et doté(e) d’une bonne capacité de travail
Vous disposez d’excellentes capacités relationnelles et de présentation, et appréciez le travail en équipe
Vous êtes dynamique, organisé(e) et méthodique
Vous maîtrisez l’anglais dans un environnement professionnel
Localisation :
Vous serez basé(e) à Paris, avec d’éventuels déplacements en province et à l’étranger.
Les conseils RH de KPMG «3 questions préférées de notre directrice recrutement»"
Paris (75),,,Ingénieur Data Intelligence SAP BI F/H,TRIMANE,- Paris (75),"TRIMANE est une société de service spécialisée dans les systèmes d’information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l’information au sein de leur entreprise. En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d’expertise de nos consultants.Nous accompagnons nos clients (CAC 40 et SBF 120) sur des prestations de Conseil, MOA et MOE, autour du traitement et l’analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique. TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d’outils d’Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique. Dans le cadre du développement de la solution décisionnelle de l'un de nos clients, nous recherchons un Consultant SAP BI. Votre mission sera de : - Recueillir et analyser les besoins des utilisateurs/métiers- Rédiger les spécifications fonctionnelles détaillées et/ou techniques- Participer aux phases de modélisation décisionnelle (étoile ou flocon)- Mettre en place les flux d’alimentation- Modéliser des univers, développer des rapports simples à complexes Webi, et selon profil gérer des tâches d'administration sous CMC- Bâtir les stratégies de recette, mener les tests d'intégration technique et fonctionnelle ainsi que leur validation par les référents métiers- Contribuer à différents projets en fonction des besoins et de vos compétences : architecture, installation, administration, optimisation, documentation, ...Profil recherché : De formation Bac+5 ou diplômé d'une école d'ingénieur, vous disposez d'une expérience d'environ 3 ans minimum dans le domaine du décisionnel. De plus, vous disposez de compétences reconnues autour de la suite SAP BI 4 à plus (Designer, Webi, Deski, CMC). Une connaissance d'autres outils décisionnels serait un atout supplémentaire.

Data"
Paris (75),,,Senior Quantitative Analyst - Machine Learning,S.R Investment Partners,- Paris (75),"A Global Investment firm is looking for a Quantitative Analyst with a strong background/ experience with Machine learning AI skills. Build Machine Learning models in Python for automated trading. This is for someone who has had experience working on Machine learning trading projects that have been executed.
A Global Investment firm is looking for a Quantitative Analyst with a strong background/ experience with Machine learning AI skills. Build Machine Learning models in Python for automated trading. This is for someone who has had experience working on Machine learning trading projects that have been executed.
Skills / Experience Required:
Understanding of financial instruments/ Markets
Trading, markets knowledge
Handling large amounts of data
E-Trading
Machine Learning / AI
Quantitative skills
MSc / PhD in Statistics, Machine Learning, Mathematics or related field
Programming / Data Science
Apply Quantitative Research to identify trading signals
Build Machine Learning models in Python for automated trading
Working in a financial trading quant role
Worked with Machine learning on real trading projects
The successful candidate should have a strong background working as a Quant Analyst with experience in handling large amounts of data. In addition to this, we are after someone who is able to build models in Python.
Location: Paris
Salary: € Competitive + Bonus
REFER A FRIEND
If you're interested in this opportunity, forward you're CV ASAP. Alternatively, if you would like to know more information or have a confidential discussion please contact Shanaz Rob - call on
Afficher le nº de téléphone
or shanaz.rob@srinvestmentpartners.com for more details
Follow for updates: https://www.linkedin.com/company/srinvestmentpartners"
Paris (75),,,Ingénieur Big Data,Softeam Finance,- Paris (75),"Vous souhaitez intégrer une communauté d'experts Big Data et Data Management, présente et référencée au sein de grands comptes de la Banque-Assurance majoritairement, mais également du Luxe, de l’Energie, des Transports ? Vous souhaitez rejoindre une équipe dont l’ambition est de vous faire progresser et développer continuellement vos compétences au travers de formations et certifications ? Vous souhaitez participer à l’animation et au développement de cette communauté d’experts ? ... Rejoignez SOFTEAM Data !
CE QUE NOUS RECHERCHONS
SOFTEAM Data recherche un(e) Ingénieur(e) Big Data disposant de fortes compétences en développement sous la plateforme Hadoop (Cloudera, Hortonworks, MapR). Une connaissance des infrastructures Cloud est appréciée (AWS, Azure, GCP).

CE QUE NOUS ATTENDONS DE VOUS
En tant que Consultant(e), vous intervenez sur toutes les phases du cycle de vie d’un projet Big Data, de l’ingestion de données dans un Datalake jusqu’à leur mise à disposition, en passant par le traitement et le stockage des données.

VOUS ETES
Ingénieur(e) de formation, vous disposez d'une expérience minimum de 3 ans autour de la stack Hadoop et du Framework Spark, des bases de données NoSQL et maîtrisez un langage de programmation tel que Python, Java ou Scala. Une connaissance du Machine Learning ainsi qu’une première expérience en environnement bancaire sont un plus. Passionné(e) par l'univers de la Data, vous êtes d'un naturel curieux et souhaitez apprendre continuellement. Bon(ne) communiquant(e), vous avez un niveau d’anglais professionnel.

NOUS VOUS OFFRONS
Un management de proximité au cours de vos missions et tout au long de votre carrière, tout en favorisant votre autonomie et votre responsabilisation. Un environnement professionnel stimulant et épanouissant grâce à nos programmes de formations et à nos communautés d'experts.
Au sein du groupe, vous faites évoluer votre carrière par l'acquisition de nouvelles compétences, qu'elles soient techniques, fonctionnelles ou en conduite de projet.
Une société où il fait bon vivre, SOFTEAM GROUPE est labellisé Happy At Work 2019 !"
Paris (75),,,Consultant big data/java - f/h,Ingéniance,- Paris (75),"Consultant big data/java - f/h
Contexte :


Cette mission se déroulera au sein de la DSI Finance Comptabilité & Ratios de la Direction des Opérations et des Systèmes d'Information de notre client.

La direction métier du domaine Finance - Comptabilité et Ratios de notre client est aujourd'hui en attente d'une solution et d'un support basé sur les technologies BigData et la notion associée de Datalake.

Le point de vue métier vis-à-vis de ce projet à réaliser est une attente très forte comme accélérateur de solution pour l'ensemble des futurs reportings règlementaires à mettre en place entre 2017 et 2020, mais également le premier instrument pour la mise en qualité des données Comptables - Prudentielles et Risques de notre client.

Missions:


La mission a pour objectif la construction d'un � datalake � Finance & Risque. Ce datalake s'appuiera sur la distribution Hadoop HortonWorks.
Par la notion de datalake, il existe une multitude de problématiques à adresser autour des thèmes suivants: audit, qualité, contrôle, gouvernance de la donnée.

Les éléments attendus par la création et la livraison du Datalake Finance & Risk, en tant qu'outil de production, à l'ensemble des métiers Comptabilité, Prudentiel, Risque, Pilotage financier sont multiples.

Le projet tant techniquement que fonctionnellement devra y répondre:
Industrialisation de l'alimentation des données sur la plateforme technique HortonWorks

Alimentation des Meta-données en parallèle des données brutes.
Monitoring de l'ensemble des flux (tenue de cette information en quasi temps-réel)
Le profiling automatique de la donnée intégrée (tag, distribution de valeurs ...)
Abstraction des données

Les notions de Business Glossary et Technical Glossary doivent permettre la passerelle vers les utilisateurs Business métier. Ils doivent pouvoir interroger le datalake avec une sémantique Finance et Risque et non avec des noms de tables ou de champs.
Interprétation du contenu - mise en correspondance des référentiels internes

Toutes les données intégrées devront être liées, enrichies, contrôlées avec l'ensemble des référentiels (Contrepartie, Desk/Book, Devise, Entité Comptable, etc) a priori en aval de la couche de stockage transversale
Application d'une sécurité forte dédiée à chaque profil utilisateur

La sécurité des données d'un datalake est une attente majeure des sponsors métiers.
Une matrice complexe doit pouvoir être définie par les outils du datalake pour y répondre. A cela s'ajoutant la dimension temporelle des politiques d'accès définies.
Piste Audit complète de la données pour tout le SI Finance & Risk

Traçabilité complète attendue, en terme de lineage de la donnée intra cluster Hadoop
Pouvoir suivre les données, leur transformation et leur contribution à quel reporting règlementaire.
Socle de Reporting / Traitement & Controles

Reporting statique donnant la situation des contrôles croisés inter-application
Production des nouveaux états réglementaires attendus (Anacrédit, MREL)
Mise en place d'une Zone d'échange Normalisée avec l'entité maison mère

Enfin, il est attendu par les Business métiers un ensemble d'outil d'interrogation � libre � de la donnée présente dans le datalake, la DataViz est donc une problématique majeure dans la construction de la solution.

Profil recherché:


Diplômé(e) d'une grande école d'ingénieurs ou de formation équivalente (Bac+5), vous avez un excellent relationnel et disposez d'une bonne capacité d'analyse.
Connaissance des méthodes et technologies de développement BigData pour les éléments Alimentation et Transformation de la donnée. En premier lieu une connaissance du moteur SPARK (avec implémentation Scala ou Python)
Capacité de modélisation via la technologie Hive (notion de partitionnement, tables externes ou managées etc...)
Compétence pour implémenter une solution propriétaire Web de monitoring et audit des flux de données (DashBoard Kibana/Graphana, ou par Angular, ou autres techno Web)
Capacité à faire un benchmark des outils marchés de Data Vizualisation (ex: Tableau, Spotfire) ou Data Wrangling (ex: Trifacta)
Compétences techniques:


REST/ JSON
Java/J2EE
Hadoop
Familier avec les méthodes de travail agile / scrum ...
Environnement UNIX/LINUX, Script SHELL
Connaissance des états réglementaires (Surfi, Protide, BDP, Corep, Finrep)
Apache, Tomcat..., Reverse Proxy (gestion d'instance), Administration d'un serveur d'application Websphere
Big Data (Java, Python, Scala, ...)
Big Data (Pig, Hive, ..)
Connaissance des principes de modélisation d'une base de données relationnelle et du langage SQL


INGENIANCE est une société jeune et dynamique qui stimule l'innovation et la transformation digitale par l'accompagnement de ses clients dans leurs projets liés aux nouvelles technologies.

Spécialiste des secteurs Banque, Finance et Assurance, INGENIANCE est également une entreprise technology-oriented qui offre une expertise multi-sectorielle autour du Big Data, du développement informatique, de la Blockchain et de la philosophie DevOps.

Ceci permet à INGENIANCE de se positionner comme une entreprise leader du marché financier et avant-gardiste des technologies disruptives."
Paris (75),"Temps plein, Freelance / Indépendant",,URGENT DATA SCIENTIST IMAGAE RECOGNITION BANQUE / Freelance,EMPIRIC,- Paris (75),"Dans le cadre de ses développements, le DataLab du groupe souhaite confier à 1 Data Scientist, venant en renforcement de son équipe data science, la mission de contrôle de documents.

La mission sera donc organisée comme suit :
a. Développer/améliorer des modèles de reconnaissance optique de caractères (OCR) et de contrôle automatique de documents scannés (au format image): reconnaissance de champs textuels dans des documents normalisés ou non normalisés (exp : nom du client depuis un justificatif de domicile, date de bulletin de salaire, etc.)
b. Enrichir ces modèles par des approches d’analyse automatique de la structure d’un document scanné: reconnaissance de titres/paragraphes, tableaux, graphiques, etc.
c. Intégrer avec les Data Engineer ces modèles dans une architecture micro-services, permettant de faire évoluer facilement les versions des différents modèles et en rajouter des nouveaux sans beaucoup d’impact sur la solution finale.
d. Transférer la connaissance et la compétence aux internes du DataLab

Les livrables attendus :
a. Etat de l’art documenté sur les modèles/approches développées
b. Modules implémentant les différents modèles de contrôle de documents scannés
c. Intégration des méthodes sélectionnées dans une solution interne
d. Documentation/Architecture
Le Data Scientist sera accompagné par une équipe interne. Il devra par ailleurs, fournir les livrables suivants :
a. Documents de spécification des librairies développées.
b. Une description des résultats : description des expérimentations, performances, etc
c. Codes sources commentés et reviewés .
Présentation et partage des travaux.

Pré-requis :
fortes compétences algorithmiques en apprentissage automatique
Python avancé
Connaissances solides en machine learning et deep learning
Connaissance avancée en OCR, reconnaissance d’objet/ d’image
Connaissances en NLP, extraction d’information, classification de textes

Merci d’envoyer vos candidatures à"
Neuilly-sur-Seine (92),CDI,,Ingénieur Big Data Paris F/H,NOVAGEN CONSEIL,- Neuilly-sur-Seine (92),"Nous recherchons des Ingénieur(s) Big DATA (H/F), fortement sensibilisés à la dimension informatique des projets Data pour notre agence de Paris.

Notre contexte :
Forte innovation et complexité technique à la pointe des technologies Data actuelles,
Développement de projets Big Data / Smart Data répondant aux besoins de nos clients,
Une montée en compétences encadrée par des sachants, experts des technologies IT Big Data et Datascience,
Travaux de veille IT, veille R&D et développement de solutions.
Environnement de travail :
Vous interviendrez au sein d'une équipe spécialisée sur les technologies et concepts Big Data /Smart Data et Data Science (Écosystème Hadoop, Spark, ElasticSearch, No SQL, Machine Learning…).

Missions :
Développements informatiques et intégration des technologies Big Data au sein d'un ou plusieurs projets,
Conception, architecture et conception de solutions informatiques Big Data, Cloud,
Réalisation en avance de phase de Proof Of Concept (POC) permettant de mettre en œuvre des technologies prometteuses et de diffuser le savoir-faire de Novagen Conseil sur les projets (au sein de notre DataLab ou en régie),
Participation à la rédaction d'articles sur le Blog Novagen, veille technologique, veille R&D,
Participation aux réponses à appels d'offre,
Mise en œuvre de Traitements et Projets Data science,
Etude de l'état de l'art des derniers travaux Data Science des sujets abordés (eReputation, Traitements prédictifs, Analyse sémantique, Approche IA, Machine Learning etc.).
Profil recherché · De formation BAC+5 Ingénieur en Informatique et/ou Datascientist, vous justifiez d’une expérience concrète en développements Data (Python, Scala, Java, AWS, Azure ...), éprouvée au sein de clients Grands comptes ou start-up,

Vous souhaitez donner une autre dimension à votre carrière en évoluant sur plusieurs des technologies Big Data (Hadoop, Spark, Storm ou Framework équivalents, Traitements Datascience), en mettant en œuvre au quotidien vos compétences sur des projets concrets,
Vous appréciez le travail en équipe, faite preuve de rigueur, d’autonomie et vous exercez une veille technologique active sur ce domaine d’expertise.
Entreprise Novagen Conseil mène des actions de Conseil, développement de projets et Formations sur les métiers du Big Data.

Notre but : l'excellence au service des Innovations métiers de nos clients.

Présents sur les Hauts-de-France et l'Ile de France, nous déployons deux offres principales :

Un cabinet de conseil Data : Stratégie / Changement / Architectures ...
Une Data Factory : Développement de solutions : Tableaux de Bord, DataLake, Briques Big Data ..."
Paris (75),"Temps plein, Freelance / Indépendant",500 € par jour,Ingénieur Data / Freelance,TLTI,- Paris (75),"Descriptif : Dans le cadre d’un projet spécifique, nous souhaiterions recruter un data engineer. Une phase de prestation sur les tehcnologies Big Data utilisée en interne peut être envisagée avant recrutement.

Mission (pour prestation préalable) : lié à un projet agile dont les sprints durent 3 semaines, il participe à la conception, aux développements et à la mise en oeuvre d’entrepôts de données spécifiques nécessaires au fonctionnement de l’application.

Compétences requises : Kafka, suite Elastic, Python, Spark, Scala. Des bonnes connaissances en administration système sont demandées pour le poste."
Paris (75),CDI,,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Data Scientist (H/F) pour renforcer ses équipes.
Dirigée par le Chief Data Officer et rattachée au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques met en œuvre la stratégie DATA avec comme principales préoccupations
D’améliorer la gouvernance des données ;
De contribuer à la data réputation de la Banque de France ;
De tirer le meilleur parti des masses et de la diversité des données disponibles au sein de la banque Centrale,
De développer des projets d’intérêt commun
De développer une culture de la donnée au sein des unités métier

Présentation du Service
Au sein de la DDSA, le SIAD (Service Industrialisation et Algorithmique des Données) a pour missions de construire et entretenir les socles techniques BIG DATA, de réaliser des prototypes de solutions basées sur les approches Data Science et IA et de mettre à disposition des solutions business intelligence pour les équipes métier.

Descriptif de mission
Le pôle « Data Science et IA » cherche à renforcer ses capacités en recrutant un(e) Data Scientist.
Les missions de ce pôle, partie intégrante du domaine « conseil et expertise », sont les suivantes :
Cartographier de façon continue, en relation avec les équipes d’innovation et les urbanistes, les processus métier pour lesquels une approche Data Science pourrait procurer un avantage compétitif ou préserver un territoire acquis
Épauler les métiers dans la définition et la stabilisation de leurs besoins
Mettre en place de façon continue les Proofs of Concept (POC) fonctionnels et techniques issus des analyses d’opportunité
Benchmarker de façon régulière les outils du Big Data
Préparer l’industrialisation des POC identifiés comme pertinents
Accompagner la montée en compétence des équipes métier et des équipes techniques sur le Big Data
Sous l’autorité du « Lead Data Scientist », vous serez en charge plus particulièrement :
De la prise en charge des besoins métier et de leur analyse ;
De l’identification des solutions potentielles et du choix de la solution la plus adéquate au regard des besoins et contraintes tant métier que techniques ;
De la conception et de la mise en œuvre de la solution (POC, prototype, MVP),
De l’accompagnement et du soutien aux équipes projets en charge de l’industrialisation des solutions.

Profil recherché
De formation supérieure en informatique ou métiers de la donnée (Ingénieur ou équivalent), vous avez minimum 2 ans d’expérience dans la mise en œuvre de solutions mobilisant des connaissances statistiques et/ou mathématiques avancées, y compris en contexte d’apprentissage/alternance dans des contextes de travail variés (recherche, entreprises commerciales, sphère publique ) constituera un avantage clé.
Vous disposez d’une forte appétence pour la concrétisation de solution dans un environnement Bigdata.Par ailleurs, vous avez la maîtrise :Des sous-jacents mathématiques aux approches Bigdata / Data Science (mathématiques et statistiques, Machine Learning, réseaux de neurones ) et des bibliothèques de Machine Learning (Scikit Learn, PyTorch, )
Du développement en Python
Seraient en outre appréciées, dans l’un ou plusieurs des domaines suivants :
Une très bonne connaissance en développement sur la stack Hadoop (Oozie, Sqoop, Hive, Hbase, ), sur les technologies Spark (MLlib, SQL, GraphX et Streaming), en langages PySpark, Java et R (SparkR).
Une très bonne maitrise des outils de Search (ElasticSearch) et de streaming (Kafka)
Une bonne connaissance des bases de données NoSQL telles que Mongodb et Neo4J
Une bonne capacité à intégrer des sources de données multiples, internes / externes, structurées / non structurées et des interconnexions entre les SGBD et Hadoop
Une bonne capacité à restituer les résultats visuellement à l’aide de Kibana ou PowerBI
Une facilité à développer dans un environnement innovant en méthodologie Devops et Scrum
Rigoureux et apte à anticiper, vous avez le sens du résultat au service du client et êtes doté d’excellentes capacités de communication pour faciliter le travail « en réseau » :
Force de proposition et aisance de communication pour démontrer la valeur ajoutée des solutions Big Data et Machine Learning.
Excellente méthodologie de travail et de gestion de projet, vous travaillerez en mode agile.
Très bon relationnel, capacité à s'adapter, esprit d’équipe, ouverture d’esprit et curiosité naturelle, vous suivez l’évolution des technologies et nouveautés relatives au Big Data, Datascience et IA
Une bonne pratique de l’anglais est nécessaire.
Ce poste, en contrat à durée indéterminée, est basé à Paris (1er), avec des déplacements ponctuels dans les sites banque de France à Paris et en régions.
La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes."
Paris 2e (75),,,Machine Learning Software Engineer,Adikteev,- Paris 2e (75),"Adikteev is the leading app retargeting solution that helps performance-driven marketers target and engage their app audiences. Combining science and creativity, Adikteev delivers measurable results that increase user LTV and fuel business growth.
Founded in 2012, Adikteev has worked with leading app companies like eBay, Nexon and Yelp to retain their loyal users and boost incremental revenue. A leading advertising technology company, Adikteev has been recognized as #10 among Inc Magazine’s Top 5000 fastest growing companies and #2 in global retargeting, of the AppsFlyer Performance Index. Its team of 60 people is based in Paris, NYC and San Francisco.

Adikteev is now looking for a talented Machine Learning Software Engineer to join the Data Science team based in Paris. Your role as a key member of the team will be to implement and maintain data-intensive models that boost performance and address business opportunities in collaboration with Data Scientists.
As the center of innovation and scientific excellence of the company, the Data Science team focuses on applied research to improve continuously the existing approaches and to design out-of-the-box models in order to improve the performance of the solution. The team relies on a platform built with the latest technology including Kafka, Cassandra, Druid, Spark, and deployed on AWS.

Responsibilities:
Set up data preparation pipelines in order to help data scientists extract valuable insights and identify new product opportunities and model improvements
Maintain and improve existing machine learning stack that requires to be scalable, high-performing and maintainable
In collaboration with other software engineers and data scientists, deploy the models in production and monitor the performance
Inspire good coding practices throughout the Data Science team

Master's degree or PhD in a quantitative field with emphasis on software engineering
Excellent analytical skills and strong knowledge of development and coding practices
4+ years of experience in Python coding applied to the implementation of out-of-the-box models
Strong knowledge of applied mathematics
Experience in working with distributed systems
Knowledge about deep learning framework (TensorFlow, Keras, etc.)
Creative, pragmatic and proactive
Loves teamwork and has great communication skills
Good to know:
Office located avenue de l’Opéra
Remote working possible (1 day / week)
Participation in scientific conferences
Annual seminar in Europe"
Gennevilliers (92),,,Data scientist,PRISMA MEDIA,- Gennevilliers (92),"1er groupe bi-média de France en audience print-digital, Prisma Media est aussi l'acteur N°1 en presse magazine et en audience vidéo. Un leadership qui assure à Prisma Media un potentiel optimal d'audience de plus de 40 millions de personnes chaque mois sur ses différents médias.
Avec un portefeuille de 25 marques incontournables, le groupe est présent sur les principaux segments grand public (féminin, cuisine, télé, people, découverte, économie…).
Porté par la mission de devancer les besoins et envies de ses lecteurs et utilisateurs sur tous les supports, Prisma Media adopte une stratégie offensive de développement et d'innovation dans les secteurs en forte croissance tels que la monétisation de la data, la vidéo et le mobile, avec une ambition d'avoir toujours UN MÉDIA D'AVANCE.
Rattaché(e) au manager du service BI / Analytics / Data science, vous intervenez en tant que Data Scientist afin de développer l’expertise data science chez Prisma Media.

Ce service a pour vocation d'optimiser l’utilisation des données client et business par les différents services de l’entreprise, pour aider à la prise de décisions, améliorer la compétitivité de l’entreprise et participer activement à la transformation digitale. Tout cela s’effectue au travers des deux leviers que sont l’activité Analytics (BI) et la Data science.

Missions :
Vous créez de la valeur autour de la data en utilisant des techniques de machine learning et de data visualization
Vous menez des projets passionnants et innovants autour de la data et de l’IA ayant un fort impact sur le business : prévision des ventes, prédiction de la valeur client, optimisation des enchères publicitaires, étude élasticité prix, …
Vous intervenez sur l’ensemble du projet : cadrage, traitement des données, modélisation et déploiement des modèles
Vous collaborez avec l’ensemble des départements (pôles marques, marketing, RH, régie publicitaire, …) en les accompagnant dans l’identification de leurs besoins et la structuration de la problématique, ainsi que dans l’appropriation des analyses et des modèles
Vous collaborez avec les équipes IT pour la mise en production des modèles
Vous apportez une aide à la décision qui s’appuie sur les enseignements tirés des analyses et vous fournissez des recommandations actionnables aux métiers
Vous intervenez notamment sur les données issues de la diffusion (des magazines), du trafic digital et de la base CRM (Users accounts qui représente environ 2 Millions d’utilisateurs actifs et 3 Millions d’utilisateurs flottants)
Vous assurez une veille technologique sur les solutions de Machine Learning et les solutions de gestion de données, les tendances et nouvelles pratiques
Vous respectez l’éthique en matière d’usage de la data.

Profil recherché :
De formation supérieure (de type BAC+5, École d’Ingénieur ou équivalent universitaire Master), vous disposez de solides connaissances techniques en matière de data et avez également une réelle aptitude à comprendre les enjeux business et plus particulièrement ceux engendrés par la data. Vous disposez d’une expertise dans le domaine de la data science et des statistiques
Vous possédez une expérience professionnelle de 3-5 ans minimum dans la conception de modélisations et d’un écosystème data au sein de systèmes complexes sur un grand volume de données et de trafic. Vous maîtrisez parfaitement les techniques de data science et de machine learning (apprentissage supervisé et non-supervisé dont gradient boosting, réseaux de neurones, clustering, réduction de dimensions, séries temporelles, statistiques avancées)
Vous êtes familier avec les méthodes agile (SCRUM / Kanban) et le cycle de vie du produit / projet.
Au-delà de vos compétences techniques, vous avez une approche business-centric.
Une connaissance des nouvelles réglementations de protection, et exploitation des données (GDPR, data cleaning, data delivery) serait un plus.
Vous êtes un bon communicant et avez la capacité de présenter des notions complexes de manière simple et claire. Vous appréciez le travail en équipe et collaborer de manière transverse.
Compétences techniques:
Python (NumPy, SciPy, Pandas, Scikit-Learn)
Compétences cloud AWS ou GCP
Git
Bases de données Oracle / SQL
NoSQL

Votre future entreprise ?
Vous vous demandez qui se cache derrière GEO, Télé Loisirs, Femme Actuelle, Capital Gala, Voici et une quinzaine d’autres titres ?
C’est Prisma Media, leader historique de la presse magazine, désormais une entreprise full media print, digital, vidéo forte de :
1,5 millions d’abonnés à nos magazines
80 millions de magazines vendu par an
Plus de 30 Millions de visiteurs uniques par mois sur nos sites Web
Son appartenance au Groupe Bertelsmann Leader mondial dans le domaine des Media (M6, RTL, BMG, Freemantle…)

Les petits plus chez nous ?
9 semaines de congés payés / RTT, 13ème mois, Participation, Télétravail possible
4 abonnements magazines print au choix dans notre catalogue ainsi que tous les magazines en digital
Des locaux attrayants : ZenZone (fauteuil massant, hamac), jardin, terrasses, Ping-pong, babyfoot, Wifi à volonté…
Une conciergerie : pressing, coiffeur, boutique…
Café et thé gratuits, cantine de qualité avec des produits de saisons cuisinés sur place
90% de nos collaborateurs sont heureux dans leur job (source : Enquête Bertelsmann 2019)
Des formations & conférences mensuelles sur des thématiques diverses : réseaux sociaux, développement personnel, intelligence artificielle…
Des events annuels : Garden party, journées Vis ma vie…

Prisma Media propose tous ses postes aux personnes en situation de handicap en privilégiant une logique de compétence et d'emploi pérenne. Le groupe est signataire de la Charte de la Diversité et partenaire de l'association Adapt.
Exercice de vos droits
Conformément à la réglementation en vigueur, vous pouvez exercer vos droits d'accès, de rectification, d'opposition, de suppression, de limitation du traitement, et à la portabilité des données à caractère personnel, en adressant votre demande au DPO du Groupe Prisma Media, soit à dpo@prismamedia.com soit par courrier à Prisma Media - DPO, 13 Rue Henri Barbusse. 92230 Gennevilliers.
Entreprise: Prisma Media SNC
Pays: France
Etat/Région: Hauts-de-Seine
Ville: GENNEVILLIERS
Code Postal: 92230
Emploi ID: 60334"
Gentilly (94),,,Data Scientist,Silex,- Gentilly (94),"Silex propose la première solution de sourcing cognitif en SaaS. Inédit sur le marché, la vocation de Silex est d’accompagner les services Achats dans l’optimisation de leur dispositif de sourcing fournisseurs. Les technologies d’intelligence artificielle permettent d’automatiser les tâches récurrentes au sein de l’organisation et assistent les acheteurs dans leurs démarches de scouting et sourcing fournisseurs en leur apportant les bonnes informations, au bon moment.
La start-up compte deux sites : l’un à Paris et l’autre sur le pôle de compétitivité de Sophia Antipolis. Au quotidien, l’équipe est composée d’une vingtaine de personnes et s’articule autour d’un pôle commercial, d’un pôle marketing et d’un pôle technique.
Suite à une levée de fonds significative, Silex est à la recherche d’un(e) Data Scientist pour intégrer l’équipe technique et travailler sur l’internationalisation de notre data warehouse. Poste central au sein d’une équipe de 25 personnes, nous sommes à la recherche d’un profil expérimenté et passionné par les solutions logiciels.
Votre mission, si vous l'acceptez :
Vous construirez et ferez évoluer l'infrastructure de reporting, d'analyse et de stockage de données, permettant à nos clients d'optimiser leurs achats et de maximiser leurs analyses
Vous deviendrez un champion du modèle de données Silex
Vous automatiserez des processus de chargement des données et construirez les outils de surveillance inhérents.
Vous améliorerez et les processus d'ingestion, de transformation, de nettoyage et de chargement des données.
Vous travaillerez en étroite collaboration avec les Product Owner et les Ingénieurs pour créer des tableaux de bord et des rapports significatifs.
Le profil que nous recherchons :
Expérience & Compétences
Vous êtes ingénieur ou titulaire d'un master ou d'un doctorat dans un domaine quantitatif ou connexe (statistiques, informatique, mathématiques).
Vous avez plus de 5 ans d'expérience pratique avec la manipulation de données : nettoyage, modélisation et intégration, le tout à un poste similaire.
Vous possédez une grande expérience en business analytics
Vous êtes capable de travailler dans une équipe multifonctionnelle aux côtés de développeurs, statisticiens et autres scientifiques de données.
Aptitude à expliquer des domaines complexes en termes simples et à collaborer avec divers partenaires commerciaux pour collecter des informations et traiter des points.
Vous êtes enthousiaste à l'idée de résoudre des problèmes et d'identifier des modèles et des informations dans des données structurées et non structurées.
Construire et faire évoluer l'infrastructure de reporting, d'analyse et d'entrepôt de données, permettant ainsi à nos clients d'optimiser leurs dépenses et de maximiser leurs économies.
Données solides et techniques de modélisation dimensionnelle.
Solides compétences analytiques SQL.
Expérience avec Elastic Search ou équivalent, Hadoop ou équivalent
Expérience avec ETL/ELT et les outils d'intégration de données (Informatica, Kettle, CloverETL, etc.) bienvenues
Expérience avec les fournisseurs de BI embarqués/OEM (par ex. Qlik, Sisense, GoodData, Birst, etc.) appréciées
Expérience en programmation avec Python ou équivalent.
Des expériences de développement en Java seraient un plus
Travailler chez Silex, c'est avant tout :
Un environnement de travail agréable et stimulant avec des challenges à relever chaque jour.
Des collègues sympathiques, talentueux, et bienveillants.
L'opportunité d'avoir un impact fort, visible et immédiat sur le développement de Silex.
Des allers-retours réguliers entre Paris et Sophia Antipolis.
Etant donné que le diable se trouve dans les détails :
Lieu : Gentilly (94250) ou Sophia Antipolis
Début : dès que possible
Type de contrat : CDI
Rémunération : Attractive - selon profil
recrutement@silex-france.com"
Paris (75),,,Consultant Data Scientist,Bartle Business Consulting,- Paris (75),"Au sein de l’équipe Math4Business, vous intervenez de façon opérationnelle sur des missions de conseil autour de sujets datas tels que l'analyse de données complexes, la segmentation, la modélisation (y compris statistique), la mise en place d’équipes ou d’environnement Big Data, en lien avec des besoins métiers concrets.

Vous participez à des missions autour de la data au sein d’équipes pluridisciplinaires. Vous comprenez les enjeux et attentes métiers de vos clients, réalisez des analyses tout en vous assurant du respect des règles méthodologiques. Vous êtes encadré par des Managers et Associés qui vous forment au métier du conseil.

Vous participez également aux projets de recherche internes afin de favoriser l’innovation et l’entrepreneuriat, des valeurs fortes de notre cabinet.
02Profil recherché
Diplômé d’une Ecole d’ingénieurs avec une majeure en statistiques ou d’une Université, avec une spécialisation en informatique et mathématiques, vous vous distinguez par votre capacité d’analyse, votre rigueur intellectuelle et votre proactivité.\r\n\r\n \r\n\r\nVous avez d’excellentes capacités relationnelles et le goût du travail en équipe. Vous êtes passionné par la Data et aimez sensibiliser vos collaborateurs à ce sujet.\r\n\r\n \r\n\r\nVous êtes à l’aise dans les domaines suivants :\r\n\r\n \r\n
Data Mining, Intelligence Artificielle, Machine Learning ;
Langages de programmation et Scripting data science (Python, R, Java, Scala) ;
Recherche opérationnelle et connaissances robustes en statistiques ;
Gouvernance des données ;
Bases de données relationnelles & NoSQL (MongoDB, Cassandre, Hbase,..) et langages de requête ( Hive, Pig) ;
Architecture technique des environnements Big Data.
\r\n
\r\n \r\n\r\nVous souhaitez développer vos capacités scientifiques dans un environnement business ?\r\n\r\nAlors, postulez et venez rejoindre notre équipe de Data Scientists !"
,,,,,,
La Défense (92),,,Data scientist / Web design,Systemathics,- La Défense (92),"Posted on: December 10 2019
Mission
You will work on the development of a market data management solution.
You will handle data collection, indexing and storing using Systemathics tools as well as implementation of APIs and data visualization features.
Hand-in-hand with Systemathics’ teams you will ease access, query, visualization and navigation through huge amounts of high quality market data.
Responsibilities
Understand challenges of market data sourcing and processing
Analyze datasets, detect patterns and implement market data integration models
Ensure robustness of the overall workflow: cleaning, validation/cross-validation and normalization
Design data visualization libraries and end-to-end monitoring features
Requirements
Web front-end development experience using Kendo UI, HTML5, JavaScript
Developing software in a .NET environment
Python web frameworks
Working knowledge of development tools such as debuggers, memory profilers, and performance measurement
Experience with low-latency, high-volume, and cloud systems"
Paris (75),,,CDD - Data Scientist ou Statisticien (F/H),Allianz France,- Paris (75),"Diplômé(e) en Data Science ou en Statistiques, vous cherchez un poste où vos compétences sont valorisées.
Vous souhaitez travailler en équipe et évoluer dans une entreprise qui met ses collaborateurs au coeur de sa stratégie de développement !
Venez apporter votre technicité et votre bonne humeur au sein de notre centre de compétences Data & Performance Vie & Santé !

Vous réalisez la rétro-documentation des Model points ;
Vous construisez des référentiels ;
Vous mettez en place des traitements industriels de données sur le périmètre Life & Health (projet Arpia) ;
Vous sécurisez le Run sur la construction des Model points.
Vous êtes diplômé(e) Bac+5 en Data Science ou en Statistiques ;
Votre très bonne maîtrise des techniques d’exploitation des données est reconnue grâce à une première expérience réussie ;
Vous connaissez l’assurance ;
Vous faites preuve d’adaptabilité ;
Vos capacités d’analyse et de synthèse ne sont plus à démontrer ;
Votre communication est aisée et vous partagez volontiers vos connaissances techniques vis-à-vis de personnes n’ayant pas les mêmes compétences ;
Vous êtes curieux et force de proposition ;
Votre maîtrise de SAS, Python, MS Office en fait pâlir plus d’un ; de même que celle de l’anglais (à l’écrit et à l’oral)."
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Nanterre (92),"Apprentissage, Contrat pro",,Alternance - Marketing Data Scientist Junior H/F,Total,- Nanterre (92),"Au sein du service Capital Client du département Marketing Réseau de Total, vous serez rattaché au Marketing Data Scientist. Vous travaillerez en étroite collaboration avec les pôles Marketing Fidélisation & Communication, Digital & Recrutement et Qualité, Satisfaction, Études & Expérience Client de l'équipe.

Vos missions :
Business intelligence : construction et suivi des KPIs
Connaissance client : comportements d'achat, préférences, valeur client, enrichissement de données, satisfaction client
Machine Learning : prédiction du churn, prévisions de vente, segmentation client, détection de la fraude, associations de produits
Ciblage des campagnes commerciales : personnalisation des offres en fonction des habitudes de consommation, des préférences, du potentiel de développement de valeur et de la générosité cible
Analyse de la performance des campagnes commerciales : attribution de la conversion, marge additionnelle et ROI
Qualité des données
Challenges en data science
Contexte et Environnement
Ce que vous développerez durant votre expérience :
SQL,
R,
Machine Learning
Profil recherché
Si vous suivez une formation supérieure orientée Data que vous recherchez un contrat en alternance d'un an à partir de septembre 2020 et que vous :
Justifiez idéalement d’une première expérience dans ce domaine;
Maitrisez SQL et R;
Savez travailler en équipe et communiquer avec des interlocuteurs externes;
Avez un bon niveau d'anglais.
Une mission passionnante vous attend au sein de Total. Alors n'attendez plus pour candidater !
Réfèrence
28726BR
Métier
Stratégie Economie
Région, département, localité
92 - Hauts-de-Seine
Localisation (Précisions/Mots-clés)
Nanterre
Type d’emploi
Alternance
Niveau d’expérience requis
0- 3 ans
Branche
Marketing & Services
Lieu des entretiens
Immeuble Spazio - Nanterre
A propos de nous/Profil de l'entreprise
BETTER ENERGY NEEDS YOU
Donnez le meilleur de vous-même à l’énergie ! Rejoignez TOTAL : plus de 500 métiers différents dans 130 pays. Une entreprise responsable avec des standards de sécurité et d’éthique forts, des perspectives d’évolution de carrière variées, une culture de l’innovation et une mission partagée par les 100.000 collaborateurs du Groupe : rendre l’énergie meilleure jour après jour.
Tâche arrivée à expiration
03-Jul-2020"
Paris (75),CDI,,Data Analyst (H/F) CDI Paris,Winamax,- Paris (75),"Nous recherchons un(e) Data Analyst (H/F) pour nous accompagner dans la gestion de nos données poker & pari sportif. Rattaché(e) au pôle Customer Relationship Management et sous la responsabilité du CRM Manager, tu as un rôle clé dans l’amélioration de notre connaissance clients et de nos offres & produits.
Tu as un réel intérêt pour les problématiques business/marketing et tu souhaites mettre à profit ton expérience dans l’analyse de données ?
Tes missions :
Apporter ton expertise technique afin de proposer à nos clients (tes interlocuteurs internes), l’offre et le canal de communication adéquats dans une démarche ROIste,
Collaborer avec les équipes techniques et métiers pour définir les besoins, restituer et expliciter les résultats obtenus :
Acquisition (performance des différents leviers, lifetime value clients, rentabilité de partenariats…),
Animation & Offre (segmentation client, cross-selling, recommandation de produits…),
Rétention (analyse de CHURN, mailing auto…),
Effectuer une veille constante des usages et pratiques en matière d’analyse de données.
Ce que Winamax peut t’apporter :
Evoluer au sein d’un pôle marketing en perpétuelle recherche d’innovation,
Des échanges avec des collègues experts dans leur domaine,
Un éventail de missions très large.
Profil recherché
Tu disposes de bases solides en mathématiques et statistiques appliquées que tu aurais acquises durant ton Master 2 Statistique ou Mathématique.
Bien qu’évoluant dans un environnement international, les échanges se font en français, il n’est pas nécessaire de parler anglais pour ce poste, tant que tu fais parler les données.
Si le poste ne requiert pas d’être un pro du poker ou des paris sportifs, ta pratique personnelle et tes connaissances du pari sportif et du poker seront autant de solides piliers pour sécuriser ta compréhension des enjeux et ta prise de poste.
Qualités requises :
Tu es motivé(e) à l’idée d’échanger avec les différents référents marketing pour comprendre leurs problématiques et y répondre,
Tu es animé(e) par l’envie de comprendre les comportements clients dans le but d’en tirer des enseignements à forte valeur ajoutée,
Tu es proactif/ve et pragmatique, tu sauras prendre en compte les besoins de tes clients internes afin de proposer des outils, analyses et reportings répondant aux différents enjeux pour une meilleure connaissance client & business,
Tu es rigoureux/se et précautionneux/se concernant les différents biais pouvant affecter tes études et tu sauras y remédier (séries temporelles, cross validation),
Tu sais prendre du recul et être pédagogue dans tes retransmissions et analyses auprès d’interlocuteurs non spécialistes en data,
Tu sais trouver le bon compromis entre délivrabilité & automatisation de manière à répondre aux impératifs urgents et de long terme.
Compétences requises :
La maitrise et pratique quotidienne des outils R, Python, SQL,
Des bases solides en automatisation et une bonne capacité à produire des codes documentés et optimisés,
L’utilisation ou la mise en place d’outils de data visualisation et/ou librairies de dataViz (Shiny, Tableau…),
L’écriture d’algorithme from scratch répondant à des nouveaux besoins (algorithme de payouts, calcul de risques des offres…).
Tu es expert(e) concernant les concepts suivants :
Statistiques descriptives (distribution univariée/multivariée, analyse factorielle…),
Data mining (recherche d’insights, extraction des données les plus pertinentes…),
Clustering supervisé/non-supervisé,
Scoring (lifetime value, CHURN rate…),
Séries temporelles,
Text mining,
Idéalement en analyse des données massives (outils, algorithmes map-reduce).
OK MAIS À PART ÇA, POURQUOI REJOINDRE LE STAFF WINAMAX ? (BONNE QUESTION!)
Tu es sûr(e) de ne pas t'ennuyer : sur un marché très concurrentiel, tirer son épingle du jeu en faisant évoluer nos applicatifs est un impératif,
Tu auras des collègues sympas et compétents auprès desquels tu apprendras énormément et qui seront ravis d'apprendre de toi,
Tu évolueras dans un cadre de travail agréable avec des espaces de travail lumineux et spacieux et une cour intérieure immense, avec une localisation centrale dans Paris,
Ah oui, on a aussi : une cafétéria avec boissons offertes, une salle de sport, une salle jeux vidéo, un babyfoot, deux terrains de pétanque, un CE au top…,
What else ?? Il ne manque que toi pour les barbecues de l’été !
MODALITÉS ASSOCIÉES AU POSTE
Poste à pourvoir ASAP en CDI temps plein exclusivementet dès que possible à Paris
Volume de travail : 35h par semaine
Rémunération : selon profil et expérience
Process de recrutement
Afin de nous permettre d’apprécier tes capacités techniques et ton parcours, nous te remercions de nous faire parvenir ton CV ainsi qu’une lettre de motivation en français.
Ce poste nécessite un certain niveau d'expertise technique, c’est pourquoi nous aimerions que tu nous partages un résumé de l’un de tes projets dont tu es le plus fier en analyse de données (idéalement en lien avec des problématiques marketing). Merci d'utiliser la zone ""Portfolio"" pour nous partager ton résumé :)
Les étapes :
Entretien téléphonique RH (~30min)
Test en ligne
Entretien physique avec le manager et le responsable R&D Betting (~1h)
Entretien avec le Directeur Général
Et plus si affinités !
Informations complémentaires
Type de contrat : CDI
Lieu : Paris, France (75007)
Niveau d'études : Bac +5 / Master
Expérience : > 3 ans"
Paris (75),,,Data Scientist / Biostatisticien(ne) / Biostatistician,Ariana Pharma,- Paris (75),"Ariana Pharma is a leading digital health Company focused on developing advanced therapeutic decision support systems. Using our advanced Artificial Intelligence technology, we help the industry transform the promises of AI and Big Data into precision medicine realities for patients.
We are transforming the way clinical trials are designed and analyzed and we believe our technology dramatically increases the chances of success therapeutics development. Moving away from binary readouts, our Explainable AI (XAI) provides a platform to capture the value of clinical assets and incrementally progress them towards approval.
We have a strong track record of success in a broad range of therapeutic areas that include Cancer, neurogenerative diseases, metabolic and auto-immune diseases etc.
We are looking for like-minded individuals who share our enthusiasm for making AI and precision medicine a reality for patients, and who want to join our rapidly growing dynamic team based in Paris. Our goal is to attract enthusiastic, dynamic, autonomous and organized Data Scientists and Biostatisticians with excellent communication skills who will thrive at the heart of technological innovation.
Responsibilities include:
Using data analytics techniques including our KEM® data mining software to analyze data from biomarker and clinical studies
Developing and applying new machine learning and statistical methods
Contributing to the design of clinical trial study plans
Writing up study reports, presenting results and suggesting interpretations.
The successful candidate will also participate in:
Commercial processes and pre-sales and post-sales technical support
Technical specifications for our technology and testing new versions of our KEM® software.
Skills required:
Masters degree, Engineering degree, PhD or equivalent in (bio) statistics, computer science, data science or applied mathematics
A good programming level in R. Other programming languages are a plus.
Proficient skills in descriptive and inferential statistics (hypotheses testing), statistical modeling (linear models, mixed models…) machine learning (NN, SVM, random forest…) and a sound knowledge of statistical methods in general.
Excellent spoken and written English.
Industrial experience as a data scientist or biostatistician, ideally related to biomarker research or clinical studies would be a plus
Knowledge of Association Rules would be a plus
Please send your application and CV by mail to : info@arianapharma.com"
Puteaux (92),Stage,12 000 € - 14 400 € par an,Data Scientist passionné e [STAGE],Avanseo,- Puteaux (92),"Détails de l'annonce
Avanseo est une marketplace de financement et une technologie de scoring qui améliore significativement l’accès des Très Petites Entreprises (TPE) au crédit de trésorerie. Grâce aux algorithmes d’apprentissage et d’automatisation, Avanseo élimine la complexité du processus de prêt et octroi un financement en 24 heures seulement en ne requérant aucune garantie de la part des dirigeants.
Avanseo est une Fintech portée par des professionnels de la finance et de la technologie. Acteur émergent et innovant de ce secteur en France, nous recherchons des personnes curieuses, humbles et positives pour nous accompagner dans la réalisation de ce beau projet. Vous aurez la chance de rejoindre une entreprise à ses débuts qui compte aujourd’hui : une centaine de clients, une levée de plusieurs millions d’euros avec des investisseurs de renom. Vous aurez également l’occasion de contribuer concrètement à la conception et au perfectionnement de ce produit plus technologique que financier. Libre de tout lègue technique ou administrative, vous aurez carte blanche. L’organisation d’Avanseo, à l’image du produit que l’entreprise développe, se veut simple, efficace et transparente : nous valorisons l’autonomie et la prise de décision.
Nos bureaux sont situés au 19eme étage de l’Arche de la Défense, dans le nouvel incubateur de Paris&Co – Le Swave.

Afin de répondre aux attentes de nos clients, nous construisons une plateforme sous forme de microservices. Nous voulons faire une plateforme robuste, intelligente et évolutive.
Vous contribuerez au succès de cet ambitieux projet et affronterez de nombreux défis techniques.
Vous serez en charge sous la supervision des ingénieurs :
De l’étude et du nettoyage des données servant à l’élaboration de nos modèles
De la conception et de la validation de modèles de machine learning pour répondre à nos problématiques
De la préparation des modèles / packages utiles / fonction d’évaluation pour la mise en production
De la documentation des modèles et de la présentation des résultats obtenus par nos modèles (KPI)
De la bonne utilisation des modèles par l’équipe de gestion clientèle (bon graphes, interprétabilités, etc)
De la vérification du bon comportement des modèles en production et de leur mise à jour si nécessaire
De la spécification et du développement de l’automatisation de ces mises à jour, en coopération avec les DevOps,
De participer aux réflexions sur les modèles pertinents à développer, aux données à collecter et aux nouvelles utilisations des données déjà en notre possession avec de répondre aux demandes clients
Les projets sont gérés par la méthode agile Kanban (avec un backlog).
Profil recherché
Vous êtes un e passionné e de modélisation. Ce que vous aimez, c’est résoudre des problèmes complexes ou mettre en production des modèles efficaces d’aide à la décision. Ce qui vous motive, ce sont des projets ambitieux qui s’attaquent à des besoins réels. Vous êtes fiable, rigoureux, et vos tests sont là pour le prouver. Vous pensez que tout travail répétitif devrait être industrialisé. Vous êtes soucieux·se de sécurité et vous aimez sensibiliser vos collègues à cette question. Vous êtes autonome et vous aimez travailler en équipe. Vous êtes organisés et avez démontré dans le passé votre capacité à gérer plusieurs projets de front.
Vos compétences :
Vous avez une solide expérience analytique, par exemple un diplôme en mathématiques, physique, informatique ou dans un domaine apparenté.
Vous avez un première expérience pratique démontrée de la modélisation prédictive et de la mise en œuvre pragmatique de techniques d'apprentissage automatique pour résoudre efficacement des problèmes du monde réel (première expérience professionnelle, stage long ou participation à des challenges).
Vous avez un très bon niveau en développement en Python (scipy, numpy, pandas, scikit-learn) ou en R.
Vous avez de bonnes connaissances en SQL et bases de données NoSQL (Mongo, Cassandra)
Vous avez de bonnes connaissances du JSON et de son formalisme
Vous mettez en œuvre un scepticisme sain, et avez bon recul sur ses productions et une bonne capacité de remise en cause de vos modèles
Vous correspondez à cette définition : quelqu'un qui ne se contente pas d'appliquer simplement des modèles prêts à l'emploi ; vous voulez savoir comment, quand et pourquoi ils fonctionnent
Vous avez le désir de construire des solutions innovantes mais pratiques aux problèmes de l'entreprise
Vous connaissez idéalement Spark et les framework big data (Storm, Flint…).
Vous maitrisez l’anglais à l’écrit comme à l’oral.
Les stacks techniques d’Avanseo sont : Python, NodeJS, Kafka, Mongo, MySQL, AWS, Scala."
Gennevilliers (92),Stage,,Stage R&D - Data Engineer / Internship Data Engineer (H/F),Diagnostica Stago,- Gennevilliers (92),"We, at the Optimisations & Methodologies are focused on data. We use it to deliver value on 3 types of projects: decision making support, data product and tools development and pure innovation. We are looking for an intern for at least 3 months to help us building a new interactive analysis tool.

Mission :
You will be in charge of developing a Shiny app that provides insight and guidance for maintenances operators and system investigators about machines' states and failures through data science tools and visualisations.

Responsibilities :
As lead developer for the app you will:
Gather user requirements,
Design a user interface,
Integrate a python module into the shiny app,
Implement datavisualisation features,
Research and implement automated diagnostics reports,
Develop and implement failure predictive models,
Organize user testing phases and gather feedback on the field."
Paris 2e (75),CDI,,Data Scientist H/F,RCi,- Paris 2e (75),"Référence de l'offre :
TR/DS

Type de contrat :
CDI

Date de l'offre :
2020-01-13

Lieu :
Paris - 75002

Missions :
Participer au développement du DataLab, en mettant en œuvre votre autonomie, votre sens des responsabilités, votre créativité et votre goût prononcé pour l'innovation autour des technologies de traitement de son, d’image et de texte
Apporter une solution industrialisable aux besoins opérationnels via le développement d’outil d’automatisation, de modèles prédictifs ou de segmentation, ou de la data visualisation
Appliquer différentes méthodes mathématiques pour construire différents scores et systèmes de décision, de la conception (analyse, recherche d'algorithmes et sélection de l'algorithme le plus approprié) à la création (intégration de l'algorithme dans les différentes solutions), en passant par la validation des résultats prédits
Explorer, identifier et manipuler toutes les données disponibles pour en extraire de la valeur
Vérifier et mesurer la qualité des données pour garantir la robustesse des résultats (backtesting)
Développer des projets d'analyse de données (data management)
Effectuer de la veille technologique sur les sujets Data Science (méthodes, techniques, outils...)
Profil :
3-5 ans d’expérience au minimum sur ce type de poste
Diplôme universitaire supérieur en statistiques, mathématiques appliquées, informatique ou domaine scientifique connexe.
Maitrise de Python, R, Spark
Solides compétences en gestion en SQL / NoSql (MongoDb…)
Agilité entre le codage d’une solution opérationnelle, l’adaptation dans les technologies Big Data et la promotion de nouvelles idées / solutions / approches
Fort intérêt pour l'apprentissage supervisé / non supervisé
Un état d'esprit pratique et analytique
Un esprit d'entreprise
Expériences dans les services cloud est un atout
Proactif, curieux, ouvert d’esprit et désireux d'essayer de nouvelles idées intéressantes
Anglais courant attendu (TOEIC 750 minimum)"
Éragny (95),Apprentissage,,APPR - BAC+5 - Data Scientist F/H,Renault,- Éragny (95),"Contexte - Environnement de travail

Le poste est à pourvoir dans le cadre d’une nouvelle activité qui s’inscrit dans le plan de modernisation de la DLPA.
La Direction a de fortes ambitions sur ces nouvelles fonctions et leurs résultats pour accompagner l’accroissement du chiffre d'affaire du Groupe Renault.

Ce poste vous donnera l'opportunité de participer à la mise en place de cette nouvelle dynamique et de construire les méthodes de demain.
La multiplicité des problématiques abordées vous donnera une vision transversale non seulement de la logique des pièces et accessoires mais aussi des directions connexes (projets véhicules, qualité, commerce...)
Vos missions

Au sein de la direction Program, Stadards et projets, vous participez à l'exploration de nouveaux axes de performance via ces nouvelles technologies.
Vous détectez et interprétez les dysfonctionnements (indisponibilité de pièces de rechanges, surstock, mauvaise qualité de stock, commandes fournisseurs incohérentes, …)
Vous trouvez les sources de données pertinentes et les exploitez dans les environnements dédiés
Vous évaluez, traitez et analysez les données
Vous restituez les analyses obtenues au métier, préconisez des actions d’amélioration et suivez leur mise en place et effets
Vous participez à la mise en place du big data DLPA
Vous élaborez et améliorez avec les analystes et prévisionnistes de l'équipe à la mise en place de méthodes innovantes de restitution de données, prévisions moyen et long terme...
Qui êtes-vous ?

Vous préparez un diplôme d'une école d'ingénieur en Data Mining / Big Data / Statistiques ou un Master universitaire spécialisé en gestion de data science / big data (Telecom Paris Tech, Ensae…) et vous recherchez un contrat d'apprentissage.

La connaissance de l'un des langages suivants est nécessaire : Python, ""R"", SQL

Vous êtes reconnu(e) pour vos capacités d’analyse et d'organisation et faites preuve d'une certaine aisance relationnelle.

Vous êtes à l'écoute des besoins de vos ""clients"" et faites preuve de pédagogie pour transmettre le résultat de vos analyses.

Enfin, vous savez travailler en équipe et êtes force de proposition.

Vous souhaitez participer à l'aventure de l'automobile de demain? Rejoignez-nous!"
Paris (75),CDI,,DATA ANALYST BANQUE / ASSURANCE - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Data analyst banque/assurance (h/f) pour conforter ses équipes.
Vous serez intégré à l'Autorité de contrôle prudentiel et de résolution (ACPR) qui a pour missions de veiller à la préservation de la stabilité du système financier et à la protection des clients, assurés, adhérents et bénéficiaires des professionnels de la banque et de l'assurance.

Présentation du Service
Au sein de la Direction du contrôle des pratiques commerciales (DCPC), le Service informations et réclamations (SIR) centralise les actions de veille et de surveillance permanente des pratiques commerciales des professionnels (banque et assurance) et coordonne la communication interne ou externe sur les sujets de protection de la clientèle.

Descriptif de mission
Au sein du pôle veille, vous serez en charge des missions suivantes :
Organiser, suivre et fiabiliser la collecte annuelle des données remises par les professionnels de la banque et de l’assurance, au titre de l’Instruction n°2019-I-23, relative au questionnaire sur les pratiques commerciales et la protection de la clientèle (Q2PC).
Contribuer à l’analyse des données, provenant des différents outils de veille (données issues des réponses au Q2PC, des qualifications des demandes de la clientèle, de la plateforme d’écoute du web, de la veille sur les publicités, des bases de données sur les innovations, etc.). À cet effet, vous participerez à la définition d’indicateurs, à la construction d’outils d’analyse et de visualisation graphique des données.
Produire des reportings à destination d’interlocuteurs internes et externes.
Répondre aux demandes d’information des professionnels relatives à la Q2PC, ainsi que des différents services de la Direction du contrôle des pratiques commerciales.

Profil recherché
Titulaire d'un diplôme universitaire, ou d’un diplôme d’ingénieur, spécialisé en big data, en statistique, ou en informatique, vous avez acquis une première expérience d’au moins deux ans, en tant qu’analyste de données, idéalement dans le secteur bancaire ou assurantiel.
À cette occasion, vous avez développé une très bonne maîtrise d’Excel et de Power BI et avez eu une expérience en développement de scripts d’analyse de données (VBA, Python/R).
Vous avez un fort attrait pour la data (structurée ou non), pour son exploitation et vous savez adapter vos travaux à différents publics.
Enfin, doté de capacités d'analyse avérées et de facilités rédactionnelles, vous êtes réactif et force de proposition.
La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes recrutées."
Paris (75),"Temps plein, Intérim",,CDD - Data Scientist ou Statisticien (F/H),Allianz France,- Paris (75),"Description de la mission
Diplômé(e) en Data Science ou en Statistiques, vous cherchez un poste où vos compétences sont valorisées.
Vous souhaitez travailler en équipe et évoluer dans une entreprise qui met ses collaborateurs au coeur de sa stratégie de développement !
Venez apporter votre technicité et votre bonne humeur au sein de notre centre de compétences Data & Performance Vie & Santé !
Responsabilités clés
Vous réalisez la rétro-documentation des Model points ;
Vous construisez des référentiels ;
Vous mettez en place des traitements industriels de données sur le périmètre Life & Health (projet Arpia) ;
Vous sécurisez le Run sur la construction des Model points.
Profil / Compétences
Vous êtes diplômé(e) Bac+5 en Data Science ou en Statistiques ;
Votre très bonne maîtrise des techniques d’exploitation des données est reconnue grâce à une première expérience réussie ;
Vous connaissez l’assurance ;
Vous faites preuve d’adaptabilité ;
Vos capacités d’analyse et de synthèse ne sont plus à démontrer ;
- Votre communication est aisée et vous partagez volontiers vos connaissances techniques vis-à-vis de personnes n’ayant pas les mêmes compétences ;
Vous êtes curieux et force de proposition ;
Votre maîtrise de SAS, Python, MS Office en fait pâlir plus d’un ; de même que celle de l’anglais (à l’écrit et à l’oral).
Informations complémentaires
CDD de 8 mois maximum à pourvoir dès que possible.

Merci de transmettre votre candidature complète (CV & lettre de motivation en précisant vos dates de disponibilité et la durée).

Localisation du poste : Paris La Défense, Tour Neptune (M° Esplanade de La Défense).
Code de référence
AZFR-7382783-1
Allianz est l’univers pour ceux qui osent – un environnement qui soutient ceux qui prennent des initiatives pour faire évoluer leur carrière et pour participer activement au renforcement de notre position de leader mondial. En accordant une réelle importance aux hommes et aux femmes – à la fois à ses 88 millions de clients particuliers et professionnels, et à ses 140 000 collaborateurs – Allianz favorise une culture dans laquelle chaque collaborateur est encouragé à travailler en équipe, à se dépasser et à innover, pour relever les défis du secteur de l’assurance. Notre principale ambition est d’être le partenaire de confiance de nos clients et de leur permettre d’avancer avec l’assurance que nous sommes là pour les accompagner. Si vous avez de l’audace, rejoignez le Groupe Allianz.

De plus, en qualité d’employeur engagé, Allianz reconnaît que sa force se trouve dans la diversité de ses collaborateurs. Nous sommes fiers de promouvoir l’intégration et l’égalité des chances quel que soit le sexe, l’âge, l’origine, la nationalité, la religion, le handicap, ou l’orientation sexuelle de nos collaborateurs.
Toutes nos offres d'emploi sont ouvertes aux personnes en situation de handicap."
Rueil-Malmaison (92),"Apprentissage, Contrat pro",,ALTERNANCE - RISK DATA ANALYST (H/F) - RUEIL-MALMAISON (92),Arval,- Rueil-Malmaison (92),"ALTERNANCE - RISK DATA ANALYST (H/F) - RUEIL-MALMAISON (92) (NUMÉRO DE L'EMPLOI : ARVAL2020_ALT_910)

Alternance - Risk Data Analyst (H/F) - Rueil-Malmaison (92)

Créé en 1989 et filiale à 100% de BNP Paribas, Arval est le spécialiste de la location de véhicules d’entreprise. Arval propose à ses clients professionnels, PME et grands Groupes internationaux des solutions dédiées visant à optimiser la mobilité de leurs collaborateurs et à externaliser les risques liés à la gestion de leur flotte automobile. Conseil d’expert et qualité de service, qui constituent les fondements de la promesse de marque d’Arval, sont délivrés dans 29 pays par plus de 6 000 collaborateurs.

La flotte d’Arval s’élève à 1 000 000 de véhicules loués dans le monde. Arval est un membre fondateur de l’Alliance Elément Arval, l’alliance la plus durable de l’industrie de la location de véhicules d’entreprise, et leader mondial avec 3 millions de véhicules dans 50 pays. Au sein de BNP Paribas, Arval est intégré au domaine d’activité Retail Banking.

Missions :

La direction RISK vise à protéger les intérêts long terme d’Arval tout en accompagnant sa croissance et en optimisant ses process. Au sein de la Direction des RISK d'Arval France, leader européen de la location longue durée de véhicules, en tant que Risk Data Analyst, vous assisterez l’équipe RISK France en participant à la mise en place d’analyses et d'outils innovants pour la surveillance et le suivi des risques sur l'ensemble des activités d’Arval France.

Descriptif des tâches

Collecte, organisation et réconciliation de données afin d’améliorer leur qualité et de réaliser des analyses de risque d’actif ou opérationnel (ex. risque de valeur résiduelle, lutte contre la fraude…)
Participation à la création de Dashboard innovants afin de mesurer et suivre les risques de concentration et de marché
Création de méthodes et d’outils innovants pour aider au contrôle de modèles statistiques et ainsi limiter le risque de modèle
Automatisation de l’écoute du marché à l’aide d’outils adaptés afin de détecter les risques émergents
Echanger avec la communauté RISK quantitatif sur des pratiques innovantes de modélisation et de reporting

Profil :

Niveau d’études souhaité : Ecole d’Ingénieur (2 ou 3ème année)

Formation / spécialisation : Ingénieur généraliste, option Data Science / Statistiques / Analytics / Informatique

Compétences techniques :

Profil quantitatif (statistiques, mathématiques, finance…)
Maîtrise de de SAS (ou SQL), Python, Office (Excel, Powerpoint)
Connaissances de Machine Learning est un plus
Anglais professionnel
Compétences comportementales :

Capacité à résoudre des problèmes
Proactif, capacité d’initiative
Capacité d’analyse et de synthèse
Rigueur et précision"
Paris 10e (75),,,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong

Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Guyancourt (78),CDI,,Data Scientist H/F,Crédit Agricole Payment Services,- Guyancourt (78),"Crédit Agricole Payment Services est le producteur paiement du Groupe Crédit Agricole, leader en France des solutions de paiement avec près de 30% de part de marché et plus de 10 milliards de transactions traitées.

Digitalisation, nouveaux usages, nouvelles concurrences, pression réglementaire le domaine des paiements connaît des mutations profondes et rapides. Dans ce contexte, Crédit Agricole Payment Services met son expertise, sa capacité d'innovation et sa performance industrielle au service des banques et des grands remettants pour leur proposer des services de paiement nouveaux conjuguant facilité d'usage et sécurité.
Référence
2020-46378
Date de parution
07/05/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Gestion des opérations
Type de contrat
CDI
Poste avec management
Non
Cadre / Non Cadre
Cadre
Missions
La maîtrise et l’exploitation des données de paiement sont une clé majeure de l’innovation en cours de bouleversement de ce secteur d’activité. La capacité d’extraire de ces données une information pertinente et en temps réel pour développer de nouveaux services à nos clients bancaires est un enjeu majeur. A ce titre Crédit Agricole Payment Service renforce ses équipes et recherche pour son département DATA un(e) « Data-Scientist Paiement ».
Les données de paiement offrent une profondeur d’information très importante, tant pour développer de nouveaux services destinés aux clients titulaire d’un compte pour la gestion de leur compte au quotidien que pour accompagner nos clients professionnels dans le développement de leur activité. Ces données sont historisées et accessible de nos outils big data.
En tant que data-scientist, vous interviendrez sur toute la chaîne de création de valeur apportée par les données :
Définition de la stratégie ;
Veille des nouveaux usages et nouveaux services apportés par les données ;
Veille sur les nouveaux outils et algorithmes de machine Learning ;
Participation à la définition de la stratégie d’exploitation des données ;
Recherche des données disponibles en Open-Data permettant d’enrichir notre démarche ;
Réalisation des études, des segmentations et des modèles prédictifs ;
Réalisation d’études statistiques sur les comportements de paiement ;
Réalisation de scores d’appétence sur les segmentent de clients particulier et professionnels ;
Construction de modèles prédictifs sur les comportements d’achat, mise au point d’approches de cross-selling à partir des comportements d’achat, détection des moments de changement de vie…
Réalisation d’études à la demande, prise en charge du cycle complet des études de la définition des objectifs, sa création, l’élaboration du rapport d’étude puis de sa présentation ;
Participation à des projets de R&D : contribution à des projets de recherche et développement avec des partenaires externes tel que des laboratoires de recherche ou d’autres entités spécialisées dans la DATA au sein du Groupe Crédit Agricole ;
Dans une logique de transversalité, vous interagirez avec les différents départements de l’entreprise ainsi que les banques du Groupe pour recueillir leurs besoins et présenter vos résultats.
Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 78 - Yvelines
Ville
Guyancourt
Critères candidat
Niveau d'études minimum
Bac + 5 / M2 et plus
Formation / Spécialisation
Ecole d'ingénieur /Master Spécialisation en data science / machine learning.
Niveau d'expérience minimum
3 - 5 ans
Expérience
2 à 5 ans d'expérience dans des fonctions de data science
Compétences recherchées
Savoirs :
Connaissance des méthodes de machine learning (algorithmes de modélisation supervisée et non supervisée, réalisation de modèles de scoring, analyse factorielle, data management) ;
La connaissance des moyens de paiement serait un plus.

Savoir-faire :
Capacité à réaliser les études statistiques : poser une problématique, réaliser des hypothèses, tirer des conclusions des analyses, synthétiser les résultats et proposer un plan d'action concret et adapté ;
Capacité à détecter et analyser les problématiques des clients, qualifier les problèmes rencontrés et les transposer dans la modélisation des données ;
Maîtrise des outils et langages de programmation en data science tels que par exemple : SAS, Dataiku, R ou Python. La connaissance d'Amadea / StatMining serait un plus appréciable ;
Capacité à lire la documentation technique en anglais ;
Capacité à optimiser/automatiser les processus d'étude.

Savoir-être :
Autonomie et sens de l'initiative ;
Rigueur et esprit d'analyse ;
Bonne capacité de communication / vulgarisation ;
Grande capacité de travail en équipe ;
Aisance relationnelle permettant de développer des liens en interne/externe à l'entreprise.
Outils informatiques
Connaissance approfondie d'outils de data management et de data science :
Microstrategy, StatMining, R ou Python, Pyspark, MAP'R
Langues
Anglais professionnel et technique"
,,,,,,
,,,,,,
,,,,,,
,,,"Internship Data Scientist, Product Analytics",Criteo,- Paris (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

We are innovative, passionate and result-driven. We are an interdisciplinary team, leveraging the strengths of engineers and scientists.
The Data Science - Product Analytics team uses cutting edge technology, advanced statistics and machine learning to understand the most complex business problems at Criteo. We are committed to designing and building technical solutions to drive Criteo’s development and keep up with a fast-evolving product landscape.
We serve as trusted partners to leadership and work closely with PMs, R&D, Finance or Business teams.
Inside Data Science - Product Analytics:
Find new ways to optimize the bidding strategy
Optimize our capability to recognize users across all their devices and their interactions in the open-internet
Define, drive and analyze results of A/B tests to assess whether online performance is in line with offline simulations
Provide data-driven insights to ensure Criteo remains one step ahead of competitive threats
Identify and size development opportunities for new products
What will you do?
You enjoy solving real-world problems with data. You will be assigned to one or several projects.
Overall, your responsibilities include:
Mine large data sets and turn them into understandable and actionable insights
Build scalable analytic solutions using state of the art tools based on large and granular datasets
Design and execute a stream of analysis and tests to measure the impact of your solutions
Master our internal analytic datasets and reporting tools
Who are you?
Last year of Master’s degree or higher in a quantitative field (Mathematics, Computer Science, Physics, Engineering, Economics,etc.)
Internship of a minimum of 6 months
Outstanding analytical skills and creative thinking
Fluency in the core toolkit of Data Science:
R/Python; SQL/Hive
Manipulating large-scale data sets
Building data pipelines
Descriptive and predictive modelling
Implementing visualizations, dashboards, and reports
Excellent interpersonal and communication skills, pro-active and independent
Fun to work with!

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Courbevoie (92),,,Data Scientist for commodity Market Analyst,ENGIE Global Markets FR,- Courbevoie (92),"Who we are:


ENGIE is a global energy company, a leading provider of electricity, natural gas, and energy services. With 153,090 employees in more than 70 countries worldwide, ENGIE achieved revenue of €66.6 billion in 2016. ENGIE is committed to being a leader in the energy transition.
We are looking for talented and motivated people to create the future of energy. Join a rewarding and flexible work environment that encourages innovation and creativity, and help us meet the energy challenges of today and tomorrow.
Global Energy Management (GEM) is one of ENGIE’s Business Units. We deliver services in supply and logistics management, asset management, risk management, market access management, while contributing to the market understanding, design and efficiency and developing market solutions to accelerate the energy transition.
GEM manages one of the largest and most diversified energy portfolios in Europe, including electricity, natural gas, bulk commodities and environmental products.
With 5 trading platforms and activities in more than 50 countries, GEM has an extended geographical coverage in Europe, Asia-Pacific and in the US. It employs 1,300 people around the world.


Organization:


The data scientist will be part of an extended team of market analysts and meteorologists who sit on the trading floor.
We offer
Intellectually challenging job
Integration within a larger team of experienced market analysts
Autonomy and possibility to take responsibilities
Possibility to grow, learn and develop, including some attendance to conference


Context:


Targeting superior energy market knowledge, we build independent analyses and provide positions to give to GEM & Engie a competitive advantage
Developing consistent market views (gas, power, oil, bulk, carbon, meteo) to explain market moves and forecast future evolution
Delivering ad-hoc fundamental, statistical and technical analyses
Pro-actively seeking innovative solutions to improve sales, traders and business developers performance as well as to support senior managers in their decision making process
Providing market analysis reports and services to a defined set of internal and external clients.
Providing strategic insights on new businesses linked to energy transition
Representing GEM in external forum or conferences in relation with energy market knowledge


Role:


The Data Scientist will coordinate developments of the team on innovative methods to analyze commodity markets. He/She will focus on fostering machine learning, automated analysis on gas & power market fundamentals (supply/ demand forecast). He/She will support the traders and GEM front entities and develop directional market views.


Main Activities:


His/Her activities will cover the following:
Develop and maintain machine learning models to forecast supply & demand components of gas & power markets
Develop and maintain models to forecast market prices in collaboration with market analysts
Coach team members in the domain of data science and machine learning
Contribute to projects with traders and portfolio managers
Contribute to data collection, cleaning and analysis
Follow academic developments in the domain of machine learning applied to commodity markets and meteo
Promote team spirit and collaboration.


Work location:

Courbevoie, ENGIE T1

Travels:


Regular travels


Qualifications
Education and professional background:


Master degree or PhD in relevant area (engineering, finance, mathematics, statistics etc)


Hard skills:


3 to 5 years experience at least in data science applied to markets
Good knowledge of commodity markets
Strong analytical skills, programming skills (Python and/or R), ability to build models and apply data science & machine learning to operational topics
Experience in trading environment: Ability to work with traders, to translate market analyses into propositions/Strategies and to communicate them clearly


Soft skills:


Clear and effective communication both written and verbal; ability to explain and convey messages about complex issues and models; ability to work in multi-cultural environment.
Reactivity, creativity, initiative, autonomy, ability to cope with tight deadlines, team spirit


Languages:


Fluent in English


Job
: Trading / Portfolio management
Primary Location
: Europe-France-Île-de-France-Courbevoie
Organization
: Global Energy Management
Schedule
: Full-time
Nature of Responsibility
: Manager / Expert
Job Posting
: Apr 6, 2020, 12:20:15 PM"
,,,,,,
La Défense (92),CDI,,Consultant senior Risk Data Analyst / Data Scientist (H/F),Deloitte,- La Défense (92),"La complexité croissante de l'environnement des systèmes d'information dans un contexte de digitalisation des métiers, d'une flexibilité et d'une adaptabilité accrue, et de profondes avancées technologiques, impose un recours à des compétences pointues en analytics pour nos missions de gestion des risques.
Dans une dynamique de croissance constante, nous souhaitons renforcer nos équipes et nos solutions en recrutant des consultants expérimentés désireux d'intégrer une équipe motivée, professionnelle et intervenant auprès d'entreprises prestigieuses.

Vous participerez à des missions variées visant à accompagner nos clients, privés ou organismes publics, dans les différentes disciplines et métiers de la gestion des risques, en apportant vos compétences en analytics, en data mining, en business intelligence, en statistiques, en intelligence artificielle et en modélisation.

Vous serez amené(e) à intervenir et/ou encadrer les types de missions suivants :
Data analytics et data mining dans le cadre de diagnostics opérationnels et financiers pour l'ensemble des secteurs d'activité ;
Audit and control analytics : mise en oeuvre de techniques avancées d'analyse de données en remplacement des diligences traditionnelles d'audit ;
Prédictions et modélisations, sur des sujets réglementaires ou métiers financiers (ex : quantification, risques de crédit...), mais également sur des missions opérationnelles (ex : prévision des ventes, prévision des risques projets...) ;
Data visualisation : mise en oeuvre de tableaux de bords et d'outils d'analyse exploratoire sur les données risque de nos clients ;
Conception de solutions technologiques adaptées aux besoins de nos clients et missions, sous l'angle « data » : structuration, architecture, modélisation, moteur d'analyse, intégration, expérience utilisateur.
Compétences recherchées :
Vous disposez de compétences parmi les éléments suivants, que vous souhaitez développer sur nos différents projets :
Bases de données: SQL Server for windows, PostGreSQL, MySQL, MongoDB
ETL: SSIS, Talend, Informatica
Big Data : Hadoop, Spark, Hive, Cloudera, Hortonworks HDP
Programmation : SQL, SAS, R, SPSS, Python, C#, Java
Statistiques
Machine learning
Visualisation : QlikView, QlikSense, Tableau, PowerBI, D3.js
Data virtualization
Votre parcours :
En rejoignant Deloitte, vous aurez l'opportunité de développer un set de compétences, partagées avec notre réseau international, et structurées autour des dimensions suivantes : leadership, métier et spécialité. Grâce aux missions variées auxquelles vous participerez et au programme de formations proposé, vous pourrez renforcer progressivement ces compétences, en acquérir de nouvelles et progresser ainsi au sein de notre firme.

Profil
De formation supérieure (école d'ingénieurs ou université), idéalement complétée par un cursus à l'étranger suivi dans un pays anglophone, vous avez une première expérience de 3 à 5 ans acquise au sein d'un cabinet de conseil ou d'une grande société dans une des disciplines analytics ou data science.
Vous avez participé ou géré des projets d'envergure dans les domaines de la gestion, l'analyse et l'interprétation des données.
Dynamique et entreprenant(e), vous avez envie de vous impliquer activement dans le développement d'offres de service.
Vous avez la capacité de travailler en équipe pluridisciplinaire et une réelle appétence pour l'analyse des données, les systèmes d'information, les problématiques métier et la gestion des risques.
Vous avez l'habitude d'encadrer des missions et avez développé des qualités managériales.
Autonome, dynamique et doté(e) de très bonnes qualités relationnelles, vous avez un goût affirmé pour la relation client et les missions d'audit et de conseil.
Vous avez un souci constant de développer vos connaissances et de mettre votre compétence au service des autres.
Votre rigueur, votre sens relationnel et vos capacités rédactionnelles contribueront à l'excellence de notre service auprès des clients.
La maîtrise de l'anglais oral et écrit est nécessaire."
Paris (75),Stage,,Data Scientist : Risque de Crédit et Algorithmes de Détection d’Anomalies - Stage de fin d'études,Beijaflore,- Paris (75),"Fondé en 2000, Beijaflore est un cabinet de conseil opérationnel en stratégie digitale présent à l’international avec des bureaux à Paris, Bruxelles, Rio de Janeiro, Sao Paulo et New York. Il regroupe plus de 1250 collaborateurs animés par une mission commune : accompagner de manière opérationnelle les entreprises dans la mise en œuvre de leur stratégie digitale.
Avec son entité Graphène Advisory, Beijaflore accompagne les entreprises dans la valorisation de leurs données par des projets Intelligence Artificielle. En proposant des solutions complètes, partant de l’identification des use cases au développement de la solution et son déploiement, Graphène Advisory amène les entreprises à créer leurs business de demain. Ces solutions sont basées sur du Machine Learning et l’IA articulés sur des architectures flexibles, modulaires et scalables appelées architectures Big Data.
Les technologies Big Data sont principalement open-source et présentent une certaine complexité à mettre en place. Bien agencées, elles procurent des performances d’analyse remarquables capables de traiter un volume et une variété de données très élevés en temps réel.
Aujourd’hui, les banques font face à un défi majeur : prévoir les pertes et leurs distributions dans le cadre de leur exposition au risque de crédit. Elles disposent de modèles internes pour calculer des paramètres de risque tels que : Probability of Default, Loss Given Default, ….
Ces modèles mathématiques, qui ne prennent pas en compte les effets de contagion et de corrélation, deviennent de plus en plus lourds à calibrer, à utiliser et à maintenir. L’utilisation d’algorithmes de Machine Learning apparait comme une alternative à ces modèles. Ils permettent d’exploiter toutes les données collectées liées au risque pour mieux le cerner et le maitriser.
Vous souhaitez rejoindre une équipe multidisciplinaire et complémentaire qui accompagne ses clients dans la réalisation de projets autour de l’IA et du Machine Learning ?
Au sein de l’équipe Graphène Advisory, vous serez en charge de développer un moteur de détection d’anomalies sur des données relatives au risque de crédit et de l’appliquer dans le contexte de la finance de marché.
Vous serez plus particulièrement chargé(e) de :
Etudier la bibliographie sur les nouvelles méthodes de détection d’anomalies et sur la valorisation du risque de crédit
Identifier et développer des algorithmes de détection d’anomalies (statistique, réseau de Neurones, …)
Tester et appliquer ces méthodes au domaine de la finance de marché (identification de données pertinentes).

Afin de mener à bien vos missions, vous avez les compétences suivantes :
Maîtrise des méthodes de Machine Learning appliquées à la détection d’anomalies
Introduction à la finance de marché et au risque de crédit (finance quantitative)
Maîtrise des outils data science (R, Python, Scala)

Etudiant(e) Bac+5 d’une Grande Ecole d’ingénieur, vous suivez un Master ou une spécialisation en Data Science. Vous êtes autonome, persévérant(e) et rigoureux(se). Vous appréciez le travail en équipe.
La qualité de nos stages a été récompensée par l’obtention du label Happy Trainees / Choose My Company. Parce que nous avons à cœur de développer les potentiels de chaque étudiant, nous vous formons pendant toute votre période de stage de fin d’études dans une optique d’embauche.
80% de nos stagiaires nous rejoignent en CDI.

Rejoignez Graphène !"
Boulogne-Billancourt (92),"Temps plein, CDI",,Data Engineer / Scientist Senior H/F,Solocal Group,- Boulogne-Billancourt (92),"Nous :
Nous fournissons des solutions ad-tech à des centaines de milliers de clients, partout en France, pour toucher des millions d'internautes chaque jour.

Nous attribuons notre succès à deux piliers. Tout d'abord, grâce à notre data utilisateur riche, à nos actifs tech maison et à nos algorithmes de machine learning pour comprendre les intérêts divers de nos utilisateurs. D'autre part, grâce à une force commerciale sans parallèle ainsi que la compréhension des besoins de nos clients.

Dans l'équipe data science, notre but est d'optimiser l'efficacité des campagnes publicitaires en ligne et de piloter notre approche commerciale. Notre quotidien est divers : parfois nous sommes amenés à concevoir un algorithme de pointe qui identifie les publicités les plus pertinentes pour nos utilisateurs, d'autres fois à comprendre les déplacements physiques de nos mobinautes pour notre offre drive-to-store.

Vous :

Nous cherchons un data engineer / scientist senior pour rejoindre notre équipe de 12 data scientists, engineers et analystes. Nous apprécions la curiosité et la capacité à porter une idée avec tact. Nous construisons une équipe de collaborateurs fiers de leur travail qui focalisent leurs efforts sur les actions les plus efficaces pour faire avancer notre entreprise.
En tant que data engineer / scientist senior, vous serez amené(e) à :

Assumer un rôle de leader dans la data engineering et la data science appliquée à nos produits RTB et drive-to-store.
Elaborer des algorithmes tout en intégrant les enjeux business.
Travailler dans un environnement agile et collaborer avec des data scientists, des développeurs et des product owners pour identifier les projets les plus pertinents sur lesquels contribuer.
Appliquer et déployer des méthodes d'apprentissage statistique en production.
Déployer des pipelines de données en production ainsi que les analyse et insights qui en découlent.
Promouvoir les best practices dans notre équipe.
Défendre vos idées en suivant la maxime : « strong opinions, weakly held ».
Profil
Profil :

Les acquis suivants sont nécessaires pour assumer ce rôle :

Masters, thèse ou équivalent en informatique, mathématiques ou statistiques.
3+ années d’expérience en développement d’applications Python pour le traitement de données.
3+ années d’expérience en machine learning, spécifiquement avec des libraires Python telles que scikit-learn, tensorflow ou xgboost.
Orientation business.

Compétences attendues
Expériences et compétences :

Les acquis suivants sont utiles pour assumer ce rôle :

Expérience de travail en mode agile sur du code partagé destiné à la production.
Expérience précédente de développement d’algorithmes d’apprentissage statistique pour la production.
Expérience avec Google Cloud Platform.
Expérience avec Spark.
Expérience en visualisation de données avec des outils comme Tableau.
Expérience dans un rôle senior en tant que mentor pour des collaborateurs juniors.
Capacité à s'exprimer de manière claire en anglais, notamment à l’écrit."
Montrouge (92),CDI,,Inspecteur data H/F,Crédit Agricole S.A.,- Montrouge (92),"Société cotée, Crédit Agricole SA est l'organe central de contrôle du Groupe Crédit Agricole.
Son organisation est au service de la stratégie et de la performance du Groupe en coordination avec les filiales et les lignes métiers.
Crédit Agricole SA regroupe et anime ses filiales spécialisées, au service des Caisses régionales et des réseaux bancaires du Groupe.
Référence
2020-48125
Date de parution
09/05/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Inspection / Audit
Types de métier complémentaires
Types de métiers Crédit Agricole S.A. - Systèmes d'information / Maîtrise d'Ouvrage
Types de métiers Crédit Agricole S.A. - Autres
Type de contrat
CDI
Poste avec management
Non
Cadre / Non Cadre
Cadre
Missions
L'Inspection Générale Groupe veille à la bonne maîtrise des risques et au respect de la réglementation. Elle joue un rôle clé pour permettre d'inscrire le développement du Groupe Crédit Agricole dans une trajectoire de risques maîtrisés.
Les équipes d’Inspection réalisent des missions dans l’ensemble du Groupe (banque de proximité, banque de financement et d'investissement, gestion d'actifs, assurance vie et dommages, services financiers spécialisés…), tant en France qu'à l'International.
Rejoignez le Corps de d’Inspection Générale Groupe en tant qu’Inspecteur DATA :
Vous interviendrez au sein des missions de la Ligne Métier Audit-Inspection, depuis le cadrage des besoins métiers (sur des domaines variés tels que le risque de crédit, la conformité, la sécurité financière ou l'assurance), le recueil et le contrôle qualité des données issues des systèmes d'information des entités auditées, la conception des analyses, l’interprétation des résultats à la documentation des diagnostic et la synthèse de la mission aux audités.
En tant que membre de la communauté DATA de la LMAI, vos activités seront encadrées par le Superviseur DATA de l'Inspection Générale.

Vous bénéficierez d’un lien fonctionnel avec l’ensemble des métiers de la DATA de la Ligne Métier Audit-Inspection et notamment de l'Inspection Générale.

Vous contribuerez à la veille technologique et à des projets transverses de la LMAI, liés aux nouvelles technologies et au digital dans le cadre du dispositif de Knowledge management d’IGL.
Lors de vos missions, vous interagirez avec de multiples interlocuteurs : les équipes de mission, les équipes IT, les équipes métiers.
Vous bénéficierez d’un parcours de formation dédié et développerez une vision transverse du fonctionnement d’un grand groupe bancaire et une exposition à ses différents métiers et à leurs enjeux, dans un environnement dynamique et exigeant.
La diversité des mises en situation rencontrées, votre montée en responsabilité progressive et votre connaissance du Groupe vous offriront, dans un second temps, de multiples perspectives d’évolution.
Des déplacements sont à prévoir en France ou à l’étranger.

Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 92 - Hauts-De-Seine
Ville
Montrouge
Critères candidat
Niveau d'études minimum
Bac + 5 / M2 et plus
Formation / Spécialisation
École d'ingénieurs, 3ème cycle universitaire, école de commerce
Spécialisations : Informatique décisionnelle, statistiques, audit.
Niveau d'expérience minimum
0 - 2 ans
Expérience
Une expérience significative en analyse de données ou en informatique décisionnelle est requise. La connaissance du secteur banque/assurance est un plus.
Compétences recherchées
Maîtrise du traitement informatique des données à des fins d'analyse ou de statistiques (SQL Server, SAS, Access).
Rigueur, discrétion, capacités d'analyse, de synthèse, d'organisation et à hiérarchiser ses priorités.
Goût du travail en équipe, faculté d'adaptation, curiosité intellectuelle.
Bonne communication orale et écrite, sens pédagogique.
Outils informatiques
Connaissances appréciées en DataViz (Power BI, MicroStrategy…), en programmation (Python, R, Cypher…), en Big Data.
Langues
Anglais opérationnel courant"
Paris (75),,,Senior Data Scientist H/F (75),Rexel,- Paris (75),"Senior Data Scientist H/F (75)
Expert de la distribution multicanale pour le monde de l’énergie, Rexel accompagne ses clients professionnels dans la mise en œuvre de solutions innovantes. Engagé vers une croissance durable, la digitalisation est au cœur de l’entreprise.
Description externe
Rexel recrute un(e) Lead Data Scientist
Poste rattaché au Responsable Business Analytics et Data Science
Au sein de la Direction Business Optimization, le/la Lead Data Scientist analyse, modélise et traduit des problématiques business en une solution analytique opérationnelle, en étroite collaboration avec les différentes équipes métiers (Commerce, Marketing, Digitale, Supply Chain et IT). L’équipe Data Science travaille également en étroite collaboration avec la Direction Data, Innovation & Services du Groupe.
Missions
Vous comprenez et analysez les besoins des clients internes, validez les enjeux avec vos partenaires (ROI) et la faisabilité (qualité / coût / délais).
Vous mettez en œuvre l'ensemble des méthodes et techniques nécessaires pour répondre aux problématiques au cours du projet avec les équipes métiers : sélection, analyse, qualification et acquisition des données, analyses exploratoires, descriptives (BI), prédictives (ML) et prescriptives.
Vous intervenez sur l’ensemble du processus : phases exploratoires, prototypage, pilote terrain, industrialisation, déploiement, run
En tant que Lead Data Scientist, vous êtes amené à piloter d’autres Data Scientists ou prestataires qui interviennent sur vos projets avec une orientation résultat et budget
Vous communiquez sur l'avancement et les résultats de vos projets en adaptant votre démarche et votre discours de manière proactive.
Vous participez à la réussite de l'équipe en partageant vos connaissances et vos méthodes. En tant que membre moteur de la communauté vous contribuez à l'expansion de la culture Data au sein de Rexel.
Vous intervenez avec un focus majoritairement France, mais également sur des projets déployés à l’international.
-
Profil
Niveau ingénieur ou Master 2 en Mathématiques appliquées et/ou Statistique et/ou Informatique et/ou recherche opérationnelle,
Vous justifiez d'au moins 3 à 5 ans d'expérience réussie sur des missions équivalentes.
Vos compétences couvrent plusieurs des points suivants :
Algorithmes de machine learning (supervisés et non supervisés) : random forest, réseaux de neurones, régressions, time series, text mining…
Optimisation, Recherche opérationnelle
Programmation scientifique dans un langage de script : Python fortement recommandé (scikit, tensorflow..), ou R
Bases de données et langage SQL
Visualisation de données (librairies Python, Qliksense, D3...)
Déploiement via docker
Gestion de projet et de prestataires
Votre capacité à analyser, modéliser et traduire les problématiques business vous permet de collaborer efficacement aussi bien au sein de votre équipe qu'avec les équipes métiers et techniques.
Vous êtes passionné et disposez d'un sens pratique qui se traduit, entre autres, par la capacité à chercher et proposer les solutions adaptées (IT/Code/logiciel, etc.).
Vous savez faire preuve de flexibilité et vous adapter à un contexte de montée en puissance de la practice Analytics au sein du groupe.
Vous êtes motivé, organisé et autonome, aimez travailler en équipe et disposez de bonnes capacités de communication.
Anglais courant pour échanger avec les différents supports éditeurs et les entités des autres pays.
D’AUTRES RAISONS DE NOUS REJOINDRE
Un package de rémunération attractif (variable, participation, mutuelle, prévoyance)
Des formations adaptées grâce à la Rexel Academy (environ 37 000 heures de formation dispensées chaque année)
Un parcours d’intégration construit sur mesure
De nombreuses opportunités d’évolutions internes en France et à l’international (450 mobilités internes réalisées par an en moyenne)
Un environnement dynamique, innovant et digitalisé dans lequel évoluer
80% de nos collaborateurs déclarent travailler dans un esprit d’équipe et de coopération. (enquête interne 2018)

QUI SOMMES-NOUS ?
Société côté en bourse et présente dans 26 pays, Rexel intervient après d’installateurs de toutes tailles, mais aussi de sociétés industrielles ou tertiaires, publiques et privées. En France, Rexel compte 5 000 collaborateurs, 460 agences et 9 centres logistiques pour un chiffre d’affaires de 2.44 milliards d’euros. Vous êtes motivé pour rejoindre une équipe de passionnés, conviviale et centrée sur ses clients ? Envoyez-nous votre candidature !
EN SAVOIR PLUS SUR NOS MÉTIERS
Découvrez nos métiers en vidéo et projetez-vous au sein d'une super équipe !
Découvrir nos vidéos métier"
Ivry-sur-Seine (94),CDI,,Data Scientist F/H,Siège Fnac Darty,- Ivry-sur-Seine (94),"Description et profil
Intéressé(e) par rejoindre un fleuron français du e-commerce ? Vous souhaitez mettre en oeuvre et développer vos compétences en data science sur des projets à fort impact ? Vous voulez travailler dans une équipe dynamique aussi passionnée que compétente et développer votre carrière ? Alors n'hésitez plus et rejoignez-nous au sein du groupe Fnac-Darty !

Vous rejoindrez l'équipe data au sein du département ecommerce et vous travaillerez sur des sujets tels que les moteurs de recherche, la recommandation de produits, le scoring d'appétence des utilisateurs, la détection d'anomalies, la segmentation des parcours, et bien d'autres sujets.

Ingénieur(e) de formation, spécialisé(e) en data science et en machine learning, seront attendus de votre part rigueur, aisance relationnelle, un fort esprit d'initiative, la volonté d'itérer et d'aller au bout de vos idées, et l'envie de comprendre profondément les métiers du groupe et de contribuer fortement à son développement par vos réalisations.

Nous interagissons tous les mois avec l'essentiel de la population d'un bon nombre de pays sur une gamme de produits, de services et d'événements extrêmement large. Vous travaillerez donc sur des données très riches dans un environnement technologique à la pointe ; en particulier, vous écrirez préférentiellement vos algorithmes en Python (des compétences en d'autres langages sont également les bienvenues) et vous mobiliserez toutes les ressources nécessaires dans des architectures distribuées sur le cloud pour les passer à l'échelle (une expérience en la matière est appréciée mais non nécessaire).
Localisation du poste
Localisation du poste
France, Ile-de-France, 94 - VAL DE MARNE
Ville
Ivry sur seine
Critères candidat
Niveau d'études min. requis
BAC +5
Niveau d'expérience min. requis
2 - 5 ans"
Paris (75),Stage,,Stagiaire Data Scientist,Fretbay,- Paris (75),"Développer et automatiser des outils et dashboards pertinents pour aider chaque équipe (Product, Sales, Marketing, etc) dans leurs décisions les plus stratégiques.
Réaliser des analyses statistiques approfondies pour apporter une compréhension du comportement de nos utilisateurs.
Participez à la construction de la stratégie Data (machine learning, modèles prévisionnels)
Savoir-faire
De formation supérieure en école d’ingénieur/université (niveau Bac+3 à Bac+5) avec une spécialisation en statistiques, datamining ou data science, vous possédez au minimum une première expérience professionnelle (stage, alternance acceptés) dans ce domaine.
Vous maitrisez les langages de développement tels que R ou Python et vous avez de bonnes connaissances des modèles de base de données (SQL).
Vous êtes doté(e) d’un fort esprit analytique et d’une excellente compréhension des enjeux et des leviers du marketing digital.
Vous êtes autonome, data-driven et reconnu pour votre capacité à produire un contenu (des reportings et analyses) précis et synthétique.
Vous avez l'esprit d'équipe : vous souhaitez rejoindre une petite équipe et collaborer avec les autres pôles de la société (Product Management, Cloud & Big Data, …).
Vous êtes proactif, vous n'hésitez pas à proposer des axes d’amélioration sur les processus existants.


Connaissances requises
En programmation (R, Python, C, C++, SQL…)
En statistiques
En machine learning
En algèbre linéaire et des fonctions de plusieurs variables


Qualités requises
Curiosité intellectuelle
Esprit entrepreneurial
Bon sens de la communication
Esprit de synthèse
Rigoureux


Rémunération et contrat
Stage de fin d’étude 6 mois
Temps plein
Salaire : à voir ensemble"
Montrouge (92),"Apprentissage, Contrat pro",,Assistant Data Scientist - Early Detection H/F,CA CIB FRANCE,- Montrouge (92),"Crédit Agricole CIB est la banque de financement de d'investissement du groupe Crédit Agricole, 12e groupe bancaire mondial par les fonds propres Tier1 (The Banker, juillet 2018). Près de 8300 collaborateurs répartis en Europe, Amériques, Asie-Pacifique, Moyen-Orient et Afrique du Nord, accompagnent les clients de la Banque dans la couverture de leurs besoins financiers à travers le monde. Crédit Agricole CIB propose à ses clients grandes entreprises et institutionnels une gamme de produits et services dans les métiers de la banque de marchés, de la banque d'investissement, des financements structurés, de la banque commerciale et du commerce international. Pionnier dans le domaine de la finance Climat, la Banque occupe aujourd'hui une position de leader sur ce segment avec une offre complète pour l'ensemble de ses clients.

Pour plus d'information : www.ca-cib.fr

Twitter: https://twitter.com/ca_cib
LinkedIn: https://www.linkedin.com/company/credit-agricole-cib/
Référence
2020-47916
Date de parution
11/05/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Risques / Contrôles permanents
Types de métier complémentaires
Types de métiers Crédit Agricole S.A. - Financement et Investissement
Type de contrat
Alternance / Apprentissage
Durée (en mois)
12 mois
Date prévue de prise de fonction
01/09/2020
Missions
Risk & Permanent Control assure le contrôle de l’ensemble des risques du groupe Crédit Agricole CIB. Elle pilote aussi le réseau des Correspondants du Contrôle Permanent.
Le Département « Modèle et Risques de Portefeuille » (MRP) se charge de la modélisation quantitative et le calcul des mesures de risque de crédit.

La cellule Early Detection a pour objectif de détecter le plus en amont possible le risque de défaillances des entreprises en exploitant notamment les potentialités de la data science et du big data.

Vous intégrerez l’équipe Early Detection et participerez à l’évolution du modèle Early Signals. Ce projet, co-construit avec MRP vise à prédire la dégradation de la qualité de crédit de grandes entreprises.

L’objectif est de transformer la manière d’analyser les risques et les opportunités commerciales de la banque grâce à l’apport de données diverses et à la modélisation avancée notamment de machine learning.

Vous serez encadré par des experts métiers, des data scientists en interne et des experts datas. Un environnement propice pour mettre en application vos connaissances acquises pendant votre cursus académique, développer vos capacités à vulgariser des sujets techniques et apprendre les métiers du financement et de l’analyse de risque de crédit.

Vous effectuerez votre alternance sur le campus Montrouge, activement ouvert sur la ville et intégré dans un écosystème et une vie locale dynamique. Vous y découvrirez un environnement de travail moderne et agréable dans des bâtiments aux dernières normes HQE environnementales, de nombreux services (salle de sports, boulangerie, conciergerie, vélos électriques, take-away, etc.).
Intégrer CACIB, c'est aussi rejoindre une banque internationale qui s'engage depuis plusieurs années en faveur de l'insertion des jeunes, en proposant un accueil et un accompagnement de qualité pour chacun de ses alternants avec :
un tuteur /une tutrice formé(e) et volontaire,
une équipe dédiée à l'alternance qui organise un suivi des étudiants : journée d'accueil, accompagnement et suivi, etc.
des opportunités post alternance en VIE, CDD et CDI
Conformément à la politique de CACIB en faveur de l’insertion de personnes en situation de handicap, ce poste est ouvert à toutes et à tous.
Si cette annonce vous correspond, postulez pour rejoindre notre communauté d’alternants en 2020, vous devez probablement être notre prochain talent !

Merci d’indiquer en titre de votre CV votre rythme d’alternance.

Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 92 - Hauts-De-Seine
Ville
Montrouge
Critères candidat
Niveau d'études minimum
Bac + 4 / M1
Formation / Spécialisation
Formation :Université, Ecole de commerce ou ingénieur/informatique
Spécialisation : Data science, Finance
Niveau d'expérience minimum
0 - 2 ans
Compétences recherchées
Hard skills :
Connaissances en Keras, TensorFlow et calcul distribué sur CPU/GPU seraient un plus.
Précédente expérience en finance (marché d'actions, de CDS ou analyse financière) serait un plus.

Soft skills :
Force de proposition
Bonne communication
Outils informatiques
Excellente maîtrise du Pack Office, VBA, Python ou R
Langues
Français et Anglais courant"
Paris (75),Stage,,US Data Scientist (End-of-studies Internship),Shift Technology,- Paris (75),"Shift Technology is reinventing insurance claims automation and fraud detection with AI. We help insurers fully automate more claims, deliver a great customer experience while protecting against risk, and accurately identify suspected claims fraud, making investigative teams more effective and reducing fraud losses.
Since our launch in 2014 in Paris, we've raised over $100M with Tier 1 investors, opened offices in Boston, Tokyo, Singapore, London, Madrid, Zurich, and Hong Kong, and currently work with more than 80 insurers globally. If you are excited about joining a fast-growing insurtech innovator with a passion for excellence and global culture, Shift is the place for you.

You are looking for an internship with a special focus on US Market? you are looking for getting strong programming skills and discover real-life problems? Come and join the French Insurtech leader to change the insurance world with A.I.!

This position is for you if you are looking for an end-of-studies intern position to complete your international degree (you have ideally spent 6 months studying in the US), and are interested in a permanent position if you think Shift is the right place to start!

YOUR ROLE

As a member of the data science team, and working alongside our technical experts, your role will be key to roll-out our different solutions to the US clients. Your day-to-day will include :

Set-up and deploy in production the data processing pipelines of our clients, including data reception in batches or in real-time, data cleaning, information extraction, calibration of fraud detection models, etc.

Work closely with our clients to understand their needs, their feedback to improve our solutions

R&D for product development and innovation (through machine learning, image analysis, NLP, trend analysis, chatbots…)

Work closely with the Sales team for prospects demo (and yes, that includes travelling worldwide, let's say if the context allows to consider it!)

WHAT WE ARE LOOKING FOR

You have a master's degree in mathematics and Statistics, (a knowledge in machine learning and/or Big Data is a plus)

You have ideally completed a semester in the US , which allows you to initiate a privileged relationship with our local clients

You have experience in object-oriented programming

You combine strong analysis with synthesis abilities and are not afraid to deal with the details

You can write quality production code

You are comfortable dealing with clients

You speak a lovely, fluent American-English

NICE TO HAVE

Another language, like French speaking would be a strong advantage

BENEFITS

Work on US projects and participate in the business international growth

Understand our products life cycle from market needs to industrialization

PERKS & INTERNAL CULTURE

International environment (we have more than 35 nationalities represented at Shift!)

Healthy seasonal basket fruits and cereals

Welcome drinks / Team building events

Technical contests

Workshop ans training

EEO Statement
At Shift we thrive to be a diverse and inclusive workforce. We hire and trust people without regard to race, color, religion, marital status, age, national or ethnic origin, physical or mental disability, medical condition, pregnancy, genetic information, gender identity or expression, sexual orientation, or other non-merit criteria.
Shift is proud to be an Equal Opportunity Employer."
,,,BIG DATA – Data Analyst (H/F),CONSULT-IT,- Paris (75),"Dans le cadre de notre développement, nous recrutons pour nos centres de services grands comptes situés à Paris ,des INGÉNIEURS BIG DATA – Data Analyst (H/F)), en mesure de contribuer activement à ce développement :

Missions :
Participer à la création de divers algorithmes de machine Learning / deep learning.

Conception, gestion et exploitation de bases de données (SQL, Hadoop / Spark).

Aide statistique à la décision.

Participer aux réunions d’équipe.

Profil recherché :
Une première expérience en analyse de données et intelligence artificielle (Tensorflow, Keras ..)

Maîtrise des méthodes de machine Learning et statistiques (R).

Maîtrise du Python et/ou C++ et des systèmes de parallélisation.

Connaissance en HPC (AWS et gestion de serveur dédié).

Intérêt pour la gestion de BDD (MySQL, no SQL, Hadoop, Spark).

Une grande capacité à travailler en équipe tout en étant autonome.

Un bon niveau en anglais.

Grande rigueur."
Paris (75),Stage,,Data Scientist : Cartographie des algorithmes de Machine Learning et leurs applications - Stage de fin d'études,Beijaflore,- Paris (75),"Fondé en 2000, Beijaflore est un cabinet de conseil opérationnel en stratégie digitale présent à l’international avec des bureaux à Paris, Bruxelles, Rio de Janeiro, Sao Paulo et New York. Il regroupe plus de 1250 collaborateurs animés par une mission commune : accompagner de manière opérationnelle les entreprises dans la mise en œuvre de leur stratégie digitale.
Avec son entité Graphène Advisory, Beijaflore accompagne les entreprises dans la valorisation de leurs données par des projets Intelligence Artificielle. En proposant des solutions complètes, partant de l’identification des use cases au développement de la solution et son déploiement, Graphène Advisory amène les entreprises à créer leurs business de demain. Ces solutions sont basées sur du Machine Learning et l’IA articulés sur des architectures flexibles, modulaires et scalables appelées architectures Big Data.
Vous souhaitez rejoindre une équipe multidisciplinaire et complémentaire qui accompagne ses clients dans la réalisation de projets autour de l’IA et du Machine Learning ?
Au sein de l’équipe R&D, vous serez en charge de définir et baliser les différents algorithmes de Machine Learning et d’identifier leurs potentielles applications dans différentes industries.
Vous serez plus particulièrement chargé(e) de :
Etudier la bibliographie sur les algorithmes de Machine Learning, afin d’appréhender les aspects techniques
Utiliser / tester des algorithmes et identifier les applications métiers potentielles
Structurer une matrice Algorithmes Vs Applications

Afin de mener à bien vos missions, vous avez les compétences suivantes :
Initiation au Machine Learning et statistiques descriptives
Initiation aux langages R / Python ou Scala (ou autre langage de programmation)

Etudiant(e) Bac+5 d’une Grande Ecole d’ingénieur, vous suivez un Master ou une spécialisation en Data Science. Vous êtes autonome, persévérant(e) et rigoureux(se). Vous appréciez le travail en équipe.
La qualité de nos stages a été récompensée par l’obtention du label Happy Trainees / Choose My Company. Parce que nous avons à cœur de développer les potentiels de chaque étudiant, nous vous formons pendant toute votre période de stage de fin d’études dans une optique d’embauche.
80% de nos stagiaires nous rejoignent en CDI.

Rejoignez Graphène !"
Paris 17e (75),CDI,,Data Scientist Confirmé / Machine Learning Engineer,Manomano,- Paris 17e (75),"Dès son lancement, le site ManoMano a développé ses propres algorithmes de machine learning, qui représentent aujourd’hui un vrai avantage compétitif. Les chantiers, nombreux et passionnants, touchent à l’ensemble des activités de l’entreprise. En voici une liste non exhaustive :
Optimisation de l’efficacité des campagnes marketing
Moteurs de recommandation
Moteur de recherche
Catégorisation des produits
Extraction des attributs des produits
Prévision des ventes
La diversité des projets et l’autonomie des data scientists font de ManoMano l’un des meilleurs terrains de jeu de Data Science en France (si ce n’est le meilleur !).
Aujourd’hui, une petite dizaine d’algorithmes sont en production. Ils reposent sur une grande diversité d'approches (business rules, régression linéaire et logistique, gradient boosted trees, product2vect, ...)
Ton travail aura un impact considérable sur la trajectoire de croissance de ManoMano.
Profil recherché
Pour ce poste, nous recherchons un Data Scientist ayant une première expérience réussie capable de porter un sujet de data science de bout en bout (de la conception à la mise en production en passant par le prototypage) grâce à l’accompagnement des Data Scientists plus seniors, ce qui requiert plusieurs des qualités suivantes :
une appétence forte pour l’informatique et des bonnes pratiques de software engineering
une capacité à comprendre et modifier le code des programmes existants,
une ou plusieurs expérience(s) significative(s) de Machine Learning en production,
une passion pour l’intelligence artificielle et le Machine Learning avec un vrai enthousiasme pour explorer et apprendre : cours en ligne, papiers de recherche, compétitions Kaggle, portfolio Git, etc.
une compréhension des enjeux de l’entreprise afin de créer et développer de nouvelles solutions adaptées,
une approche pragmatique des problèmes, pour créer des outils utilisables en production rapidement, notamment en s’appuyant sur l’existant,
une capacité à tester et expérimenter,
de la pédagogie pour expliquer des concepts complexes à des audiences non techniques.
Tu feras partie de l’équipe Data Science et auras des contacts fréquents avec les équipes IT et Produit. Tes missions seront transverses à l’ensemble de la société.
Vie de l’équipe
Six data scientists expérimentés ayant des profils variés (Université, école d’ingénieur, recherche) qui aiment partager et apprendre
Point hebdomadaire avec l’équipe pour partager et échanger sur les sujets de chacun
Point hebdomadaire avec son manager direct
Lab technique bimensuel où un membre présente un sujet de son choix
L’équipe Data Science est incluse dans une équipe Data plus large, avec des Data Engineers, des Data Analysts, et des Growth Hackers
Environnement technique : Airflow, Python, AWS S3, Gitlab, 2 serveurs 256 Go de RAM avec 24 coeurs et un GPU pour l’expérimentation.
Quelques exemples d'articles écrits par l'équipe : https://medium.com/manomano-tech/tagged/data
Ce que nous offrons
Un environnement de start-up made in France en hyper croissance
Equilibre vie pro / vie perso
Télétravail possible (1 jour par semaine)
Implication communautaire (temps alloué à la communauté, blog technique, etc.)
Des Crafternoons pour se former sur des sujets aussi divers que passionnants
Sponsoring de MM pour assister à des talks et conférences
De l’autonomie avec un champ d’action très large
Une immersion dans le data-driven e-commerce
Environnement Agile & international avec des collègues brillants et sympathiques
Carte de restaurant, mutuelle, transport, 7 semaines de vacances
Process de recrutement
Echange téléphonique avec un Talent Recruiter
Entretien physique avec deux Data Scientists de l'équipe
Test technique à faire à la maison
Entretien physique avec deux autres Data Scientists de l'équipe
Entretien physique ou téléphonique avec le VP Data ou le CMO
Informations complémentaires
Type de contrat : CDI
Date de début : 01 avril 2019
Lieu : Paris, France (75017)
Niveau d'études : Bac +5 / Master
Expérience : > 2 ans
Télétravail ponctuel autorisé"
Paris (75),Stage,,Data Scientist - English Speaking (End-of-studies Internship),Shift Technology,- Paris (75),"Shift Technology is reinventing insurance claims automation and fraud detection with AI. We help insurers fully automate more claims, deliver a great customer experience while protecting against risk, and accurately identify suspected claims fraud, making investigative teams more effective and reducing fraud losses.
Since our launch in 2014 in Paris, we've raised over $100M with Tier 1 investors, opened offices in Boston, Tokyo, Singapore, London, Madrid, Zurich, and Hong Kong, and currently work with more than 80 insurers globally. If you are excited about joining a fast-growing insurtech innovator with a passion for excellence and global culture, Shift is the place for you.

Are you looking for an internship where you can get strong programming skills and discover real-life problems? Come and join the French Insurtech leader to change the insurance world with A.I.!

This position is for you if you are looking for an end-of-studies internship to complete your degree, and are interested in a permanent position if you think Shift is the right place to start!

YOUR ROLE

As a member of the data science team, and working alongside our technical experts, your role will be key to roll-out our different solutions to the clients. Your day-to-day will include :

Set-up and deploy in production the data processing pipelines of our clients, including data reception in batches or in real-time, data cleaning, information extraction, calibration of fraud detection models, etc.

Work closely with our clients to understand their needs, their feedback to improve our solutions

R&D for product development and innovation (through machine learning, image analysis, NLP, trend analysis, chatbots…)

Work closely with the sales team for prospects demo (and yes, that includes travelling worldwide!)

WHAT WE ARE LOOKING FOR

You have a master's degree in mathematics and Statistics, (a knowledge in machine learning and/or Big Data is a plus)

You have experience in object-oriented programming

You combine strong analysis with synthesis abilities and are not afraid to deal with the details

You can write quality production code

You are comfortable dealing with clients

You are fluent in English, and ideally in an other European language

PERKS AND BENEFITS

Nice office in central Paris

International environment (we have more than 35 nationalities represented at Shift!)

Lunch card and public transportation sponsorship

Healthy seasonal basket fruits and cereals

Welcome drinks / Team building events

Workshop and training

EEO Statement
At Shift we thrive to be a diverse and inclusive workforce. We hire and trust people without regard to race, color, religion, marital status, age, national or ethnic origin, physical or mental disability, medical condition, pregnancy, genetic information, gender identity or expression, sexual orientation, or other non-merit criteria.
Shift is proud to be an Equal Opportunity Employer."
Saint-Cloud (92),CDI,,Senior Data scientist F/H,KYRIBA,- Saint-Cloud (92),"Dans le cadre de notre vision du data-as-a-service, Kyriba investit dans l'IA et le ML. Nous voulons automatiser les tâches manuelles et fastidieuses effectuées quotidiennement par nos clients et leur fournir des informations leur permettant de prendre de meilleures décisions.

Au sein d'une équipe d'une quinzaine de personnes, spécialisée dans la Business Intelligence et les données, mêlant expertise produit et technique, vous participerez à la phase de recherche et développement sur les différents thèmes de data science à l'étude et à venir chez Kyriba. Vous serez la référence en matière de science des données à Kyriba.

Votre rôle :
Répondre aux cas d'utilisation soumis par l'équipe produit et l'équipe d'ingénierie.

Proposer des orientations de recherche sur les différents cas d'utilisation identifiés à travers les quatre principaux produits de Kyriba : Trésorerie, Paiement, Gestion des risques, Financement de la chaîne d'approvisionnement. Les cas d'utilisation sont diversifiés, tels que la détection des fraudes, les prévisions de trésorerie, la maintenance prédictive par exemple.

Sélectionner, mettre en œuvre et améliorer les modèles. Vous devrez travailler en situation d'avant-vente avec les clients afin de créer des prototypes pour démontrer les concepts d'apprentissage des machines que vous maîtrisez. Vous aiderez ensuite l'équipe Ingénierie à industrialiser les prototypes sélectionnés par l'équipe Produit.
Profil recherché Maîtrise en sciences des données. Votre parcours universitaire vous a naturellement conduit à une carrière orientée vers la recherche et le développement. La science des données, l'apprentissage automatique, l'apprentissage approfondi, le traitement du langage naturel vous fascinent et vous savez en parler

Un minimum de 5 ans d'expérience en sciences des données, en particulier dans l'apprentissage machine. Vous souhaitez évoluer vers le management.

Vous êtes créatif et curieux de nature. L'apprentissage machine à grande échelle (Big Data) et l'industrialisation des pipelines d'apprentissage machine sont des sujets que vous considérez comme primordiaux. Vous êtes à l'écoute de vos clients.

Vous êtes capable de travailler au sein d'une équipe internationale. L'anglais, tant à l'écrit qu'à l'oral, est une pratique quotidienne.

Le candidat sera amené à documenter et à présenter l'avancement de ce travail à l'équipe mais aussi à un public plus large (compétences de vulgarisation appréciées).
Entreprise Editeur de solutions logicielles, Kyriba est le leader mondial en solutions de gestion de trésorerie en mode SaaS (software-as-a-service). Kyriba a développé une expertise approfondie pour répondre aux besoins de ses clients (directions financières, trésoriers d’entreprise). Son offre 100% dans le Cloud a été développée pour fournir une gamme complète de solutions de gestion de trésorerie, de risques financiers et de Supply Chain Finance. En mettant en œuvre les solutions Kyriba, les entreprises optimisent le cash disponible, gèrent les risques et valorisent le capital.

Créée en 2000, la société compte aujourd’hui 700 salariés et accompagne plus de 2 000 clients dans le monde. Le siège social de Kyriba est basé à New-York avec des opérations dans le monde (Hong-Kong, Londres, San Diego, Paris, Rio de Janeiro, Singapour, et Tokyo)."
Paris (75),,,Consultant Big Data,BLUESCALE,- Paris (75),"Nous recherchons plusieurs Consultants Big Data afin de nous accompagner sur les points suivants:
Analyse des besoins en relation avec les équipes métiers de nos clients et participation à l'avant-vente (POC, Maquettes, etc.)
Participation à la définition de stratégies architecturales de BDD Big data (modélisation, design et implémentation)
Conception et mise en œuvre d'architectures logicielles et techniques de plateformes Big Data
Identification, évaluation et recommandation auprès du client des outils et technologies adaptés à ses besoins
Création et optimisation des BDD Big Data
Optimisation technique et fonctionnelle des bases de données en termes de performance et de fiabilité
Maintenance et optimisation des systèmes mis en place
Conception et installation de mises à jour des logiciels de management de BDD Big Data
Installation et déploiement des clusters, des sauvegardes et des procédures de récupération des données
Rédaction de livrables et présentation des solutions proposées
Veille technologique
Profil :
Vous êtes Bac + 5 en informatique ou issu d'une Ecole d'Ingénieur (Centrale, Mines, Telecom Paris, etc.) et êtes sensibilisé aux sujets analytiques. Vous avez au moins 1 expérience réussie dans la mise en œuvre d'un projet Big Data et/ou Data Viz.
Vous possédez des qualités relationnelles et rédactionnelles. Rigoureux et précis, vous êtes à l'aise dans des démarches d'analyse de problématiques complexes."
Paris (75),,,Consultant(e) Data Scientist,Avanade,- Paris (75),"Au sein de nos équipes, vous aurez la possibilité de créer un changement pour nos clients et pour vous-même.

Vous ferez partie d’une société consciente de la valeur de vos compétences, qui investit dans votre intégration, votre formation et votre progression de carrière.

En nous rejoignant, vous interviendrez auprès de grandes entreprises nationales et internationales.

Avec nous, vous serez partie prenante de projets d’innovation et de transformation d’entreprises.

En tant que Consultant(e), vous serez intégré(e) au sein d’une équipe Data Science avec des valeurs fortes et formé(e) continuellement sur les nouvelles tendances et solutions en Intelligence Artificielle. Vous accompagnerez nos clients sur des projets au sein de diverses industries.

Pour mener à bien ces missions, vous pourrez vous appuyer sur les outils Open Source et l'offre Microsoft Azure intégrant des services cognitifs, des capacités de stockage et de computation. Vous travaillerez avec des équipes multidisciplinaires, vous aurez également la possibilité de participer aux Hackathons et de valider des certifications reconnues à l’international.

Vos missions :
Vous serez amené(e) à intervenir sur des missions Agile qui requièrent les tâches suivantes :

Animation d’ateliers d’expression de besoins et de définition de cas d’usage,
Encadrement et supervision du process Data Science des profils junior,
Exploration avancée des données (apprentissage non supervisé), Feature Engineering,
Manipulation et entraînement avec du Big Data (PySpark, sparklyr, SparkR, H2O),
Entrainement Deep Learning (Keras, Tensorflow): NLP, Computer Vision, Time Series,
Visualisation des données : Shiny, ggplot2, plotly, Bokeh
Vous êtes…

De formation Data Scientist ou équivalent, vous avez une expérience d’au moins 3 ans en Data Science plus particulièrement dans l’entrainement, la validation et l’évaluation des modèles de machine learning.

Vous maîtrisez au moins un des langages de programmation Python, R

Une expérience en environnement Big Data est appréciée : Spark, Hadoop, YARN.

Vous savez contextualiser les données. Vous disposez d’une sensibilité business vous permettant d’appréhender le besoin du client, et des compétences machine learning pour résolution des problématiques du client avec la data.

Un bon niveau d’anglais à l’oral comme à l’écrit est indispensable."
Paris (75),CDI,,Data Scientist,Presans,- Paris (75),"CONTEXT
Presans is hiring a highly motivated Data Scientist to contribute to the machine learning/data mining tools it develops, first, to automate the discovery of experts, but also to improve user experience and to provide feedback on its internal processes’ performance.
The ideal candidate for this position will possess an extensive experience in the conception and implementation of Big Data Applications, ranging from harvesting/storage/extraction of data to analysis/prediction of information, together with visualization techniques.
Examples of current projects are: automatic extraction of data from web-pages or PDFs, categorization of scientifc publications by domain or by type, grouping of experts by similarity, re-ranking of search engine’s results, etc.
JOINING PRESANS MEANS
Building the future of work in an extraordinary startup;
Combining excellence and impertinence;
Mixing grey hairs and young hackers;
Working in a huge creative community of entrepreneurs;
Being open-minded, loving to think & being challenged;
Loving urban exploration (especially underground ?).
RESPONSIBILITIES
Gather requirements from other developers & end-users.
Imagine & propose machine learning/data mining solutions.
Design, implement, test & document solutions.
Maintain & improve solutions over time.
Design clean and effcient APIs to interact with Back/Front-Ends.
Report to operatives & end-users.
SKILLS
Engineer or PhD in Data Mining/Machine Learning.
Strong coding experience (Java, R/Python…).
Experience with ML/DM tools (Weka/SparkML,Caret/Scikit, TensorFlow…).
Knowledge in data storage (ElasticSearch, PostGreSQL…).
Working in agile team (peer-reviewing, CD/CI…).
Experience with versioning systems (Git, SVN).
Would be a plus:
Skills in web scraping (Norconex…).
Microservices architecture (Docker…)
CV + cover letter at jobs@presans.com"
Paris (75),Stage,,Data Scientist : Architecture Big Data - Stage de fin d'études,Beijaflore,- Paris (75),"Fondé en 2000, Beijaflore est un cabinet de conseil opérationnel en stratégie digitale présent à l’international avec des bureaux à Paris, Bruxelles, Rio de Janeiro, Sao Paulo et New York. Il regroupe plus de 1250 collaborateurs animés par une mission commune : accompagner de manière opérationnelle les entreprises dans la mise en œuvre de leur stratégie digitale.
Avec son entité Graphène Advisory, Beijaflore accompagne les entreprises dans la valorisation de leurs données par des projets Intelligence Artificielle. En proposant des solutions complètes, partant de l’identification des use cases au développement de la solution et son déploiement, Graphène Advisory amène les entreprises à créer leurs business de demain. Ces solutions sont basées sur du Machine Learning et l’IA articulés sur des architectures flexibles, modulaires et scalables appelées architectures Big Data.
Les technologies Big Data sont principalement open-source et présentent une certaine complexité à mettre en place. Bien agencées, elles procurent des performances d’analyse remarquables capables de traiter un volume et une variété de données très élevés en temps réel.
Vous souhaitez rejoindre une équipe multidisciplinaire et complémentaire qui accompagne ses clients dans la réalisation de projets autour de l’IA et du Machine Learning ?
Au sein du Lab Data Science, vous serez en charge de développer une architecture technique pour accueillir une plateforme data science. Celle-ci vous permettra de développer des algorithmes, de les tester et de les appliquer à un use case identifié.
Vous serez plus particulièrement chargé(e) de :
Etudier la bibliographie sur les technologies Big Data (Kafka, Spark, Spark Streaming, …)
Développer la plateforme technique permettant le développement d’algorithmes d’analyse et documentation
Tester et appliquer cette plateforme avec un use case (analyse sémantique, détection d’anomalies, …).

Afin de mener à bien vos missions, vous avez les compétences suivantes :
Maîtrise des technologies Big Data
Maîtrise des outils data science (R, Python, Scala)
Un background technique est souhaité

Etudiant(e) Bac+5 d’une Grande Ecole d’ingénieur, vous suivez un Master ou une spécialisation en Data Science. Vous êtes autonome, persévérant(e) et rigoureux(se). Vous appréciez le travail en équipe.
La qualité de nos stages a été récompensée par l’obtention du label Happy Trainees / Choose My Company. Parce que nous avons à cœur de développer les potentiels de chaque étudiant, nous vous formons pendant toute votre période de stage de fin d’études dans une optique d’embauche.
80% de nos stagiaires nous rejoignent en CDI.

Rejoignez Graphène !"
Montrouge (92),"Apprentissage, Contrat pro",,Assistant Data Scientist H/F,CA CIB FRANCE,- Montrouge (92),"Crédit Agricole CIB est la banque de financement de d'investissement du groupe Crédit Agricole, 12e groupe bancaire mondial par les fonds propres Tier1 (The Banker, juillet 2018). Près de 8300 collaborateurs répartis en Europe, Amériques, Asie-Pacifique, Moyen-Orient et Afrique du Nord, accompagnent les clients de la Banque dans la couverture de leurs besoins financiers à travers le monde. Crédit Agricole CIB propose à ses clients grandes entreprises et institutionnels une gamme de produits et services dans les métiers de la banque de marchés, de la banque d'investissement, des financements structurés, de la banque commerciale et du commerce international. Pionnier dans le domaine de la finance Climat, la Banque occupe aujourd'hui une position de leader sur ce segment avec une offre complète pour l'ensemble de ses clients.

Pour plus d'information : www.ca-cib.fr

Twitter: https://twitter.com/ca_cib
LinkedIn: https://www.linkedin.com/company/credit-agricole-cib/
Référence
2020-48108
Date de parution
18/05/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Systèmes d'information / Maîtrise d'Ouvrage
Types de métier complémentaires
Types de métiers Crédit Agricole S.A. - Financement et Investissement
Type de contrat
Alternance / Apprentissage
Durée (en mois)
12
Date prévue de prise de fonction
01/09/2020
Missions
La filière IDT (Innovation & Digital Transformation) a pour mission d’accompagner Crédit Agricole CIB dans la définition et la mise en place de sa transformation digitale (Architecture des données, veille digitale, projets digitaux, etc.)
La mission principale de l’équipe transversal Innovation & Digital Transformation (IDT) est d’accompagner tous les métiers et fonctions support de la banque dans leur transformation digitale. Nos objectifs s’articulent autour de 5 piliers : La gouvernance et l’architecture data, l’expertise sur les nouvelles technologies, l’accompagnement et la réalisation de projet digitaux, l’animation d’un écosystème, et la veille.
Vos missions seront les suivantes :
Travailler en étroite collaboration des experts IA (Data Science et Machine Learning) et les chefs de projets de l’équipe
Aider à réaliser des cas d’usages qui peuvent être variés, allant d’analyses descriptives ou statistiques des données, à des modèles prédictifs, en passant par le natural language processing ; pour les fonctions commerciales (segmentation clients, scoring, priorisation d’emails, connaissance du clients…) ou les fonctions supports (détection de fraude, anticipation de risque, détection d’anomalies…)
Interagir régulièrement avec les métiers commanditaires.

Vous effectuerez votre alternance sur le campus Montrouge, activement ouvert sur la ville et intégré dans un écosystème et une vie locale dynamique. Vous y découvrirez un environnement de travail moderne et agréable dans des bâtiments aux dernières normes HQE environnementales, de nombreux services (salle de sports, boulangerie, conciergerie, vélos électriques, take-away, etc.).
Intégrer CACIB, c'est aussi rejoindre une banque internationale qui s'engage depuis plusieurs années en faveur de l'insertion des jeunes, en proposant un accueil et un accompagnement de qualité pour chacun de ses alternants avec :
un tuteur formé et volontaire,
une équipe dédiée à l'alternance qui organise un suivi des étudiants : journée d'accueil, accompagnement et suivi, etc.
des opportunités post alternance en VIE, CDD et CDI
Conformément à la politique de CACIB en faveur de l’insertion de personnes en situation de handicap, ce poste est ouvert à toutes et à tous.
Si cette annonce vous correspond, postulez pour rejoindre notre communauté d’alternants en 2020, vous devez probablement être notre prochain talent !

Merci d’indiquer en titre de votre CV votre rythme d’alternance.
Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 92 - Hauts-De-Seine
Ville
Montrouge
Critères candidat
Niveau d'études minimum
Bac + 4 / M1
Formation / Spécialisation
Formation : Ecole d'ingénieur/Informatique,Université
Spécialisation : Data science / Machine learning /Statistique
Niveau d'expérience minimum
0 - 2 ans
Outils informatiques
Connaissances indispensables : Python de préférence à R, SQL, Power BI, Git, GitLab et connaissances data mining, Machine Learning et/ou text mining, NLP
Connaissances complémentaires bonus : Docker, Java, Bases No SQL, écosystème digital et data, connaissances d'un ou plusieurs métiers de la BFI
Langues
Français et Anglais courant"
Paris (75),CDI,,Data scientist - Produit,Happn,- Paris (75),"Description du poste
Environnement
Vous voulez trouver des insights forts pour accélérer la croissance d’une startup innovante et développer des algorithmes business driven? Rejoignez notre équipe data riche en compétences, vivante et éclectique qui regroupe data scientists, engineers, BI et analysts.
On attend de vous que vous soyez force de proposition dans l'équipe, qui est toujours à la recherche d'idées nouvelles!
Descriptif de missions
Au travers d’études descriptives et prédictives approfondies, estimation du ROI d'un projet, ton rôle premier sera d’identifier les principaux leviers de rétention et d’engagement par rapport à l’activité sur le produit pour les équipes métiers.
Tu seras force de proposition d'opportunités de mise en œuvre de machine learning et / ou scores répondant aux besoins métier pour co-construire la roadmap Produit avec le Product Owner;
Participation au cadrage / kick-off avec le Produit: objectif, périmètre, méthode ainsi que capacité d’industrialisation pour obtenir la validation métier et technique avant démarrage;
Développement des modèles et méthodes d’apprentissage automatique permettant de répondre à une problématique métier en accord avec la roadmap stratégique. Les problématiques Produit seront liées aux fonctionnalités existantes ou celles en devenir, à la recommandation de profil ou encore à la création de valeur à partir des données de géolocalisation;
Test de robustesse de tes algorithmes sur des jeux de données adaptés;
Définition et analyse des A/B tests de monétisation;
Vulgarisation de tes travaux (lors des démos et ateliers de travail) en présentations captivantes, visuelles et synthétiques aux équipes business et à la direction afin de mobiliser les différentes équipes associées à tes projets et de te synchroniser avec elles.
Méthodologies et bonnes pratiques:
Référent en statistique de l’équipe data, tu accompagneras les différents métiers de la data pour mettre en place un A/B tests framework (tests statistiques, KPIs à suivre, périmètre de l’A/B test).
Suite à tes études, tu pourras recommander aux ingénieurs BI la mise en place de nouveaux indicateurs clés, perfectionnant les tableaux de bord existants.
Tu participeras à l'amélioration de bonnes pratiques au sein du CORE Data science.
Profil recherché
Formation
De formation supérieure d’une grande école d’ingénieur spécialisée en statistiques / datamining / mathématiques.
Vous avez 2 ans d’expérience minimum en tant que data scientist dans le domaine du digital
Hard skills (Compétences métier)
Obligatoire : Python / SQL / connaissances statistiques et machine learning
Subsidiaire : Tensorflow / Elastic Search / Spark / R / Git / Tableau
Soft skills (Compétences interpersonnelles)
Vous êtes owners de vos projets: vous prenez des initiatives, vous êtes flexible et autonome, et faites preuve d’une grande rigueur
Vous êtes une personne de confiance
Vous êtes synthétique, clair(e) et avez de bonnes qualités de communication
Vous avez l’esprit d’équipe: vous avez un bon relationnel, aimez le partage et le challenge
Vous savez faire preuve d’empathie
Déroulement des entretiens
Entretien avec l'équipe
Test
Entretien Manager et DRH"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris,,,Développeur Python / Data science | Objets connectés (IoT) – E Santé,In-Team,- Paris,"Vous recherchez un nouveau challenge Python avec de fortes problématiques data science ?
Alors, rejoignez cette société qui a révolutionné le monde de la santé connectée en travaillant sur les nouveaux objets de notre quotidien !
Cette entreprise à l’esprit startup est spécialisée dans la conception et réalisation d’objets et d’applications connectés innovants dans le domaine du bien-être.
Créée il y a 8 ans ; ils sont aujourd’hui plus de 300 personnes et sont présent à l’international depuis leur débuts! Partenaire d’Apple et de Google les équipes sont très souvent invitées à leur event (Keynote et Google I/O)
Au sein de l’équipe technique de 50 personnes, vous travaillerez en relation direct avec leur 10 data scientists et aurez pour rôle de développer un outil de stockage et de gestion des données collectées lors des campagnes de R&D
La stack technique ? Python ; PostgreSQL ; Linux ; Git
Vous êtes curieux d’en savoir plus ?

Votre mission :
L’équipe technique est composée de 50 personnes expertes sur les technologies iOS, Android, DataScience, Devops et Web.
Au sein de l’équipe data de 10 data scientists vous serez amené à faire dans un environnement agile :
Développer en Python un outil de gestion des campagnes R&D à destination des data scientists
Travailler sur un volume important de données (code ; requêtes SQL)
Travailler sur l’architecture logicielle
Réaliser l’intégration, les tests, le déploiement, la migration et le maintien de la solution développée
Travailler en relation direct avec les data scientists
Être force de proposition sur les améliorations d’organisation des ensembles de données
Être force de proposition sur les améliorations produit

Votre profil :
Bac +5 école d’ingénieur
Une première expérience en développement Python et un attrait pour le monde de l’IoT
Vous êtes exigeant sur la qualité de votre code et l’architecture logiciel car c’est quelque chose que vous jugez important
Des parties de jeux-vidéos sur la pause déjeuner vous font rêver
Anglais courant

Opportunité :
Travailler en autonomie sur un projet from scratch avec de fortes problématiques data science
Être en contact direct et quotidien avec les data scientists
S’épanouir au sein d’une structure pérenne avec un esprit startup, reconnue pour son innovation et sa volonté de révolutionner le monde de la santé connectée.

Salaire et avantages :
A convenir selon votre profil et vos compétences
Participation aux évènements d’Apple
Supers locaux très spacieux et agréable
Contrat en CDI
Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !
Si vous souhaitez avoir d’autres informations sur cette opportunité je vous invite à me contacter également."
Nanterre (92),,,Data Scientist confirmé H/F,METRO AG,- Nanterre (92),"Data Scientist confirmé H/F
Numéro de l'emploi :
103241
Horaire
: Temps plein
Lieux de travail
:
METRO Nanterre (HQ)
5 rue des grands prés ZA du Petit Nanterre
NANTERRE 92000
Connaissez-vous METRO ?

N°1 en France et partenaire omnicanal préféré des restaurateurs et commerçants indépendants, nous sommes 9 000 collaborateurs au service des entrepreneurs du goût !
Ce qui nous tient à cœur ? La qualité de nos produits, la relation de confiance avec les producteurs et le conseil que nous apportons à nos clients professionnels.
Notre volonté : permettre à tous d’accéder à une alimentation et à une restauration authentiques, saines, savoureuses et créatives.



Vos challenges :

Proposer et exécuter des méthodes d’analyses (simples ou complexes), en assurant l’uniformisation (interprétation unique) des résultats dans différents domaines.
Connaissances clients/produits/fournisseurs :
Définir les indicateurs et mettre en œuvre les outils de pilotage en collaboration avec les services concernés
Mettre en œuvre et garantir la modélisation statistique des données clients (pour développer les segmentations clients, caractériser le cycle de vie des clients, développer des algorithmes d’apprentissage et scénarii prédictifs des comportements clients).
Proposer le développement de levier de création de valeur client (optimisation des assortiments, modèles d’efficacité op, test de performance)

Analyser et optimiser des campagnes et opérations commerciales avec les services concernés :
Définir les critères de ciblage des campagnes de marketing direct afin d’optimiser les investissements, et la pression commerciale.
Définir les indicateurs de mesure et d’analyse de la performance des opérations commerciales, quantifier le CA additionnel généré et mesure le ROI.

Identifier et rassembler l’ensemble des sources de données structurées (transactionnelles) ou non structurées (qualitatives, relation client, commentaires sur réseaux sociaux) nécessaires pour l’appropriation et l’exploitation de la donnée (client, produit & fournisseur) :
Etudier et mettre en place les meilleures solutions techniques pour gérer les grands volumes de données, en collaboration avec le pôle « BI » de la DSI.
Tester, contrôler et valider la qualité et la cohérence des données pour une correcte exploitation.

Votre profil :

Diplômé d'une école d'ingénieur ou d'un Master en statistique et informatique décisionnelle, économétrie.
Vous justifiez d'une expérience réussie et signification de 3 à 5 ans minimum dans la valorisation des données clients.
Une première expérience en management est requise.
Une expérience dans le retail serait un plus.
Compétences en R, Python, Tableau, QlikView et SQL.



Informations complémentaires
- Statut Cadre
Rémunération sur 13 mois + variable + intéressement + participation
Remise sur les achats
Perspectives d'évolution au sein d'un grand groupe international
METRO France
Offre d'emploi publiée le
: 25 janv. 2019"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community
Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),,,Data Scientist confirmé(e) (H/F),Allianz France,- Paris (75),"Au sein de la direction Vision Client, Big Data et Intelligence Artificielle d’Allianz, vous rejoignez une équipe chargée de créer des modèles prédictifs pour nous aider à mieux comprendre le comportement de nos clients.
Pour cela, vous êtes amené(e) à travailler en étroite collaboration avec les équipes de data engineering d’un côté et les équipes opérationnelles de l’autre.

Vous contribuez à la réalisation de travaux d’analyse et de développement d’algorithmes directement sur la plateforme Big Data du Groupe Allianz - plateforme distribuée sous langage Python (moteur de traitement : Spark).

Vos principales responsabilités sont les suivantes :
Monter en compétence sur les modèles existants (indicateurs IA)
Recueillir, analyser et comprendre les besoins métiers
Proposer de nouvelles modélisations et/ou perfectionner les modèles existants
Accompagner les équipes opérationnelles à l’appropriation de ces indicateurs et au suivi de leurs impacts
Explorer de nouveaux usages, élaborer des analyses à des fins d’amélioration de la connaissance client et d’optimisation de parcours clients, de segmentation d’offre, de prédictions de comportement
Exemples de projets qui pourront vous être confiés :
Mise en place de nouveaux modes de scoring clients : utilisation de méthodes de machine learning pour déterminer le cross-sell client, l'attrition, la satisfaction,... sur notre plateforme Big Data
Refonte de la segmentation client : calcul de score de revenus et patrimoine, segmentation comportementale…
Modélisation de parcours clients pour identifier les leviers d'insatisfaction client, mise en place de leviers d'amélioration et calcul de l'impact économique
De formation supérieure (BAC +5, Doctorat) dans le domaine scientifique, vous justifiez d’une expérience de 3 ans minimum dans des travaux de modélisation marketing et souhaitez continuer à perfectionner votre expertise dans le domaine de l’IA.
Vous maitrisez le langage Python et les outils informatiques de manière générale
Vous avez une excellente capacité d’écoute et de synthèse auprès de public variés, d’experts informatiques et métiers
Une maîtrise orale et écrite de l’anglais est demandée."
Paris (75),CDI,,Consultant(e) Data Scientist,SOCIO DATA MANAGEMENT,- Paris (75),"Contexte
Depuis plus de 40 ans, Socio Data Management est leader dans le traitement et l’analyse de données, ainsi que dans les solutions applicatives pour en optimiser l’exploitation et la restitution.
Nos consultants experts accompagnent nos clients durant toutes les étapes de leurs projets Data : depuis le recueil et l’intégration des données jusqu’à leur mise à disposition sur des plateformes en ligne, nous mettons notre savoir-faire au service de nos clients sur toute la chaîne de valeur de la Data.
Spécialistes des modélisations intelligentes, nous les aidons à exploiter efficacement leurs données pour prendre des décisions optimisées, tant sur le plan opérationnel que stratégique.
Missions
Afin de renforcer nos équipes, nous recherchons un(e) Consultant(e) Data Scientist, pour intervenir chez l’un de nos clients grands comptes.
Vous aurez pour mission :
L’identification et la formalisation de Business Cases et des problématiques des Directions Métiers ;
L’exploration des données internes et externes ;
La proposition de solutions adaptées ;
La réalisation des projets Big Data (ingestion de sources, traitements, tests, recettes, déploiements) ;
Le crunching, l’analyse et l’exploitation de données (CRM, Produits, Digitales, Logistique, Yield, Open data…) ;
L’optimisations et l’industrialisations des modèles de Machine Learning et d’intelligence artificielle.
Profil recherché
Vous êtes diplômé(e) d’un Bac + 5 dans un domaine tel que les statistiques, l’informatique, l’ingénierie, les mathématiques, et vous justifiez idéalement d’une première expérience en Machine Learning/Big Data/Analytics.
Une expertise en mathématiques appliquées (statistiques, optimisation, machine learning, NLP) est indispensable.
Vous maîtrisez la programmation informatique : Python (pandas, numpy, scikit-learn), R, C++, Scala, Spark… Et vous avez de solides connaissances en algorithmie et gestion des bases de données (SQL, noSQL, MapReduce, Hadoop…).
Doté d’une grande qualité d’écoute et d’analyse, vous aimez travailler en équipe. Vous êtes curieux de nature et passionné par la Data, avec le souhait de mettre vos compétences au service des clients.
Nous rejoindre
Rejoindre l’équipe Socio Data Management c’est :
Un engagement de proximité : entreprise à taille humaine, nous restons proches de nos collaborateurs afin de les accompagner de façon pertinente dans leurs carrières.
Une garantie de diversité : nous intervenons sur des projets divers, enrichissants, innovants et à forte valeur ajoutée pour nos clients dans différents secteurs d’activités.
Une promesse d’innovation : en tant qu’expert Data, nous faisons partie du Data Lab, un véritable pôle R&D qui a pour vocation de faire émerger des initiatives innovantes.
Un gage d’intégration : faisant partie intégrante d’un groupe, nos collaborateurs ont la possibilité de créer et de tisser du lien, tout en développant leurs connaissances sur des sujets transverses (cybersécurité, gestion des risques, IT…).
Bénéficier de nos avantages : accès à notre plateforme CE, attribution de chèques-cadeaux, tickets-restaurants, prime vacances…"
,,,,,,
Clamart (92),CDI,,DATA SCIENTIST H/F,Audioptic,- Clamart (92),"Informations générales

DÉTAILS DE L'OFFRE
Références : DATASCIENT/0220-1445
Métier : Systèmes d'Informations
Contrat : CDI
Durée du contrat : mois

ENTITÉ DE RATTACHEMENT
Rejoindre le groupement Optic 2ooo, c'est travailler pour 3 enseignes - Optic 2ooo, Lissac et AUDIO 2000 – et plus de 2 000 magasins répartis sur toute la France

Depuis sa création il y a plus de 50 ans, le dynamisme et la volonté d'innovation ont permis au groupement Optic 2ooo de devenir leader sur son marché
Avec, pour demain, la même ambition qu'à ses débuts : évoluer constamment pour garder un temps d'avance

Vous aussi, contribuez à son développement !

DATA SCIENTIST H/F

DESCRIPTION DE LA MISSION
Au sein du service Etudes et développement de la DSI, le pôle « DATA », nouvellement créé, est en charge de centraliser les flux de données, rendre cohérentes ces données afin de fournir des analyses et indicateurs à destination des équipes internes du groupement et des magasins adhérant au groupement.

A ce titre nous recrutons un DATA SCIENTIST h/f

Vous aurez pour missions :
Construire puis maintenir l'architecture des entrepôts de données et outils d'analyse

En collaboration avec le pôle « Etudes et Performance », prendre en charge les projets les études
Formaliser les demandes issues des directions utilisatrices
Identifier les données utiles pour ces analyses, les rendre cohérentes et exploitables
Construire les modélisations à la fois mathématiques et informatiques permettant de répondre à ces demandes
Interpréter les résultats des études pour donner du sens aux analyses
Expliciter les résultats des analyses et les rendre exploitables par les directions métier

Etre force de proposition sur
La construction des outils
La création de métriques et indicateurs à destination de l'ensemble des directions
Les tendances à analyser, les pistes d'études à explorer

Proposer et mettre en œuvre l'aspect Gouvernance des données en étroite collaboration avec le pôle « Etudes et Performance »

PROFIL RECHERCHÉ
De formation Bac+5 minimum type Ingénieur, vous avez une expérience d'au moins 3 ans dans l'analyse de données, au cours de laquelle vous avez développé les compétences suivantes :

animation d'ateliers internes ou de rencontres ciblées avec des experts métier et/ou techniques
analyse et synthèse des besoins
prise en charge du cycle depuis le recueil des besoins jusqu'à la restitution des analyses en passant par les phases de datacleaning, modélisation et codage
prototyper pour proposer des pistes de solution rapides

Vous êtes force de proposition à la fois sur les outils à mettre en œuvre (Dataware / datamarts, algorithmes d'auto-apprentissage et cas d'usage, data-visualization) et sur l'interprétation des tendances

Rigoureux, organisé, curieux, vous êtes un bon communiquant doté de qualités rédactionnelles, mais aussi curieux et aimez le travail en équipe

Comptétences techniques :
Socle technique robuste (Structure de données, bases de données (Postgresql, éventuellement NoSQL) programmation Python voire R)
Expertises en algorithmie,
solide bagage mathématique / statistiques

LOCALISATION DU POSTE
Ile-de-France, Hauts-de-Seine (92)
5 avenue Newton 92140 CLAMART
92140"
Paris (75),"Temps plein, CDI",,Data Engineer H/F,Groupe Pierre & Vacances - Center Parcs,- Paris (75),"Afin de répondre aux besoins croissants des métiers qui doivent s’appuyer sur un maximum de données récoltées pour conceptualiser leurs besoins et trouver les informations les plus pertinentes qui leur seront utiles, nous recherchons un data engineer capable de concevoir et gérer des systèmes de Big Data.

En tant qu'expert du traitement de la donnée, vous aurez pour mission
la modélisation et la réalisation d'infrastructures permettant la gestion de la Data de l’entreprise en adéquation avec les enjeux business
de proposer et conseiller les équipes internes sur les outils et technologies inhérentes aux infrastructures Big Data dont vous superviserez l’implémentation.
Vous serez en charge de
de l’architecture des données collectées en continue sur nos serveurs au travers de nos différentes applications.
la réalisation des fonctions de collecte, de stockage et de traitement des données
l’automatisation des tâches de traitement
la mise en place des outils permettant d'assurer leur supervision dans une vision industrielle en collaboration avec les eService manager du département
la documentation technique de vos travaux destinée à la maintenance et à l’exploitation des solutions mises en œuvre
la mise en place des processus de déploiement et la coordination des déploiements sur les différents environnements (Recette/Pré-production/Production)
veiller au bon fonctionnement des applications après mise en production : gestion des sondes/alertes, mise en place du process support, définition et brief du eService manager chargé de la maintenance courante.
Participer aux activités de veille technologique dans le domaine Big Data (recherches, expérimentations)
Localisation du poste
Localisation du poste
EUROPE, FRANCE, 75 - Paris , Paris
Critères candidat
Niveau d'études requis
Mastère ou équivalent
Niveau d'expérience requis
3 à 5 ans
Outils Informatiques
Travail en équipe, Méthodologie Agile (SCRUM)
Capacité à appréhender des algorithmes et mécanismes complexes de traitement de données (Machine et Deep Learning, systèmes de recommandations produits…)
Implémenter des workflows d'acquisition et d'analyse de la donnée pour faire émerger des possibilités métiers encore inexploitées
Assurer l’adéquation entre les solutions développées et la stratégie de l’entreprise
Assurer la mise en œuvre, le suivi, l’exploitation et la mise à jour des différents outils
Assurer de la scalabilité de l’infrastructure
Améliorer l’acquisition, l’extraction et le nettoyage des données
Appréhender les différents environnements (local, développement, recette…)
Excellent background technique : Python, Java, ElasticSearch, BigQuery
Compétences
Passionné(e) d'algorithme, vous disposez d’une ou plusieurs expériences sur la mise en place d’architectures Big Data et Cloud sur des thèmes de traitements analytiques de données à grande ampleur, de préférence avec des aspects de temps réel et traitements de données en flux
Vous êtes :
Pragmatique et focus sur le résultat/enjeux
Réactif, avec le sens du service, vous justifiez de bonnes capacités d'écoute, d'un bon relationnel et d’une bonne gestion du stress
Curieux, autonome et proactif
Aisance orale et rédactionnelle
Méthodique et rigoureux dans l’exécution
Langues
Anglais (Correct - Parlé / Ecrit)"
Paris 1er (75),CDI,,Data Analyst PowerBI F/H,TRIMANE,- Paris 1er (75),"Nous recherchons un Data Analyst afin d'accompagner notre client dans le développement de ses outils de reporting.

Tes missions :
Recueil et analyse du besoin

Accompagner le Lead dev dans les développements Power BI

Conception, développement des rapports

Refonte d'une application web en application Power BI
Profil recherché - Diplômé d'une école d'ingénieur ou d'un Master avec une spécilisation relative au traitement et à l'analyse de la donnée,

Une expérience d'un an minimum en environnement PowerBI : Power Query et son langage M, Power Pivot et son langage DAX
La connaissance/expérience de la suite Microsoft BI : SSIS, SSAS, SSRS
Entreprise TRIMANE est une société de service spécialisée dans les systèmes d'information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l'information au sein de leur entreprise.

En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d'expertise de nos consultants.

Nous accompagnons nos clients (CAC 40 et SBF 120) sur des prestations de Conseil, MOA et MOE, autour du traitement et l'analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique.

TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d'outils d'Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique."
Paris 10e (75),,,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong

Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris,40 000 € - 60 000 € par an,,Développeur Python/Java – Data science – Optimisation énergétique & IA,In-Team,- Paris,"Vous êtes à l’aise en Python et en Java et recherchez un nouveau challenge dans le secteur de l’énergie ?
Alors rejoignez cette société qui développe une solution Saas à destination des grands groupes industriels.
Leur cœur de métier ? En appliquant les outils d’intelligence artificiel, de data science et de machine learning au concept d’ontologie, ils fournissent à leurs clients des solutions sur mesure d’optimisation énergétique.
Ayant levé 4 millions d’euros en 2017, ils poursuivent leur internationalisation et cherche à renforcer leur équipe technique avec un nouveau développeur pour travailler en collaboration avec les équipes de développement et de data science.
Au programme : Développement en Python et Java, machine learning, deep learning
VOTRE ROLE
Au sein de l’équipe data votre rôle sera :
Développement Python & Java
Travailler en collaboration avec les data scientist – Python – Machine learning / Deep learning
Veille technique
VOTRE PROFIL
Bac +5
Bonne connaissance des langages Python & Java
Connaissances en data science
Une 1ère expérience et/ou une appétence pour le secteur de l’énergie est un vrai plus
OPPORTUNITE
Utiliser vos compétences au sein d’un projet dynamique et innovant
Rejoindre un startup’ en plein essor et en pleine internationalisation
Rejoindre une structure ayant une culture de la formation et de la montée en compétences
Avoir des perspectives d’évolutions en interne
LE SALAIRE ?
40-60k€ selon profil
Si vous aimez :
Le challenge technique et les projets d’envergure
Travailler dans un environnement technologique stimulant
Mettre vos idées en avant et les mettre en application de A à Z
Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !"
Massy (91),,,Ingénieur(e) statistiques,Crédit Agricole Consumer Finance,- Massy (91),"Qui sommes nous ?

Crédit Agricole Consumer Finance est un acteur majeur du crédit à la consommation en Europe. Filiale du groupe Crédit Agricole, elle apporte son expertise du crédit à la consommation en mettant à disposition de ses clients et partenaires des offres adaptées et innovantes.

La mission que l'on propose

Vous rejoindrez la direction du développement des partenaires bancaires et plus spécifiquement le service marketing. La direction du Développement des Partenariats Bancaires (DPB) a pour mission de contribuer au développement de l'activité du crédit à la consommation dans les banques de proximité du Groupe : les Caisses Régionales et LCL.
Avec la montée en puissance des leviers digitaux et des nouvelles technologies (IA, machine Learning, Big Data…), la data est au cœur de la stratégie du groupe Crédit Agricole, générant à la fois des opportunités business et une meilleure efficacité opérationnelle.
Une meilleure connaissance des moments de vie et des parcours des clients permet de mieux détecter en amont leurs besoins.
Servir le projet client en proposant la bonne offre au bon moment.
Augmenter le business et la satisfaction client.
Les données de nos partenaires bancaires sont très riches, il est donc primordial de pouvoir exploiter pleinement la DATA pour accompagner davantage nos partenaires à développer leur business.
Dans ce contexte, vous rejoindrez l’équipe « Etudes, Analyses et Scores » composée de 5 ingénieurs statistiques dont les missions principales sont :
1- De modéliser des comportements et parcours clients : scoring d’appétence, segmentations, détection de signaux liés aux comptes bancaires…
2- D’améliorer la connaissance client en réalisant des études, des diagnostics de portefeuille
3- De participer au Plan Marketing au travers des préconisations de ciblage, des sélections
optimisées des clients et de l’analyse des opérations commerciales

Vous aurez pour missions principales :
Réaliser des études de portefeuille, des reportings
Réaliser le ciblage des campagnes Marketing : préconisation des cibles et sélection optimisée des clients
Analyser les résultats des campagnes Marketing Direct
Participer avec l’équipe à l’optimisation des modèles de scoring ou de segmentation

#Ta formation

Bac +4/5
Spécialisation : statistiques – mathématiques – data science - analyse de l’information
Formation ingénieur ou université avec une spécialisation en statistique/data science/datamining

#Tes compétences

Autonomie
Rigueur
Esprit d’équipe
Force de proposition
Le goût pour l’innovation serait un plus (curiosité, intérêt pour les nouvelles technologies…).
Outils informatiques : langage de programmation (SAS, R, Python…), VBA, pack office


#Nos pré-requis

Maîtrise des techniques d’analyses de données.
Bon esprit d’analyse et de synthèse"
Paris,40 000 € - 60 000 € par an,,Développeur Python – Optimisation énergétique / IA & data science,In-Team,- Paris,"Vous êtes développeur Python et recherchez un nouveau challenge dans le secteur de l’énergie ?
Alors rejoignez cette société qui développe une solution Saas à destination des grands groupes industriels.

Leur cœur de métier ? En appliquant les outils d’intelligence artificiel, de data science et de machine learning au concept d’ontologie, ils fournissent à leurs clients des solutions sur mesure d’optimisation énergétique.
Ayant levé 4 millions d’euros en 2017, ils poursuivent leur internationalisation et cherche à renforcer leur équipe technique avec un nouveau développeur Python.
Au programme : Python / Java / NodeJS
VOTRE ROLE
Au sein de l’équipe technique votre rôle sera :
Travail sur les API en Python, Java, NodeJS
Travailler en collaboration avec les data scientist sur l’amélioration de l’outil Saas
Faire de la veille technologique
VOTRE PROFIL
Bac +5
Une 1ère expérience et/ou une appétence pour le secteur de l’énergie est un vrai plus
OPPORTUNITE
Utiliser vos compétences au sein d’un projet dynamique et innovant
Rejoindre un startup’ en plein essor et en pleine internationalisation
Rejoindre une structure ayant une culture de la formation et de la montée en compétences
Avoir des perspectives d’évolutions en interne
LE SALAIRE ?
40-60k€ selon profil
Si vous aimez :
Le challenge technique et les projets d’envergure
Travailler dans un environnement technologique stimulant
Mettre vos idées en avant et les mettre en application de A à Z
Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !"
Puteaux (92),CDI,,DEVELOPPEUR BIG DATA F/H,ALTRAN,- Puteaux (92),"Contexte :
Nous recherchons un/e DEVELOPPEUR BIG DATA H/F pour intégrer nos équipes BI / Big Data & Software. Vous serez directement rattaché(e) à la Division Finance & Public Sector.

Vos missions :
Développer des flux d'alimentation de Data Lake et de traitement des données.
Concevoir les modèles de données.
Participer à la mise en place de l’architecture BIG DATA.
Participer à la réalisation technique de chargement / traitement des données.
Profil recherché Profil :
Diplômé(e) Bac+5 en informatique, d’une école d’ingénieur ou d’un doctorat, vous justifiez d’une expérience réussie d’au moins 2 ans dans un ou plusieurs projets BIG DATA..
Vous possédez idéalement un background technique en développement (JAVA, C++), des compétences en modélisation et en manipulation de données.
Vous maîtrisez au moins l’une des distributions suivantes: Ecosystème HADOOP, Spark, Scala, Python, Elasticsearch, R.
A compétences égales, ce poste est ouvert aux personnes en situation de handicap.

Pourquoi nous rejoindre ?

En nous rejoignant, vous accompagnerez une équipe d'experts en travaillant sur des missions qualitatives et stimulantes. Vous serez accompagnés par l'Expertise Center ALTRAN pour les formations et certifications. Vous aurez également la possibilité d'évoluer en tant qu'expert technique, consultant senior, solution architect, chef de projet BI / Big Data & Software.

Si vous aussi vous aimez relever des défis, si vous souhaitez vivre une aventure humaine et technologique unique, n'hésitez plus et rejoignez-nous!

Venez inventer le futur avec nous sur www.altran.fr !

Venez inventer le futur avec nous sur www.altran.fr !
Entreprise Altran recrute plus de 3800 ingénieurs en France en 2019 : rejoignez-nous! Leader mondial du conseil en innovation et ingénierie avancée, Altran propose à ses clients d’innover autrement en les aidant à développer ou en développant pour eux les produits et les services de demain.

Altran compte aujourd'hui plus de 11 500 collaborateurs en France (47 000 dans le monde) et intervient depuis 35 ans auprès des grands acteurs de nombreux secteurs.

Si vous aussi vous aimez relever des défis, si vous souhaitez vivre une aventure humaine et technologique unique : venez inventer le futur avec nous sur www.altran.fr !"
Versailles (78),,,Consultant Quant (Data Science),Eurodecision,- Versailles (78),"Description du poste
Au sein du département Conseil, vous participerez à des missions stratégiques et tactiques pour nos clients. A l’aide de modèles mathématiques, vous réaliserez des études pour fournir des recommandations ou accompagner nos clients sur des problématiques d’analyse de données clients (Customer Data Analytics).
Sous la responsabilité d’un consultant expérimenté, vous interviendrez dans toutes les phases d’une étude :
Analyse du besoin client
Recueil et traitement des données
Choix de modélisation et algorithmes adéquats
Prototypage de solution OU paramétrage de nos outils d’aide à la décision
Lancement des simulations
Analyse et restitution des résultats au client (BI)
Vous évoluerez dans un environnement à forte composante technique (mathématiques/informatique) ; des compétences en gestion de données à forte volumétrie et langages de programmation sont requises.
Pour vous, un excellent rapport avec le client est la clé d’un projet réussi. Doté(e) d’un sens aigu de l’écoute, d’une bonne capacité d’analyse, d’esprit de synthèse et d’une authentique envie de convaincre, rejoignez une équipe jeune et dynamique experte dans l’aide à la décision !
Pourquoi nous rejoindre ?
Vous êtes curieux des nouvelles technologies, vous souhaitez contribuer à des projets innovants pour nos clients
Vous voulez travailler au contact de problèmes réels sur des missions à forts enjeux avec des résultats concrets et un impact visible sur les processus de vos clients
Vous avez envie de découvrir des secteurs d’activité variés (aérien et aéroportuaire, agroalimentaire, distribution, hôtellerie de plein air, industrie, oil&gaz…)
Vous recherchez un poste où vous pourrez mettre à profit vos compétences en mathématiques appliquées
Compétences requises
De solides connaissances en mathématiques appliquées, modélisation statistique et analyse de données. Les techniques de prévisions et d’apprentissage n’ont aucun secret pour vous.
Langages : la maîtrise d’un langage de programmation (R, python ou C++, Java), ainsi que la capacité à appréhender rapidement le fonctionnement d’autres langages et outils
Anglais courant
Bases de données
Profil
Titulaire au minimum d’un Bac + 5, d’un diplôme d’ingénieur ou d’un doctorat, vous disposez idéalement d’une première expérience"
Paris (75),CDI,,CONSULTANT DATA SCIENCE,Axtrid,- Paris (75),"A la pointe de la recherche et de l'innovation, nous développons des solutions sur mesure pour des clients allant de la start-up aux grands comptes.
Nos équipes sont composées de profils riches et variés qui travaillent en cohésion pour une ambition commune : soutenir l'innovation de nos clients. Nous concevons et réalisons des systèmes pour répondre à des besoins de prototypage, de bancs de test ou de traitement de données, intégrant capteurs connectés, analyse temps réel, pilotage et lois de commande. Notre activité s'étend aujourd'hui aux secteurs de la mobilité, défense, aéronautique, mais aussi luxe, cosmétique ou assurance.
Membre du cluster Genaris, nous profitons de l'agilité d'une petite entreprise et de la puissance d'un groupe. Si vous souhaitez rejoindre une équipe à taille humaine, où vous pourrez perfectionner vos performances dans un environnement stimulant, rejoignez-nous!
Description du poste
Dans le cadre de notre fort développement, nous renforçons nos équipes en ingénierie. Ainsi nous recherchons un consultant Matlab et Big Data pour accompagner l’un de nos clients et nos équipes internes sur des projets à long terme.
Vous avez au moins 3 ans d’expérience sur Matlab ? La Data Science ne vous fait pas peur ? Vous souhaitez partager des projets ambitieux pour 2020 et intégrer une équipe de passionnés d’innovation ? Cette offre est peut être faite pour vous !
1) Quelles seront vos responsabilités ?
Mise en place de stratégie de validation et de revue des modélisations dans l’outil
Mise en place de stratégie d’évolution en adéquation avec la réglementation du client
Pilotage des améliorations des performances
Gestion de projets métiers et techniques multiples

2) Quelles seront vos missions ?
Automatisation des processus
Migration Matlab périodique
Optimisation et maintenance du code Matlab
Mise en place de nouvelles fonctionnalités (Métier/Techniques) pour pérenniser les performances
Réflexion sur les données (construction, stockage et transfert)
Formation des collaborateurs aux nouvelles évolutions Matlab
Assistance des utilisateurs et des modélisateurs
Soutien des administrateurs pendant les phases de production
Rédaction des rapports de validation, de réunions et de livraisons
Profil recherché
1) Vous êtes à l'aise dans ces environnements :
Matlab, Windows, ClearCase (GutHub), débogage, profiling
Calcul parallèle (MPI), bigData, algorithmie
Secondaire : Java/Linux
Bientôt: Spark

2) Vous possédez les qualités suivantes :
Etre à l’écoute, disponible, pluridisciplinaire, curieux, efficace
Expériences dans le développement, optimisation de code, algorithmie
Ouvert à l’univers de l’assurance
Profil ingénieur et plus: majeur mathématiques appliquées, statistiques, automatique, calcul parallèle, temps réel"
Paris (75),CDI,,Administrateur Big Data H/F,AMF,- Paris (75),"Informations générales
Entité de rattachement
L'Autorité des marchés financiers, autorité publique indépendante, est le régulateur de la place financière française. Nos 500 collaborateurs veillent à la protection de l'épargne, à l'information des investisseurs et au bon fonctionnement des marchés financiers.
Rejoindre l'AMF, c'est également s'ouvrir à un monde d'opportunités humaines et professionnelles. Nous avons à cœur d'accueillir, accompagner et développer les talents d'aujourd'hui et de demain.
Référence
2020-53
Votre contexte
Description du contexte
La division de la surveillance des marchés comprend 25 personnes. Elle appartient à la Direction des marchés qui regroupe une cinquantaine de personnes, réparties au sein de trois divisions (surveillance des marchés infrastructures de marché et suivi des intermédiaires de marché) assistées d’une équipe juridique. En charge notamment d’identifier de potentiels manquements, elle examine quotidiennement l’ensemble des opérations réalisées sur les marchés ainsi que toutes les autres sources d’information disponibles afin de détecter tout événement ou comportement anormal. La mine d’informations dont elle dispose lui offre un positionnement stratégique pour réaliser une veille de marché, identifier de nouveaux comportements ou des changements des modes de fonctionnement des marchés résultant tant de l’évolution de la réglementation que des innovations financières.
Votre mission
Métier
IT, data et sécurité
Intitulé du poste
Administrateur Big Data
Contrat
CDI
Description de la mission
La plateforme répond aux exigences introduites par les textes européens MIFID/MIFIR en matière de données de marché. Elle permet aussi de rassembler des données hétérogènes (structurées ou non) dans un lac de données. Cette plateforme fait appel à des technologies innovantes (Big Data, Machine learning...) et facilite la mise en œuvre de méthodologies nouvelles. Elle offre davantage d’autonomie aux métiers afin de faciliter l’exploitation des nouvelles sources de données et leur permettre une plus grande réactivité dans l’analyse de marchés financiers. Au-delà d’un programme informatique, la modernisation de la plateforme est un projet d’entreprise touchant à la refonte de processus et méthodes de travail internes. La mise en œuvre de cette plateforme constitue un programme de transformation pour l’AMF, présentant des enjeux majeurs en termes d’investissements, d’évolutions technologiques, d’organisation et de complexité. Vous serez en charge de la bonne adhérence de son environnement applicatif avec le reste du Système d’information de l’AMF et aurez pour responsabilités d’
Assurer le rôle d’Administrateur Big Data Expérimenté
administrer et superviser l’infrastructure technique d’ICY (HADOOP, KAFKA, AKKA, ELASTIC)
installer, paramétrer et configurer les composants et les ressources de la plateforme
assurer la transmission des procédures appropriées à l’équipe d’exploitation
assurer la qualité et la conformité des opérations dans le respect des règles de l’art et des procédures mises en œuvre à l’AMF
gérer les droits d’accès des serveurs et des applications en fonction des profils
assurer le traitement niveau 3 (diagnostic, identification, formulation, correction) des incidents, de problèmes, des demandes et des changements sur le périmètre applicatif dans le respect des niveaux de service et des processus ITIL implémentés
analyser l’historique d'exploitation et des incidents pour proposer les améliorations applicatives susceptibles d’engendrer des gains de productivité significatifs en termes d’exploitation
surveiller les journaux applicatifs pour prendre les mesures préventives nécessaires
suivre la qualité opérationnelle et participer à l’élaboration les tableaux de bord de disponibilité
contrôler et optimiser les environnements (capacité, disponibilité, sécurité, etc.)
assurer l’automatisation de la chaîne de livraison avec l’outillage DevOps (Visual studio, Urban Code) mis à disposition
réaliser et maintenir l’inventaire des différents composants de son périmètre
Assurer le support de niveau 3 applicatif / écosystème Hadoop / Elastic
assurer l’exploitation de troisième niveau des applications en production
veiller au respect de la qualité opérationnelle des applications (performance, incidents, etc.)
administrer les middlewares (Hadoop / Elastic) sous sa responsabilité
mettre en place les outils et procédures nécessaires à l’exploitation et la surveillance automatisée des applications (scripts, modules de supervision,...)
Profil
Diplômé de l’enseignement supérieur (université ou école d’ingénieur), vous avez acquis une expérience d’au moins 5 ans en administration / exploitation de systèmes complexes de type Big Data, au sein d’une ESN ou d’un client final. Vous avez des connaissances approfondies des technologies Linux et de solides compétences en architecture technique d’infrastructure (Hadoop / Elastic).
Vous êtes reconnu(e) pour vos qualités/compétences suivantes :
Rigueur, adaptabilité
Travail en équipe, pédagogie
Très bon relationnel
Capacité technique opérationnelle
Orientation service / résultat
Esprit d’innovation, ouverture d’esprit
Anglais professionnel
Votre profil
Niveau d'expérience min. requis
min. 5 ans
Langues
Anglais (2- Niveau professionnel)
Localisation du poste
Localisation du poste
Ile-de-France, Paris (75)
Lieu"
Vélizy-Villacoublay (78),,,APPRENTISSAGE - Ingénieur développement / Machine Learning - Big Data (H-F),Dassault Systèmes,- Vélizy-Villacoublay (78),"Imaginez demain...

Les nouvelles technologies et la data science vous passionnent, vous souhaitez découvrir le champ des possibles parmi de nombreux domaines d’expertise comme le Data Engineering, le Machine Learning, le Deep Learning et la visualisation des données?
La Direction des Systèmes d’Information vous propose de venir relever les challenges du futur. Au contact de nos équipes, vous imaginerez, concevrez et délivrerez de nouveaux services à destination des différentes équipes métiers de Dassault Systèmes. Ces services à valeur ajoutée reposeront sur notre lac de données et les procédés de l’intelligence artificielle.

Vos futurs défis...

Au sein du pôle Architecture, la mission sera multiple.
De l’analyse du besoin à la mise en production de micro services, en passant par le design d’architecture logicielle et la réalisation de prototypes d’application.
Il s’agira de gérer des projets permettant d’offrir de nouveaux services aux équipes métier. Les domaines d’application sont très variés. Il s’agit de maintenance prédictive et de détection d’anomalies sur la base d’analyse de logs serveurs, ou bien du traitement automatique de type NLP pour des chatbots par exemple:
La spécification du besoin et la recherche de solutions innovantes.
La réalisation de prototypes de services de bout en bout.
Le développement de la chaîne de traitement des données et de modèles prédictifs.
La mise en œuvre de web service de forme « Predict as a service ».
La spécification d’architecture logicielle et de data model de solutions industrielles.
Le transfert de compétences vers les équipes de développement et de production.
Veille technologique sur les solutions Big Data et Intelligence Artificielle.


Vos atouts pour réussir...

Etudiant(e) préparant un diplôme de niveau BAC+5 en Ecole d'Ingénieur ou Master universitaire;
Vous recherche un contrat d'apprentissage de 12/24 mois.

Options souhaitées : Informatique, Développement, Big Data

Compétences techniques souhaitées :

Software developpement (Python, Spark)
Linear Algebra, Statistics, Probabilities
Machine Learning, Deep Learning;

Qualités professionnelles attendues :

Vous êtes curieux(se), créatif(ve), rigoureux(se) et passionné(e) par les nouvelles technologies.
Un très bon sens relationnel est également une qualité essentielle.
Anglais courant."
Paris (75),CDI,,Data Scientist H/F,ADROMA CONSEIL,- Paris (75),"Afin de renforcer notre équipe Data Science, nous recherchons nos futurs talents et plus particulièrement nous recrutons un(e) :
Data Scientist / Data Engineer H/F
Vos missions :
Fidèle aux best-practices DevOps, vous travaillez sur la mise en place d'infrastructures Big Data, réalisez les flux de données, validez leur fonctionnement en sécurité et performance, assurez la pérennité de leurs évolutions.
Participerez à l'évaluation des besoins métiers en collaboration avec les différentes entités impliquées,
Construirez des outils d’analyse pour collecter les données de sources multiples, qu’elles soient structurées ou non structurées,
Gérerez et analyserez les données et en déduirez les modèles les plus adéquats à la problématique rencontrée,
Rédigerez et présenterez les résultats obtenus aux métiers,
Connaissances requises types :
Vous êtes issue(e) d'un parcours type Ecole d’ingénieurs/ Master / PhD en Machine Learning ou équivalent. Vous maîtrisez les principaux algorithmes de Machine Learning, connaissez l'environnement Linux, maîtrisez les langages de programmation utilisés en Data Science (Python, R, ...), les bases de données aussi bien SQL (Oracle ...) que NoSQL (Cassandra ...) les méthodes et outils d'intégration continue (GIT, Jenkins) et les outils open source autour de la Data Science et de l'écosystème HADOOP (Spark, Kafka)."
Paris 10e (75),,,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community

Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),"Temps plein, CDI",,MACHINE LEARNING ENGINEER,Linkfluence,- Paris (75),"About
Linkfluence first started as a passion project between four students with an ambitious goal: to understand and “map” the social web. With backgrounds in engineering, artificial intelligence, and sociology, these founders soon realized the potential of this idea and launched a company in 2006 to fulfill this potential.
Today, Linkfluence is a leading social media intelligence company that turns social data into valuable insights for global brands. Our hybrid combination of AI and human expertise is what sets us apart from other social listening players in the industry.
We serve over 500 clients worldwide across all industries, from global brands like LVMH, Danone, Carrefour, AirFrance, Pernod Ricard, and agencies like Publicis and Havas.
Our team is young, diverse, and ambitious, and we’re growing rapidly. We have 220 people of over 20 different nationalities spread across our offices in Paris, London, San Francisco, New York, Düsseldorf, Shanghai, and Singapore. We are a multicultural organization, and are committed to a gender-balanced workforce.
If you’re passionate about staying on top of online trends, if your ambition is to help companies serve their customers, if you’re curious about what’s happening in the world and love to listen to others, and if you’re thrilled to be a part of shaping the future of social media intelligence, then we want to hear from you!
Job description
Linkfluence is looking for a Machine Learning Engineer to join our Artificial Intelligence team and help us scale our ambitious Natural Language Processing (NLP) and Machine Learning (Vision, Speech) efforts to build the best Social Media Intelligence platform.
As a member of this team, you will use your practical knowledge and experience with NLP, machine learning, and artificial intelligence to take on meaningful technical problems. You will have the opportunity to contribute to every cool project around Linkfluence and transfer your ideas into solutions with high product impact. You will have full ownership of your projects and build end-to-end machine learning systems and modules.
What you’ll do:
Develop highly scalable models based on state-of-the-art machine learning and neural networks methodologies.
Take projects from initial data mining and research through all stages of prototyping, development and final integration into the production environment.
Collaborate with machine learning engineers, software engineers, product managers, data scientists and analysts across Linkfluence to design creative solutions to challenging problems.
Have an impact on the product and be part of the innovation process by suggesting new ideas in a strong R&D environment.
External engagement such as publishing, giving talks, contributing to the community is encouraged.
Requirements
Solid background in Computer Science (data structures, algorithms, software design) and statistics.
In-depth knowledge in NLP, deep learning and machine learning in general. Strong understanding of machine learning techniques, their performance characteristics and their computational tradeoffs.
Strong software engineering abilities in one of the following programming languages: Java, Scala, Python or C++.
Experience in working with large scale and real-world datasets. Solid hands-on skills in sourcing, cleaning, manipulating, analyzing, visualizing and modeling of real data. Practical experience using modern machine learning frameworks (Tensorflow, PyTorch) and practical experience in shipping models to production is a plus.
Practical experience with Big Data technologies such as Hadoop, Spark, Elasticsearch, HBase, Storm, Kafka, is a plus.
Creative, proactive, collaborative, and innovation focused mindset.
Excellent verbal and written communication skills and presentation skills.
Why should you join the team and take on the mission?
As a social media intelligence company, social media and technology are our future. We’re committed to innovation and work hard to stay ahead of digital and social trends.
We’re passionate about giving a voice to consumers by helping brands to understand online conversations and exchanges, and by providing the human expertise necessary to respond to these exchanges. We believe helping businesses around the world to better understand each other can only lead to good outcomes.
As a growing company, we combine a startup mindset with the resources necessary to commit to exciting new initiatives. We have a proven track record of success and funding and work with global brands with significant influence and market presence.
At Linkfluence, everyone has an opportunity to make a difference. We believe in hiring motivated individuals with passion and talent, and we listen to our employees when making company-wide decisions.
Our Paris office is situated in the heart of Paris, 9th arrondissement (South Pigalle), which means we’re well-connected with 4 different metro lines and surrounded by fantastic restaurants and bars!
If you’ve read this far, you should probably apply!
We’re already looking forward to knowing more about you!
Job Types: Full-time, Permanent
Experience:
machine learning engineer ou similaire: 1 year (Preferred)"
Paris (75),CDI,,Data Analyst - H/F,prestashop.com,- Paris (75),"En tant que Data Analyst, vous rejoindrez l’équipe Data de PrestaShop. Vous aurez pour rôle de valoriser les données collectées pour identifier les opportunités à saisir par les équipes Produit, Opérations, Marketing et Sales. Vous êtes passionné par la data et sa valorisation d’un point de vue business.
Il s’agit d’une nouvelle ligne métier chez PrestaShop, et vous aurez donc tout à construire et participerez à faire de PrestaShop une organisation data driven.
Vos missions :
Recueillir et préciser les besoins auprès des équipes
Extraire, manipuler, analyser et interpréter des ensembles de données complexes concernant l’environnement business de l’entreprise
S’assurer de la qualité des données
Analyser des processus métiers à travers de la donnée quantitative et qualitative
Participer à des projets d’amélioration, en interaction avec des fonctions métiers
Produire et suivre des indicateurs de performance clés
Réaliser des reportings et des dashboards automatisés
Réaliser des projets d’études statistiques (par exemple, segmentations et scoring)
Challenger et optimiser les process et programmes Analytics existants
Profil recherché
Tu te reconnais dans cette description ? Ton profil nous intéresse :)
Sens de la communication, sait faire parler les données, vulgariser et convaincre (dataviz, storytelling data)
Vous savez parfaitement coder en SQL et en Python. De l’expérience avec BigQuery est un plus.
Une maîtrise de Tableau, PowerBI ou Qlik est un gros plus
Maîtrise des outils commerciaux et marketing utilisés chez PS (GAnalytics, Zendesk, HubSpot, etc …)
Vous connaissez les techniques statistiques appliquées au Marketing Direct : échantillonnage, mise en place de témoins, analyse des résultats, bonne connaissance des techniques de segmentations et de scoring
La maitrise de l’anglais est indispensable
Vous êtes diplômé d’une école d’ingénieur ou d’une formation scientifique niveau BAC+5 ou plus et avez entre 2 et 3 ans d’expérience dans un poste similaire, hors stage
Déroulement des entretiens
Entretien téléphonique avec notre Talent Acquisition Specialist
Business case
Entretien avec notre Data Operations Manager
Entretien avec notre Chief Revenue Officer
Entretien RH"
Gennevilliers (92),,,Data scientist,Prisma Media SNC,- Gennevilliers (92),"1er groupe bi-média de France en audience print-digital, Prisma Media est aussi l'acteur N°1 en presse magazine et en audience vidéo. Un leadership qui assure à Prisma Media un potentiel optimal d'audience de plus de 40 millions de personnes chaque mois sur ses différents médias.
Avec un portefeuille de 25 marques incontournables, le groupe est présent sur les principaux segments grand public (féminin, cuisine, télé, people, découverte, économie…).
Porté par la mission de devancer les besoins et envies de ses lecteurs et utilisateurs sur tous les supports, Prisma Media adopte une stratégie offensive de développement et d'innovation dans les secteurs en forte croissance tels que la monétisation de la data, la vidéo et le mobile, avec une ambition d'avoir toujours UN MÉDIA D'AVANCE.
Rattaché(e) au manager du service BI / Analytics / Data science, vous intervenez en tant que Data Scientist afin de développer l’expertise data science chez Prisma Media.

Ce service a pour vocation d'optimiser l’utilisation des données client et business par les différents services de l’entreprise, pour aider à la prise de décisions, améliorer la compétitivité de l’entreprise et participer activement à la transformation digitale. Tout cela s’effectue au travers des deux leviers que sont l’activité Analytics (BI) et la Data science.

Missions :
Vous créez de la valeur autour de la data en utilisant des techniques de machine learning et de data visualization
Vous menez des projets passionnants et innovants autour de la data et de l’IA ayant un fort impact sur le business : prévision des ventes, prédiction de la valeur client, optimisation des enchères publicitaires, étude élasticité prix, …
Vous intervenez sur l’ensemble du projet : cadrage, traitement des données, modélisation et déploiement des modèles
Vous collaborez avec l’ensemble des départements (pôles marques, marketing, RH, régie publicitaire, …) en les accompagnant dans l’identification de leurs besoins et la structuration de la problématique, ainsi que dans l’appropriation des analyses et des modèles
Vous collaborez avec les équipes IT pour la mise en production des modèles
Vous apportez une aide à la décision qui s’appuie sur les enseignements tirés des analyses et vous fournissez des recommandations actionnables aux métiers
Vous intervenez notamment sur les données issues de la diffusion (des magazines), du trafic digital et de la base CRM (Users accounts qui représente environ 2 Millions d’utilisateurs actifs et 3 Millions d’utilisateurs flottants)
Vous assurez une veille technologique sur les solutions de Machine Learning et les solutions de gestion de données, les tendances et nouvelles pratiques
Vous respectez l’éthique en matière d’usage de la data.

Profil recherché :
De formation supérieure (de type BAC+5, École d’Ingénieur ou équivalent universitaire Master), vous disposez de solides connaissances techniques en matière de data et avez également une réelle aptitude à comprendre les enjeux business et plus particulièrement ceux engendrés par la data. Vous disposez d’une expertise dans le domaine de la data science et des statistiques
Vous possédez une expérience professionnelle de 3-5 ans minimum dans la conception de modélisations et d’un écosystème data au sein de systèmes complexes sur un grand volume de données et de trafic. Vous maîtrisez parfaitement les techniques de data science et de machine learning (apprentissage supervisé et non-supervisé dont gradient boosting, réseaux de neurones, clustering, réduction de dimensions, séries temporelles, statistiques avancées)
Vous êtes familier avec les méthodes agile (SCRUM / Kanban) et le cycle de vie du produit / projet.
Au-delà de vos compétences techniques, vous avez une approche business-centric.
Une connaissance des nouvelles réglementations de protection, et exploitation des données (GDPR, data cleaning, data delivery) serait un plus.
Vous êtes un bon communicant et avez la capacité de présenter des notions complexes de manière simple et claire. Vous appréciez le travail en équipe et collaborer de manière transverse.
Compétences techniques:
Python (NumPy, SciPy, Pandas, Scikit-Learn)
Compétences cloud AWS ou GCP
Git
Bases de données Oracle / SQL
NoSQL

Votre future entreprise ?
Vous vous demandez qui se cache derrière GEO, Télé Loisirs, Femme Actuelle, Capital Gala, Voici et une quinzaine d’autres titres ?
C’est Prisma Media, leader historique de la presse magazine, désormais une entreprise full media print, digital, vidéo forte de :
1,5 millions d’abonnés à nos magazines
80 millions de magazines vendu par an
Plus de 30 Millions de visiteurs uniques par mois sur nos sites Web
Son appartenance au Groupe Bertelsmann Leader mondial dans le domaine des Media (M6, RTL, BMG, Freemantle…)

Les petits plus chez nous ?
9 semaines de congés payés / RTT, 13ème mois, Participation, Télétravail possible
4 abonnements magazines print au choix dans notre catalogue ainsi que tous les magazines en digital
Des locaux attrayants : ZenZone (fauteuil massant, hamac), jardin, terrasses, Ping-pong, babyfoot, Wifi à volonté…
Une conciergerie : pressing, coiffeur, boutique…
Café et thé gratuits, cantine de qualité avec des produits de saisons cuisinés sur place
90% de nos collaborateurs sont heureux dans leur job (source : Enquête Bertelsmann 2019)
Des formations & conférences mensuelles sur des thématiques diverses : réseaux sociaux, développement personnel, intelligence artificielle…
Des events annuels : Garden party, journées Vis ma vie…

Prisma Media propose tous ses postes aux personnes en situation de handicap en privilégiant une logique de compétence et d'emploi pérenne. Le groupe est signataire de la Charte de la Diversité et partenaire de l'association Adapt.
Exercice de vos droits
Conformément à la réglementation en vigueur, vous pouvez exercer vos droits d'accès, de rectification, d'opposition, de suppression, de limitation du traitement, et à la portabilité des données à caractère personnel, en adressant votre demande au DPO du Groupe Prisma Media, soit à dpo@prismamedia.com soit par courrier à Prisma Media - DPO, 13 Rue Henri Barbusse. 92230 Gennevilliers.
Entreprise: Prisma Media SNC
Pays: France
Etat/Région: Hauts-de-Seine
Ville: GENNEVILLIERS
Code Postal: 92230
Emploi ID: 60334"
Paris (75),CDI,,DATA ENGINEER (H/F),Epsilon France,- Paris (75),"EPSILON accompagne la transformation business des entreprises grâce à la data. Nous sommes le plus grand acteur datamarketing en France, avec 750 talents Adtech et Martech qui aident les entreprises à stimuler leur croissance et améliorer leur efficacité opérationnelle grâce et autour de la data.
Dans le cadre du développement de notre pôle Conseil Data et Implémentation Analytics Platform (cadrage fonctionnel et technique, définition de use-cases, stratégie des moyens, accompagnement du changement, mise en œuvre, maintenance et commercialisation de solutions), nous recrutons un Data Engineer.
QUE FAIT UN DATA ENGINEER
Délivrer des projets Data Lake / Big Data (ingestion de sources, Pipeline de traitements de données, modélisation, tests, déploiements) dans un contexte de plus en plus DevOps,
Comprendre les besoins des équipes digitales, principalement associés aux projets Data Science et leurs technologies / outils (Jupyter, Zeppelin, R, Python, Pandas, …),
Etes capable de faire le lien avec les contraintes techniques (IT, sécurité, accès, outils) d’une DSI,
Assurer la veille technologique sur les composants d’une plateforme Datalake,
Maintenir les environnements techniques et partagez vos connaissances (capitalisation, séminaires, formations, KM en ligne),
Rédiger des documents projets (design, réalisation, déploiement, …),
Gérer l’évolution des solutions proposées, et possiblement en assurer la TMA.
VOUS MARQUEZ DES POINTS SI
Vous avez une première expérience d’un projet de type Datalake en environnement HDFS.
Vous possédez de bonnes compétences en Unix, Java, Spark ainsi que sur les problématiques d’intégration (fichiers, messages, data) avec la connaissance d’au moins une plateforme Big Data Cloudera, Hortonworks (administration, configuration, monitoring, débogage, mise en œuvre).
Vous connaissez les technologies Hadoop/HDFS, Hive, Python et le requêtage de données (Impala, Hive, ...).
Votre expérience dans le traitement de flux en streaming (KafKa) est un plus.
Votre niveau d’Anglais est opérationnel."
Paris 17e (75),CDI,,Data scientist confirmé(e) H/F,Orange,- Paris 17e (75),"Mission
Le/la data scientist incarne l'offre Digital for Business dans le domaine de la « Data ». Il/elle participe à son développement et à son évolution en relation avec les équipes marketing et opérationnelles. Il/elle promeut cette offre vers nos clients en support à nos forces commerciales.
Enjeux -objectifs
L'activité Digital for Business se développe dans le domaine de la donnée. Ce développement est porté par la mise en avant de la vision d'Orange Applications for Business concernant la Data. Cette vision est le reflet de l'expérience du groupe Orange sur le domaine et du savoir faire d'Orange Applications for Business dans la conduite d'activités dans ce domaine.
Contenu de l'activité
Avant-vente / prospection & développement à l'international
Le/la data scientist prend en charge le rendez-vous client d'expertise accompagné de l'avant-vente, pour présenter les solutions Orange Applications for Business et comprendre le besoin métier. Il/elle contribue à l'élaboration de la réponse avec l'avant-vente / chargé d'affaire
Il/elle propose de nouvelles opportunités notamment en se basant sur les projets en cours de réalisation, en proposant des lots complémentaires et en s'informant régulièrement des besoins des clients
Il/elle est mobile pour de courtes périodes à l'étranger, Il/elle contribue au développement de l'activité à l'international, en interne et en externe, Il/elle a donc un bon niveau de connaissance en anglais et un bon niveau en management transverse
Il/elle réalise des études de veille sur le marché de la prestation d'analytics, les outils, les demandes.
Prestation
Le/la data scientist confirmé(e) peut gérer un projet complexe pour un client avec les experts Orange Applications for Business sur le sujet
Il/elle sait gérer le relationnel client pour assurer le bon déroulement de la prestation, et de gérer les risques pouvant se présenter.
Il/elle assure le bon niveau de reporting vers sa hiérarchie, les équipes commerciales et avant-vente, ainsi que l'équipe d'expert dont il fait partie.
Il/elle peut réaliser des missions d'audit pour les clients, en se basant sur l'expertise des référents qu' il/elle pilote sur ce type de projets
Encadrement
Le/la data scientist confirmé(e) est leader technique sur plusieurs projets sur lesquels Il/elle intervient sur sollicitation des juniors ou du chef de projet, et s'assure régulièrement du bon déroulé
Il/elle gère les prévisions de charges des juniors qu'ils accompagnent et suit leur évolution technique.
about you
De formation Bac +5 minimum, vous avez une expérience dans des activités de développements dans le domaine de la Data et de bonne connaissance des architectures techniques big data.
Vous avez la capacité à porter un projet, à faire adhérer, à leader en transverse et à travailler à l'international. Vous savez communiquer en interne et vers les clients (orale et écrite) et travailler en transverse avec des services marketing, commerciale et des équipes d'expert.
Côté technique: Programmation big data : Python, R, SQL, Java (dont Android), C, Hadoop, Spark, Elasticsearch, Kibana
Expertise confirmée en Machine learning et deep Learning.
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Levallois-Perret (92),"Temps plein, CDI",,FULL REMOTE Senior Data Scientist H/F - CDI,Jellysmack,- Levallois-Perret (92),"Nous continuons de recruter et avons adapté notre processus de recrutement. Tous nos entretiens, ainsi que l’onboarding, se déroulent désormais en full remote.
Cette offre d'emploi est proposée en FULL REMOTE
Jellysmack est une entreprise spécialisée dans la création de contenus vidéos originaux sur les réseaux sociaux. Avec plus de 3 milliards de vues par mois, Jellysmack a connu une ascension fulgurante, ne cesse de grandir et ambitionne de devenir le leader mondial dans son domaine. La recette de ce succès repose sur la qualité de nos contenus, mais aussi sur la technologie opérant en arrière-plan. Jellysmack a développé une suite d'outils propriétaires, propulsés par l'IA, permettant à nos équipes de contenu de publier, s'inspirer, comprendre la trend, analyser les résultats, mais bien plus encore, des outils qui analysent le contenu en ligne, les réactions des gens devant ce contenu, et déterminent ce que sera la tendance demain.
Après plus de 2 ans de développement technique, Jellysmack propose une technologie unique articulée autour de 3 produits qui visent à optimiser la création et la distribution sociale de vidéos.
L'équipe Tech œuvre pour la mise en place d’outils utilisés en interne par les équipes contenu afin de déterminer les sujets qui buzzent, les aider dans la création de contenu, suivre les performances des vidéos internes etc... en injectant dans chacun de ces produits une dose conséquente d’algorithmie, de statistiques et de machine / deep learning.
En lien direct avec le Head Of Data (basé en Corse), vous serez amené à travailler sur différentes problématiques - prioritairement axées autour du NLP - et sur des projets de taille très différentes, impliquant d’importantes quantités de données (plusieurs centaines de millions de vidéos stockées en base à date avec leur métadata textuelles, plus de 21 milliards de commentaires...).
Au sein d’une équipe de sept data scientist, vous serez le référent de l’équipe sur ces sujets d’analyse et de compréhension du langage et vous aurez un rôle consultatif.
Missions principales
Passer d'une problématique métier à un algorithme de data science
Passer d'un POC à un algorithme en production
Vulgariser un algorithme à l'état de l'art et être référent de l'équipe Data Science
Etre autonome sur les outils comme Git, avoir déjà travaillé sous docker - idéalement sous AWS
Quelques exemples de sujets :
Analyse de sentiments sur les commentaires des vidéos
Extraction de topics à partir des titres, descriptions, commentaires des vidéos
Catégorisation de vidéos en thématique à partir de l’ensemble des éléments textuels dont nous disposons
Génération automatique de titre/tag de vidéos...
Création d’un algorithme d’identification des meilleurs créateurs sur une thématique donnée
Analyse de vidéos (contenu et metadata) pour mieux comprendre la rétention des utilisateurs
Optimisation de coût sur l’acquisition de fans
Génération automatique de montage de vidéos...
Profil recherché
Docteur en computer science ou diplômé d’une maîtrise en data science, vous disposez d’au moins 5 ans d’expériences,
Une autonomie sur le passage en production d’algorithmes sera indispensable,
Vous êtes pédagogue sur la transmission de votre savoir,
Vous avez un très bon niveau de SQL (MySQL et PostgreSQL).
Avantages :
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
full remote senior data scientist h/f - cdi ou similaire: 1 an (Souhaité)"
Vélizy-Villacoublay (78),,,Docteur - Machine Learning / Data Scientist pour les neurosciences H/F,Altran,- Vélizy-Villacoublay (78),"Leader mondial du conseil en innovation et ingénierie avancée, Altran propose à ses clients d’innover autrement en les aidant à développer ou en développant pour eux les produits et les services de demain.
Depuis plus de 10 ans, notre direction recherche & innovation connecte les talents d’Altran et de son écosystème pour comprendre, anticiper, imaginer et concrétiser des produits et services innovants en santé, mobilité, ingénierie, industrie, énergie, réseaux et intelligence artificielle.
Dans ce contexte, nous avons lancé un projet ambitieux autour des usages des systèmes d’interaction cerveau-machine.
Vos responsabilités
Ce projet consiste à concevoir, développer et expérimenter avec des partenaires publics et privés des solutions innovantes d’interaction homme-machine, embarquant des technologies de type interfaces cerveau-machine.
La candidat sera intégré pendant deux ans au sein d’une équipe multidisciplinaire, sous la supervision des responsables de Programmes R&I. Ses activités consisteront (notamment) à :
Réaliser des travaux de R&D en lien avec les partenaires du projet: développer des méthodes d’analyse de données neurophysiologiques en lien avec les experts en traitement du signal, et des algorithmes de classification / prédiction en fonction des usages ciblés,
Assurer une veille technique, scientifique et du marché sur son domaine d’expertise
Participer au développement de nouveaux partenariats
Capitaliser et valoriser les résultats (communications scientifiques et industrielles)
Encadrer des stagiaires
Les travaux pourront donner lieu à un (des) dépôt(s) de brevet(s) et/ou publication(s) scientifique(s).
Votre profil
Formation: Doctorat / post-doctorat en Mathématiques Appliquées et / ou Informatique et disposant de compétences fortes en Intelligence Artificielle
Une expérience en neurosciences est souhaitée
Compétences techniques :
Maîtrise des langages Python, Matlab, C/C++
Maîtrise des techniques d'analyse et de traitement de données
Bonnes connaissances théoriques Machine Learning / Deep Learning
Rigueur, curiosité scientifique, force de proposition
Bon relationnel, autonomie, ouverture d’esprit
Maîtrise du français et de l’anglais
Des connaissances en traitement du signal, extraction de caractéristiques, dispositifs médicaux et interaction Homme-Machine seraient un plus
Maitrise des outils OpenViBE, BCI2000 serait un plus
ALTRAN_MindAct_Offre_Data_Science.pdf"
Paris (75),,,Data analyst,DataDome,- Paris (75),"About Datadome :
DataDome is one of the fastest growing tech start-up in Paris. We offer a cutting edge technology, based on AI & Machine Learning, that protects in real-time eCommerce websites against advanced cyber attacks, such as credential stuffing & intensive scraping.

Today, we are proud to protect more than 10 000 domains worldwide, including TripAdvisor, The New-York Times, Carrefour, BlaBlaCar, Rakuten, Veepee, Adevinta.

Our offices in Paris & New-York gather talents coming from 10 different countries and our team is working in an highly stimulating and fascinating industry, focusing on the security and reliability of our customers sites, keeping an eye on new attacks and new technologies and making our solution as reliable, fast and scalable as possible.

Our Dashboard technical stack is mainly composed ElasticSearch for the storage, Symfony 5 & Angular 8 for our dashboards. Our infrastructure is deployed on AWS, GCP and Azure, using Docker, Ansible and Terraform, and monitored with Grafana and Prometheus.

The team:
We are looking for a Data Analyst who will be in charge of analyzing the bot traffic collected by our detection platform, creating dedicated data visualizations, helping our customers to decide how to act when they are encounter bot attacks.

You will be more specifically in charge of:
Analyzing huge web traffic data sets (across more than 100 billions documents)
Creating automates to detect outliers in our global traffic
Working in collaboration with dev teams to continuously improve their detection engine
Contributing to support Level 2 to help our customers in taking the right actions regarding their bot traffic
Determining potential issue root causes and add new alerts to our detection platform

You're the perfect candidate if you :
Have a previous experience in the Data analysis of Big Data
Are fluent in English and French
Have a real passion for data
Have expertise on Network or Web infrastructure

Bonus points

You have a previous experience or background in cybersecurity
You have already used Kibana
You have worked with systems like Apache Kafka, Apache Flink or ElasticSearch
You understand how internet works

What we offer if you join our dream team:
A stimulating working environment with passionate individuals and a first-class R&D team creating a top-quality and innovative solution, making DataDome one of the strongest performers in the bot protection industry globally.
A joyful workplace with many events throughout the year: annual offsite, summer and Christmas parties; drinks, breakfast every Friday morning...
Amazing office located Rue de Rivoli with a 360 view of the most beautiful city in the world!
A lunchr card
A health insurance plan with excellent cover"
Poissy (78),,,S&OP Data SCIENTIST H/F,PSAPeugeotCitroen,- Poissy (78),"PSA is currently implementing the « Sales & Operation Planning (S&OP) » which is a decision process at Executive Committee level, intended to optimize total value for the Company through planning. In S&OP process, important amount of data are collected and need to be analysed in order to present to ExCom the right scenario decisions on the tactical horizon.

The S&OP data scientist shall understand and manipulate important volume of data used in S&OP process on worldwide perimeter for PSA Groupe (volumes per month, per country, per carline, per powertrain, per trim in demand and supply with alternative scenarios and CO2 impacts) in order to :
o Structure the data for easy usage by the stakeholders (synthesis and deep dive)
o Propose statistical models and algorithms to improve the S&OP forecasts, alternative scenarios and reconciliation between demand and supply
o Perform the relevant analyses on the data
o Provide business recommendations to help decision making based on the data analysis
o Drive supply chain business improvement on sales forecast through big data analysis
Profil
Skills
o Mathematics and statistics
Statistiscal predicitive analysis
Scoring algorithm
o IT
Understand programmation languages (Python, R,…)
Datavisualisation tools (Power BI,…)
Databases management
o Behaviour
Good communication
Adaptability
Capacity for synthesis
Business mindset
Innovation / Curiosity
Rigor / capacity for analysis
English spoken

Education
o BAC+5 in Science (Engineering School, Master Degree,…)

Working Experience
o At least 5 years working in analysing and manipulating databases
o Sales Forecast
o Experience in FMCG (Fast Moving Consumer Good) would be appreciated
Localisation du poste
Pays
Europe, France, Ile-de-France, Yvelines (78)
Ville
poissy
Critères candidat
Niveau d'expérience min. requis
5 à 10 ans
Langues
Anglais (C1 - Courant (3,5 - 4,4 Bright))"
Paris (75),CDI,,Data Scientist (H/F),Quantic Dream,- Paris (75),"Position Duties
Dans le cadre de son développement, Quantic Dream recherche des collaborateurs talentueux pour rejoindre ses équipes sur ses prochaines ambitieuses productions.

Au sein de l'équipe R&D Maya, vous apporterez vos connaissances notamment en Machine Learning et Deep Learning afin de permettre le développement de notre nouvel outils interne propriétaire de reconnaissance faciale à partir d'une vidéo (tracking vidéo).

En étroite collaboration avec le Lead et un développeur Recherche & Développement outils 3d de l'équipe, vos missions seront les suivantes :
Analyser et effectuer des recherches en développement dans le cadre du développement d'un nouveau solver facial in-house à base de tracking vidéo ;
Effectuer des recherches/veille technologique afin de prototyper et d'adapter notre stratégie en conséquence dans la perspective d'implémenter ce nouvel outils dédié à tous nos tournages internes d'animation faciale sur notre plateau de motion capture et permettant le traitement ultérieur par nos animateurs 3d ;
Communiquer sur les résultats des analyses et transmettre ces informations de façon pédagogique pour un public varié ;
Développer les algorithmes dédiés.

Nous vous offrons la possibilité de rejoindre des équipes de passionnés et de travailler dans un environnement créatif et innovant.
Candidate Profile
Diplômé(e) d'école d'ingénieur ou équivalent Bac+4/5, vous avez une première expérience réussie à un poste similaire
Expérience en Deep Learning (et de ses modèles de type Réseau neuronal convolutif (CNN)) et des outils de développement associés (Tensorflow, Torch)
Expertise en développement Computer Vision et dans le développement de fonctionnalités de Machine Learning en langage Python
Vous avez un intérêt marqué pour l'analyse de données orientée Computer Vision
Vous avez une bonne maitrise du langage Python ainsi que des connaissances solides en statistiques
Vous êtes doté(e) d'une bonne capacité d'écoute, de compréhension, et vous savez traduire les besoins en spécifications
Vous faites preuve d'autonomie et de curiosité
Compétences de gestion du temps et des processus de développement, et capacité à appliquer efficacement ces principes à travers des plannings et des deadlines.
Attitude proactive cherchant à améliorer ses compétences et son savoir et à partager cela avec les autres membres de l'équipe.
Anglais.
Additional Information
Poste à pourvoir en CDI au sein d'une R&D talentueuse et passionnée."
,,,Data Scientist Analyst M/F,Danone,- Paris (75),"Danone Research is looking for a Data Scientist Analyst M/F in Paris.

Each time we eat and drink, we vote for the world we want to live in.

Danone’s mission is Bringing health through food to as many people as possible and we want to invite people to join the movement for a healthier world. We recognize the power people have to impact the world through their daily choices. Healthy food needs a healthy planet, and this is what our new signature One Planet One Health embodies.

THE CONTEXT

To support Danone’s top-level ambition to adopt a data-enabled organization, we are building a team in Paris to be the “Data analytics and AI center of Excellence”. Our ambition is to become the data science talent hub for all Danone in Europe. This team will be part of the new Chief Data Office at Danone promoting data as an asset and covering fields such as data science, data governance, data transformation and master Data Management.

Our target team is a picture of diversity and inclusiveness. In Data analytics and AI team, we are starting today with a team of 6 people coming from various backgrounds with 47 cumulated years of passion for data and we want to build an enthusiastic, highly-skilled and delivery-oriented team from a mix of junior, senior, team leader & expert profiles.

Your mission, as a Senior data scientist, will be to promote a new data mindset by delivering state of the art, pragmatic, and creative data science solutions to answer complex business problems. Our target is to work for all of Danone’s businesses and address topics such as demand/supply forecasting, commodity pricing, milk collection optimization, marketing optimization and environmental impact reduction.

Joining us will be an exciting adventure as we are starting today with a team of 6 people coming from pharma, FMCG, banking, consulting, airlines, automotive industry background with accumulated 47 years of data passion.

Finally, as the data office team is international, you will have the chance to be part of an international fellowship of data scientists.

ABOUT THE JOB

Collaborate with business partners & data project leaders to identify business needs and translate them into actionable measures.
Support the implementation of these solutions.
Implement ETL workflows, Data Mining/Wrangling to make data useable and understandable for other Data Scientists or business teams.
Apply state-of-the-art algorithms and predictive models (Machine Learning/Deep Learning) to answer business problems.
Share results with technical and business teams (Data Visualization).
Build & improve team’s knowledge, processes and best practices.

ABOUT THE CAREER PATHS

Trainings and certifications possibilities will be given as part of the onboarding and continuous development process. Career opportunities will be built internationally and accross Worldwide Business Units (WBUs) and across fields.

ABOUT YOU

We are looking for people having :

2 to 6 years of experience in Data Science with :
Experience in developing machine learning models in Python or R
Experience in programming (e.g, Python, R)
A MSc, PhD or other Advanced Degree in a field linked to computer science, applied mathematics, statistics, machine learning, or closely related fields
Experience in Fast-Moving Consumer Goods (FMCG) industry is a plus
English is a must

ABOUT YOUR SKILLS

We are looking for people having several skills among the following :

We are looking for people having several technical skills among the followings:

Programming: Python, R, SQL, Git
Databases: Relational/Non-relational databases
Modeling : Advanced Statistical Analysis, regressions, Gradient Boosting, Random Forest, Neural Netwok
Viz’: Power BI and MicroStrategy
Infrastructure: Cloudera HDFS, AWS, Docker, CI/CD
Data Science tools/modules : Jupyter Notebook, Databrick, ML Flow

Experience in all or several parts of Advanced Analytics process will be challenged:
Explore the potential of a raw data set
Build relevant and performant models and analyses
Automate workflows
Scale, deploy and monitor industrialized projects

Mandatory skills:
Ability to understand business needs
Knowledge of agile development methodologies and tools:
SCRUM methodology
Flexibility and iterative way of working
Experience with Jira/Trello/ Asana solutions
Ability to meet tight deadlines and work in an environment with multiple priorities.
Ability to work independently and in a structured way
Excellent written and verbal communications skill. In particular, a strong proven ability to communicate statistical and modeling results in a clear manner.
Ability to perform detailed analyses

If we just described your profile, please click the “apply now” button and upload your CV!

DANONE AND ITS BRANDS

Mix 75g of Activia, 130g of a small Blédina pot, 50cl of an Evian bottle and add a drop of Fortimel ... you get 4 brands representing the 4 divisions of the Danone group: Fresh Dairy Products and Vegetables (Activia, Danette, Actimel, Alpro, etc.), Waters (Evian, Badoit, Volvic, Salvetat), Medical Nutrition (Fortimel, etc.), and Infant Nutrition (Blédina, Gallia).
All these brands are worn by 100,000 Danoners in the World. Don’t wait, vote for the world you want to live in and join the movement!

A LITTLE TASTE?

Need advice on applying?
Follow our Danoners and our brands on Instagram, Facebook, Linkedin, Twitter
An overview of the premises: our head office in Paris and the new headquarters of Blédina in Limonest
What our trainees / alternates think about us: Happy Trainees # 4
Learn more about our jobs on Jobteaser.

140678
#LI-FR"
Paris (75),"Temps plein, CDI",,Machine Learning Engineer – Audio / Imaging / Deep Learning / Algorit,USA Recruitment,- Paris (75),"Machine Learning Engineer – Audio / Imaging / Deep Learning / Algorithms

Are you looking for an exciting new role in the field of Machine Learning? I am currently hiring for a client in Paris, who is looking for talented engineers to work on a variety of projects in Machine learning, Deep Learning, Image sensors and Audio domains.

Requirements
MSc in Computer Science + 4 years’ industry experience with Machine Learning systems
Software development experience in C, C++, Java, Python
Knowledge in Real-time processing of image sensor data
Practical experience in Micro-service architectures and Machine Learning libraries.
Bonus: expertise in Cloud infrastructures – AWS/Azure
Must be eligible to work in the EU

Key words: #MachineLearning / #DeepLearning / Algorithms / Audio / Image sensors / Imaging / C++ / Java / Python / Docker / Kubernetes / Scikit-Learn / TensorFlow / Keras / Computer Science


By applying to this role, you understand that we may collect your personal data and store and process it on our systems. For more information please see our Privacy Notice https://eu-recruit.com/about-us/privacy-notice/"
Paris (75),"Temps plein, Freelance / Indépendant",,DATA ANALYST KYC / Freelance,PARTECK INGENIERIE,- Paris (75),"Le client recherche un profil de type Data Analyst pour la réalisation d’une mission stratégique de rationalisation du référentiel des données de contreparties avec pour objectif la refonte de la base de données des contreparties internes et externes de la banque.

Les contributions principales attendues sur la mission sont les suivantes :

Enrichissement des dictionnaires de données
Support à la migration des données du système existant vers les systèmes cibles
Spécifications et support aux différentes équipes IT (Architecture, Applications) pour toute question concernant les données / nomenclatures à intégrer dans leurs applications cibles et lors de la mise en place de nouveaux flux
Définition de nouvelles règles de synchronisation des données Tiers entre différentes entités et le Groupe
Définition de la stratégie cible de contrôle et de suivi de la qualité des données. Spécification de ces contrôles
Analyse des demandes de création de nouvelles données locales (définition des solutions court, moyen et long terme)

Environnement francophone et anglophone
Expertise d’Excel ++ pour data crunching,
outils d’exploration data science serait un plus

Expertise des problématiques d’architecture et modèles de données
Avoir participé à des projets de rationalisation de référentiels tiers, de données KYC, Tax, FATCA, risk, CRM"
Paris 1er (75),CDI,,Data Scientist -Big Data F/H,AINABL TECHNOLOGIES FRANCE,- Paris 1er (75),"Analyse des besoins et des problématiques des directions métiers

Récupération, étude et analyse des données des projets Data Science, par des approches big data et/ou data mining

La modélisation des résultats d’analyse des données structurées et non-structurées, l’exploitation et les recommandations business pour des décisions stratégiques, tactiques et opérationnelles

Capitalisation des solutions data science mise en œuvre

Veille des méthodes et des technologies de de big data et/ou data mining

Relation fiable et de qualité avec les fournisseurs (éditeurs et société de conseil)
Profil recherché Formation BAC+4/Bac+5

Expérience de 2 ans mini. Appétence particulière pour data intégration, data modeling, data visualisation (Spark, Python)
Anglais courant
Sens de l’organisation et rigueur
Ouverture d’esprit et innovation
Entreprise Ainabl Technologies France, Sas, société deeptech est spécialisée dans la recherche intelligente et la connexion sémantique des données en temps réel – basée sur les technologies d'apprentissage automatique/profond et le graphe de connaissances. Créée en France en 2019, Ainabl apporte une cohérence globale et la clarté dans des situations les plus complexes au service des analystes, stratèges, professionnels de l'investissement, institutionnels et grands groupes mondiaux."
Suresnes (92),"Temps plein, CDI",40 000 € - 60 000 € par an,Data Engineer,Kertios,- Suresnes (92),"KERTIOS est une société de conseil en management et en informatique, spécialisée dans la gestion du capital humain et la mise en œuvre d'applications packagées. Nos clients sont des entreprises internationales prêtes à transformer leurs processus pour atteindre les meilleures pratiques dans leur domaine. Notre accompagnement se fait dans toutes les phases de leur transformation, de la stratégie à la mise en œuvre.
Les ""Plus"" KERTIOS Consulting :
Développer une triple compétence : métier, projet et système d’information en évoluant au cœur de projets complexes et ambitieux, accompagné par nos consultants seniors experts
Evoluer au sein d’une société qui exige le meilleur de ses collaborateurs tout en cultivant la cohésion et l’esprit d’équipe
Le Data Engineer participe à l’évolution et l’optimisation du système d’information décisionnel existant. Il conçoit et met en œuvre des plateformes basées sur des technologies Big Data.
Si vous souhaitez…
Travailler directement auprès des Directions Métiers (Commerciale, Marketing, Ressources Humaines, Finance, Risque, Informatique)
Accompagner ces directions dans la définition de leur stratégie d’exploitation des Big Data ainsi que dans sa déclinaison opérationnelle
Participer à des projets de transformation d’envergure à forte valeur ajoutée.
Alors pourquoi pas vous ?
Vous êtes motivé et dynamique ? Vous possédez d’excellentes capacités de communication ainsi qu’un sens développé du service ?
De formation Bac+5, vous disposez d’un profil ingénieur informatique et avez déjà réalisé des projets ou missions « Big Data » participant à ce grand virage dans le monde du décisionnel.
A l’aise dans l’utilisation des nouvelles technologies (écosystème Hadoop, Scala, Python, Shell, Linux, Unix) et ayant acquis de très bonnes connaissances des bases de données (SGBD comme Oracle, PostGre, MySQL,… ou NoSQL comme Hive, Hbase, Impala, Cassandra, …), vous bouillonnez d’idées et aimez les mettre en application.
Hadoop : ⭐⭐⭐
Base de données : ⭐⭐⭐⭐
Data prep : ⭐⭐⭐⭐
N’hésitez plus, rejoignez-nous !
Type d'emploi : Temps plein, CDI
Salaire : 40 000,00€ à 60 000,00€ /an
Expérience:
data engineer ou similaire: 2 ans (Requis)"
Paris (75),,,Data Consultant,WENEXT,- Paris (75),"Salary p.a.

Job Description
The job involves understanding the information hidden in vast amounts of data and help us make smarter decisions to deliver even better products. Your primary focus will be in applying data mining techniques, doing statistical analysis, and building high quality prediction systems integrated with our product. They work with development teams or managers for keeping the applications up-to-date and prioritizing needs, among other tasks.

The Data Consultant serves as a lead technical resource on the Data Analytics Development team and participates in all phases of the development life cycle. The Data Scientist analyzes complex business and technical problems and shapes and delivers the new digital platform and services. The Digital Data Consultant analyzes, configures and tunes Data Analytics applications. The digital Data Consultant also enforces software development standards.

Responsabilities:
Collaborates with cross-functional teams to define, design, implement, test, and deploy new Data Analytics features in a fast paced environment.
Selecting features, building and optimizing classifiers using machine learning techniques
Data mining using state-of-the-art methods
Extending company’s data with third party sources of information when needed
Enhancing data collection procedures to include information that is relevant for building analytic systems
Processing, cleansing, and verifying the integrity of data used for analysis
Doing ad-hoc analysis and presenting results in a clear manner
Creating automated anomaly detection systems and constant tracking of its performance
Writes unit tests in order to increase reliability and quality of applications.
Addresses system defects and implements enhancements to existing functionality.
Troubleshoots issues with minimal guidance, identifies bottlenecks in existing workflows and provides solutions for a scalable, defect-free application.
Complies with Company policy and practices relating to the System Data Development Life Cycle.
Maintains productive working relationships with project sponsors and key systems users.
Keeps up on industry trends and current technological standards, languages, coding techniques, utilities and operational considerations.
Makes suggestions for process, coding, implementation, and performance improvements.
Provides mentoring, training and technical guidance to junior developers and assists in training other programming or support team members in a cooperative and effective manner.
Performs other job-related duties as assigned or apparent.
Analysis and drafting of technical specifications
Development of new applications
Tests, acceptance, integration and production start-up
Evolutive and corrective maintenance of existing applications
Support and assistance to users

Interfaces:
Project Manager usually sits within the Solution team, led by a Solution Manager and must be aligned with:
Solution Manager
Commercial/Financial Lead
Technical Delivery Architect
Practice Project Manager/program Manager
Bid Management Team

Communication skills:
French fluent
English business fluent
Technical skills:
The Data Consultant is specialized Data solutions
Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.
Experience with common data science toolkits, such as R, Weka, NumPy, MatLab, etc. Excellence in at least one of these is highly desirable
Experience with data visualisation tools, such as D3.js, GGplot, etc.
Proficiency in using query languages such as SQL, Hive, Pig
Experience with NoSQL databases, such as MongoDB, Cassandra, HBase, Elastit, Elasticsearch
Good applied statistics skills, such as distributions, statistical testing, regression, etc.
Good scripting and programming skills
Data-oriented personality
Education & Working Experience:
Bachelor's degree in Business, Information Systems, Computer Science or equivalent.
5-10 years.
Soft skills:
Excellent communication skills with ability to explain technical concepts to lay audiences.
Results oriented with ability to deliver on-time and in-line with organizational/business benefit.
Strong critical thinker with problem solving aptitude.
Team player with experience leading and collaborating cross-teams.
Strong conceptual and analytical skills - demonstrating outside-the-box problem solving skills.
Exceptional analytical skills.
Exceptional verbal, written and listening skills.
Must have excellent interpersonal and communication skills.
Ability to work effectively in a team-oriented environment, both independently and collaboratively."
La Défense (92),,,Data Engineer,Dalkia,- La Défense (92),"Dalkia, filiale du Groupe EDF, est le leader des services énergétiques en France. Proposer des solutions sur-mesure à l'échelle de chaque bâtiment, chaque ville, chaque collectivité, chaque territoire et de chaque site industriel, telle est notre vocation.

Vous voulez rejoindre un acteur majeur de la transition énergétique ?
Vous avez de la passion pour les technologies du Big Data ?
Le Data Lake évoque pour vous un monde d’aventures à explorer ?
Rejoignez Dalkia, filiale des services énergétiques du groupe EDF,
Votre mission
Dalkia, met son expertise au service de ses clients pour développer, réaliser et gérer des solutions énergétiques plus écologiques et plus économiques.
Au sein de la Direction des Systèmes d’Informations et du Numérique du Groupe Dalkia, vous rejoignez en tant que Data Engineer l’équipe de valorisation de la donnée pour accompagner le déploiement du Data Lake d’entreprise pour dalkia.
Dans cette démarche centrée sur la donnée, vous contribuez aux objectifs de mise en œuvre étendue de nos capacités de reporting et de développement d’un service d’analyse des données pour les métiers.
Le périmètre est transverse et sert l’entreprise dans son intégralité.
Dans ce cadre, et plus spécifiquement, vous assurez les activités suivantes :
Mettre en place des projets Data Lake (ingestion de sources, pipeline de traitements de données, modélisation, tests, déploiements),
Structurer les données au sein du Data Lake (environnement AWS)
Garantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats
Participer à la gouvernance de la donnée et assurer la tenue du dictionnaire de données
Garantir l’architecture globale du stockage, des flux de données et des process
Gérer les incidents et s’assurer de leur résolution
Assurer la supervision des traitements
Mettre à disposition les données pour les data analysts et les data scientists
Industrialiser les analyses de données validées
Comprendre les outils utilisés par les analystes et les data scientists (Tableau, Python, Jupyter...)
Assurer la veille technologique sur les composants d’une plateforme Data Lake
Proposer des scénarii, des frameworks et des choix d’outils,
Participer aux décisions stratégiques concernant le choix des technologies utilisées
Votre futur environnement, au cœur de la Défense
Vous intégrez nos équipes, dynamiques et bienveillantes, dans l’environnement rénové de la Tour Europe où les espaces sont dessinés pour combiner la collaboration et le bien-être au travail.
Comme nos collaborateurs, vous apprécierez l’ambiance positive régnant dans nos équipes.
Vous intervenez dans un contexte de transformation numérique et d’une dynamique “go to cloud”
Vous pourrez profiter de nouveaux services, par exemple d’une grande salle de fitness juste sous notre tour !
Au coeur de la Défense, les commerces et les transports sont à 2 pas !
Bonus, intéressement et participation feront partie de votre package

Choisirez vous cette mission ?
Diplômé-e d’un Bac +5 en École d’ingénieur vous avez impérativement une expérience des solutions Big Data sur des projets en production.
Vous maitrisez le technologiques AWS (S3, Athena, Redshift, Snowflake…)
Vous avez croisé des outils de visualisation de données (Tableau, Qlik…, kibana)
Enfin Agile et DEVOPS, sont pour vous autre chose que des Buzzwords.
Vous aimez travailler en équipe, vous êtes créatif mais votre passion pour les données vous emmène à être également rigoureux !"
Paris (75),Intérim,1 500 € - 1 700 € par mois,DATA SCIENTIST INTERN,Justice.cool,- Paris (75),"DESCRIPTIF DU POSTE
Intégré(e) au sein d'une équipe R&D de très haut niveau (Centrale Paris, Telecom Paris, Imperial College) tu seras supervisé(e) par notre CTO.
Tes objectifs :
Mettre en place des méthodes utilisant le Machine Learning et plus particulièrement le NLP appliqué à des décisions de justice :
Collaborer avec l'équipe production pour intégrer les méthodes Machine Learning sur notre plateforme.
Concevoir et intégrer des solutions IA scalables et data-driven pour automatiser nos workflows.
Développer des pipelines de traitement de données de haute-performance.
Prétraiter des GB de données textuelles du langage juridique.
Implementer des modèles ML sur un dataset de 1,5M décisions de justice ️
Justice.cool t'offre une ambiance de travail conviviale, au coeur de l'univers des Start-Up fançaises à
Station F
, au sein de l'incubateur HEC. Tu auras probablement l'occasion de voyager pour participer à des évènements et intervenir dans le cadre de nos collaborations avec des laboratoires de recherche et des cursus étudiants.
PROFIL RECHERCHÉ
Formation :
Diplômé(e) d’une Grande École d’Ingénieur (X, Mines, Centrale, Telecom...)
Tu as déjà réalisé un stage, de préférence en tant que data scientist/engineer/analyst
Tes compétences techniques :
Languages : Python (requis), et au moins un autre language (JavaScript, Angular/React, Java, SQL)
Packages : Pandas, Scikit Learn, Numpy...
Connaissances algorithmiques en data science (régression linéaire, random forest, boosting, back-propagation...)
Ce serait un plus si tu justifies de :
Connaissances en NLP (Information extraction/retrieval, Text mining, Text classification…)
Maîtrise d’une librairie de deep learning (PyTorch, Keras...)
Expériences en web scraping, data cleaning, data preprocessing
Connaissances en technologies Cloud (AWS, GCP, Git...)
PROCESS DE RECRUTEMENT
1- Entretien de présentation
2- Entretien technique
3- Entretien de motivation
INFORMATIONS COMPLÉMENTAIRES
Type de contrat : CDD / Temporaire (5 mois)
Date de début : 01 juillet 2020
Lieu : Paris, France (75013)
Niveau d'études : Bac +5 / Master
Salaire : entre 1500€ et 1700€ / mois"
Orsay (91),,,Data Scientist,PARIS-SACLAY CENTER FOR DATA SCIENCE,- Orsay (91),"The Paris-Saclay CDS for has opened data science positions to reinforce the data science ecosystem and to build and support a data science platform. The data scientist will work on (in order of priority):
Data-science support: The CDS has many collaborations between scientists and engineers across scientific disciplines. The candidate will work on a small number of data-science projects with different scientific partners. The candidate should be interested in a variety of scientific applications of data processing and able to understand an application, to communicate with scientists of a different culture, and to deploy data-processing solutions for their needs. Current projects include:
Galaxy/star classification for preparing the LSST data processing pipeline.
Particle tracking for the ATLAS/LHC upgrade.
Segmenting and classifying Solar wind time series data.
Classifying hospital stays (PMSI coding) with APHP.
Laser spectrometry to improve the safety of intravenous drug administration.
Improving search in large biological and biomedical data sets.
Analyzing sensor data for tracking pollution and its health effects (Polluscope).
Classifying crowdsourced ecology data (Spipoll).
Software engineering: The objective to enable researchers to do better science thanks to better software tools. It means bringing state of the art data science research software into high quality toolboxes (as scikit-learn). Getting involved with open source development. Assisting data scientists (students, postdoctoral fellows, permanent researchers) to develop their software engineering skills and to get them involved with open source development.
Training: Accompany domain scientists in their data analysis efforts. Accompany data scientists in their methodological research. Designing training sprints and practical material for the courses (cf. based on software carpentry)
Team
The data scientist will work with scikit-learn core developers such as Gaël Varoquaux, Olivier Grisel, Loic Estève, Alexandre Gramfort and others. Possible collaboration with data and domain science researchers such as Balazs Kegl, Isabelle Guyon, Sarah Cohen-Boulakia, Karine Zeitouni, David Rousseau, and others.
Qualifications
M.S. / Ph.D. in Computer Science, Statistical Machine Learning
Good understanding of the data science workflow. Experience with data challenges is a plus.
Strong programming experience with one or more data science languages (Python, R, Matlab)
Experience with open source development (desired but not required).

The applicant should send a CV, a statement of purpose, and up to three letters of recommendations to cdsupsay@gmail.com.

Position is open now and will be open until it is filled.

Description:
Duration: 18 months
Gross salary per month in €: 2500-2817"
Paris (75),"Temps plein, CDI",,Machine Learning Engineer – Audio / Imaging / Algorithmns / Deep Learning,USA Recruitment,- Paris (75),"Looking for a challenging new position in the area of Machine Learning? Want to work in a position that combines more than one of your interests?

Currently hiring for a client in Paris, who is looking for talented engineers to work on a variety of projects in Machine learning, Deep Learning, Image sensors and Audio domains.

Required Skills;
Masters degree in Computer Science (or similar)
4 years industry experience using Machine Learning
Software development background in C, C++, Java, Python
Expertise in Real-time processing of image sensor data Practical experience in Micro-service architectures and Machine Learning libraries.
Must be eligible to work in the EU

Desired Skills;
Expereince in Cloud infrastructures – AWS/Azure

Machine Learning Engineer – Audio / Imaging / Algorithmns / Deep Learning

Key Words: Machine Learning Engineer / Audio / Imaging / Algorithmns / Deep Learning / C++ / Java / Computer Science / Docker / Tensorflow / Sensors / Python

Machine Learning Engineer – Audio / Imaging / Algorithmns / Deep Learning Job

By applying to this role, you understand that we may collect your personal data, store and process it on our systems. For more information please see our Privacy Notice (https://eu-recruit.com/about-us/privacy-notice/)

Machine Learning Engineer – Audio / Imaging / Algorithmns / Deep Learning"
,,,,,,
,,,,,,
Paris (75),"Temps plein, Freelance / Indépendant",,DataMiner/Data Analyst / Freelance,Eurostaff group SAS,- Paris (75),"Diplômé en statistiques et probabilités
Analyser les données et analyser les informations chiffrées générées par l’activité
Expertise des techniques d’analyses des données, des méthodologies statistiques
Accompagner les équipes internes sur l’interprétation des reportings
Contrôler la qualité́ et la cohérence des données
Faciliter les prises de décision en assurant un rôle de consultant, par exemple en proposant des pistes d’améliorations des organisations
Maîtriser les outils statistiques et les informations nécessaires à la mise en place des livrables
Traduire des données brutes en données statistiques
Modéliser et assurer les mises à jour régulières des livrables
Participer à l’analyse et à l’exploitation des données enregistrées
Participer aux reportings et proposer des solutions de visualisation et d’automatisation
Esprit d’analyse et de synthèse, créativité́, esprit critique et qualités relationnelles
Bon niveau d’anglais (réunion avec les US)"
,,,,,,
,,,,,,
,,,Intern - Data Engineer,Enexflow,- Paris (75),"Location: Paris (Subway station: Saint-Paul)
Start date: June 2020
Contract: Internship
About us
Founded in 2018, Enexflow is positioned at the crossroads of technology, economics and power market operations. With a unique skill set, Enexflow brings cross-functional expertise that is needed when it comes to tackling the complex challenges of the future of power markets. In the context of an ever evolving regulation driven by the penetration of new assets (renewable, storage, demand response, electric vehicles), it becomes critical for energy players to seize the digitalization opportunity to run their operations more efficiently.

At Enexflow, we provide a unique approach combining subject matter expertise on power industry value chain, market processes and data engineering. We help key energy stakeholders to define, develop, deploy, and maintain relevant data flows for their operations.
Responsibilities
Being part of a small development team starting an ambitious product, you will be working closely with our Tech Lead in order with the following key responsibilities:
Architecturing new features
Develop reliable and performant python software
Process large quantities of real-time structured data

We are looking for highly motivated talents willing to accelerate the energy transition and eager to get involved in all aspects of a growing business.
Skills
We’re looking for someone who has:
Background: Software Engineering (engineering school, certification, self taught)
Experience: Junior
Language: Proficiency in English
Technologies: python, flask, kubernetes
Software development lifecycle: best practices in software testing, git, CI, automated deployment
Soft skills: proactive, communicative, eager to learn
Nice to have:
Knowledge of functional programming and at least one functional programming language
Willing to work on the energy transition
Top reasons to join the team
We have an international exposure with clients across the globe (USA, Europe, Asia)
We are a passionate team with complementary skills in energy and tech
We ambition to grow and want you to be part of it, and accelerate it!
Interested? Apply at jobs@enexflow.com"
Paris (75),,,Data Analyst (H/F),MFG Labs,- Paris (75),"Ce que l’on vous propose
Dans un contexte de partage, de challenge continu et de veille où vous pourrez monter en compétences et vous épanouir vous :
Échangerez avec le client pour comprendre ses objectifs business
En collaboration avec le chef de projet et les data scientists, définirez les besoins en données et en assurerez la collecte
Évaluerez la qualité des datasets et ferez des analyses exploratoires de ces datasets
Analyserez et challengerez les résultats de modèles
Travaillerez main dans la main avec des data scientists et des développeurs pour passer d’une modélisation ad hoc à la mise en production d’un système programmable
Créerez des rapports et définirez des métriques pour aider à la prise de décision
Aiderez à communiquer des chiffres ou les résultats d’une analyse par des visualisations ou du storytelling
Pour vous épanouir sur ce nouveau poste nous vous accompagnerons dans votre parcours d’intégration, de formation et dans le suivi de votre carrière.
Votre profil
Vous vous épanouissez en faisant aussi progresser les autres. Vous avez le goût pour le travail bien fait et vous souhaitez vous investir dans des projets dont vous serez fier(e). Vous possédez :
Une formation en Informatique, Mathématiques Appliquées ou Statistiques.
Un esprit curieux, passionné, avec une forte envie d’apprendre.
Une compétence analytique (statistiques ou programmation).
Une capacité à communiquer de manière claire et efficace.
Une capacité à comprendre les problèmes et y proposer des solutions.
De la rigueur, de la méthodologie et de l’organisation.
Une volonté d’appliquer ces compétences dans un contexte business.
Un niveau de français courant et un bon niveau d’anglais.
Vous possédez également les compétences techniques suivantes :
Maîtrise d’au moins un langage de programmation axé Data Science (Python/R)
Maîtrise du SQL (requête et intégration de données)
Expérience avec des outils de visualisation (de préférence Tableau)
Modélisation des données (SQL et autres paradigmes)
Compréhension des algorithmes de Machine Learning classiques
Détails de l’offre
Poste à pourvoir dès que possible
Temps plein
Lieu de travail : Paris
Vous vous reconnaissez dans cette annonce ? N’hésitez pas à nous contacter et partager votre profil, nous serons ravis d’échanger avec vous."
Aubervilliers (93),"Temps plein, CDI",,Data Scientist H/F,Veolia,- Aubervilliers (93),"Job Purpose
Mettre en oeuvre le design et élaborer des solutions data science, depuis le recueil des besoins jusqu'à la mise en production.
Une participation à des activités d’animation de la communauté data science sera également envisageable.

Activités
- Collecter, étudier, comprendre et sélectionner les données pertinentes pour les différents projets en fonction des besoins
- Appliquer les techniques (statistiques, text mining, comportementale, géolocalisation, …) d’extraction et d’analyse d’informations, obtenues à partir de gisements de données (Big Data)
-Obtenir des données adéquates, trouver les sources de données pertinentes, faire des recommandations sur les bases de données à consolider, modifier, rapatrier, externaliser, internaliser, conçoit des datamarts, voire des entrepôts de données
-
Traduire les problématiques métiers et opérationnelles dans des dimensions statistiques et algorithmiques
- Proposer les modèles prédictifs en fonction des besoins
- Analyser la performance et robustesse des modèles pour optimisation continue
- Modéliser les résultats afin de fournir des visualisations pertinentes

Profil recherché - Compétences requises
Diplômé(e) d’un Bac+5 en école d’ingénieur ou équivalent universitaire avec une spécialisation en mathématiques appliquées, data science ou intelligence artificielle. 5 à 7 ans d’expérience dans des environnements de traitement et d’analyse de la données.

Competence
-Big Data: Maîtrise de l'exploitation et de l'analyse de «données massives» orientés digitales
-Machine Learning: Connaissance des algorithmes de machine learning et de deep learning de type Decision Tree, Random Forest, Boosting, Neural Network…
-Statistiques: Maîtrise des techniques du data mining, des statistiques descriptives, des statistiques inférentielles, du text mining...
-Digital: Connaître l'environnement des technologies digitales utilisées par Veolia: Cloud, GCP, AWS, Solutions SAAS, IOT ….
-API: Connaissance d'APIs externes

Compétences comportementales
- Aptitude à collaborer de manière constructive
- Capacité à proposer des solutions, à entreprendre et à faire avancer les dossiers
- Capacité à argumenter, comprendre et écouter auprès d'interlocuteurs tant IT que business
- Faculté à proposer des solutions innovante pour répondre à un besoin
Emploi
Informatique / Systèmes d'Information
Localisation
France-Seine-Saint-Denis-AUBERVILLIERS
Poste publié depuis le
21 févr. 2020, 13:45:10
Type de contrat
CDI -
Temps de travail
Temps plein
Statut
Cadre"
Paris (75),CDI,,Data Scientist Senior H/F,BPCE SA,- Paris (75),"Présentation de l'entreprise
Le Groupe BPCE, issu du rapprochement des Banques Populaires et des Caisses d’Epargne et 2ème groupe bancaire français, se positionne comme un partenaire financier majeur pour les particuliers, les entreprises et l’ensemble de l’économie. Il ambitionne d’être la première banque du quotidien des Français, de leurs entreprises et de leurs institutions.
Avec 8 200 agences sur le territoire français, les deux grands réseaux Banque Populaire et Caisse d'Epargne, qui conservent leur marque respective et leur autonomie, exercent avec succès les trois métiers du Groupe BPCE : la banque de proximité, la banque de financement et les services financiers.
BPCE, l'organe central commun aux Caisses d'Epargne et aux Banques Populaires, est notamment chargé de :
Définir la politique et les orientations stratégiques du Groupe et de ses réseaux et d'assurer la coordination des politiques commerciales ;
Représenter le Groupe et ses réseaux dans les instances réglementaires ;
Mettre en œuvre tous les moyens permettant de piloter le Groupe en matière de liquidité, de solvabilité, de maîtrise des risques et de contrôle interne.
Au sein de BPCE, la direction de l’Inspection générale groupe assure le contrôle périodique de l’organisation, notamment du dispositif de contrôle interne, de la gestion et de la situation financière des établissements du Groupe, anime et pilote la Filière Audit du Groupe.
Pour faire face aux enjeux, l’Inspection Générale souhaite développer ses pratiques en matière d’analyse de données :
En s’appuyant sur la création de datalakes/datamart au sein du groupe BPCE pour réduire le temps consacré à l’acquisition des données et accroître le temps de contrôle et d’exploitation ;
En faisant évoluer les techniques d’analyses de données tout en s’appuyant sur de nouveaux outils et de nouvelles méthodes ;
En renforçant la culture de l’analyse de données structurées et non structurées auprès de l’Inspection Générale et de la filière audit.
Mission
Au sein d’une équipe de 6 personnes, le Data Scientist Senior :
Prépare les données en collaboration avec l’équipe Data ou les équipes d’Audit ;
Réalise des analyses sur la base de ces différentes sources de données en appui des travaux sur place des inspecteurs ; et intervient sur site lorsque nécessaire ;
Met en place des méthodologies et outils d’analyse de l’Inspection Générale et documentation associée ;
Au sein de l‘équipe Data, peut être amené à mettre en place des liens persistants avec les SI du groupe : analyse préalable des données sources et coordination avec les équipes en charge des SI métiers ;
Assure la promotion de la démarche au sein de l’IG.
Vous pourrez également participer à des travaux de Risk Assessment de l’Inspection Générale (collecte des données, alimentation des outils, contrôle de cohérence) et en analyser les résultats en lien avec les inspecteurs.
Par son rôle central dans la fourniture de données aux équipes d’Audit, cette équipe contribue à la performance des techniques d’audit.
Profil recherché
De formation supérieure de type ingénieur ou de commerce, IEP, université, vous justifiez d’une expérience de 5 ans minimum dans le secteur de la data.
Vous disposez de compétences aguerries en programmation SAS / Python et traitement statistiques. Doté d’une expertise dans le développement de requêtes, vous disposez d’une capacité à administrer des bases de données. La connaissance d’outils de data préparation / data visualisation (Spotfire) serait un plus. Vous disposez de bonnes connaissances d’un outil de datascience. Vous maîtrisez le machine learning, deep learning et l’utilisation de GPUs.
Autonome et force de proposition, vous faites preuve d’une excellente qualité d’écoute. Vous êtes rigoureux et possédez une approche méthodique et structurée.
La maîtrise de l’anglais, tant à l’oral qu’à l’écrit, serait un plus.

Informations complémentaires sur le poste :

Si le poste est basé à Paris/Ile de France, il peut nécessiter quelques déplacements de courte durée en province."
Paris (75),CDI,,Manager Data Science Consultancy (h/f),Nova Consulting,- Paris (75),"CDI
Nova Consulting :
Créée il y a 12 ans, Nova Consulting est une « Boutique » de Conseil en Stratégie, spécialisée dans l’analyse de la performance et l’optimisation
de la rentabilité des investissements dans des secteurs dotés d’une forte part d’irrationnel et d’émotion : la Culture, le Sport, le Tourisme et les
Marques. Le cabinet accompagne chaque année sur des problématiques diverses une quarantaine de directions générales de groupes du CAC
40 ou de marques de niches emblématiques de grandes institutions culturelles, sportives ou touristiques et de collectivités locales.
Depuis sa création, le Cabinet a développé une expertise ainsi que des méthodes quantitatives et statistiques reconnues dans ces quatre
secteurs, dont la combinaison permet la conception de stratégies « sur-mesure », à la fois innovantes et rentables. Nova Consulting accompagne
tous ses clients avec le même niveau d’exigence et d’engagement, depuis la phase de définition de leur stratégie jusqu’au pilotage de sa mise
en œuvre.
Le cabinet est en très forte croissance (> 40% par an depuis sa création) : le succès du développement de Nova repose sur une fidélité
remarquable de ses clients (78% de son CA est réalisé par des clients de plus de 3 ans) et une expertise sectorielle unique qui permet une
conquête très forte (71% de succès sur proposition commerciale depuis 2 ans).
Pour soutenir cette croissance et son ambition, Nova est structuré autour de 4 principaux managers associés :
Un Président (25 ans d’expérience : L’Oréal, BCG, Havas)
Un Directeur Général (25 ans d’expérience : Senior Partner au BCG)
Un Directeur Associé du Pôle Marques (22 ans d’expérience : L’Oréal, Unilever, McKinsey, Accenture Strategy)
Un Directeur Associé du Pôle Entertainment (20 ans d’expérience : Centre Pompidou)
Le Pôle « Marques » accompagne chaque année ses Clients dans la définition et la mise en œuvre de leur stratégie. Grâce à des compétences
sectorielles approfondies et des méthodologies reconnues, le pôle « Marques » aide ses clients sur différentes problématiques (Stratégie
CRM/PRM, ROI, études de marché, plan stratégique, modèles prédictifs, segmentations…).
Le cabinet a structuré en 2018 un pôle Data regroupant toutes les expertises dédiées du cabinet en vue d’accélérer la transformation de ses
clients sur ces problématiques. Vous serez en charge de ce nouveau pôle composé de 2 à 3 data scientists avec la responsabilité de le structurer
et le développer.
Voici les principales missions business que vous conduirez :
Management du pôle Data Science en lien direct avec le Président et le Directeur Général du Cabinet
Gestion d’une équipe de Consultants-Data Scientists
Suivi des missions et des différents projets appliqués à l’ensemble des missions en cours en lien avec les consultants du cabinet
(segmentation statistiques, développement d’analyses prédictives, de scores etc.)
Présentation des solutions aux clients
En lien direct avec la Direction du cabinet, et avec une forte vision business appliqué, vous serez également en charge de :
Contribution aux initiatives de R&D Data du cabinet (création de nouveaux modèles d’analyses de données et de l’implémentation de
nouveaux outils)
Publications de travaux de recherche sur des sujets d’innovation en lien avec nos secteurs (revues spécialisées, etc.) et en lien avec
des acteurs de références sur ces problématiques (Professeurs, chercheurs, etc.)
Travail avec Nova le Lab sur des partenariats avec des start-ups et entreprises de la tech de premier rang
Contribution à des éventuels Tech Tour, Hackathon, etc.
Proposition de nouveaux business cases pour Nova le Cabinet
Participation au développement de la Business Unit Data Science
Profil recherché :
Ecole d’ingénieur ou de commerce de premier rang
Niveau avancé en statistiques
Excellente maitrise des outils statistiques (SPSS, R…)
Maitrise des langages de programmation (Python, SQL…)
Vous êtes passionné (e) par les nouvelles technologies liées à la Data : Business Analytics, Analyse prédictive, construction et
exploitation de base de données SQL à forte volumétrie
Vous avez idéalement une expérience de plus de 3 ans au sein d’un département de Data Science d’une grande entreprise / cabinet
de conseil en stratégie / cabinet d’études ou toutes autres entreprises spécialisées dans l’analyse de données et l’innovation
Vous avez un excellent sens du travail en équipe et du leadership
Date de prise de fonction : Candidature :
Dès que possible
Pour postuler, remplissez le formulaire de candidature à l’adresse
Lieu : suivante : https://www.nova-consulting.eu/offres
Paris 4ème
Nova Consulting
Rémunération : 20, rue Sainte-Croix de la Bretonnerie, 75004 Paris / site :
Rémunération très attractive www.nova-consulting.eu"
La Défense (92),"Apprentissage, Contrat pro",,Alternance - Ingénieur Big Data H/F,EDF,- La Défense (92),"Type de contrat :
Alternance

Niveau de formation :
Master 2

Spécialité(s) :
DATA - Mathématiques appliquées - Statistiques

Pays / Région :
France / Ile-de-France

Département :
Hauts-de-Seine (92)

Ville :
20 esplanade de la défense tour PB6 puteaux

EDF est labellisé Happy Trainees

Description de l'offre
Au sein de la Direction Transformation et Efficacité Opérationnelle, la Direction des Systèmes d'Information du Groupe EDF impulse, accompagne, contribue à la Transformation Numérique du Groupe. Elle communique et élabore la vision globale des systèmes d’informations en lien avec la stratégie du Groupe EDF. Au service de tous les métiers du Groupe, elle développe ou contribue aux activités liées à la valorisation des données, notamment le Data Analytics, l’Intelligence Artificielle.
Dans ce cadre, l’Usine Data Analytics de la DSI Groupe a en charge la valorisation des données métiers des différents producteurs nucléaire, thermique, hydraulique et énergies renouvelables du Groupe, par des méthodes de data science (Statistiques, Machine learning, traitement du langage, DataMining, dataviz, deep learning, L, etc...), afin d’optimiser la maintenance et l’exploitation des sites de production.


L'équipe dans laquelle vous serez amené à travailler regroupe une vingtaine de personnes ; l'équipe est composée de data scientist, de data analyst, d'ingénieurs big data, de chef de projet. Le mode de travail est le mode projet agile, avec nos clients, à savoir les producteurs d'énergie des filières nucléaire, hydraulique, thermique et énergies renouvelables.
L'environnement de travail est un espace ouvert ; chaque équipe, multidisciplinaire (data scientist, data analyst, data Engineer), de 3 à 4 personnes travaille sur 2 à 3 use case métier en parallèle. Les travaux réalisés sont des travaux d'études, sédentaires, mais nécessitent de rencontrer régulièrement les donneurs d'ordre métier et/ou les maitrises d'oeuvre IT qui nous fournissent les données et exploitent notre data lake (réunions en région parisienne principalement).
Le rôle de l'alternant ""Data Engineer"" au sein de cette entité est de de mettre à disposition des DataScientist un datalake de qualité sur une infrastructure performante
L'alternant data engineer s’appuie sur ses compétences informatiques, statistiques et mathématiques.
Sa mission consiste à :
mettre en place le rôle de DataStewart au sein de l'équipe permettant de cataloguer les données et améliorer leur rex d'exploitation
améliorer le moteur de recherche interne de notre DataLake
intégrer des données OpenData à notre environnement
Il sait travailler en interaction avec les équipes IT de EDF, mais aussi avec les data scientist et data analyst de l'équipe pour répondre à leurs besoins, pour optimiser la valorisation des données traitées. Il peut appliquer des méthodes de travail habituelles au contexte de développement informatique : travail en mode agile, gestion de versionning (gestion d’un Git par exemple).
Profil souhaité
Vous souhaitez apporter votre expérience et votre dynamisme à l'un des enjeux les plus importants pour EDF ?

Dans un cursus de formation ingénieur(e), avec une spécialisation dans le Big Data, vous pourrez nous apporter vos connaissances théoriques. En période d'entreprise vous devrez, au quotidien, développer votre autonomie en vous intégrant dans un collectif de travail. Nous vous appuierons dans votre progression et vos prises d'initiatives seront saluées.

Conformément aux engagements pris par EDF SA en faveur de l'accueil et de l'intégration des personnes en situation de handicap, cet emploi est ouvert à toutes et à tous sous réserve de l'accord de la médecine du travail."
Levallois-Perret (92),CDI,,EXPERTS DATAMINING / DATASCIENCE H/F,Micropole,- Levallois-Perret (92),"Groupe international spécialisé en conseil et solutions innovantes dans le domaine de la Data et du Digital.
Aujourd’hui, plus de 1250 experts métiers et ingénieurs accompagnent nos clients sur 3 offres complémentaires : Digital Experience, Data Intelligence & Performance et Data Governance & Architecture.
Depuis 30 ans, nous sommes tous animés par une volonté commune : aider les entreprises à se transformer en tirant le meilleur parti de l’innovation !
Nous recrutons des experts focus sur l’analyse des données, le data mining et la data science dans l’optique de répondre aux enjeux métiers de nos clients. Avec plus d’une centaine de références sur ces sujets depuis 2009, Micropole est un acteur de référence sur ces domaines.
En nous rejoignant, vous aurez l’opportunité de mettre en œuvre des projets de DataScience à forte valeur ajoutée pour nos clients et serez amenés à collaborer avec les data engineers de notre practice BigData lorsque les architectures SI de nos clients le nécessiteront.
Description de l’offre
Pour vous, la data science ne se résume pas à appliquer des algorithmes de machine learning à l’aveuglette et des milliers de modèles sur une table toute préparée et des variables anonymisées.
Vous êtes persuadé(e) que les 2 phases les plus importantes d’un projet sont la compréhension et le cadrage des besoins métiers ainsi que la phase de préparation des données et l’ajout d’indicateurs pertinents.
A partir de besoins métier et de données exploitables, vous proposez et mettez en œuvre des méthodologies qui répondent de manière efficace et opérationnelle à ces besoins : de la phase de préparation des données au déploiement des modèles prédictifs et aux recommandations métier.
Vous savez choisir la ou les bonnes méthodes en fonction des enjeux / besoins (performance vs compréhension, contraintes d’industrialisation, délais de réalisation).
Vous avez le sens des priorités, savez être force de proposition et pouvez gérer et piloter en autonomie certains projets.
Vos compétences :
Vous disposez de plusieurs expertises significatives sur les aspects métier / technique / logiciel parmi les propositions suivantes :
Fraude, risque, monétique, maintenance prédictive, marketing, connaissance client
Data mining, segmentation, scoring, apprentissage non supervisé, apprentissage supervisé, moteurs de recommandations, analyse de logs web, NLP, text mining, optimisation sous contraintes, deep learning, analyse d’images, fuzzy matching, analyse de réseaux, Data quality management, mise en œuvre de datalab
Python, Scikit Learn, SAS, R, SQL, TensorFlow, Dataiku, Alteryx, H2o, SPAD, IBM SPSS, Amadea, Scala…
Vous avez l’habitude d’optimiser vos programmes pour attaquer de fortes volumétries de données.
Vous maitrisez les fondements des principaux algorithmes de data mining et de machine learning et savez les paramétrer en fonction des contraintes projet ou de la nature des données à traiter.
Vous maitrisez le langage SQL et au moins deux langages de programmation parmi SAS, Python, R et Scala.
Vous savez mettre en forme et valoriser les résultats obtenus par rapport aux objectifs initiaux.
Vous avez la fibre pédagogique et un bon relationnel pour transmettre vos compétences à nos clients et encadrer nos profils junior sur les projets que vous conduisez.
Votre profil :
Solide formation en statistique et en data science
Au minimum 3 ans d’expérience professionnelle.
Rigoureux, pragmatique et autonome, vous avez le sens du service et de la relation client; de fortes capacités d’analyse et de synthèse, un très bon relationnel et rédactionnel.
Poste basé à Paris.
Depuis 2015, Le Groupe Micropole est labellisé Happy Trainees et happy at Work for Starters.
En 2018, le Groupe est une nouvelle fois propulsé dans le top 10 des entreprises françaises où il fait bon démarrer sa carrière !

#LI-CD1"
Paris 2e (75),"Apprentissage, Contrat pro",,ASSISTANT DATA SCIENTIST H/F (ALT C 50 2020),RCi,- Paris 2e (75),"Référence de l'offre :
ALT C 50 2020

Type de contrat :
Alternance

Date de l'offre :
2020-04-15

Lieu :
Paris - 75002

Service d’accueil : DATA LAB
Au sein de la Direction Marketing et Stratégie, vous intégrerez le département Data Lab qui est composé de Data Scientists, de Data Engineers et de Gestionnaires de Projets. La mission du Data Lab est d'apporter des solutions IA et Big Data aux différents métiers de RCI Bank and Services. Vous ferez partie de la structure qui accompagne le groupe dans sa transformation digitale à travers la réalisation de projets innovants.
Vos missions :
Doté(e) de compétences solides en Mathématiques, Statistiques et Programmation (R, Python, SQL), vous aurez pour mission la réalisation des objectifs suivants :
Manipuler d'importants volumes de données structurées et non structurées (image, audio, texte) provenant de différents départements (Marketing, Finance, Opérations, Audit…)
Apporter une solution industrialisable aux besoins opérationnels via le développement de modèles prédictifs ou de segmentation, d'outil d'automatisation ou de data visualisation
Formaliser et restituer les résultats des projets aux métiers dans un rapport détaillé
Mettre en place des processus de backtesting pour les modèles développés
Effectuer de la veille technologique sur les sujets Data Science (méthodes, techniques, outils…)
Apports de l’Alternance :
Compétences en Data Science
Aptitude en gestion de projet en Agile
Sens de l'organisation et du relationnel
Exposition à l'international
Vos qualités / Compétences :
Esprit d'équipe,
Rigueur,
Autonomie
Capacité d'analyse, de synthèse, d'innovation
Bon niveau en Mathématiques et Statistiques
Bon niveau en Programmation : R, Python, SQL
Maitrise de Hadoop, Spark, Git serait un plus
Bonne maîtrise de l'anglais (TOEIC 750 minimum)
Niveau de formation
Vous préparez, un BAC +5 (Master 2).
Informations complémentaires :
Durée du contrat : 12 mois
Date de début : Octobre 2020
Autres Avantages : 0.58 RTT/mois, Prise en charge de 50% du titre de transport, Tickets Restaurant."
Paris (75),,,Data Engineer,Excelya,- Paris (75),"Présentation
“De toute façon, dans l’industrie pharmaceutique, les entreprises de prestation se valent toutes” Si vous pensez ça, nous vous invitons à découvrir Excelya de toute urgence !
Parce qu’Excelya est nouvelle sur le marché et cherche à construire un partenariat de qualité avec ses employés. Vous avez le sentiment d’avoir un lien de plus en plus distendu avec votre hiérarchie ? Tentez l’expérience d’un véritable attachement à votre entreprise. Vous avez des compétences ou des centres d’intérêt extra-professionnels originaux ? Excelya vous aidera à les promouvoir.
2. Mission
La direction Biométrie et data sciences a pour mission de :
Fournir une expertise en statistiques et en gestion de la donnée à nos partenaires au sein de la R&I sur des sujets comme statistiques conventionnelles et modernes, sciences informatiques (parallélisations sur plusieurs machines des calculs statistiques), data mining, mathématiques appliquées, analytique prédictive outil de visualisation.
S’assurer de la qualité de la collecte et du stockage des données des études cliniques ainsi que sur les projets non-cliniques ;
Définir la stratégie optimale de la gestion globale des données de leur collection à leur analyse ;
Réaliser et / ou superviser l’analyse statistiques des études pré-cliniques, cliniques, ainsi que le support auprès des autres fonctions lors de la réalisation des plans d’expériences, de fouille de données ou le développement de méthodes innovantes ;
Développer des méthodologies innovantes pour optimiser les résultats et s’appuyer sur des outils digitaux pour repousser les limites fonctionnelles du passé.
MISSION
Accompagner les équipes et les projets pour assurer la qualité et l’innovation dans le cycle de vie de la donnée R&I avec l’utilisation de technologies Big Data principalement sur des données.
Coordonner l’ensemble des activités opérationnelles de gestion des données concernant différents projets basé sur une stack technique Big Data Cloudera
Assurer la compliance réglementaire de Data Privacy sur l’ensemble des données de la R&I sur des projets incluant des données personnelles et en assurer le suivi
REPONSABILITES
Assure la traduction des besoins utilisateurs en besoins fonctionnelles et techniques.
Assure la conception et développement des flux de données (ingestion, data modeling, data warehousing, data cleaning) avec des technologies Big Data
Assure l’ingestion, la modélisation conceptuelle, la qualité, et la disponibilité des données
Développe, déploie et maintient la stratégie de meta données, y compris le déploiement d’outils, gouvernance, bonne pratiques, formations et animation du sujet
Propose une expertise opérationnelle et de gestion adaptée à chaque projet
Gère au quotidien ces projets dans le respect des plannings et budgets définis en méthode agile
Assure la continuité des interactions et le déroulement de l’activité en l’absence du Responsable Data & Information Management
Assure la mise en œuvre des missions suscitées dans le respect des standards de qualité, du planning et du budget
3. Profil
Bsc ou Msc en Data Engineering ou équivalent
2 ans d’expérience en tant que Data Manager/Data Engineer ou équivalent
Forte expérience opérationnelle en gestion de la donnée
Expérience avec l’environnement Hadoop, Hive, Impala, Kudu, HBase. Kafka serait un plus.
Expérience avec Python est obligatoire. Spark, Scala, SQL serait est un plus.
Expérience avec un système ETL e.g. Alteryx, Talend, Informatica, Trifacta, Knime, Dataiku etc.
Expérience dans un environnement de développement Agile/Kanban
Forte expérience en gestions de projets
Excellentes qualités interpersonnelles avec la capacité à interagir efficacement avec les personnes, en interne
Excellentes qualités de présentation à l’écrit et à l’oral.
Esprit d’équipe au-delà de ses propres responsabilités et capacités de synthèses.
Leadership, autonomie et proactivité"
Paris (75),,,Consultant Data Visualisation H/F,Group onePoint,- Paris (75),"Description de l'entreprise
Nous sommes des architectes de la transformation des entreprises et de la modernisation des Etats, courageux, authentiques, ouverts, engagés et élégants. L'organisation de nos
expertises en communautés ouvertes, permet d'apporter à nos clients une proposition de valeur depuis la réflexion stratégique jusqu’à sa mise en œuvre en intégrant les compétences métiers et tech les plus avancées.
Nous sommes aujourd'hui 2300 collaborateurs, répartis dans 15 implantations dans le monde (Paris, Bordeaux, Toulouse, Nantes, Lyon, Amsterdam, New-York, Bruxelles, Luxembourg, Melbourne, Singapour, Montréal, Tunis, Zele).
Mission : Nous aidons chacun de nos clients à dessiner concrètement un chemin d’avenir en étant audacieux, en allant au-delà de l’évidence, pour créer de nouvelles façons de travailler, de nouveaux modèles économiques et de nouveaux lieux. Autrement dit, chaque matin, nous nous levons pour contribuer à dessiner un nouveau monde.
C’est ainsi qu'est définie notre raison d’être – Design a New World – et notre signature : Beyond the Obvious, au-delà de l’évidence
Description du poste
Vous rejoignez notre cabinet en tant que Consultant Data Visualisation.
Nous rechercons des profils hybrides ayant à la fois une connaissance avancée d’une ou plusieurs solutions data visualisation, capables de travailler en relation directe avec des équipes métier et capables de piloter des projets data.
Vous pourrez être amenés à :
Être l’interlocuteur unique et privilégié d’une équipe métier pour le maquettage et la construction d’un reporting data visualisation dans une démarche de co construction avec le client
Être force de proposition sur des approches d’analyse, d’indicateurs de performance, de visualisation et d’expérience utilisateur en cohérence avec l’usage, les compétences et les attentes du client
Travailler en mode agile et en autonomie, avec des sprints très courts de quelques jours entrecoupés de restitutions client
Organiser des ateliers suivant la méthode design thinking pour faire émerger les besoins
Proposer une stratégie data moyen terme, notamment en termes de gouvernance de la donnée
Vous participerez activement à la capitalisation de nos connaissances ainsi qu’au développement de notre business unit data.

Vous serez formé(e) à nos méthodologies et aurez l'opportunité de travailler au sein d'équipes pluridisciplinaires.
Qualifications
Diplômé(e) d’une école ingénieur, vous justifiez d’une expérience réussie de 4 à 8 ans dans un grand groupe, cabinet de conseil ou start-up.
Vous possédez une forte appétence pour la Data, le BI et l’univers des starts-ups.
Vous travaillez en environnement agile
Vous savez créer et s’assurer de la bonne tenue de votre backlog.
Vous suivez les différentes cérémonies agiles comme : le sprint planning, les daily meetings, des rétrospectives, des démonstrations au client.
Vous avez une bonne compréhension et des expériences réussies dans un ou plusieurs domaines de la data
Déploiement ou exploitation d’écosystèmes data (Hadoop, ELK, etc.)
Analyse exploratoire ou mise en place d’une solution de visualisation de données (Qlikview, Tableau, Power BI, etc.)
Mise en place ou maintenance de data warehouse
Animation ou réalisation de développements spécifiques en Python, R, Scala ou autre langage spécifique
Une bonne compréhension des algorithmes data (modèles statistiques et prédictifs) est un plus.
Curieux et adaptable, votre rigueur et votre proactivité vous permettent de contribuer à l'excellence de notre service auprès des clients.
Votre capacité d'analyse et de synthèse, vos qualités d’écoute et de communication écrite et orale suscitent la confiance.
La maitrise d'un ou plusieurs outils de traitement de données (data quality, data cleansing, ETL, analytics, dataviz...) serait un plus
Informations complémentaires
Nous vous proposons :
Des missions et projets passionnants
Une communauté de consultants active
Un cabinet de conseil différent (« Startup spirit »), très qualitatif et à taille moyenne
Une opportunité unique de développement et d’évolution dans un esprit communautaire
Un suivi et une formation personnalisés"
Paris (75),"Temps plein, CDI",,Knowledge Graph Expert – Machine Learning / Algorithms / NLP / Semantic / Data Mining,USA Recruitment,- Paris (75),"We are recruiting for a Knowledge Graphs Expert with extensive knowledge in Machine Learning techniques and exposure to NLP, Semantic Analysis and/or Data Mining to join our client in the Paris area of France on a permanent basis

Our client is a global name in mobile and tech development, and as a Knowledge Graph Expert you will be responsible for researching knowledge graphs and Machine Learning architectures and algorithms plus analyzing the development trends in knowledge Graphs and Machine Learning.

Required kills:
Good experience in knowledge graph projects
Familiarity with knowledge construction, knowledge extraction, knowledge convergence, knowledge storage, knowledge calculation, and the overall process of knowledge application.
Have experience with with NLP, semantic analysis, data mining, machine learning, and graph technologies.

***Please note, we cannot accept candidates requiring visa sponsorship ***

Key words:
Knowledge Graph / Machine Learning / Algorithms / NLP / Semantic / Data Mining

#software
#AI&Machine Learning

By applying to this role you understand that we may collect your personal data and store and process it on our systems. For more information please see our Privacy Notice (https://eu-recruit.com/about-us/privacy-notice/)"
Paris (75),"Temps plein, CDD",50 000 € - 70 000 € par an,Data Scientist,Prolancer,- Paris (75),"One of the world’s leading financial consultative service providers are looking for Data Sceintists to join their team. The Company provides financial advisory and consultations to more than 4,500 clients in more than 35 countries, worldwide.
Job Description
Maintaining business excellence for us means the acquisition of new talent that are experts in new technologies and sciences.
We are looking for an experienced Data Scientist to join our team of technologists and data scientists to help us deliver data-driven solutions to our clients.
We are looking for someone with experience in using machine learning and natural language processing technologies to isolate, identify and utilize relevant data and help in designing and implementing new technologies and solutions to both simple and complex financial problems.
Roles & Responsibilities
Liaise with clients and our senior management team to understand client needs
Identify and process various sources of client/third-party financial data
Analyse sets of data to identify structures, patterns and trends
Use patterns in data to propose solutions and strategies for client problems
Create and present findings to senior management team and other stakeholders, as and when required
Collaborate with our technical team to design and implement automated data collection tools/processes, using predictive analytics and machine learning algorithms
Collaborate with our product development team to make recommendations for service improvements
Essential Requirements
5+ years of relevant experience (e.g. Data Scientist, Data Analyst, Statistician, Economist, etc.)
Working knowledge of machine learning algorithms and technologies
A great knowledge and/or experience of business intelligence tools (e.g. VBA, SQL, Tableau, etc.)
MSc or higher in Data Science, Statistics, Economics or a related field
Experience delivering agile solutions to various small and large clients
Strong problem-solving skills
Excellent attention to detail
Impeccable listening skills
Excellent verbal and written communication skills
Able to create and maintain strong working relationships with both internal and external colleagues and clients
Great planning and organisational skills
A desire for continuous learning and professional improvement
Desirable Skills
Experience working within the financial services (or similar) sector
Knowledge of cloud computing technologies (MS Azure, Amazon AWS, etc.)
A working knowledge of Python programming
Experience providing advisory or consultation services to client
Apply directly at: https://prolancer.com/jobs/send-proposal/298
Benefits:
Work from home opportunities
Flexible working hours
Contract length: 12 months
Job Types: Full-time, Contract
Salary: 50,000.00€ to 70,000.00€ /year"
Clichy (92),,,Datascientist - Intern - DATA LAB,L'Oreal,- Clichy (92),"[STAGE]

Rejoignez nos équipes Datascience au sein du DATA LAB!

*** Stage de 6 mois à partir de Septembre 2020 ***

Contexte :

Leader mondial de la beauté, L’Oréal est présent dans 130 pays sur les cinq continents. Le groupe s’est donné pour mission d’offrir le meilleur de l’innovation cosmétique aux femmes et aux hommes du monde entier dans le respect de leur diversité. En agissant comme un réel business partner pour toutes nos divisions, notre équipe IT Global contribue directement au succès de l’ensemble du portefeuille de marques de L’Oréal : Lancôme, Yves-Saint Laurent, Biotherm, Kiehl’s, La Roche Posay, Vichy, Garnier, Maybelline New-York, Kerastase, Redken (…).

L’Oréal a entamé une véritable transformation technologique majeure en voulant devenir le leader de la Beauty Tech, dans ce contexte nous avons créé un nouvel écosystème avec le Beauty Tech Accelerator ayant pour vocation de traiter des projets stratégiques pour le groupe, avec une forte valeur Tech (Big Data, AI, Deep Tech UX/UI), et de structurer les pratiques dans ces domaines à l’échelle du groupe.
Pour votre stage, vous rejoindrez l’équipe Data Science de l’accélérateur dont les 4 principales missions sont :
Le Conseil :
Définir et appliquer les best practices Data Science et IA cohérentes au sein du groupe
Fournir une expertise sur l’ensemble des technologies définies
Le Data Lab :
Promouvoir l’Analytics au sein du groupe en démontrant la valeur apportée aux métiers et à l’IT
Structurer des POV pour répondre aux besoins de nos différents métiers
Contribuer au suivi des roadmaps éditeurs ainsi qu’une veille technologique sur les solutions et méthodologies Data Science / IA
Les Projets :
Construire et opérer des projets autour de la Data Science et de l’IA
Supporter toutes les divisions L’Oréal worldwide dans la mise en œuvre des projets
La communauté Data Science et IA du groupe :
Enrichir la communauté Data Science et IA du groupe (internationale, IT/métiers et multi-divs)
Identifier les partenaires extérieurs les plus pertinents : écoles, startups, compagnies, éditeurs, …
Animer la communauté via la définition et la mise en place d’évènements internes et externes
Vous évoluerez dans un environnement international favorable :
Réalisation de projets entouré d’experts dans leurs domaines respectifs : Data Science, IA, Data engineering, architecture Big Data, solutions technologiques BI & Big Data, …
Diversité des missions (commerce, marketing, industrie, média, réseaux sociaux…)
Diversité des données disponibles (internes/externes, structurées ou non …)
Latitude pour identifier et tester de nouvelles approches, technologies et outils
Principales missions et responsabilités :
Vous rejoindrez l’équipe Data Science de l’accélérateur dans des projets déjà démarrés sur lesquels une piste d’exploration vous sera entièrement dédiée ou bien sur des projets entièrement nouveaux ou un « Proof of Value » vous sera demandé. Vous travaillerez en grande autonomie dans un contexte agile, encadré par des Data Scientists / Machine Learning engineer.
Les projets peuvent être dans des domaines métiers assez larges (Finance, Marketing, Opérations, Retail, Web, …) et dans des champs de l’intelligence artificielle tout aussi divers (Traitement du Language, Systèmes de recommandation, Séries Temporelles, Vision Machine, etc.). Selon l’avancement sur votre sujet et dans le cadre de l’avancement de l’équipe un second projet pourra vous être proposé.
Voici à titre d’exemple des missions effectuées lors de précédents stages:

Création d’un outil permettant le traitement automatique de contrats (reconnaissance de certains types de clauses et de signatures sur des contrats numérisés dans plusieurs langues: Français, Anglais, Chinois)
Création d’un moteur de recommandation pour nos clients professionnels pour simplifier l’achat de produits multi-marques.
Création d’un outil de détection d’anomalies.
Prédiction du Traffic dans nos boutiques.
Vos principales missions seront :
Parcourir la bibliographie afin de trouver si des recherches existantes peuvent être utiles pour le problème posé.
Prioriser des approches basées sur des critères de faisabilité et de besoin business
Implémentation et tests des différentes approches de façon continue, en respectant les principes de l’équipe en matière de code et méthodologies.
Effectuer des revues de code sur divers projets, tout comme présenter votre code a vos pairs pour qu’il soit revu et amélioré en continu.
Présenter les résultats aux différents métiers et être capable de remettre en doute certaines demandes lorsque cela est nécessaire, vulgariser votre travail au plus grand nombre.
Construire une solution industrialisable.
Documenter les développements et taches réalisées.

Votre Profil :
Formation : Cursus ingénieur ou équivalent en formation Data Science ou IA
Compétences techniques :
Machine Learning: Connaissance des algorithmes classiques et plus avancés. (NLP, Deep Learning,..)
Programmation Python : librairies de manipulation de données, de Machine Learning, connaissance sur l’orienté objet, les tests unitaires, documentation docstrings.
Outil de gestion et versionning de code, type GIT
Rédaction de documentation technique et fonctionnelle
Des compétences en programmation Spark (Scala, PySpark) seraient un plus
Des notions en back-end (flask, Django, NodeJS), en front-end (ReactJS, VueJS), CI / CD et outils tels que Docker, Kubernetes serait un plus.
Compétences comportementales :
Flexibilité/ouverture d'esprit ; capacité de vulgarisation et d'argumentation ; diplomatie, relationnel ; qualités rédactionnelles tant en français qu’en anglais ; esprit de synthèse.
Anglais opérationnel
Ce que nous vous offrons :
Vous intégrez une équipe experte, passionnée et enthousiaste, ayant à cœur de faire monter en compétence les membres de l’équipe projet.
Situé en région parisienne (Clichy).
6 mois au sein d’une équipe passionnée et internationale.
Une expérience formatrice.
Des challenges, des opportunités à saisir et autant de responsabilités à prendre.
Un suivi RH pour vous accompagner dans la construction de votre future carrière.

Pour plus d’informations sur le Groupe L’Oréal, rendez-vous sur notre page LinkedIn

Postulez dès maintenant pour rejoindre l’aventure L’Oréal !"
Paris 6e (75),CDI,,Ingénieur Data Intelligence SAP BI F/H,TRIMANE,- Paris 6e (75),"Dans le cadre du développement de la solution décisionnelle de l'un de nos clients, nous recherchons un Consultant SAP BI. Votre mission sera de :

Recueillir et analyser les besoins des utilisateurs/métiers
Rédiger les spécifications fonctionnelles détaillées et/ou techniques
Participer aux phases de modélisation décisionnelle (étoile ou flocon)
Mettre en place les flux d'alimentation
Modéliser des univers, développer des rapports simples à complexes Webi, et selon profil gérer des tâches d'administration sous CMC
Bâtir les stratégies de recette, mener les tests d'intégration technique et fonctionnelle ainsi que leur validation par les référents métiers
Contribuer à différents projets en fonction des besoins et de vos compétences : architecture, installation, administration, optimisation, documentation, ...
Profil recherché Profil recherché :
De formation Bac+5 ou diplômé d'une école d'ingénieur, vous disposez d'une expérience d'environ 3 ans minimum dans le domaine du décisionnel. De plus, vous disposez de compétences reconnues autour de la suite SAP BI 4 à plus (Designer, Webi, Deski, CMC). Une connaissance d'autres outils décisionnels serait un atout supplémentaire.
Entreprise TRIMANE est une société de service spécialisée dans les systèmes d'information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l'information au sein de leur entreprise.

En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d'expertise de nos consultants.

Nous accompagnons nos clients (CAC 40 et SBF 120) sur des prestations de Conseil, MOA et MOE, autour du traitement et l'analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique.

TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d'outils d'Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique."
Paris (75),,,Systematic Quant Researcher,Anson McCade,- Paris (75),"My client is a leading quant investment firm with offices globally. They deploy systematic trading strategies across asset class; including equities, futures, and foreign exchange. Researchers are responsible for conducting quantitative research using statistical and predictive modelling techniques.
Successful researchers manage all aspects of the research process and work on the full lifecycles of strategy development, including analysis, testing, prototyping, back-testing, and performance monitoring.
Systematic Quant Researcher
My client is a leading quant investment firm with offices globally. They deploy systematic trading strategies across asset class; including equities, futures, and foreign exchange. Researchers are responsible for conducting quantitative research using statistical and predictive modelling techniques. Successful researchers manage all aspects of the research process and work on the full lifecycles of strategy development, including analysis, testing, prototyping, back-testing, and performance monitoring.
The ideal candidate will join from a similar background in another fund of quant trading group within a bank. This is the opportunity to join a small team and work alongside highly profitable Portfolio Managers and with some of the brightest minds in the industry. Team members combine strong technical skills and a passion for problem solving with an intense curiosity about financial markets and human behaviour.
Role:
Research and implement various trading strategies
Identify new trading opportunities by using statistical methods and analysing large data sets
Ensure that all data and related processes are prepared and check over strategies that have been implemented as well as tracking their behaviour
Work closely with other researchers to develop and continuously improve upon mathematical models, and help translate algorithms into code
Ideal Candidate
Experience of researching, or implementing quantitative models for equities, futures, and/or FX,
Masters or PhD in Maths, Stats, Physics, Computer Science, or other quantitative discipline
Strong analytical and quantitative skills
Demonstrated ability to conduct independent research utilizing large data sets
Programming in any of the following: C++, Java, C#, MATLAB, R, Python, or Perl
Detail-oriented"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
La Garenne-Colombes (92),,,Commercial Data Science Manager (F/M),Bayer,- La Garenne-Colombes (92),"Commercial Data Science Manager (h/f)

Do you want to join a company that contributes to improving the quality of life for patients?
Participating in the improvement of commercial efficiency thanks to your skilful manipulation of data is right for you?
For you, supporting operational decisions through data performance is essential?

If you think I am talking about you, it may be because you are our future Commercial Data Science Manager (F/M)!

Department :
Pharmaceuticals – Marketing Operations
Tasks and Responsabilities :

As the Commercial Data Science Manager, you are responsible of the following missions:
Process analytical models and create or modify customer journeys while activating a brand plan and measurable insights as well as
Provide recommendations into commercial strategies and tactics for key products in the market
Be responsible for key aspects along the data modelling cycle from definition of business questions and hypotheses to data sourcing and preparation, model development, and insight generation
Close collaboration with other functions (e.g. commercial business insights, integrated multi-channel marketing) to advice, and support Business Unit (BU) leadership team in various types of advanced quantitative analyses
Demonstrate thought leadership and content expertise to business partners and major markets including development of key training programs
Support evaluation of global commercial experiments and pilots (digital, data mining, etc.), including KPIs
Work with onshore and offshore resources, as well as in-house and external consultant

What about you? :

University degree (Master preferred) in quantitative field (e.g. statistics, management science, operations Research, engineering, finance, applied mathematics, mathematics, business administration)
Several years of progressive advanced analytics work experience with recent experience in pharmaceutical industry or health care consulting
Experience in multi-touch attribution, AI-driven content personalization, advanced segmentation & targeting, conversion modelling, recommendation engine for sales force and marketing systems, journey optimization, simulation, and/or decision analysis
Good understanding of personalizing customer experience through programmatic media, CRM, e-commerce and mobile apps from data generation to optimization is a plus
Experience in machine learning, AI model development and production roll-out as well as experience in R, Python and visualization tools like Tableau
Experience in handling and analyzing various internal and external commercial data types (e.g. sales data sources like IQVIA, Cegedim, patient longitudinal, claims data, distribution, demand, units, promotion)
Ability to influence cross-functional and upper management to impact decision-making combined with strategic business acumen and focus on results
Excellent verbal and written communication/presentation skills in English and French

Join us ! :

Location : Paris or lille
Type of Contract : Permanent Contract
To be filled : as soon as possible

Do you want to take up the challenge? So log on to our career site www.carriere.bayer.fr and apply live on the job!
Your application
Are you looking for a new challenge where you can show your passion for innovation? Are you interested in working as part of a global team to improve people’s lives? Then send us your online application including cover letter, CV and references.
Bayer welcomes applications from all individuals, regardless of race, national origin, gender, age, physical characteristics, social origin, disability, union membership, religion, family status, pregnancy, sexual orientation, gender identity, gender expression or any unlawful criterion under applicable law. We are committed to treating all applicants fairly and avoiding discrimination."
Paris 9e (75),Stage,,Data Engineer Assistant,Numberly,- Paris 9e (75),"Company Description
Numberly helps its customers collect, analyze and leverage their data across all marketing channels. To do this, we are more than 100 engineers (a quarter of Numberly) divided into teams with a human dimension, where we ensure that everyone develops a positive influence and can be autonomous. Our sustained growth forces us to constantly question our technical and organizational choices.
With seven offices worldwide and clients in more than fifty countries, our challenges are global.
Due to our wide range of interconnected products, our technical challenges are very varied and often complex. Our daily missions consist of processing thousands of requests per second, distributed throughout the world, operating databases of several petabytes (Big Data™), automating our entire bare-metal infrastructure, and building the digital marketing interfaces of tomorrow.

Job Description
Numberly is looking for a Data Engineer to join its dedicated team to Big Data and RTB.
As a Data Engineer you will:
Create and maintain pipeline jobs that transfer client data to/from our database diverse infrastructure (Hive, MongoDB, ScyllaDB).
Nurture our large Hadoop cluster, optimize distributed Data Operations and Storage.
Participate in decision making concerning efficient & ethical use of data and technological evolution at Numberly.
Work alongside Data Scientists, DevOps, and many other talented techs.
Suggest your own technological solutions and try them out (our latest successful POCs include Apache Kafka and ScyllaDB) .
Join a great multicultural team filled with wonderful people

Qualifications
You :
Like data in all its forms: raw, reworked, refined, calculated, analyzed, reused…
Like work well done and pay attention to detail
Dream of being able to develop and manage website databases with strong traffic
Want to work with various, prestigious clients on different problems
Are on the lookout for new languages/technologies and test the latest open source trends before others
You love the following stack ?
Hadoop ecosystem (HDFS, Hive, Impala, HBase, ...)
Apache Spark
ETL (Apache Airflow or equivalent)
SQL Databases (MySQL, SQLServer)
NoSQL databases (MongoDB, ScyllaDB, ElasticSearch, ...)
Apache Kafka
Python, Java, Scala
Git
Linux
Even better if you know :
Cloud Solutions (AWS, GCP, …)
API REST, WebServices
Docker
Kubernetes
Apache Druid
Data Science and Machine Learning
Message Queuing (RabbitMQ, Celery, …)

Additional Information
Even with 500 people we like to spend time together!
Participate to “Happy Meetings’” where we share the Group’s news with everyone from around the world
Go to yoga classes, cross-training, barbecues, internal parties...
Find the most incredible fancy costume for the next party"
Paris (75),"Apprentissage, Contrat pro",,Alternance - Data Scientist Junior (H/F),DSOgroup,- Paris (75),"Poste basé à Paris
Contrat d'alternance à pourvoir
Formation : Vous intégrez un Master 2 (Mathématiques Appliquées, Data Sciences, Statistiques etc) que vous souhaitez réaliser en alternance
Leader français en gestion et acquisition de créances, iQera accompagne les grandes entreprises et les institutions financières à chaque étape du cycle financier client en associant intelligence humaine et artificielle. Le groupe place l’expérience client au cœur de sa stratégie pour créer la différence et répondre aux enjeux de transformation des fonctions Finance, Crédit et Relation Client. Plus largement, iQera aspire à activer de nouveaux leviers de croissance, de responsabilisation et de relations à la fois agiles et durables pour toutes ses parties prenantes. Le groupe, présent sur 16 sites dans le monde, compte 2100 collaborateurs et a réalisé 210 millions de revenus cash (Juin 2019 LTM).
VOS MISSIONS
Rattaché(e) à la Direction de l’Innovation et de l’Expérience Client et à l’équipe Data&Analytics, vous aurez pour mission de participer à l’ensemble des sujets d’innovation en lien avec la Data.
Vous serez en charge :
D’échanger avec le métier afin de comprendre leurs attentes et proposer les solutions adéquates,
D’explorer et caractériser les données existantes,
De traduire les problématiques métiers en problème data science/IA,
De développer des modèles statistiques pour prédire, scorer et classifier,
De démontrer l’utilisation concrète d’un modèle par le biais d’un prototype,
De synthétiser, traduire et restituer les informations utiles à la prise de décision.
VOTRE PROFIL
Vous intégrez un Master 2 (Mathématiques Appliquées, Data Sciences, Statistiques etc) que vous souhaitez réaliser en alternance. Vous avez un bon niveau en statistiques, Data Science, IA (Deep Learning). Vous avez développé au cours de votre cursus des compétences en Python ou R. La connaissance en Recherche Opérationnelle serait un plus.
Doté(e) d’une très forte curiosité intellectuelle, vous souhaitez participer à la diffusion d’une véritable culture Data au sein du groupe et devenir un relais entre les opérationnels et la direction.
Vous êtes particulièrement intéressé(e) par tous les sujets touchant de près à l’IA.
Rejoignez nos équipes et l’aventure iQera !
REJOINDRE L’AVENTURE iQera, C’EST :
Intégrer une équipe qui a de l’expertise et de l’ambition
S’affranchir de la routine et de l’uniformité
Évoluer dans un environnement stimulant qui encourage la prise d’initiative
Forts de notre positionnement marché, d’une culture portée par la technologie, les expertises de pointe et l’intelligence humaine, nous développons l’ambition de devenir un acteur incontournable de la transformation de notre métier.
Notre objectif : améliorer la relation financière client de nos entreprises clientes et répondre à leurs enjeux de performance.
Si vous souhaitez participer à notre aventure, et bénéficier de nos opportunités, rencontrons-nous !
Notre groupe est engagé dans une politique en faveur de l’intégration et du maintien dans l’emploi des personnes en situation de handicap. Tous nos postes vous sont ouverts.
Vous pouvez nous adresser votre candidature par mail : recrutement@mcsfr.com
Merci de renseigner dans l'objet de votre mail la ville et l'intitulé du poste pour lequel vous postulez."
Paris (75),Stage,,DATA ANALYST INTERN,Data&Data,- Paris (75),"JOB DESCRIPTION
Data&Data leverages artificial intelligence to track product sales on the internet, across independent websites, marketplaces, and social media. We offer solutions to deal against both counterfeiting and grey-market.
As a business/data analyst intern, your core mission will be to get more value out of our data.
As part of this mission, you will:
Uncover and report on quantitative and qualitative insights.
Design and build client reports or dashboards.
Participate in client meetings and collect client feedback.
Help put together client reports.
PREFERRED EXPERIENCE
You are:
An excellent communicator, operational in English.
Value-driven, proactive, and curious about the business side of things.
Critical-minded, with strong analytical and problem solving skills.
Result-oriented, organized and resourceful, enabling you to deliver on time.
Able to interpret data and tell the story behind it.
Ideally you:
Are able to craft your own Python/R/SQL to fetch and manipulate the data you need.
Are a final year student or recent graduate.
Are native or bilingual English and/or French speaker.
Have worked with startups or agile teams before.
Have experience with data visualisation tools.
Have experience with machine learning, information retrieval, or NLP.
ADDITIONAL INFORMATION
Contract Type: Internship
Location: Paris, France (75013)"
Paris (75),Stage,,Data Science Internship Program,Institut des Systèmes Complexes de Paris Île-de-France (ISC-PIF),- Paris (75),"We are looking for students who are interested in Data Science and Machine Learning! A great opportunity to work with cutting-edge technologies and billions of data. You will be working on Multivac Platform developed at ISCPF : our platform is one of the biggest academic repositories with over 15 billion documents hosted across 80 servers on dedicated servers and cloud services.
Diploma required : Bac + 5 in a quantitative field (applied mathematics, statistics, computing…)
Internship starting date : Flexible
Duration : 2 – 6 month
Salary policy : the internship is paid according to the legal wage rates (approx. 560€/month)
About the Institute of Complex Systems (ISC-PIF)
Interface between disciplines, but also between research organisations and higher education, the ISC-PIF is a place dedicated to the development of innovative and interdisciplinary research on complex systems. Since 2005, the institute is facilitating access to skills, trainings, work areas and pooled research resources based on high performance computing and big data. The institute is a unit of the National Center for Scientific Research (CNRS), one of the largest french research organisation.
Address :
Institut des Systèmes Complexes de Paris 113 rue Nationale 75013 Paris
About the internship
Description :
You will be working on Multivac Platform developed at ISCPIF. Multivac Platform is one of the biggest academic repositories with over 75 billion documents hosted across 100 servers on dedicated servers and cloud services. The datasets contain metadata from published scientific papers and social networks with wide range of topics. Multivac platform is meant as an interface between researchers and Big Data, especially in domain of NLP and text mining. It offers services such as comprehensive dashboards that enable scientists to explore and discover facts with a wider overview on large-scale data through visualisations. It also offers API access that allows researchers to exploit this huge architecture and computation without any prior technical knowledge. In addition, Multivac Data Science Lab offers interactive notebooks over Apache Hadoop/Spark cluster in private Cloud.
Why Multivac Platform :
Multivac Platform is built by cutting-edge technologies such as:
Large-scale databases (MongoDB and Redis with over 12 billion documents)
Search engine clusters (Elasticsearch/Kibana with over 6 billion documents)
Distributed computations and real-time processing (RabbitMQ, NodeJS, etc.)
Cloudera Hadoop 2.0 with interactive Spark notebooks (HDFS, YARN, Apache Spark, Apache Hive, Apache HBase, Apache Zeppelin, Hue, etc.)
Cloud services (OpenStack)
You get to learn all about these new technologies and have access to Multivac Data Science Lab. Multivac Platform hosts over 14 billion data with over 50 million data everyday.
Multivac Data Science Lab
Requirements :
Master in Statistics or Data Sciences
Basic knowledge of Machine Learning Algorithms
Basic knowledge of Scala, Python or R
Basic knowledge of text mining in social networks
Interest in NLP tasks and Graph analytics
(Bonus) Experience with Twitter datasets and other REST API services
(Bonus) Experience with Apache Spark or any other Hadoop components
(Bonus) Experience with a Deep Learning library (BigDL, Tensor Flow …)
Responsibilities (two or more) :
Work on un-supervised learning algorithms for topic detection
Work on supervised learning algorithms for classifications and predictions
Develop and optimise our existing LDA implementations
Implement algorithms to perform NLP tasks such as clustering, topic detections, etc. (StanfordCoreNLP)
Implement algorithms to improve sentimental analysis and mentions clustering
Implement methods of automatic detection of opinions in Tweets
Implement methods of keyword extractions in scientific publications
How to Apply :
Please email your job application (reference in subject line: Multivac Intern) including a cover letter, a resume and an indication of availability date to maziyar dot panahi at iscpif dot fr."
Paris (75),Stage,,Stage en Data Science and BI,Innoscape,- Paris (75),"Innoscape est une startup RetailTech d’intelligence de marché digitale. Nous analysons les canaux de distribution et fournissons des outils d’aide à la gestion marketing et commerciale.
Notre plateforme de BigData as a Service fournit à nos clients, grandes marques B2C, la visibilité opérationnelle d’un seul clic afin de contrôler leur présence en magasin, optimiser les actions de leurs forces de vente, traquer le référencement des produits concurrents et leurs prix de vente, analyser les avis consommateurs… pour gagner des parts de marché.
Notre technologie et business model ont été validés et nous préparons l’expansion suivante.
Contexte :
Nous collectons des millions de données chaque semaine et notre rôle est de leur donner du sens.
Comment dire peu mais juste, quel impact business d’une variation des prix ou le référencement d’un produit?
Vos travaux auront un fort impact sur nos solutions et vous les accompagnerez en production lors du stage.
Profil & Mission :
Personnalité énergique et entreprenante, geek dans l’âme et forte curiosité.
Connaissances solides et envie d’approfondir l’expérience en outils BI, Python, SQL, bases relationnelles, HTML.
Expérience du développement sur le cloud et les langages R / noSQL sont un plus.
Capacité à analyser et exploiter les corrélations entre divers features dans le but de créer de nouveaux insights.
Anglais et excellent esprit d’équipe, tout en simplicité.

Comprendre nos utilisateurs et intégrer leurs contraintes dans l’application. Optimiser les solutions existantes.
Modéliser / développer de nouvelles dimensions d’analyse.
Force de proposition pour des nouveaux cas d’usage, en phase avec le core model d’Innoscape.
Réaliser des POC en testant de nouvelles technologies (Natural Language Processing NLP, sentiment analysis, image / pattern recognition…).
Participer à la veille des systèmes BI d’analyse et de restitution.

Before sending your resume, take a moment to self-asses yourself – this will help you to understand if you can fit well with the rest of our team:
– Do you like taking initiatives?
– Are you a true team player?
– Are you considered as reliable and trustful?
– Are you transparent in communication with peers?
– Do you have a strong desire to deliver quality service and results?
– Can you handle pressure, change and fast-paced environment?"
Paris (75),CDI,,Consultant/ Manager Data Science,Solantis - Consulting Agency,- Paris (75),"Notre client est une société de conseil internationale, pionnière et référente en Data Science.
Data Native ET résolument humains. C’est leur ADN, notre différence. Ce qui les rend unique. C’est la raison pour
laquelle tous leurs consultants sont aussi Data Scientists.
Ils amplifient l’humain grâce à la data et à la technologie. Ils décuplent la technologie et la data grâce à l’humain. Ils
injectent de puissants outils dans toutes leurs missions : algorithmes propriétaires, innovations statistiques, machine learning.
Ils mobilisent, chaque jour, à vos côtés, leurs consultants, créatifs, curieux, atypiques, pour vous accompagner jusqu’à la
mise en oeuvre.

Dans un contexte de forte croissance, ils recherchent un Manager pour rejoindre leur équipe à Paris.
Le Manager chez notre client a un rôle de Chef de Mission et il est aussi moteur de projets internes.
Plus particulièrement le Manager aura les responsabilités suivantes :

Relation client :
En tant que Manager, vous êtes chef de mission et garant de la gestion opérationnelle et quotidienne auprès de grands
comptes. Vous coordonnez la gestion de plusieurs projets en parallèle.
Vous participez de façon active aux décisions stratégiques liées à vos comptes et êtes en mesure de porter l’ensemble des
offres de notre client. Vous intervenez au niveau comité de direction. En parallèle vous cultivez votre réseau externe

Gestion de la production :
Vous êtes responsable de l’ensemble de la production (modeling) et des livrables sur vos comptes et vous assurez le respect
de l’excellence des standards de qualité.

Business :
Vous avez une compréhension fine des enjeux business chez vos clients ou au sein d’un secteur d’activité. Interlocuteur
privilégié des directions générales ou opérationnelles, vous êtes en mesure de les conseiller et les accompagner dans la prise
de décision stratégique.

Management d’équipe :
Vous participez activement à l’évolution de carrière des consultants que vous encadrez. Vous réalisez les évaluations de
performance de votre pool et vous identifiez des axes d’amélioration et vous accompagnez leur développement et leur
montée en compétence.

Culture d’entreprise et projets transverses :
Vous êtes acteur dans la conduite des projets transverses et structurants. Vous êtes investi dans la conduite
opérationnelle des décisions stratégiques qui impactent l’évolution du cabinet

Solides compétences analytiques. Capacité à encadrer des équipes de consultants data scientists
Gestion de la relation client. Faire grandir vos comptes, porter une offre, se créer des opportunités commerciales.
Manager RH, recruter, développer, évaluer et engager les talents
Gestion de projet/programmes
Business : connaissance d’un secteur, capacité à conseiller des dirigeants, vision stratégique
Qualités personnelles :
Vous êtes rigoureux
Force de proposition
Tenace
Vision business
Motivation / enthousiasme
A l’aise dans un environnement entrepreneurial
Souhait d’évoluer et grandir dans un cabinet de conseil
Ce que nous offrons :
Environnement de travail bienveillant
Interaction avec l’international : New York, Londres, Hong Kong, Dubaï
Possibilité de contribuer à de nouvelles idées, nouvelles approches
Culture d’entreprise forte et environnement de travail stimulant
Cadre de travail agréable
Travailler sur des sujets et industries variées, correspondant à l’offre Ekimetrics
Travailler sur des projets stratégiques en utilisant les données pour répondre aux problématiques business
Rejoindre une entreprise innovante et en forte croissance, dont la culture est basée sur l'excellence et le partage de
connaissance."
Paris (75),,,Stage - Data Engineer,SCOR,- Paris (75),"EMEA
Paris France (FR)
|
Stage - Data Engineer
Internship
Information Technology
About SCOR
SCOR, the 4th largest reinsurer in the world, provides insurance companies with a diversified and innovative range of solutions and services to control and manage risk. Using its experience and expertise, “ The Art & Science of Risk ”, SCOR provides cutting-edge financial solutions, analytics tools and services in all areas related to risk – in Life & Health insurance as well as in P&C insurance. Our specialist teams operate in over 120 countries, developing value added and innovative products and services and making long-term commitments to their clients, namely insurers and large corporations.
SCOR's aim, as an independent global reinsurance company, is to develop its Life and P&C business lines, to provide its clients with a broad range of innovative reinsurance solutions and to pursue an underwriting policy founded on profitability, supported by effective risk management and a prudent investment policy, in order to offer its clients an optimum level of security, to create value for its shareholders, and to contribute to the welfare and resilience of Society by helping to protect insureds against the risks they face.
- Departement:
The hELIOS Business Competency Centre (hBCC) is the structure supporting the new ways of working regarding individual data management. It holds the responsibility for the following activities:
Promote and support alignment on relevant processes and roles.
Provide structured support to the users and business advice on hELIOS
Support treaty onboarding, data transformation package creation and reporting/ requirements
Manage the Platform (e.g. identification of new requirements, backlog prioritization, etc.)
Support the roll-outs
The hBCC includes 8 staff members.
- Missions:
hBCC seek a Data engineer to:
Analyse, create and maintain logical sequences for automating client data recognition, data structures and data transformations using the hELIOS Platform
Assist with the checking of Policy, Claims and Financial data.
Liaise with other teams in order to gain understanding of the data and the requirements of the transformations.
Assist with other data-oriented tasks relating to the system implementation which may arise.
Provide an expert support on DE functionalities to users.
Contribute to the identification/assessment of new functionalities for the DE module by having a pro-active relationship with the users.
Take part to the defects triage for the DE module.
Organize and take part to the tests of the new releases of the DE module.
- Profile :
Required Skills:
Good knowledge of Microsoft packages (particularly Excel/Access)
Strong Data Analysis skills
Data Transformation experience requiring coding of complex formulae
Experience of working with large, complex and diverse datasets
Experience of working both within a team and as a self-motivated individual
Desirable Skills:
Experience of working in life insurance/reinsurance/financial services
Knowledge and understanding of life insurance products
Previous experience with large IT global implementation"
Paris (75),"Temps plein, CDD, CDI",,Data Engineer - Search team -,Adevinta,- Paris (75),"Search Engineering is a new team comprised of highly skilled and senior engineers; experts in the search domain. We are building a global Search Component in our Paris Hub which we will quickly take on a journey from MVP to 100 +million unique users a month as we integrate the product with our marketplaces all over the world.
Responsibilities :
Engineer and implement highly scalable systems, using the best development practices and tools.
Implements complete and solid data pipelines that allow training of different machine learning models on behavioral data in production with a key eye on performance
Help define our development environment, and communicate the best development practices within the organisation (i.e. code reviews, testing, etc).
Continuously monitor the quality of our systems, design measurements to monitor their health (both the engineering systems and data quality).
Keep on top of the latest and greatest developments in distributed systems, the cloud, data engineering and data science
Qualifications
Required skills:
+5 years experience as software engineer
Bachelor's degree in Computer Science or similar curriculum
You are able to troubleshoot highly scalable architecture
You have a deep understanding of algorithms and data structures
You’re fluent in Python or you are already proficient in another programming language and wish to learn Python
Proficiency in modern Big Data and ETL technologies (e.g. AWS EMR, Spark, Airflow, etc.)
Experience with streaming solutions such as Kafka, Spark Streaming, Flink is a plus
Versatile in AWS (preferable), Google Cloud, or Azure Cloud
Linux's administration expertise, able to troubleshoot issues on a Linux server
Able to handle end-to-end deployment of data pipelines and machine learning models training optimizing for performance in production
Nice to have experience with Elasticsearch / Solr / Lucene and Elasticsearch Learning-to-rank
Great team player with a can-do attitude, committed with a high level of initiative
Engineer by heart, but exposure to machine learning techniques.
Fluency in English
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more"
Paris 17e (75),"Temps plein, Stage",1 000 € par mois,Stage Data Engineer [4 à 6 MOIS - A partir juillet],Inex Circular,- Paris 17e (75),"Ton rôle
Au cœur du développement stratégique, tu seras le Data Engineer d’iNex aux côtés du CDO (Chief Data Officer) et au sein de l’équipe Produit d’iNex constituée du Product Owner, des Data Analystes et de nos développeurs Front.
Tes missions
Data Engineering – Développement de nouvelles technologies
· Mises à jour automatiques des données
· Consolidation de données
· Prédiction de données
· Visualisation des données
Data Engineering – Collecte & Retraitement de données
· Collecte via des scrappers (crawler), API ou exports
· Développement de pipelines de collecte et traitement de la donnée
Data Analyse – Contrôle Qualité
· Tests échantillonnage
· Revues de cohérence des résultats
Environnement de travail
· Méthode scrum (agile) par sprint d’1 semaine
· Langages principaux : Python, MongoDB, SQL
· Technologies développées : présentées lors de l’entretien
Ton profil
· Tu termines une école d’ingénieur avec une spécialité en data engineering/science
· Tu as de solides connaissances en Python et MongoDB
· Tu as une première expérience du développement en équipe (ex : github, gitlab)
· Tu souhaites être un moteur dans la transition vers une économie circulaire locale
· Tu fais preuve d’autonomie et de proactivité, qualités essentielles pour vivre une aventure chez nous et dans le monde de la ressource, ce dont tu rêves bien sur
Ce que l’on fait pour toi
· Des feedbacks réguliers te seront faits et nous construirons ensembles ton projet professionnel
· Tu participeras à l’ensemble des meetings de direction d’iNex
· Tu découvriras nos méthodes de travail à la pointe de l’agilité !
· Tu acquerras en quelques mois une culture industrielle
· Tu seras stimulé aux côtés d’autres start-up de la Green Tech
Chez iNex Circular, nous avons à coeur de faire valoir l’autonomie, l’audace et l’engagement en faveur d’une économie responsable et circulaire. Si tu te reconnais là-dedans, envoies-nous ton CV pour nous convaincre.
Avantages :
Participation au transport
Application Deadline: 17/06/2020
Statut : Cadre
Type d'emploi : Temps plein, Stage
Salaire : 1 000,00€ /mois
Expérience:
Stagiaire/Projets Data Engineering ou Analyse: 1 an (Souhaité)
Formation:
Bac +4 (Maîtrise) (Requis)
Télétravail:
Oui"
Gennevilliers (92),Stage,,Stage R&D - Data Engineer / Internship Data Engineer (H/F),Stago,- Gennevilliers (92),"We, at the Optimisations & Methodologies are focused on data. We use it to deliver value on 3 types of projects: decision making support, data product and tools development and pure innovation. We are looking for an intern for at least 3 months to help us building a new interactive analysis tool.

Mission :
You will be in charge of developing a Shiny app that provides insight and guidance for maintenances operators and system investigators about machines' states and failures through data science tools and visualisations.

Responsibilities :

As lead developer for the app you will:
Gather user requirements,
Design a user interface,
Integrate a python module into the shiny app,
Implement datavisualisation features,
Research and implement automated diagnostics reports,
Develop and implement failure predictive models,
Organize user testing phases and gather feedback on the field.
Profil
You have a significant experience with R, Shiny and Git (Python is a plus),
You have an experience as data analyst and have data science notions,
You have UX and web design sensitivity,
You must speak fluent English and/or French,
You possess an open-mind to the ideas of others are able to offer creative solutions to problems."
Paris (75),,,Consultant(e)s Débutant(e)s en Data & Analytics et Innovation – Secteur financier (H/F),EY,- Paris (75),"Dans le cadre du développement en forte croissance de son activité ""Digital Entreprise Transformation"", leader du marché de la transformation digitale end to end et de l’innovation dans le secteur financier (Banque, Assurance, Prévoyance, Gestion d’actifs), EY recherche des Consultants débutants en Data & Analytics et Innovation, ayant eu une première expérience dans ce domaine.

L’opportunité
En travaillant dans une équipe en forte croissance sur les différents métiers Data & Analytics et Innovation, vous participez à des missions à forte valeur ajoutée auprès de nos clients en mettant en œuvre et en développant vos compétences en :
Data management (gouvernance, qualité, stratégie, GDPR),
Data science (advanced analytics, machine learning, deep learning),
Data tech (architecture big data, data lake, data hub)
Conseil en innovation (robotics, intelligence artificielle, cloud, blockchain, API, devops, design thinking).
Vous réalisez vos interventions au service de banques, de sociétés d’assurance ou de gestionnaire d’actifs de taille nationale ou mondiale et vous pourrez acquérir une expérience précieuse, bénéficiant de vastes possibilités de développement professionnel, tout en disposant de tout le soutien dont vous avez besoin pour atteindre votre potentiel.

Vos missions
Selon vos compétences, vous êtes amené à travailler sur des missions de conseil de:
Gestion & management de la donnée (gouvernance, gestion et optimisation de la qualité, stratégie d’utilisation de la donnée…)
Accompagnement des choix de plateformes technologiques data ou analytics et missions d’identification des meilleures architectures data
Développement d’outils d’aide à la décision ou d’outils de Business Intelligence dans les domaines du customer, du digital, de la tarification, de la conformité en utilisant des outils de visualisation de la donnée
Analyse de données en big data, programmation algorithmique, analyse prédictive (scoring, segmentation), data science & intelligence artificielle (Machine Learning, Natural Language Processing, Deep Learning…)
Automatisation et robotisation de processus de gestion de la donnée ou de processus analytiques

Votre profil
Diplômé(e) d’un master en data science ou data management, en technologie appliquée au big data, en mathématiques, en économétrie ou en statistiques ou diplômé(e) d’une école d’ingénieur ou d’une école de management, vous êtes attiré(e) par les challenges du métier de conseil et le travail en équipe dédiée au conseil en Data & Analytics et en Innovation.
Doté(e) d'un excellent sens relationnel, vous savez allier le sens de l'analyse et de la synthèse, rigueur et méthode.
Vous êtes dynamique, autonome et responsable.
Une connaissance du secteur financier est un plus.

Présentez-nous votre candidature, notre service recrutement est à votre service !
À propos d’EY
EY rassemble aujourd’hui 284 000 associés et collaborateurs à travers le monde dans plus de 150 pays. Grâce à ce réseau, dont le niveau d’intégration et l’ampleur internationale sont gages d’une même excellence partout dans le monde, EY renforce sa position de leader mondial de l’Audit, du Conseil, des Transactions, de la Fiscalité et du Droit. Nous faisons grandir les talents afin, qu’ensemble, ils accompagnent les organisations vers une croissance pérenne. Et notre engagement envers nos équipes commence avec cette promesse : quel que soit votre parcours avec nous, l’expérience EY dure toute une vie.

Si vous pouvez démontrer que vous répondez aux critères mentionnés ci-dessus, veuillez nous contacter dès que possible.
Vivez l’expérience EY, Rejoignez-nous !
Dans le cadre de sa politique Diversité, EY étudie, à compétences égales, toutes candidatures dont celles de personnes en situation de handicap."
Paris 18e (75),Stage,,Data Scientist (H/F) [STAGE],Hello Watt,- Paris 18e (75),"Détails de l'annonce
Le paysage énergétique français n’a pas évolué depuis des décennies, il est temps de le dépoussiérer. L’ambition d’Hello Watt est de créer LA plateforme qui révolutionne la façon dont on consomme de l’énergie, partout en Europe.Notre mission : changer et moderniser la manière dont les gens consomment de l’énergie chez eux et digitaliser ce marché au potentiel énorme mais inexploité.Grâce à Hello Watt, les particuliers identifient simplement les gisements d’économie d’énergie de leur logement. Ils accèdent ensuite à des professionnels sérieux et payent le prix juste pour leur énergie, leurs équipements énergétiques et leurs travaux de rénovation. En bref, Hello Watt les accompagne dans toutes les étapes de la transition énergétique de leur logement.
Avec plus de 60 personnes recrutées en 3 ans, Hello Watt ne compte pas s’arrêter là pour créer la plateforme de référence de l’énergie !
Tes Missions :
Hello Watt développe une plateforme de diagnostic énergétique permettant d'orienter les particuliers vers des actions d'économie d’énergie pertinentes. Intégré à l’équipe Data Science, tu seras au coeur du projet de R&D porté par Hello Watt:
Analyser les consommations d’énergie des particuliers en utilisant les données des compteurs communicants Linky et Gazpar respectivement déployés par ENEDIS et GRDF
Intégrer les données (données de consommation issues des compteurs communicants, données déclaratives, données tierces) à la plateforme Hello Watt
Participer à la conception et au développement de la plateforme de diagnostic énergétique
Profil recherché
Entreprenant et structuré tu es capable de mener un projet en choisissant les données pertinentes pour arriver à tes fins
Te retrouver avec une montagne de données à structurer ne te donne pas le vertige
Tu jongles avec les acronymes des algorithmes mais es capable d’expliquer en détail l’algèbre qui les constituent
Tu sais communiquer sur tes résultats et les mettre en valeur notamment avec de la dataviz
Python ne te pose aucun problème
Tu as un goût prononcé pour les belles choses ainsi que pour les défis individuels et collectifs.
Pourquoi Hello Watt?
Tu as envie de travailler sur de multiples projets où les mises en production de tes travaux sont rapides
Tu veux intégrer une Greentech travaillant sur un produit à la pointe en Europe
Tu veux utiliser la data pour proposer des services permettant de réduire l’empreinte carbone et les factures d’énergie
De plus …
Idéalement situé sur 2 lignes de métro, 1 ligne de tram, 3 lignes de bus et à trois pas de Gare du Nord/Gare de l’Est
Garage à vélos
After-Work réguliers
Terrasse et BBQ
Déroulement des entretiens :
Entretien téléphonique
Etude de cas
Entretien avec le Head of data, le CTO et un membre de l'équipe"
Paris 8e (75),"Temps partiel, Stage",,Stage Développeur Python / Data engineer,CapCar,- Paris 8e (75),"Chez CapCar, nous sommes convaincus qu’une bonne expérience client est indispensable et indissociable de notre réussite. Pour permettre à nos équipe de travailler le plus efficacement possible, nous construisons différents outils en interne. Afin de nous aider dans leur développement, tu rejoindras l’équipe Tech & Product CapCar. Celle-ci est composée de développeurs, de product managers et d’un Data Scientist, avec lesquels tu travailleras en étroite collaboration. Tu seras force de proposition sur les outils et process de traitement des données.
Tes missions au quotidien seront, entre autres :
Épauler notre Data Scientist dans l’élaboration et perfectionnement du modèles de données CapCar
Automatiser et optimiser les flux de collecte de données ainsi que le code existant
Identifier, proposer et tester des améliorations des pipelines d’ingestion de données
Développer de nouvelles briques qui s'intégreront à notre socle technique (nouvelles features, nouvelles technos, etc.)
Faire de la veille et documenter tes développements, et oui, c’est important
Plus généralement, collaborer avec les équipes tech au sein de CapCar

Profil recherché :
De formation supérieure, type École d’Ingénieurs ou Master en Informatique / Data Science, tu recherches un stage de fin d’études.
Tu maîtrises le langage de programmation Python, notamment l’orienté objet, et as de bonnes connaissances en SQL ainsi que des outils type Git ou Docker.
Tu connais également l’environnement cloud AWS (comme les services EC2, S3, etc.).
Enfin, humainement tu es passionné•e et curieux•se.

Déroulement des entretiens :
Le process de recrutement se déroule en 3 étapes :
Un premier entretien téléphonique pour faire connaissance
Un entretien technique chez nous ou en visioconférence
Et enfin un dernier entretien avec le CTO et l’équipe

Conditions :
Stage avec un démarrage ASAP, ça veut dire As Soon As Possible :P
Localisation : Paris 8ème"
Paris (75),,,Consultant en Data & Digital – 3/5 ans d’expérience,Eight Advisory,- Paris (75),"MISSIONS
Souhaitant renforcer ses capacités en ""advanced analytics"" et accélérer sa transformation digitale sous l'impulsion de recrutements externes, de savoirs faires développés dans les équipes métiers et de fortes capacités de modélisation, l'ambition de Eight Advisory est d'offrir un conseil toujours plus pertinent en utilisant les dernières technologies disponibles.
Rattaché au centre d'excellence ""Data & Digital"" qui combine des compétences fonctionnelles et techniques, vous serez en interface client au sein des équipes Eight Advisory. Vous participerez au développement et à la structuration du centre d'excellence. Pour cela, vous serez impliqué dans les domaines suivants :
Accompagner nos clients dans des missions complexes, combinant des aspects fonctionnels, Data & digitaux, dont les principaux objectifs sont l’amélioration et la sécurisation de la performance de l'entreprise (opérationnelle & financière) :
Participer à la définition de la stratégie et des modes opératoires des différents projets (approche, outils, méthodologie)
Manager les consultants techniques (Data Analyst et Data Scientist) afin de réaliser les missions avec des experts fonctionnels
Interagir avec les clients, que ce soit les équipes Data, IT et fonctionnelles pour sécuriser l'acquisition de données et la validation des résultats
Garantir, au cours des interventions, la qualité des conclusions, des messages et des visualisations associées
Présentation aux clients (CEO, CFO, Opérationnels) la synthèse de nos travaux
Accompagner nos clients dans l’internalisation des modèles/solutions développés
Participer au développement du centre d’excellence « Data & Digital »
Accompagner le développement de nos profils juniors
Construction d'actifs/modèles pour faciliter et optimiser la livraison des missions
Améliorer en continu le fonctionnement de l'équipe
Participer au recrutement des nouveaux talents
Participer au développement de la dimension « Data & Digital » en travaillant avec l’ensemble des départements pour proposer des offres combinées à nos clients :
Accompagner la montée en compétence de l’ensemble des collaborateurs sur les sujets data, visualisation et digitaux afin qu’il puisse identifier des opportunités
Participer au développement d’offres combinées avec les départements Transactions Services, Restructuring et Evaluation
PROFIL RECHERCHÉ
Diplômé(e) d’une école d’ingénieur ou d'une école de commerce, avec une spécialisation en statistiques ou en data science,
Excellentes capacités analytiques et de résolution de problèmes complexes
Agilité, curiosité, proactivité, ouverture, flexibilité et créativité
Expérience en conseil, dans l'analyse de données et capacité démontrée de gestion de projet et management de consultants juniors
Excellentes capacités de communication et fortes qualités relationnelles
Expérience en visualisation de données (Power BI, Tableau, QlikView, SpotFire)
Expérience en langages de programmation : SQL
Volonté de participer au développement d’une équipe en pleine croissance, goût entrepreneurial, volonté d'excellence
Volonté de participer de manière proactive au développement commercial
Français et anglais courant (écrit et oral)
Seraient un plus : Expérience en langages de programmation : Python
Mots-clés : Digital, data, data science, BI, transactions, Python, deals, transaction services, restructuring, transformation, analytics, stratégie, statistique"
Courbevoie (92),,,"Principal Consultant, Data Lake & Analytics",AWS EMEA SARL (France Branch),- Courbevoie (92),"Bachelor’s degree, or equivalent experience, in Computer Science, Engineering, Mathematics or a related field
10+ years of experience of IT platform implementation in a highly technical and analytical role.
5+ years’ experience of Data Lake/Hadoop platform implementation, including 3+ years of hands-on experience in implementation and performance tuning Hadoop/Spark implementations
Ability to think strategically about business, product, and technical challenges in an enterprise environment.
Experience with analytic solutions applied to the Marketing or Risk needs of enterprises
Highly technical and analytical, possessing 5 or more years of IT platform implementation experience.
Understanding of Apache Hadoop and the Hadoop ecosystem. Experience with one or more relevant tools (Sqoop, Flume, Kafka, Oozie, Hue, Zookeeper, HCatalog, Solr, Avro).
Familiarity with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto).
Experience developing software code in one or more programming languages (Java, JavaScript, Python, etc).
Current hands-on implementation experience required

Are you a Data Analytics specialist? Do you have Data Warehousing and/or Hadoop/Data Lake experience? Do you like to solve the most complex and high scale (billions + records) data challenges in the world today? Would you like a career that gives you opportunities to help customers and partners use cloud computing to do big new things faster and at lower cost? Do you want to be part of history and transform businesses through cloud computing adoption? Do you like to work on-site in a variety of business environments, leading teams through high impact projects that use the newest data analytic technologies? Would you like a career path that enables you to progress with the rapid adoption of cloud computing?

At AWS, we are hiring the best Data / Analytics cloud computing consultants, who can help our clients and partners derive business value from Data in the cloud. Our consultants will collaborate with partner and client teams to deliver proof-of-concept projects, conduct topical workshops, and lead implementation projects. These professional services engagements will focus on customer solutions such as Machine Learning, IoT, batch/real-time data processing, Data and Business intelligence. This role will specifically focus on Data processing capabilities and helping our customers and partners to remove the constraints that prevent our customers from leveraging their data to develop business insights.

Responsibilities include:

As Principal Consultant you will develop strategy across multiple projects and teams, and influence broadly.

You will work as trusted senior advisor at the CxO/VP level or equivalent, both internally and externally. You will engage directly, and in broad one-to-many forums, providing leadership to cross-functional initiatives and account teams, helping to secure new opportunities and address complex blocker. You will influence industry-thinking, directly and through others, on leading-edge approaches and best practices.

As a member of the Principals of Amazon (PoA) community, you will be a force-multiplier and enable new levels of agility, speed and scale for customers, partners and internal teams. You will consistently grow and improve customer business outcomes for multi-national, complex and long-running operations.

As a senior Amazonian leader, you will increase, directly and through others, business and technical innovations that will influence broadly throughout whole industries and deeply in technical domains. You will personally generate unique and commercially valuable IP that enables patents, products and services.

Amazon aims to be the most customer centric company on earth. Amazon Web Services (AWS) provides a highly reliable, scalable, low-cost infrastructure platform in the cloud that powers critical applications for hundreds of thousands of businesses in 190 countries around the world.

This is a customer facing role. You will be required to travel to client locations and deliver professional services when needed.

Experience in a Distinguished Engineer, Chief Data Officer role or similar
Masters or PhD in Computer Science, Physics, Engineering or Math.
Hands on experience leading large-scale global data warehousing and analytics projects.
Ability to lead effectively across organizations.
Understanding of database and analytical technologies in the industry including MPP and NoSQL databases, Data Warehouse design, BI reporting and Dashboard development.
Demonstrated industry leadership in the fields of database, data warehousing or data sciences.
Implementation and tuning experience specifically using Amazon Elastic Map Reduce (EMR).
Implementing AWS services in a variety of distributed computing, enterprise environments.
Computer Science or Math background preferred.
Customer facing skills to represent AWS well within the customer’s environment and drive discussions with senior personnel regarding trade-offs, best practices, project management and risk mitigation. Should be able to interact with Chief Marketing Officers, Chief Risk Officers, Chief Technology Officers, and Chief Information Officers, as well as the people within their organizations."
Boulogne-Billancourt (92),"Temps plein, CDI",,Data Analyste H/F,Solocal Group,- Boulogne-Billancourt (92),"Pagesjaunes.fr, avec plus de 20 millions de visiteurs uniques, est l'un des quinze principaux sites français en audience. Principale marque de Solocal, Pages Jaunes se positionne au second rang des régies françaises par le chiffre d'affaires, et au 6ème rang des régies Internet au niveau mondial.

Rattaché(e) à l'équipe connaissance client et au sein de la Direction Marketing Groupe, l'analyste de données a pour mission d'analyser l'ensemble des données que vont permettre produire et améliorer la connaissance client. L'objectif principal est d'identifier à partir de l'exploitation de la donnée les leviers pour favoriser l'acquisition, le développement et la rétention de nos clients.

Avec une vision 100% orientée client et de façon transverse avec les différentes directions de l'entreprise, l'analyste de données est un contributeur majeur à la réussite de la stratégie client Solocal.
Description des activités
Analyse de la base de données Clients et prospects
Gestion des fichiers avec l’extraction et croisement des données pour la mise en place de campagnes et actions commerciales
En relation directe avec les data scientistes et en mode Agile contribuer à la définition et structuration de la vision 360 de nos clients
Etudes Adhoc avec la direction commerciale et la direction produit
Profil
Titulaire d'un Bac + 5 avec une spécialisation en marketing ou en statistique, une expérience significative d’au moins 2 ans dans l’analyse de données marketing (stage compris).
Compétences attendues
Connaissance de R, Python, SQL.
Bonne maitrise d’Excel et power point
La connaissance de Marketing Cloud est un vrai plus
Orientation business avec une stratégie customer centric, rigueur et organisation, appétence pour l’apprentissage des nouvelles technologies et méthodes analytiques
Bon relationnel : capacité d'écoute et réactivité face aux demandes internes. Motivé(e), autonome, persévérant, proactif"
Paris (75),CDI,45 000 € - 55 000 € par an,Data Engineer,Neoxia,- Paris (75),"Mission
Au sein de la team DATA de Neoxia, tu travailleras sur des projets en lien direct avec la stratégie numérique de nos clients.

Ton champ d'action pourra être très large (en fonction aussi de ta capacité à être autonome et ta proactivité) : les membres de l'équipe sont à la fois architectes, développeurs et responsables qualité en contact quotidien avec nos clients.
Le Data Engineering sera au coeur de ton activité mais tu interviendras aussi sur de la Data Science et du DataOps.
profil
Diplômé(e) en ingénierie informatique
Plusieurs expériences 100% Data.
Dynamique et rigoureux (se) , tu as un bon relationnel. Tu es à la fois autonome et à l’écoute des autres.
Tu es passionné(e) de technologie et curieux(se) au sujet de l'évolution des pratiques d'ingénierie logicielle (Continuous Delivery, DevOps, ...).
compétences
Cloud : GCP (BigQuery, Bigtable, Dataflow...), AWS (S3, Lambda, Redshift, Glue, Athena...), Azure (ADLS, Databricks, Data Factory, Azure ML...)
Data engineering : Airflow, Spark (Python, Scala, Java), Kafka, Hadoop
En bonus : connaissances en machine learning"
Boulogne-Billancourt (92),CDI,,Consultant Data Analytics F/H,HEXALEAD,- Boulogne-Billancourt (92),"En île de France, HEXALEAD recrute des consultant Data Analytics

Dans le cadre de nos projets, vous serez amené(e) à :
Analyser des données et en extraire les informations essentielles. Vous avez une première expérience réussie le Data Mining ou le Machine Learning et vous maitrisez des langages d’analyse comme R ou des algorithmes statistiques.

Travailler avec des volumes très importants de données. Vous connaissez Hadoop, Hive, Pig, et les technologies Big Data.

Mettrez en œuvre des architectures modernes et hybrides de gestion de l’information.

Développer des solutions de Business Intelligence innovantes, liées aux nouveaux outils ou aux nouvelles pratiques.
Profil recherché Issu(e) d’une formation de niveau Bac+5, vous possédez de solides connaissances de Hadoop et des technologies Big Data, ainsi que des technologies Azure liées aux données (Azure Stream Analytics, Azure Data Factory, Azure Machine Learning…).

Vous maitrisez le développement .NET et/ou PowerShell et démontrez un fort intérêt pour les problématiques Data (Gestion de données ou Business Intelligence)

Idéalement, vous connaissez Power BI.

A bientôt !

L'équipe HEXALEAD
Entreprise Bonjour !

HEXALEAD est un cabinet de conseil intervenant dans le domaine industriel, et spécialisé en identification et mise en oeuvre de gains de compétitivité.

Nos activités sont basées sur 6 business lines portant nos expertises techniques et fonctionnelles, et accompagnent nos clients dans leur processus de transformation / transition industrielle.

Notre vocation est d'apporter une réelle valeur ajoutée à nos clients, et donner un sens complémentaire aux carrières de chacun de nos consultants en leur confiant un rôle de leader.

Rencontrez-nous pour en parler de vive voix !

Retrouvez-nous sur : www.hexalead.com"
Paris 10e (75),,,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong

Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),CDI,,Consultant Data Analytics (H/F),Azeo Talents & Technology,- Paris (75),"Dans le cadre de notre développement, la Practice Data & AI recherche ses nouveaux talents : des consultants spécialisés en BI (Business Intelligence) H/F. N’hésitez-pas à vous lancer avec nous dans cette nouvelle aventure !
Acteur de référence en France, AZEO est une société créée par des anciens Microsoftees, cultivant le talent de ses consultants et l’approche pluridisciplinaire. Chez AZEO, l’expertise rime avec passion, innovation et évolution. Aujourd’hui, nous sommes fiers d’être le 3eme partenaire de l’éditeur Microsoft en France.
AZEO fait également partie du palmarès des entreprises où il fait bon travailler ! Notre politique RH a notamment été reconnue par Great Place To Work et Happy Candidates. Très à l’écoute de nos équipes, nous veillons à conserver un management de proximité et favorisons l’esprit de communauté que ce soit dans nos événements techniques ou divertissants : AZTech, AZDrink, AZFun, AZterWork !
Rejoindre notre communauté d’experts, c’est à la fois développer son expertise technique et sa posture de conseil tout en travaillant aux côtés des meilleurs consultants Microsoft français.
AZEO est un employeur signataire de la charte de la diversité. Nous nous engageons à garantir le respect de la diversité au sein de nos effectifs ainsi que la lutte contre toute forme de discrimination.
Mission
Les missions qui seront confiées à nos consultants en Data Analytics seront réalisées dans les locaux de nos clients, intégrées aux équipes de développement locales ou directement dans les locaux d’AZEO.

Compétences
Une connaissance de Hadoop et des technologies Big Data
Une connaissance des technologies Azure liées aux données (Azure Stream Analytics, Azure Data Factory, Azure Machine Learning…)
Une connaissance des modules de BI classique de SQL Server (SSIS, SSRS, SSAS)
Intérêt pour les problématiques Data (Gestion de données ou Business Intelligence)
Des Bases en développement .NET et/ou PowerShell
Etre curieux et motivé pour apprendre davantage tous les jours
La connaissance de Power BI est un atout considérable
Une certification Microsoft associée à ces technologies apparaitra comme un plus pour votre candidature
Profil
Vous aimez les données et vous aimez les technologies Microsoft.
Vous aimez analyser des données et en extraire les informations essentielles. Vous êtes à l’aise avec des langages d’analyse comme R ou des algorithmes statistiques. Vous connaissez le Data Mining ou le Machine Learning. Vous vous reconnaissez dans le rôle de Data Scientist.
Vous avez l’habitude de travailler avec des volumes très importants de données. Vous connaissez Hadoop, Hive, Pig, et les technologies Big Data.
Vous souhaitez mettre en œuvre des architectures modernes et hybrides de gestion de l’information.
Vous souhaitez creuser tous ces sujets en développant des solutions de Business Intelligence innovantes, liées aux nouveaux outils ou aux nouveaux usages.
Vous vous reconnaissez dans cette description que ce soit par vos compétences actuelles ou celles que vous rêvez d’acquérir. Vous souhaitez vous dépasser, développer vos compétences et tendre vers l’expertise.
Vous voulez avancer, apprendre tous les jours au sein d’une équipe soudée et communicante, le tout dans une entreprise en plein développement."
Paris,40 000 € - 55 000 € par an,,Développeur Python | Secteur de l’énergie & big data,In-Team,- Paris,"Vous recherchez un nouveau challenge Python avec de fortes problématiques data science ?
Alors, rejoignez cette société spécialiste de la gestion énergétique au sein de parcs immobiliers !
Existant depuis plus 3 ans, cette entreprise développe une solution Saas qui, à travers la collecte de grande quantité de données, propose des solutions innovantes et impactantes d’optimisation énergétique. Vous l’aurez compris, au cœur de ce projet : la data.
Leurs clients ? JCdecaux, Picard, les plus grands groupes bancaires… leur font déjà confiance
Venant de lever 2.5 millions d’euro, il recherche pour renforcer leur équipe technique de 5 personnes, un développeur Python afin de travailler sur le développement back-end de leur solution, mais également sur la manipulation de grandes quantités de données.
La stack technique ? Python (Flask) ; JS (VueJS) ; MongoDB ;
Vous êtes curieux d’en savoir plus ?

Votre mission :
Au sein de cette entreprise d’une trentaine de personnes, vos missions seront :
Développement en Python – Flask et JS – VueJS
Créer l’architecture des applications : distribuée, redondante et durable
Configurer et utiliser des données sous SGBD non relationnel (MongoDB, Redis, InfluxDB)
Travailler sur la manipulation de grandes quantités de data
Monter en compétence sur du management (sélection, formation et encadrement des profils juniors)
Veille technique
Votre profil :
Bac +5 école d’ingénieur
2-5 ans d’expérience en développement Python / JS
Vous êtes exigeant sur la qualité de votre code et l’architecture logiciel car c’est quelque chose que vous jugez important
Opportunité :
Travailler sur un poste hybride avec des problématiques de développement et de data science
Être en contact direct avec le top management de l’entreprise
S’épanouir au sein d’une structure pérenne avec un esprit startup, reconnue pour son innovation
Salaire et avantages :
40-55k€
Contrat en CDI
Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !
Si vous souhaitez avoir d’autres informations sur cette opportunité je vous invite à me contacter également."
Paris (75),CDI,,Consultant(e) Beijaflore Digital - Data,Beijaflore,- Paris (75),"Fondé en 2000, Beijaflore est un cabinet de conseil en stratégie digitale présent à l’international avec des bureaux à Paris, Bruxelles, Rio de Janeiro, Sao Paulo et New York. Il regroupe plus de 1250 collaborateurs animés par une mission commune : accompagner de manière opérationnelle les entreprises dans la mise en œuvre de leur stratégie digitale.
Digital regroupe plus de 550 personnes en France qui accompagnent nos clients dans la réalisation et le déploiement de leur stratégie digitale. Aujourd’hui, plus de 70 clients nous font confiance pour repenser la digitalisation de leur fidélisation client ou encore transformer leurs infrastructures…
L’Offre Digital est structurée autour de 5 départements : Digital and Operational Consulting, Business Applications, Digital Enablers, IT Efficiency, Data.
Intégrer le département Data, c’est :
Grands programmes
Quelques exemples de programmes auxquels vous allez contribuer :
Pour la Data : Big Data, Gouvernance, BI, Analytics
Pour l’Innovation : Mise en place d’un chatbot, solutions d’automatisation de BPO, systèmes de maintenance prédictive pour les réseaux et les Data Centers, démarche de prévision de vente
Métiers
Quelques exemples de postes que vous allez occuper :
Data analyst, data scientist, data engineer, data manager (gouvernance)
Tech lead, expert BI, consultant machine learning, chef de projet intégration de solutions innovantes…
Environnements technologiques
Des environnements technologiques variés avec lesquels vous allez travailler :
Méthodologie : Agile, Lean Six Sigma, Cycle en V, UML, ITIL, DAMA – DMBOK, AB testing, CRISP
Outils/PF :
Bases de données : SQL / Oracle / MySQL / NOSQL / Teradata
Big Data : Hadoop, Spark, Splunk, MapReduce, Elastic Search  Data Science : Dataiku, Alteryx
Manipulation de données : Excel, Tableau Software, Qlikview, R, Python, VBA
EDI, ESB, ETL : Talend / Informatica ; Master Data Management (MDM)
Business Intelligence : powerBI, Snowflake
Vous souhaitez travailler sur la chaîne de valeur de la Data ? Vous impliquer sur les enjeux de stockage et de production ?
Vous êtes diplômé(e) Bac+5 d’une école d’ingénieurs ou de commerce spécialisé en Data. Pour les postes de Data analyst et de data engineer, vous justifiez d’une première expérience sur des projets liés à l’analyse de données métiers ou des projets liés au stockage et à l’exploitation de la donnée.
Pour le poste ingénieur IA, vous maîtrisez le Machine Learning, savez coder en Python et en R. Vous savez configurer les plateformes techniques en intégrant les données des clients, au travers d’algorithme.
Vous êtes curieux(se) et avez le goût de la relation client. Vous êtes persévérant(e), déterminé(e) et avez un fort esprit d’équipe."
La Défense (92),"Temps plein, Stage",,Stage 6 mois - Data Analyst - Mars 2020,AstraZeneca,- La Défense (92),"Nous recrutons un(e) :
Data Analyst au sein de la Direction Innovation et Business Excellence
Stage de 6 mois – à partir de mars/avril 2020
AstraZeneca
Fortement impliqué dans la recherche tant dans les molécules chimiques que dans le domaine des traitements biologiques innovants, avec un Chiffre d’Affaires de 21 milliards de dollars en 2017, AstraZeneca est un laboratoire pharmaceutique présent dans plus de 100 pays.
Chaque jour les collaborateurs d’AstraZeneca cherchent, trouvent et commercialisent les traitements d’aujourd’hui et de demain. C’est cet environnement et cette formidable aventure que nous vous invitons à partager aujourd’hui.
Vos missions :
En tant qu’apprenti(e) au sein de l’In-Field Effectiveness (IFE), vous serez en soutien des IFE Business Partners dans l’optimisation de la performance de la filiale française. Vous collaborerez avec les équipes IFE, Multicanal, CRM et IT.
Votre périmètre intégrera les réseaux de visite médicale, des autres canaux de communication innovants à destination des professionnels de santé, ainsi que des données relatives à l’équipe Medical Excellence.
Vous participerez notamment aux projets suivants :
Scoping :
Analyser les besoins côté business en collaboration avec les équipes IFE et Multicanal
Auditer la donnée et les outils disponibles avant le lancement du projet (données de ventes, d’activité, de ciblage ; données médecins, pharmaciens ou patients…)
Collecter le feedback Terrain et Siège sur les outils actuellement utilisés
Phase exploratoire :
Rechercher d’autres sources de données pertinentes en interne et en externe
Data cleansing des sources de données retenues
Faire évoluer les outils existants via création / utilisation d’algorithmes
Proposer de nouveaux outils / visuels à mettre en place
Phase d’industrialisation :
Mettre en place ces solutions techniques de traitement de la donnée, de développement d’algorithmes et de programmes de traitement de données sur des projets récurrents ou ad ’hoc à partir des bases de données retenues
Définir et créer des rapports / dashboards en collaboration avec l’équipe SFE
Mettre en place les process et les data flows nécessaires au bon fonctionnement des outils développés
Documenter l’utilisation des bases de données et des outils développés
Votre profil :
Formation de niveau Bac + 4 à Bac + 5 dans le domaine de l’ingénierie informatique, du marketing, des études statistiques et/ou grande école d’ingénieur
Maitrise des outils Microsoft Office (Word, Power Point, Excel, Access)
Maitrise des outils de Business Intelligence (traitement et analyse des données)
Connaissances dans le développement d’application Business Intelligence: manipulation de données / restitution
Intérêt développé pour les solutions de traitement du big data et pour les solutions innovantes
Esprit analytique, rigueur et créativité.
Passion ou volonté de se développer dans la compréhension des enjeux de la santé, des patients
Volonté de contribuer à l’analyse du marché des médicaments et autres produits de la santé.
Aisance dans la communication orale et écrite
Bonne maîtrise de l’anglais
Esprit collaboratif et capacité à mobiliser des équipes transversales.
Des connaissances et/ou expériences dans l'un des domaines suivants seraient un plus :
Connaissance approfondie du domaine de la santé
Expérience dans les études sur bases de données
Expérience dans les études de santé et patients
Connaissance des bases de données publiques de la santé
Expérience dans le développement et l’exploitation de base de données, du big data
Connaissances dans le développement d’application BI : manipulation de données / restitution
Langage(s) SQL et/ou de programmation"
La Défense (92),CDI,,Data Analyste Sénior F/H,Orange,- La Défense (92),"Description
Le centre de compétences Data Science, fait partie de l'entité Data d'OAB, entité d'Orange Business Services dédiée aux services aux entreprises.
Notre équipe de 30 personnes, réalise des projets en data science, analysées de données, data ingéniérie, machine learning, pour nos clients, essentiellement des grandes entreprises, en France, ainsi que d'autres entités du groupe Orange.
L'équipe est structurée avec 5 data analyst seniors, qui encadrent les projets et les analystes juniors dans le cadre de projets Big Data ou Data Science, gèrent la relation avec le client, les présentations et s'assurent de la bonne conduite des projets et des analyses.
A ce titre, nous cherchons un ou une data scientist/data analyst senior. Ce rôle est similaire à celui d'un lead data scientist.
Le/la data analyste senior a pour objectif de délivrer des prestations de qualité en analyse de données, de mettre en place les datamart nécessaires à la réalisation des analyses, de piloter un projet dont les analyses sont réalisées par des data scientists juniors, dont il a la charge sur le projet, et de proposer des prestations complémentaires à son client.
Contenu de l'activité :
Conduite de projets data et réalisation de projets data science
Le/la data scientist senior a en charge les projets big data, sur la partie analyse, qui peuvent être sous forme de PoC (quelques jours) ou de missions plus longues (plusieurs mois)
Il/elle est garant des livrables et du timing des projets.
Met en forme les livrables mettant en valeur les travaux auprès des clients
Répond à une problématique métier par des analyses statistiques, des segmentations, scoring
Adapte le niveau de complexité de la réponse au cahier des charges clients
Rend compte au responsable de centre de compétences des succès et difficultés sur les projets
Travaille en transverse avec les autres centres de compétences (architecture big data, data visualisation …)
Capacité à gérer plusieurs projets de manière concomitante
Encadrement et management de data scientists juniors
Le/la data scientist senior veille à la bonne montée en compétences des juniors, et à la qualité des analyses et travaux qu'ils réalisent.
Planifier sa charge de travail et celles des analystes positionnés sur les projets dont il a la charge
Production et réalisation de travaux en data science
Le/la data scientist travaille sur les problématiques les plus complexes, qui ne peuvent pas être gérées par les juniors.
Il est lui/elle aussi en production, et réalise des analyses
Les langages privilégiés sont R, Python ou Scala. Nous utilisons Dataiku et ELK de manière croissante.
Capacité à convaincre un client et à interagir avec les équipes métiers ou data
Le/La data scientist senior est régulièrement en face des clients, pour proposer de nouveaux travaux, présenter les analyses réalisées.
Propose des lots complémentaires d'analyse sur les projets en cours
Détecte
about you
Profil :
Diplômé(e) d'un bac+5 d'une école d'ingénieur, vous avez de l'expérience en data mining / data analyse /data science / projets big data / projets en data science.
Vous êtes à l'aise dans la manipulation de bases de données et dans l'utilisation de la suite office, et la formalisation des résultats sous power point.
Connaissance en programmation SAS, R, Python
Capacité à communiquer en interne et vers les clients
Capacité à travailler en collaboration, en transverse.
Niveau min requis :
4 ans d'expérience
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Paris (75),,,DATA ENGINEER / ARCHITECT (H/F),Suricats Consulting,- Paris (75),"Si là où certains ne voient que des bases de données et des flux vous voyez des écosystèmes critiques à développer au cœur des entreprises, notre poste d'Ingénieur Data est fait pour vous.
Ingénieur ou autodidacte passionné vous avez acquis des compétences solides en travaillant opérationnellement plusieurs années sur des projets en liaison avec la gestion et la valorisation des données.
Nous recherchons des Data Engineers et des Data Architects
La maîtrise de la donnée, sa manipulation et sa gestion sont au cœur des préoccupations et des projets innovants de nos clients. Nous recherchons des ingénieurs et architectes de la donnée pour les accompagner et les aider à faire évoluer leurs systèmes d'informations.
Issu d'un parcours qui vous a amené à évoluer « opérationnellement » dans des environnements d'exploitation et de gestion des données différents, vous êtes familiarisés avec les principales approches et technologies du marché.
Vous cochez à minima 3 des compétences suivantes :
Mise en œuvre des différents schémas de base de données y compris les graphs
Maîtrise d'une des architectures de traitement temps réel
Connaissance pratiques de l'offre data, analyse et machine learning d'un des acteurs cloud du marché.
Expert SQL avec un minimum de notion sur un autre language (Python, Java, C#, R …)
Notions pratiques de machine learning et d'intelligence artificielle
Design d'architecture de données performant (Modèle + Infra)
Champion des batches et traitements ETL
Au-delà de ces atouts, vous avez surtout à cœur d'intervenir sur les systèmes d'informations complexes d'acteurs majeurs du retail et de la banque, de vous challenger et de croiser vos pratiques avec celles des autres. En bref, envie de nous rejoindre…
Mais pas que… En tant que membre de la tribu, vous participez :
A la veille
aux projets d'expérimentation menés au sein de notre LAB interne
à la communication (article, intervention, … )
à l'organisation des meetups technique (ML, Data temps réel,…)
à la dynamique Suricats (événements internes, MBA, …)
aux activités commerciales,
…
Les activités de votre futur quotidien (entre autres)
Diagnostic et audit
Optimisation de chaine de valorisation de la donnée
Design d'architecture
Définition et implémentation de traitement temps réel Optimisation des performances"
Paris (75),,,Consultant Data & Digital – Analyste,Eight Advisory,- Paris (75),"MISSIONS
Souhaitant accélérer sa transformation digitale et le renforcement de ses capacités en ""advanced analytics"" sous l'impulsion de recrutements externes, de savoirs faires développés dans les équipes métiers et de fortes capacités de modélisation, l'ambition de Eight Advisory est d'offrir un conseil toujours plus pertinent en utilisant les dernières technologies disponibles.
Rattaché au centre d'excellence ""Data & Digital"" qui combine des compétences fonctionnelles et techniques, vous serez en interface client au sein des équipes 8 Advisory. Vous participerez au développement, à la structuration et à la montée en compétence du centre d'excellence. Pour cela, vous serez impliqué dans les domaines suivants :
1 – Accompagner nos clients dans des missions combinant des aspects fonctionnels, Data & digitaux, dont les principaux objectifs sont l’amélioration et la sécurisation de la performance de l'entreprise (opérationnelle & financière) :
Accompagner votre manager dans la définition de la stratégie et des modes opératoires des différentes projets
– Garantir la qualité technique et méthodologique de l'intervention notamment sur les aspects extraction et préparation de la donnée
– Accompagner nos clients dans l’internalisation des modèles/solutions développés
2 – Participer au développement du centre d’excellence « Data & Digital » en travaillant avec l’ensemble des départements pour proposer des offres combinées à nos clients :
– Accompagner la montée en compétence de l’ensemble des collaborateurs sur les sujets data, visualisation et digitaux afin qu’il puisse identifier des opportunités
– Participer à la réalisation de projets avec les équipes des départements Transactions Services, Restructuring et Evaluation
PROFIL RECHERCHÉ
Vous avez un Bac +2/3 STID ou informatique de gestion avec une première expérience réussie dans des projets Data
Connaissances en langages liés aux bases de données (SQL) et sur les outils de l’écosystème BI de MICROSOFT (SQL Server, Power Query, Power Pivot, Power BI)
Maitrise d’un logiciel de data visualisation (Power BI, Tableau, QlikView, SpotFire)
Excellentes capacités analytiques et de résolution de problèmes complexes
Agilité, curiosité, proactivité, ouverture, flexibilité et créativité
Connaissance en langages de programmation : Python
Volonté de participer au développement d’une équipe en pleine croissance, goût pour l’entrepreneuriat
Anglais niveau professionnel
Seraient un plus : Connaissances en Finance d’entreprise
Mots-clés : Digital, data, data science, data analyst, BI, transactions, SQL, Python, deals, transaction services, restructuring, transformation, analytics, stratégie."
Paris (75),CDI,,Consultant Data et Machine Learning,Nexworld,- Paris (75),"Missions principales
Le Consultant Data a globalement pour mission de construire des solutions prenant en compte une masse importante de données avec des technologies telles que Spark pour le traitement Big Data, NoSQL pour les bases de données et Hadoop pour les infrastructures Big Data.
Il doit s’assurer de la collecte, du stockage et de l’exploitation fluides des données en développant des solutions qui peuvent traiter un gros volume de Data dans un temps limité. Il doit avoir un intérêt pour le développement et les opérations (DevOps).
Il peut avoir une double compétence en Machine Learning, c’est à dire qu’il doit être capable d’implémenter des algorithmes (imaginés par les Data Scientists ou sur étagère) dans un contexte Big Data où les exigences en matière de volume et de scalabilité sont fortes.
Compétences principales
Data
Frameworks Big Data : Hadoop (HDFS, Map reduce), Spark, Hive, HBase, Ozzie, Pige, Impala
Frameworks de traitement temps réel : Kakfa, Kafka Stream, Flink, Spark Streaming, Samza
Bases de données NoSQL : Cassandra, MongoDB, Redis, CouchBase, Neo4j
Search : Elastic, Solr
Solutions éditeurs: Horton Works, Cloudera, MapR, Trifacta, Attunity
Cloud :
Azure: HD Insight, Data Factory, DataBricks, CosmosDB
Google : Cloud Storage, Big Table, Big Query, DataFlow, DataProc
Amazon: EMR, Kinesis, Redshift, DynamoDB
Machine Learning
Connaissances liées à l’implémentation à l’échelle et à l’industrialisation des algorithmes de Machine Learning :
Frameworks : Apache Spark MLlib & ML, Tensorflow, Keras, Caffee, Mahout
Connaissance théorique des algorithmes et technique de Data Science permettant de travailler avec les Data Scientists
Compétences additionnelles souhaitées
Bonne maîtrise du développement sur les langages : Java, Python, Scala
Connaissance du système Linux
Avoir une connaissance des architectures Big Data et du Système d’Information
Qualités recherchées
Capacité à travailler en équipe
Avoir un bon relationnel, aisance orale
Ouvert d’esprit et curieux
Communiquer en anglais à l’écrit et à l’oral
Aimer partager
Attitude Conseil
Postuler
Le poste
Poste en CDI, basé à Paris,
Statut Cadre.
De formation Bac+5 (école d’ingénieurs, formation universitaire) vous justifiez d’une expérience d’au moins 3 ans dans un poste similaire et idéalement au sein d’une société de conseil en nouvelles technologies.
Vous disposez d’un solide bagage technique et vous êtes passionnés par les projets à forte dominante technologique. Vous disposez d’une culture SI large et généraliste, avec nécessairement des compétences diverses. Vous êtes capable de descendre dans l’applicatif tout en gardant une vue globale du SI."
Issy-les-Moulineaux (92),CDI,,DATA ENGINEER H/F,BNP Paribas,- Issy-les-Moulineaux (92),"DATA ENGINEER H/F (NUMÉRO DE L'EMPLOI : REAL_ESTATE20_0309_2)

Leader européen de services immobiliers, BNP Paribas Real Estate couvre l’ensemble du cycle de vie d’un bien : Promotion, Investment Management, Property Management, Transaction, Conseil et Expertise.

Avec plus de 5400 collaborateurs, BNP Paribas Real Estate accompagne localement propriétaires, locataires, investisseurs et collectivités dans 36 pays (15 via ses implantations et 21 via son réseau d’alliances) en Europe, Moyen Orient et Asie.
Poursuivant sa croissance, BNP Paribas Real Estate a acquis en 2017 Strutt & Parker, l’un des principaux acteurs indépendants du marché immobilier au Royaume-Uni. En 2018, BNP Paribas Real Estate a réalisé 968 M€ de revenus.

BNP Paribas Real Estate est une société du Groupe BNP Paribas
Pour plus d’informations : www.realestate.bnpparibas.fr

Nous recherchons dans le cadre d'un CDI, un(e) :

Data Engineer H/F
Poste en CDI - basé à Issy-les-Moulineaux (92)

A ce titre, vos missions sont les suivantes :
Identifier et mettre en œuvre des moyens pour améliorer la qualité et la fiabilité des données ;
Automatiser des process manuels afin d’accumuler et organiser les données rapidement ;
Mettre en place, entretenir et maintenir le pipeline de data. Rendre les données accessibles aux data scientists et aux data analysts ;
Collaborer étroitement avec les data scientists afin de mettre en production les modèles de ML ;
Proposer des architectures data adaptées aux besoins de différents projets en collaboration de la DSI ;
Dans un contexte à forts enjeux de migration de plateforme cloud : accompagner la DSI dans la migration des données, transposer les traitements et les use cases dans un nouvel environnement
Participer au développement de nouvelles fonctionnalités sur la nouvelle plateforme selon la courbe de maturité ;
Assurer une veille, et surtout de vous former et former les autres.

Environnement de Travail :
Vous serez rattaché(e) à un Chief Data Scientist et intégré(e) au sein d’une équipe de 4 personnes passionnées et motivées avec un esprit d’initiative.

Le département « Data Science & Analytics office » est amené à jouer un rôle clé dans la maîtrise du cycle de vie de la donnée et dans la conception des solutions transverses aux lignes de métiers, aux fonctions et aux pays.

Apports de la mission :
Riche en diversité et en échanges avec les différentes lignes de métier, fonctions et différents pays, ce poste vous permettra d’instaurer une relation de confiance auprès de vos interlocuteurs, tout en développant vos compétences techniques dans l’apprentissage de sujets différents. La promesse de travailler sur des sujets innovants et variés !

Profil recherché :
Vous disposez d’une formation Bac+5 école d’ingénieur ou équivalent, et d’une expérience d'au minimum 3 ans en tant que data engineer.

Vous parlez anglais couramment.

Compétences techniques :
Solide connaissances et expériences en bases de données SQL et NoSQL (Oracle, Postgre, Cassandra, MongoDB…)
Maitrise parfaite de python et d’autres langages de programmation (scala, java …)
Plusieurs expériences en environnement cloud : Azure, Amazon (EMR, EC2, Athena, databricks…)
Maitrise des architectures distribuées, et du fonctionnement de l'environnement BigData (Hadoop, Spark, Hive, Pig, Impala)
Mise en place de modèles machine learning en production
Connaissances avancées en sourcing de données venant aussi bien de sources internes que d’API externes
Outils de virtualisation et container
Bonne culture générale (méthodologies agiles, environnements, intégration continue)
Connaissance de Tableau
Grand intérêt pour la science des données
Capacité à estimer la complexité des tâches techniques.

Compétences comportementales :
Rigueur
Capacité à collaborer
Capacité à synthétiser
Capacité à décider
Ecoute active"
Paris (75),"Temps plein, CDI",,DATA SCIENTIST,Homeys,- Paris (75),"DESCRIPTIF DU POSTE
Nous recherchons aujourd’hui un data scientist pour :
Affiner les algorithmes de machine learning qui font le lien entre température intérieure, température extérieure et consommation énergétique du bâtiment
Développer des algorithmes de clustering pour regrouper les logements qui ont des caractéristiques similaires,
Faire des analyses statistiques sur la performance énergétique et environnementale du parc immobilier français.
PROFIL RECHERCHÉ
Solides connaissances et statistiques et en machine learning,
Python (pandas, scikit-learn),
MongoDB, PostgreSQL,
Git.
INFORMATIONS COMPLÉMENTAIRES
Type de contrat : CDI
Date de début : 01 septembre 2019
Lieu : Paris, France (75006)
Niveau d'études : Bac +5 / Master
Expérience : > 6 mois"
Paris (75),CDI,,Graphène Advisory - Data Scientist,Beijaflore,- Paris (75),"Fondé en 2000, Beijaflore est un cabinet de conseil opérationnel en stratégie digitale présent à l’international avec des bureaux à Paris, Bruxelles, Rio de Janeiro, Sao Paulo et New York. Il regroupe plus de 1250 collaborateurs animés par une mission commune : accompagner de manière opérationnelle les entreprises dans la mise en œuvre de leur stratégie digitale.
Avec son entité Graphène Advisory, Beijaflore accompagne les entreprises dans la valorisation de leurs données par des projets d’Intelligence Artificielle. En proposant des solutions complètes, partant de l’identification des use cases au développement de la solution et son déploiement, Graphène Advisory amène les entreprises à créer leurs business de demain. Ces solutions sont basées sur du Machine Learning et l’IA articulés sur des architectures flexibles, modulaires et scalables appelées architectures Big Data.
Vous souhaitez rejoindre une équipe multidisciplinaire et complémentaire qui accompagne ses clients dans la réalisation de projets autour de l’IA et du Machine Learning ?
En tant que Data scientist, vous êtes en charge des traitements analytiques avancés répondant à des cas d’usage transverses en fonction du client. Vous avez pour objectif de tirer le meilleur parti de l’analyse de données massives et variées disponibles chez le client.
Vous avez également un rôle de conseil et d’accompagnement dans l’utilisation des résultats de ces traitements analytiques.
Vos enjeux : choisir et mettre en place des modèles innovants pour des systèmes de recommandation, des prévisions, de l’analyse de bout en bout de l’expérience client, de la reconnaissance d’images et de l’analyse sémantique….
Vous êtes plus particulièrement amené(e) à :
Comprendre les problématiques des directions métiers des différents clients et proposer une résolution fondée sur des approches analytiques (algorithmes).
Organiser les données massives, structurées ou non structurées, internes et externes, et construire les jeux de données nécessaires à la modélisation.
Construire des modèles analytiques qui permettent de répondre à la problématique client et accompagner la mise en production des modèles avec les équipes IT.
Formaliser des recommandations et restituer les résultats aux métiers.
Diplômé(e) d’une Grande Ecole d’ingénieur ou d’une Université en Mathématiques Appliquées, Statistique ou Informatique (Bac+5 ou PhD) avec une spécialisation en Data science. Vous justifiez d’une première expérience en tant que Data Scientist, éventuellement acquise lors de votre stage de fin d’études. A cette occasion vous avez développé une ou plusieurs des compétences suivantes :
Machine Learning, Deep learning (image et son), Text mining, Optimisation sous contraintes, Analyse en séries temporelles …
Et vous avez évolué dans un environnement utilisant (en fonction des clients) :
Les langages Python et/ou R (Scala ou Matlab)
Des outils du Big Data (Hive, Impala, Spark)
Vous faites preuve de rigueur scientifique, d’autonomie et d’un fort esprit d’équipe.
Doté d’une bonne expression orale et écrite, vous avez développé une réelle capacité de vulgarisation des sujets techniquement complexes et vous souhaitez évoluer au sein d’un environnement innovant et dynamique ?
Rejoignez-nous !"
Paris (75),"Temps plein, CDI",,Machine Learning Engineer – Deep Learning / TensorFlow / C++ / Python,USA Recruitment,- Paris (75),"Strong background in Machine Learning?

Familiar with Deep Learning algorithms and Machine Learning frameworks?

Machine Learning Engineer

European Recruitment are working closely with a leading Tech company, based in the Paris, who are looking for a talented Machine Learning Engineer to join their team.

In this role you will be joining a group of engineers passionate about innovation and turning disruptive ideas into products that impact the industry at large.

You will:
– Have experience architecting, building, developing and scaling ML systems
– Excellent software development and scripting skills C/C++/Java/Python
– Experience with real time processing of image and/or large amounts of sensor data
– Hands on experience with micro-service architecture (Docker/Kubernetes) and ML libraries (Scikit-Learn, TensorFlow, Keras)

If this role is of any interest please apply directly on LinkedIn or send a copy of your CV to nh@oldeu-clone.local

Key Words: Machine / Learning / Engineer / Deep / C++ / Python / Java / TensowFlow / Keras

By applying to this role you understand that we may collect your personal data and store and process it on our systems. For more information please see our Privacy Notice https://oldeu-clone.local/about-us/privacy-notice/"
Suresnes (92),CDI,,Data Engineer F/H,KERTIOS CONSULTING,- Suresnes (92),"Le Data Engineer participe à l’évolution et l’optimisation du système d’information décisionnel existant. Il conçoit et met en œuvre des plateformes basées sur des technologies Big Data.

Si vous souhaitez…

Travailler directement auprès des Directions Métiers (Commerciale, Marketing, Ressources Humaines, Finance, Risque, Informatique)

Accompagner ces directions dans la définition de leur stratégie d’exploitation des Big Data ainsi que dans sa déclinaison opérationnelle

Participer à des projets de transformation d’envergure à forte valeur ajoutée.

Alors pourquoi pas vous ?
Profil recherché Vous êtes motivé et dynamique ? Vous possédez d’excellentes capacités de communication ainsi qu’un sens développé du service ?

De formation Bac+5, vous disposez d’un profil ingénieur informatique et avez déjà réalisé des projets ou missions « Big Data » participant à ce grand virage dans le monde du décisionnel.

A l’aise dans l’utilisation des nouvelles technologies (écosystème Hadoop, Scala, Python, Shell, Linux, Unix) et ayant acquis de très bonnes connaissances des bases de données (SGBD comme Oracle, PostGre, MySQL,… ou NoSQL comme Hive, Hbase, Impala, Cassandra, …), vous bouillonnez d’idées et aimez les mettre en application.

Hadoop : ⭐⭐⭐

Base de données : ⭐⭐⭐⭐

Data prep : ⭐⭐⭐⭐

N’hésitez plus, rejoignez-nous !
Entreprise KERTIOS

est une société de conseil en management et en informatique, spécialisée dans la gestion du capital humain et la mise en œuvre d'applications packagées. Nos clients sont des entreprises internationales prêtes à transformer leurs processus pour atteindre les meilleures pratiques dans leur domaine. Notre accompagnement se fait dans toutes les phases de leur transformation, de la stratégie à la mise en œuvre.

Les ""Plus"" KERTIOS Consulting :
Développer une triple compétence : métier, projet et système d’information en évoluant au cœur de projets complexes et ambitieux, accompagné par nos consultants seniors experts

Evoluer au sein d’une société qui exige le meilleur de ses collaborateurs tout en cultivant la cohésion et l’esprit d’équipe"
Paris (75),"Temps plein, CDI",50 000 € - 60 000 € par an,Data Scientist / Engineer – Secteur Ecologie,UNLCK,- Paris (75),"Contexte
Vous avez une expérience professionnelle significative dans la Data ? Travailler dans une entreprise dont l’activité est étroitement liée à l’environnement vous motive tout particulièrement ?
Rejoignez cet important acteur dans le secteur de l’écologie. Leur objectif ? Conseiller et accompagner les entreprises afin de réduire leur impact sur l’environnement.
Basée en plein centre de Paris, la société cherche à intégrer un nouveau Data Scientist en CDI pour accompagner sa croissance.
Responsabilités
Au sein de l’équipe technique, vous interviendrez sur les projets suivants :
Designer et intégrer un Data Lake et un Data Warehouse
Assurer la collecte et le traitements de données (outils d’aide à la décision)
Assurer la qualité et sécurité des données utilisées
Participer à la mise en place de processus d’automatisations
Technologies : Python, BI, Talend, Apache, Hive, Hadoop, Spark
Profil
Vous avez une expérience significative sur un poste similaire
Vous maîtrisez les concepts de Data Warehouse et Data Lake
Vous savez faire preuve d’autonomie mais également collaborer au sein d’une équipe Agile
Vous êtes sensible au domaine de l’écologie/environnement
Vous avez un bon niveau d’anglais (écrit + oral)
Avantages
Locaux situés au cœur de Paris
Environnement de travail spacieux et agréable
Nombreux challenges techniques
Société référente sur son marché
Type d'emploi : Temps plein, CDI
Salaire : 50 000,00€ à 60 000,00€ /an
Expérience:
data scientist / engineer – secteur ecologie ou similaire: 3 ans (Souhaité)
Télétravail:
Temporairement en raison du COVID-19"
Paris (75),,,Python Data Engineer,keepitup,- Paris (75),"About Company
They are a Marketing platform built with the latest technology. They use technologies as Kubernetes, Docker, Presto, Python ML frameworks, Elasticsearch or React.
Their SW is a mix between Python and Scala, designed for cloud and deployed on AWS.

Their solution processes and analyzes hundreds of terabytes of data every day from clients across 13 countries. It runs dozens of powerful and carefully designed machine & deep learning algorithms.
What will you do?
Being part of our engineering team, focused on data backend.
Improve the quality, reliability and scalability of their stack
Work on data preparation over TB sized datasets
Improve predictive models by a processing pipelines made by you
You will work with great Data Scientists, DevOps, Fullstack engineers..

If you have...
At least 2 years of experience in Python coding with a taste for simplicity, efficiency and pragmatism
You are dedicated to write software that ships and works your production-ready code is clean, scalable, and maintainable
You are experienced in deploying business code on an orchestration framework (Airflow, Kubeflow, Apache Beam...)
You are at ease with a data transformation framework (PySpark…)
Capacity to work autonomously keeping team player mindset and a great curiosity
... this job is made to you, so... please, keep reading!

If you also have...

An experience with a modern Deep Learning framework (PyTorch, TensorFlow, Keras…)
Being a contributor to mainstream Open-Source projects
Taste for working in a genuine scientific environment
... Just apply, and ¡let's talk!"
Paris (75),CDI,,Data Ingénieur H/F,Extia,- Paris (75),"Vous souhaitez rejoindre une entreprise qui place l’humain au cœur de ses préoccupations ? On vous attend chez Extia !
Société de conseil en ingénierie, Extia propose depuis 2007 une approche inédite dans son domaine en alliant bien-être au travail et performance. Un modèle qui fonctionne : plus de 2000 Extiens répartis en France et en Europe, 2ème au palmarès Great Place To Work France en 2019, 180 M€ de chiffre d’affaires et une énergie sans limite !
Chez Extia, c’est « D’abord qui, ensuite quoi ! » alors, allons-y !
D’abord qui ?
D'un naturel organisé, vous êtes une personne autonome et force de proposition.
La Data n'a pas de secret pour vous !
Vous disposez de connaissances fines en gestion des données sur Cloudera
Vous souhaitez vous investir au sein d'une structure dynamique en pleine évolution.
Profil recherché
Ensuite Quoi !
Au sein du service Data Science, vous êtes en charge de :
- Accompagner les équipes et les projets avec l’utilisation de technologies Big Data,
- Coordonner l’ensemble des activités opérationnelles de gestion des données concernant différents projets basés sur Cloudera,
- Assurer la compliance réglementaire de Data Privacy sur l’ensemble des données.
Votre profil :
Vous maitrisez l'environnement Hadoop, Hive, Impala, Kudu, HBase.
Vous disposez impérativement d'une expérience avec Python
Vous avez des connaissances sur un système ETL (ex: Alteryx, Talend, Informatica, Trifacta, Knime, Dataiku etc).
La maitrise de l'anglais est impérative.
Le mieux, c'est qu'on en discute ensemble… A vos marques, prêt, candidatez ! #LI-AC3"
Nanterre (92),CDI,,Ingénieur Data Visualisation F/H,TRIMANE,- Nanterre (92),"Nous recherchons un Consultant Data Visualisation pour accompagner nos clients dans la mise en œuvre de leurs solutions décisionnelles dédiées :

Analyse des besoins en collaboration avec l'équipe métier
Rédaction des spécifications techniques
Conception, développement et documentation de la solution
Accompagnement des utilisateurs
En fonction de votre expérience, vous soutiendrez l'équipe commerciale dans ses activités de qualification avant-vente (réponses à appel d'offres …).
Profil recherché Vous êtes de formation ingénieur ou Bac + 5 avec une spécialisation en Data, Informatique, Statistique, Mathématiques. Vous disposez d'une expérience de 4 ans minimum en environnement décisionnel (modélisation, intégration, ETL, Datawarehouse, Reporting).

De nature curieuse, vous avez la volonté découvrir de nouveaux outils de Datavisulisation, en plus de celui/ceux déjà maîtrisé(s).

Vous êtes passionné par la Data et vous effectuez une veille permanente autour des sujets suivants :

Data Mining, Intelligence Artificielle, Deep Learning, Machine Learning ;

Langages de programmation et Scripting data science (Python, R, Java, Scala) ;

Langages de requêtage (SQL, NoSQL, MDX, DAX etc.)

Recherche opérationnelle et bonnes connaissances en statistiques ;

Gouvernance des données ;

Data Visualisation : Tableau Software, Qlik Sense, PowerBI, Tibco, Microstrategy, Oracle Data Visualisation etc. ;

Bases de données relationnelles & NoSQL (MongoDB, Cassandre, Hbase,..) et langages de requête (Hive, Pig) ;

Architecture technique des environnements Big Data (Hadoop, Spark, Scala, Hive…)

Environnements Cloud (Microsoft Azure, Google Cloud, AWS) ;
Entreprise TRIMANE est une société de service spécialisée dans les systèmes d'information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l'information au sein de leur entreprise.

En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d'expertise de nos consultants.

Nous accompagnons nos clients (CAC 40 et SBF 120) sur des prestations de Conseil, MOA et MOE, autour du traitement et l'analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique.

TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d'outils d'Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique."
Clamart (92),,,Data Analytics Specialist,Lafarge,- Clamart (92),"Position Summary:

The Data Analytics Specialist is responsible for enabling data analytics to be performed across the Group Internal Audit function, by (a) providing data analytics know-how and support to the Group Internal Audit Hubs to enable them to perform their own local analytics, and (b) implementing, maintaining and enhancing a centralised data analytics platform for use by all Group Internal Audit staff.

The Data Analytics Specialist contributes to the development of Group Internal Audit in order help achieve its key objectives:
provide to the Group Board Audit Committee and to the CEO independent and objective assurance over internal control effectiveness in any of the Group’s entities and functions;
help improve effectiveness and efficiency of operations,
develop and share knowledge

The Data Analytics Specialist should also:
create, expand and maintain Group Internal Audit’s knowledge and tools to ensure continuous adaptation to the evolution of LafargeHolcim’s business.
support the development of LafargeHolcim's Audit department through acting as a «Technical Specialist» to enhance audit effectiveness and efficiency.

Key Responsibilities:
Data Analysis
The Data Analytics Specialist:
Develops the data analytics framework for Group Internal Audit, covering processes, procedures and standards
Manage and maintain the technological infrastructure and data that support Internal Audit Analytics
Coordinates data analytics knowledge sharing across the Group Internal Audit Hubs and with other key stakeholders in the LafargeHolcim Group
Coordinates with LafargeHolcim’s IT organisation at Group and Regional levels to ensure access to the relevant data and the appropriate tools are in place to perform data analyses
Translates Group Internal Audit requirements into technical specifications, builds queries using data querying tools and tests the query results for appropriateness and completeness for:
The planning, fieldwork and reporting stages of individual Group Internal Audit missions
Wider Group Internal Audit management reporting, such as benchmarking, risk assessment, etc.
Join specific audit missions when ad-hoc advanced data analytics are required
Applies continuous improvement principle to mature data analytics in Group Internal Audit

Knowledge development & sharing
The Data Analytics Specialist should:

Develop and deliver training material to the Group Internal Audit staff on the use of audit and data analytics tools specifically, integrating those tools into standard audit practices.
Support Group Internal Audit staff in enhancing the audit approach and audit guides suggesting IT based audit procedures.
Develop and maintain relationships with other Group Assurance Providers (Line of Defense 2) to promote continuous monitoring analytics program.
Develop and maintain relationship with Group IT and Regional ITSCs to keep up-to-date on any technology and/or business process changes that may occur across the LafargeHolcim Group
Advise on any analytical technology tools or enhancements that would help the department realize efficiencies.
The Data Analytics specialist can also be assigned to projects aimed at improving Group Internal Audit’s performance and internal processes.

JOB DIMENSIONS:
Audited domains
Possibly all Group business processes and domains (Finance, Order to Cash, Source to Pay, Product Quality, etc.)

List of direct reports:
No direct reports

Reporting lines
The Data Analytics Specialist reports hierarchically to the Head of IT Audit Hub.
Key interfaces, stakeholders and relationships:
The Data Analytics Specialist develops effective working relationship with the IS/IT community, the Business Process Owners (at Group or Operation levels), the Group Internal Control team, and other assurance providers from the Line of Defense 2.
Skills, Qualifications and Experience:
Master of Science, Bachelor degree
CPA, CIA, CISA, ACL Certified Data Analyst and/or CFE considered as a plus"
Paris (75),40 000 € - 55 000 € par an,,Data scientist | Solution big data dans le secteur de la foodtech,In-Team,- Paris (75),"Vous êtes data scientist et cherchez un nouveau challenge au sein d’une startup’ innovante en plein essort ?
Alors rejoignez cette startup’ en plein croissance développant une solution SaaS dans le secteur du big data.
Leur objectif ? Permettre à leur client, à travers du scraping de grandes quantités de data, d’identifier les opportunités foodtech inhérentes à leur activité et les accompagner dans son déploiement et son optimisation.
Vous l’aurez compris, au cœur de ce projet : la data !
Travaillant déjà avec de grands noms du paysage entrepreneurial Français et Européens comme le Heineken ou Unilever, il cherche aujourd’hui un data scientist pour rejoindre leur équipe technique de 12 personnes.
Au programme : Python – Machine learning (sk learn, pandas, numpy) – Deep learning (keras, tensorflow)
Vous êtes curieux d’en savoir plus ?

VOTRE RÔLE
Dans une ambiance extrêmement dynamique et réactive, vos missions seront :
Développement d’algorithme de Machine learning – Python, pandas, numpy, sk learn, – & de Deep learning – Keras ; Tensorflow
Faire de la R&D
Un petit peu de développement (Python & JS)

VOTRE PROFIL
Bac+5 / bac+8
Une 1ère expérience/une appétence pour la data science est un vrai plus

OPPORTUNITE
Travailler sur de très grande quantité de donnée
Rejoindre un projet innovant, dynamique et porteur au début de sa croissance
Être en contact direct avec le top management de l’entreprise
S’épanouir au sein d’une structure pérenne avec un esprit startup, reconnue pour son innovation

LE SALAIRE
40-55K€ selon profil et expérience

Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !
Si vous souhaitez avoir d’autres informations sur cette opportunité je vous invite à me contacter également.

Tel :
Afficher le nº de téléphone
_
6 Cité de l’Ameublement
75011 Paris
www.inteam.fr"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community
Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),CDI,,Graphène Advisory - Data Engineer,Beijaflore,- Paris (75),"Fondé en 2000, Beijaflore est un cabinet de conseil opérationnel en stratégie digitale présent à l’international avec des bureaux à Paris, Bruxelles, Rio de Janeiro, Sao Paulo et New York. Il regroupe plus de 1250 collaborateurs animés par une mission commune : accompagner de manière opérationnelle les entreprises dans la mise en œuvre de leur stratégie digitale.
Avec son entité Graphène Advisory, Beijaflore accompagne les entreprises dans la valorisation de leurs données par des projets d’Intelligence Artificielle. En proposant des solutions complètes, partant de l’identification du use cases au développement de la solution et son déploiement, Graphène Advisory amène les entreprises à créer leurs business de demain. Ces solutions sont basées sur du Machine Learning et l’IA articulés sur des architectures flexibles, modulaires et scalables appelées architectures Big Data.
Vous souhaitez rejoindre une équipe multidisciplinaire et complémentaire qui accompagne ses clients dans la réalisation de projets autour de l’IA et du Machine Learning ?
En tant que Data Engineer, vous êtes en charge des données, leur stockage, leur manipulation et leur structuration dans un écosystème technologique spécifique à chaque client. Vous aurez pour objectif de sourcer et de préparer les données afin de tirer le meilleur parti de leurs analyses à l’aide d’algorithmes.
Vous avez également un rôle de conseil et d’accompagnement dans l’utilisation des données durant les phases de traitements analytiques.
Vos enjeux : déployer une architecture data performante et une structuration des données adéquate à leur valorisation. Mettre en place les outils big data de manipulation de données.
Vous avez plus particulièrement amené à :
Définir, développer et mettre en place et maintenir les outils et infrastructures adéquats à la conception d’algorithmes de data science et de recherche opérationnelle, intégrant les contraintes liées à des volumes de données très importants, à des modèles de grande dimension, au temps réel, ainsi qu’à la sécurité, la disponibilité et la performance,
Déployer des pipelines de données et les modèles ci-dessus en production notamment en concevant et en développant une architecture en micro-services,
Participer à l’amélioration des étapes du workflow scientifique du client : phase de recherche sur des environnements de calculs distribués, développement d’outils, mise en production, et tests.
Diplômé(e) d’une Grande Ecole d’ingénieur ou d’une Université en Mathématiques Appliquées, Statistique ou Informatique (Bac+5 ou PhD) avec une spécialisation en Data science option manipulation de la donnée. Vous justifiez d’une première expérience en tant que Data Engineer, éventuellement acquise lors de votre stage de fin d’études.
A cette occasion vous avez développé une ou plusieurs des compétences suivantes :
Maîtriser différents systèmes de base de données (SQL et NoSQL)
Avoir une appétence pour les technologies utilisées dans le Big Data (Hadoop, Map Reduce, Spark, Kafka…),
Être familier avec les concepts et algorithmes de statistiques, de data science, de deep learning et d’optimisation en général (recherche opérationnelle notamment),
Avoir une bonne connaissance/expérience de méthodologies d’ingénierie informatique : contrôle des sources, tests unitaires, revue de code,
Maîtriser un ou plusieurs langages structurés (Scala, Javascript, Java, C/C++,…),
Être curieux et avoir une forte capacité d’adaptation dans un environnement en mutation constante.
Et vous avez évolué dans un environnement utilisant (en fonction des clients) :
Les langages Scala, Python et/ou R (Matlab)
Des outils du Big Data (Hive, Impala, Spark, Spark Streaming)
Vous faites preuve de rigueur scientifique, d’autonomie et d’un fort esprit d’équipe.
Doté d’une bonne expression orale et écrite, vous avez développé une réelle capacité de vulgarisation des sujets techniquement complexes et vous souhaitez évoluer au sein d’un environnement innovant et dynamique ?
Rejoignez-nous !"
Ivry-sur-Seine (94),CDI,,Consultant Data F/H,AFTERDATA,- Ivry-sur-Seine (94),"Vous intégrez notre équipe mixte R&D et Projets.

Epaulé par deux consultants séniors, CTO et COO AfterData, vous participez aux projets clients et vous apportez votre brique à la construction de la plateforme AfterData.

Votre objectif : manipuler les données client et externes afin d’en faire un levier de valeurs

Vos missions seront les suivantes :
Communiquer avec nos data scientists et nos clients pour mener les projets à leur terme

Participer aux ateliers métier et data

Participer à la préparation de données et à l'évaluation des modèles

Etre force de proposition sur l’amélioration de la solution et de la méthodologie

Participer à la roadmap produit
Profil recherché Diplôme ingénieur ou Master 2

3 ans d'expérience dans un poste similaire

Passionné(e) de nouvelles technologies et curieux(se)

Conscient(e) des enjeurs clients, terre à terre

Vous maîtrisez le language Python, en particulier la librairie Pandas

Vous connaissez les principes du Machine Learning, principaux modèles et leurs usages.

Bonne capacité à faire le lien entre un jeu de données et sa signification dans le monde réel ! Vous savez faire preuve de créativité.
Entreprise Notre plateforme de marketing prédictif en mode SaaS met l’intelligence artificielle au service des équipes business pour décupler la valeur de la data en entreprise.

La solution AfterData permet de répondre avec une précision inégalée aux principales problématiques marketing : Quel client risque de résilier ? Quel visiteur de mon site web est sur le point de commander ? Quelle nouvelle offre proposer à un client ?

AfterData est une startup de la French Tech en forte croissance. Nous sommes implantés au Village by CA à Paris et à Ivry-sur-Seine. Grâce une levée de fonds fin 2019, nous accélérer fortement notre déploiement hexagonal avant un lancement européen d’ici 2 ans.

Nos clients : de grands et très grands comptes tels que BNP PARIBAS, Energie Mutuelle, Société Générale, SOMFY, GMF, Mutuelle de Poitiers…"
Puteaux (92),CDI,,Ingénieur de développement Big Data F/H,Groupama Supports et Services,- Puteaux (92),"Pour le compte de la Direction des Etudes, Développement et Programmes, au sein de l'équipe Gestion de la données/Plate-forme de données, les principales

missions seront :
la réalisation de travaux de conception de solutions techniques en lien avec les technologies Big Data
la réalisation de travaux d'implémentation et de développement dans l'écosystème Hadoop et Big Data
élaborer des jeux et plan de tests
exécuter les tests unitaires et d'intégration
participer aux tests de recette et de pré-production
réaliser l'instruction des anomalies, leur correction et leur livraison
la réalisation de dossiers d'études techniques et de prototypes
d'assurer la maintenance des solutions en Production pour assurer la qualité de service
De manière générale vous analyserez, paramétrerez, coderez et testerez les solutions logicielles applicatives, ainsi que les évolutions souhaitées dans le respect des normes, procédures, coûts et des délais définis
Profil recherché Profil du candidat: BAC +5

Vous êtes spécialiste du traitement de grande volumétrie de données et bénéficiez d'une expérience professionnelle significative (2 ans minimum) dans un poste similaire.

Vous êtes un bon communicant, de nature curieuse et savez travailler dans une équipe pluridisciplinaire, en appliquant les méthode Cycle en V ou Agile

Vous maîtrisez les nouvelles technologies BIG DATA :
Maîtrise des technologies BIG DATA autour de Hadoop : PIG / HIVE / SPARK / HDFS / AVRO / PARQUET / IMPALA / KAFKA / HBASE
Les outils et langages suivants : Hortonworks, Cloudera, Java, Scala, Python, R, IntelliJ, GitLab
Entreprise Etre ancré dans la réalité de nos clients et engagé auprès d'eux, quel que soit son métier, c'est ça être un vrai collaborateur Groupama Supports et Services.

Pour répondre à leurs attentes, postulez en nous indiquant ce qui fera de vous un vrai collaborateur Groupama.

Sa filiale, Groupama Supports et Services, accompagne le Groupe dans son développement par la mise à disposition de son savoir-faire et de son expertise en matière de solutions informatiques, d'immobilier d'exploitation, de services généraux et d'achats.

Dans le cadre de sa politique en faveur de la Diversité, Groupama étudie, à compétences égales, l'ensemble des candidatures dont celles de personnes en situation de handicap."
Paris (75),"Stage, CDI, Apprentissage, Contrat pro",,DATA ANALYST,HTS Consulting,- Paris (75),"DESCRIPTION

Vous souhaitez travailler sur des projets ambitieux au sein d’une société en pleine croissance ? Vous êtes passionné par les nouvelles technologies et l’univers des big data, vous êtes prêt(e) à participer au développement d’une start-up, à vous impliquer dans une équipe dynamique tout en y prenant des responsabilités ! Nous recherchons un data analyst pour accompagner le lancement d’une nouvelle offre, centrée sur l’exploitation des (big) data au service de nos clients. En appui de nos équipes, vous serez pleinement impliqué dans le développement de cette offre en y apportant votre savoir-faire technique. En particulier, vos principales missions seront les suivantes:
Exploiter des bases de données internes et externes et en automatiser la collecte et le traitement
Construire des modèles prédictifs sur la base de ces données
Contribuer à la réalisation de rapports d’études communicants pour nos clients
Etre force de proposition sur les méthodologies mises en œuvre

PROFILS RECHERCHÉS

Formation Grande école (X, Mines, Ponts, Centrale, Telecom, ENSAE, HEC, ESSEC, ESCP, EMLyon, Dauphine), doctorant, ou école informatique (EPITA…) avec une forte sensibilité statistique /data science/modélisation.
Esprit entrepreneurial et créatif, dynamique ayant envie de participer activement au développement d’une entreprise
Connaissance des nouvelles technologies, capacité à être force de proposition et à apporter des idées
Esprit d’équipe, collaboratif et « sympa » afin de bien vous intégrer à la culture d’entreprise
Pour réussir, le candidat devra avoir des compétences dans les domaines suivants :
Statistiques et datamining : manipulation et analyse de données, connaissance des méthodes d’analyses statistiques descriptives et prédictives, réalisation de modèles et d’algorithmes prédictifs
Programmation statistique (R, Python, SAS, SPSS…), gestion de bases de données relationnelles (SQL) et non relationnelles (plateformes Hadoop, Pig…). Une expérience en développement informatique serait un plus (HTML, Javascript…).
Connaissance d’outils de datavisualisation

PRÉSENTATION DE LA SOCIÉTÉ

HTS Consulting (Hommes Tendances & Stratégies) est un cabinet de conseil en stratégie créé en 2011.
Sa raison d’être est de permettre aux Directions Générales des grands groupes français et européens d’anticiper et de s’adapter aux changements de fond que connaissent actuellement leurs marchés.
Créé par des partners issus de grands cabinets de conseil, HTS Consulting a pour ambition d’accompagner ses clients dans la définition de leur vision et dans la préparation des réponses aux enjeux de demain en terme d’innovation, de performance marketing et commerciale et de transformation des organisations.
Convaincu que les cabinets de conseil doivent faire évoluer leur offre et leurs modes de fonctionnement interne, HTS Consulting adopte une approche du métier de Consultant résolument nouvelle dans une logique de Start-Up. Cela l’amène à lancer régulièrement des offres en rupture avec le marché traditionnel du conseil."
Paris (75),,,Data Analyst,Actimage,- Paris (75),"About the Data Analyst position
We are looking for a certified Data Analyst who will help us turning data into information, getting insights and developing business decisions based on the analysis results. Your responsibilities will include conducting full lifecycle analysis to include requirements, activities and design and also monitor performance and quality control plans to identify improvements.
We expect you to possess analytical mindset with creative approach to tasks and the ability to find patterns and correlation when dealing with big volumes of information. You should also be able to work under a flexible schedule and report on your findings in a detailed and straightforward manner.

Data Analyst responsibilities are:
Manage databases, data collection systems, data analytics and other strategies that optimize statistical efficiency and quality
Collect required data, analyze results using statistical techniques and provide ongoing reports
Retrieve information from primary or secondary data sources and maintain databases/data systems
Identify, analyze, and interpret trends or patterns in complex data sets
Review computer reports, printouts, and performance indicators to locate and correct code problems
Collaborate with management to prioritize business and information needs
Find and evaluate new process improvement opportunities

Data Analyst requirements are:
2+ years' experience of working on a Data Analyst or Business Data Analyst position
Significant experience of working with data models, database design development, data mining and segmentation techniques
Excellent knowledge of statistics and experience using statistical packages for analyzing datasets, including Excel, SPSS, SAS and so on
Good practical experience with reporting packages (e.g. Business Objects), databases (SQL etc), programming (XML, Javascript, or ETL frameworks)
Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy
Good report writing and presenting skills
BS degree in Mathematics, Economics, Computer Science, Information Management or Statistics"
Paris (75),,,Data Analyst,DataDog,- Paris (75),"About Datadog:
We're on a mission to build the best platform in the world for engineers to understand and scale their systems, applications, and teams. We operate at high scale—trillions of data points per day—providing always-on alerting, metrics visualization, logs, and application tracing for tens of thousands of companies. Our engineering culture values pragmatism, honesty, and simplicity to solve hard problems the right way.

The team:
We are building a first-class Internal Analytics team composed of Data Engineers and Data Analysts. We use cutting-edge data collection, transformation, and analysis tools in order to provide other teams with data that will help them better understand both our customers and our own operations so they can make strategic data-driven decisions.
The opportunity:
As a Data Analyst within the Internal Analytics team, you will help ensure all teams at Datadog have the data they need to drive their projects. You will have a chance to interact with all other departments including other Engineering teams, Product Managers, Designers, Marketing, and Customer Success.

You will:
Contribute to building the data model layer that is used by the whole company to query internal data and analytics
Build actionable data reports and visualizations that will help other teams make strategic decisions
Help product managers, designers, and engineers to understand our products usage and user behaviors, and facilitate data-driven decision making
Help marketing teams optimize their initiatives
Run deep data analyses and investigations
Work to discover how different technologies are being adopted over time by different segments of users
Present findings to team leads and executives
Train other employees to use data to answer questions without assistance

Requirements:
You are a clear, concise communicator that works well with others
You can explain complex datasets to non-technical people in understandable ways
You are able to clean a dataset and conduct a data analysis in Python or similar language
You are fluent with SQL and are able to write complex and performant queries with no assistance
You’ve mastered data analysis and visualization in Looker, Excel, Google Sheets, Tableau and/or similar tools
You have a natural curiosity and investigative mindset - driven to know “why”
You want to work in a fast, high-growth startup environment and thrive on both autonomy and collaboration
2+ years of professional experience
Bonus points:
You are familiar with Spark and/or Hadoop
You have some experience with data stores similar to AWS Redshift or S3
You are familiar with data storage optimization (keys, schemas, …)"
Créteil (94),,,RESEARCH ENGINEER DEEP LEARNING,Valeo,- Créteil (94),"Ready to tackle the challenges of the vehicle of the future? Join us and take part in the autonomous and connected car revolution at Valeo!

Under the leadership of Patrick Pérez, in 2018 Valeo created Valeo.ai, a research center in artificial intelligence for automotive applications, based in the center of Paris.

Valeo.ai is currently looking for a Research Engineer in Machine Learning and Computer Vision to support the team's researchers in their research projects on assisted and autonomous driving.

Your challenges ?

To be at the heart of the different subjects of the research team, and to provide support on code and data, in order to facilitate the realization, sharing and publication of the team's work
- Working in a growing international team of researchers
- Contribute to research projects that will shape the future of independent driving

Let's talk about you...

You have an engineering degree or a PhD, in the field of information processing
- You ideally have at least 3 years experience as a research engineer (programming in Artificial Intelligence)
- Python and C coding are a must for you
- You know the classic products in Artificial Intelligence: Tensorflow, Pytorch and have already worked on neural networks
- You are fluent in English (spoken and written)
- You have an open and curious mind, excellent interpersonal skills, and know how to adapt to work within a growing team

Moreover…

An experience in a start-up would be a plus
- You have experience in server maintenance and GPU coding (GPU monitoring, job scheduling)

Join-us !

Thanks to its strategy based on innovation, Valeo is at the heart of the three revolutions that are revolutionizing the automobile: the electrification of the vehicle, the advent of the autonomous and connected vehicle, and the development of digital mobility.

Revolutions that Valeo has anticipated and that are today synonymous with great career opportunities, including abroad! At Valeo, innovation is driven by diversity, authenticity and the energy of its talents. Would you like to live new technological and human adventures? Join Valeo and its 111,600 employees in 33 countries!

More information about valeo : https://www.valeo.com
Primary Location: FR-IDF-Creteil
Job: Research and Development
Organization: E80E Driving Assistance R&D FRANCE
Schedule: Full-time
Shift: Day Job
Employee Status: Regular
Job Type: Regular
Job Posting: 28/02/2020, 2:00:47 AM"
Boulogne-Billancourt (92),CDI,,Consultant Data - BI Microsoft F/H,HEXALEAD,- Boulogne-Billancourt (92),"En île de France, HEXALEAD recrute des consultant(e)s expérimenté(e)s sur l’offre décisionnelle de Microsoft pour intervenir sur les solutions SSIS, SSAS, Azure, Power BI…, la modélisation de données relationnelles ou OLAP et l’accompagnement nos clients vers les nouvelles pratiques de la BI.

Dans le cadre de nos projets, vous serez amené(e) à :
Mettre en pratique vos connaissances « classiques » de BI Microsoft, Reporting Services, packages SSIS, scripts, les principes de la modélisation décisionnelle.

Intervenir sur les items services Data d’Azure (Azure SQL Database, Azure CosmosDB, Azure SQL Data Warehouse, Azure Databricks, HDInsight, Azure Machine Learning, Azure Data Lake, Azure Analysis Services…)

Déployer vos connaissances sur les sujets d’Infrastructure IT (Windows Server, AD, Azure…) et sur les environnements IT d’entreprises de tailles diverses.

Développer des solutions de Business Intelligence innovantes, liées aux nouvelles pratiques en vigueur.

Au-delà des activités d’ingénieur Data - BI, vous êtes intéressé(e) par la recherche d’efficacité dans les tâches que vous réalisez ou pilotez au quotidien. Désireux de jouer un rôle clef dans les stratégies et processus de transformation pour lesquels HEXALEAD accompagne ses clients à travers ses 6 business Lines, venez rejoindre notre équipe et prendre la place de leader que vous souhaitez !
Profil recherché Issu(e) d’une formation de niveau Bac+5, vous possédez une expertise reconnue (certifications MS BI) et une expérience réussie dans la conception, la mise en œuvre et l’optimisation solutions décisionnelles Microsoft. Vous êtes intéressé(e) par les problématiques Data (Gestion de données ou Business Intelligence). Vous avez une bonne expérience des modélisations relationnelle et dimensionnelle.

A bientôt !

L'équipe HEXALEAD
Entreprise Bonjour !

HEXALEAD est un cabinet de conseil intervenant dans le domaine industriel, et spécialisé en identification et mise en oeuvre de gains de compétitivité.

Nos activités sont basées sur 6 business lines portant nos expertises techniques et fonctionnelles, et accompagnent nos clients dans leur processus de transformation / transition industrielle.

Notre vocation est d'apporter une réelle valeur ajoutée à nos clients, et donner un sens complémentaire aux carrières de chacun de nos consultants en leur confiant un rôle de leader.

Rencontrez-nous pour en parler de vive voix !

Retrouvez-nous sur : www.hexalead.com"
Paris 10e (75),,,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong

Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris 10e (75),,,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community

Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),CDI,,Data Scientist – W/M,Diabeloop,- Paris (75),"Data Scientist H/F

La mission de Diabeloop est de rendre accessible aux personnes vivant avec un diabète de type 1
des innovations technologiques de rupture. Pour tenir cet engagement, nous co-construisons tous les
jours avec les patients et leurs familles des projets qui ont un impact réel sur leur vie quotidienne. Née
d’un projet de recherche médicale, Diabeloop SA rassemble aujourd’hui les compétences et les
talents des 60 personnalités qui composent son équipe à Grenoble et à Paris.

Notre premier produit, le DBLG1® System est un dispositif médical auto apprenant qui met l’IA au
service du patient. Il comprend un capteur de glucose en continu (CGM), une pompe à insuline type
patch et un terminal dédié qui héberge les algorithmes de calculs/décisions. Il a reçu le marquage CE
en novembre 2018 ; Diabeloop travaille désormais à un déploiement commercial progressif en
Europe.

Pour accompagner cette stratégie et l’intérêt toujours grandissant autour de Diabeloop et ses
solutions, nous recherchons un ingénieur Data Scientist H/F.
Votre mission sera principalement la contribution à l’amélioration de l’algorithme d’IA de Diabeloop
pour la prédiction de glycémie et le développement de nouveaux algorithmes de traitement autour de
différents indicateurs liés au diabète.

Votre profil : Autonomie, esprit d’initiative, force de proposition
Bon relationnel pour travailler en équipe
Ingénieur, Master ou Docteur en mathématiques appliquées, en data-science
Anglais courant

Connaissances requises à travers des formations et des expériences (au minimum 3 ans) :
Bonne maîtrise de Python
Machine Learning : réseaux de neurones récurrents (LSTM …) et apprentissage par
renforcement (Q-Learning ...)

Connaissances appréciées : C++
Analyses statistiques
Méthodes d’estimation/prédiction : filtres de Kalman, optimisation, méthodes Bayésiennes,
méthodes de séries temporelles (ARMAX…)
Modélisation : modèle physiologique, représentations d’états
Automatique : commande prédictive, commande adaptative, commande robuste

Ce qu’on vous propose :
des problématiques avec des challenges ancrées à la vie réelle et ayant un impact direct sur
des patients
des ressources scientifiques, de la puissance de calculs, publications, brevets
de la synergie entre les différentes équipes


Si vous souhaitez rejoindre une entreprise qui donne du sens à votre travail, postulez maintenant !

Situation géographique : Paris, Grenoble
Type de contrat : CDI
Date de démarrage : ASAP
Contact : r ecrut@diabeloop.fr
Pour plus dinformations, vous pouvez consulter notre site : www.diabeloop.fr



Data Scientist M/W

Diabeloop’s mission is to make technological disruptive innovations accessible to people with Type 1
diabetes. To fulfill this commitment we work everyday with families and patients to co-build projects
with real-life positive impact. Born, in 2015, out of a medical research project, our company gathers
the talents of 60 team members, in Grenoble, where the headquarters are located, and Paris.

Our first product, the DBLG1 System, is an external medical device embedding artificial intelligence to
automate insulin delivery. After receiving CE marking in November 2018, we are now focusing on a
progressive commercial roll-out in Europe.

In order to support this strategy and the ever growing interest around Diabeloop and its solutions we
are looking for a Data Scientist Engineer M/W.

You’ll contribute to the improvement of thee AI algorithm for blood sugar prediction and for new
algorithms development around other key diabetes indicators.

Your profile : You are autonomous, you enjoy taking initiative
Good relationship with people, team spirit
Engineer, master degree or Phd in applied mathematics or data science
Your english level is fluent enough to easily speak with non francophone people, as well as
reading and writing technical documents

Required skills through education and experience (at least 3 years): Python mastery
Experience in Deep Learning (LSTM, GRU …)
Reinforcement learning (Q-Learning, Actor Critic ...)

Appreciated skills:
C++
Solid knowledge in statistical analysis
Kalman, optimization, Bayesian methods, time series methods (ARMAX ...)
Modelling
Predictive control, adaptive control, robust control

What we offer :
Complex challenges attached to real life and having a real impact on patient life
Scientific resources, mathematical facilities, publications, patents
Synergy between the teams
If you want to join a company giving you the ability to have a job that makes sense, apply now!

Location : Paris, Grenoble
Type of contract : Permanent
Starting date : ASAP
Contact: recrut@diabeloop.fr
Please find more informations on our website: www.diabeloop.com"
Paris (75),,,Senior Machine Learning Engineer,Doctrine,- Paris (75),"Our mission: we are advancing open justice around the world.
Our products: we are building legal research and analytics software for legal professionals to search through the law, handle their cases, and grow their business.
Our ambition: in a ""traditional"" industry, we strive daily to offer our customers the latest technologies, especially in the field of artificial intelligence, through simple and well-designed products

-

At Doctrine, we apply cutting edge machine learning (including deep learning) and natural language processing (NLP) technologies to the largest database of court decisions ever gathered. Data is the core of our business. As it takes exceptional people to build the future of law, we are looking for an exceptional Senior Machine Learning Engineer to make an impact in extracting relevant information from our massive dataset of legal documents and making law understandable.

As a Senior Machine Learning Engineer, you will:
Develop NLP systems that help us structure and understand legal documents
Design and build customized, large-scale cloud-based machine learning systems
Provide technical leadership, recommend and enforce best practices, develop engineering strategy and roadmap
Interact cross-functionally with a wide variety of people and teams especially other engineers, product managers and product designers to identify the next product opportunities

We’re looking for teammates with:
relevant work experience (e.g., as a statistician / computational biologist / bioinformatician / data scientist), including deep expertise and experience with statistical data analysis such as linear models, multivariate analysis, stochastic models, sampling methods
A strong interest in Artificial Intelligence and how it will shape our future
Great software development skills in Python, with a focus for building sound and scalable algorithms
A good knowledge of machine learning (both classical methods and deep learning approaches)
An exposure to NLP methods and challenges: you’ll implement Named Entity Recognition, Text Classification, Topic Modeling, Text Summarization and Search algorithms
Excitement about taking cutting-edge technologies and techniques to one of the most important and most conservative industries
A passion for finding, analyzing, and incorporating the latest research directly into the production environment. Good intuition for understanding what good research looks like, and where we should focus effort to maximize outcomes
A good knowledge of French, as you will process French court decisions.

Bonus points if you have:
You're interested in law (but you're not required to have an experience in the legal field for this job :) )
-

Why you should apply:
It's the ideal time to join Doctrine in terms of growth and opportunities
We have a strong team spirit and company culture, we live our values at a daily basis
Top-notch learning environment: ongoing mentorship, weekly best practices sharing
We work in a cool and classy office in the heart of Paris (Métro Sentier)
Regular feedback and compensation reviews - we nurture the feedback culture and reward great work

Benefits:
Competitive package, including stock options
Unlimited time off
Referral bonuses
A great health insurance policy
Lunch coupons

Other perks:
IT equipments
Free coffee, tea, and fresh fruits
Thursday beers, Wednesday breakfasts and monthly events with the team


We are an equal opportunity employer and value diversity at our company. We do not discriminate on any basis including religion, color, origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Remote applicants: This position is based in our office in Paris. If you're interested in remote work, check back soon as our needs may change."
Paris (75),,,DATA ENGINEER,Aquila Consulting,- Paris (75),"NOTRE MISSION
En tant que spécialiste reconnu, Aquila Data Enabler accompagne et conseille ses clients sur la Data Science et
l’intégration Big Data, principalement au sein des Labs R&D.
Notre positionnement est celui de la Recherche Opérationnelle. Aquila Data Enabler est une structure qui répond avec
réactivité, transparence et proximité aux besoins de ses clients en les aidant à faire les bons choix, et à les mettre en oeuvre
avec efficacité.
POSTE PROPOSE
Pour l’un de nos clients grand compte basé sur Paris, nous recherchons un Data Engineer (F/H) pour intégrer une équipe
d’architecture et de développement de projets d’envergure.

Vos missions principales sont :

Conception et mise en oeuvre de plateformes basées sur les technologies Big Data
Conception et mise en oeuvre de flux d’intégration de données structurées et non structurées
Mise en oeuvre de la stratégie d’exploitation des plateformes Big Data
Amélioration continue de l’architecture et de l’infrastructure data
Accompagnement des différents métiers du client dans la mise en place de leurs projets Data Driven
Participation aux activités d'architecture, conception et développement
Apporter votre savoir-faire sur un plan technique et méthodologique

Les outils utilisés : Hadoop, Spark, Pyspark, Scala, Elastic search.

VOS QUALIFICATIONS
De formation Bac+5 informatique, vous justifiez d’une première expérience en tant que Data engineer / Développeur avec
des projets Big Data.

Vous connaissez les outils Hadoop, Spark et Python.

Enfin, vous avez la pêche, le smile attitude, assez pour prétendre de faire partie de l’Aquila Team !
Si vous vous reconnaissez dans cette description, n’hésitez pas à nous envoyer votre candidature, nous serons ravis de faire
connaissance autour d’un café !



ENVIE DE REJOINDRE NOTRE EQUIPE ?
Merci de nous envoyer votre CV et lettre de motivation à jobs@aquiladata.fr
Pour un traitement interne plus rapide, veuillez nommer vos documents comme suit : Prénom Nom_CV ou CL. N'hésitez pas
à ajouter tout document divers pouvant supporter votre demande. Nous veillerons à examiner votre demande et à vous
répondre dans les 48h."
Paris (75),,,Speech Recognition Engineer,"Sonos, Inc",- Paris (75),"About You
More than a candidate that checks every box, we’re looking for people who are excited to work, learn, and grow at Sonos—no matter their background or how they identify. If that’s you, we hope you’ll apply for this role.
You want to be part of a team.
You come with new ideas and a unique point of view. You look forward to collaborating with a diverse team of individuals. You assume everyone’s best intentions, welcome a healthy debate, and embrace differing opinions. You eagerly seek and give help. Transparency tops your list of values, and you proactively contribute to a culture of respect and inclusion.
You enjoy a challenge.
Inquisitive and focused, you see every challenge as an opportunity. You’re ambitious and comfortable making mistakes because you learn from them and bounce back quickly. You would rather create the future than wait for it. You prioritize long-term value over short-term objectives.
You love to listen.
You approach every interaction with curiosity and a desire to understand. You want to make a positive impact in the world. You’re passionate about culture and know the power that music, film, podcasts, games, and stories have to bring people together.
What You’ll Do
Train state of the art acoustic models
Minimize the model footprint while keeping high performance in both noisy and far field conditions
Manage, scale and optimize our Kaldi training pipeline (data management, infrastructure and metric tracking)
Skills You’ll Need
Qualifications:
Experience with machine learning models applied to speech recognition (GMM-HMM, DNN-HMM, E2E models) and related algorithm (forward-backward, viterbi search, backprop, etc)
Python, C++
Good knowledge of Kaldi, and at least one other deep learning framework (Tensorflow, PyTorch)
MS / PhD in Computer Science or Machine Learning
At least two years of experience in deployment of machine learning models in production
Excellent verbal and written communication skills (English)

Preferred Qualifications:
Experience using Docker
SQL, noSQL database
Rust

More About Sonos
Sonos is a sound experience company. We pioneered multiroom wireless audio, made it sound amazing, and changed the way people listen, making it effortless for them to enjoy what they want, where they want, how they want.
Today we continue empowering listeners by developing new technologies, thoughtfully designing products, expanding our software platform, and crafting brilliant sound experiences while participating in a culture that values respect, transparency, collaboration, and ownership.
Together we’re working to positively impact the world and inspire everyone to listen better—because listening brings people together, builds understanding, drives change, and makes us happier.
Notice to European Job Applicants: Information you submit as a part of your job application will be used in accordance with Sonos EU Job Applicant Privacy Notice.
Notice to U.S. Job Applicants: Sonos is an equal opportunity employer. We evaluate qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other legally protected characteristics.
Follow the links to review the EEO is the Law poster and its supplement. The pay transparency policy is available here. Sonos is committed to working with and providing reasonable accommodations to individuals with disabilities. If you need a reasonable accommodation because of a disability for any part of the employment process, please send an e-mail to accommodations@sonos.com and let us know the nature of your request and your contact information."
Paris (75),,,Data Scientist Senior : Machine Learning & Deep Learning,Sept Lieues,- Paris (75),"Start Up de 12 collaborateurs sur Paris qui a développé une solution innovante.
Située en plein coeur de Paris - Locaux superbes avec une grande terrasse - Cuisine - Team Building - Remote possible.
LE POSTE / LES MISSIONS
Au sein de l'équipe Innovation qui est en pleine croissance, vous travaillerez sur des projets autour de la vidéo, notamment de reconnaissances faciales.
PROFIL RECHERCHÉ
Profil :
Bac +5 ou +7
Compétences en Machine Learning
Expérience significative de 4 ans minimum
Expertise dans un champ d'application du deep learning
Maîtrise d'un framework
Expertise en Python
Anglais

Le plus : Connaissances en traitement de vidéos"
Neuilly-sur-Seine (92),CDI,,Data Engineer H/F,JCDecaux FR,- Neuilly-sur-Seine (92),"Au sein de la nouvelle Direction Data, chargée de l'exploitation et de la valorisation des données à travers le groupe, nous recherchons un Data Engineer H/F pour intégrer une équipe dynamique en forte croissance composée de Data Engineers, Data Scientists, Data Analysts.

Au quotidien vous serez amené à :

Participer à l'identification et l'intégration des sources de données pour permettre son utilisation par l'ensemble de la Direction Data ;
Designer et implémenter les méthodes de collecte de données externes ;
Interagir étroitement avec la DSI pour l'intégration, mise en production des outils et algorithmes développés par la Direction Data ;
Travailler en collaboration avec les Data Scientists de la Direction Data pour assurer l'intégrité et la qualité des codes développés ;
Adapter des outils et méthodologies statistiques industrialisés en fonction des sources de données disponibles par pays.

Vous aurez la chance de participer à la mise en place de cette Direction, et interviendrez sur l'ensemble de la chaîne Data à nos côtés.
Profil
Amoureux de la Data, passionné par ses utilisations, avec un esprit innovant et autonome, vous cherchez à relever un défi et êtes motivé par les challenges en perspective liés à la mise en place d'une telle équipe.

De formation Bac +5 minimum de type école d'ingénieur, vous avez au moins une expérience préalable dans le traitement et l'intégration de données en industrie, sur une infrastructure Big Data, avec le désir d'approfondir vos compétences.

Compétences requises :

Capacité reconnue des langages de développement ou de traitement de la donnée (Java, Scala, C++, Python) ;
Connaissance du cloud service (AWS ou Google) ;
Expérience dans l'intégration de données de sources multiples ;
Intérêt pour la compréhension et l'implémentation de méthodologies statistiques ;
Volonté de travail en équipe.

La maîtrise de l'anglais est indispensable pour ce poste à dimension internationale.
Localisation du poste
Localisation du poste
France, Ile-de-France, Neuilly
Critères candidat
Niveau d'études
Bac +5 et plus
Diplôme
DESS / DEA / Master
Niveau d'expérience global pour le poste à pourvoir
1ère expérience (de 1 à 3 ans)"
Paris (75),,,Data Engineer,Pretty Simple,- Paris (75),"We are looking for a skilled Data Engineer to work on our current and upcoming data engineering projects within our Data Intelligence department.
You will undertake a variety of data-related tasks, under the responsibility of senior data scientists, ranging from the implementation of predictive behavior modeling to the automation of metrics recovery.
This is an excellent opportunity to join a fantastic company and a great chance to become an integral part of a highly creative and motivated team.
We are not just invested in games; we are also invested in people. We know that our overall success is a combined effort, and we therefore strive to provide opportunities for our employees to learn, grow and thrive. Organized extracurricular activities and social outings bring our international team even closer together, making our work environment casual, inviting and inspiring.
Responsibilities:
Your main responsibility is to build and operate data-driven products that provide accurate, reliable and insightful data to support our current and future products.
Construct and test large-scale processing systems that aggregate the behavior of our millions of daily players to provide impactful insights.
Translate business requirements into concrete data systems.
Build and into production machine learning models that predict player behaviors, detect fraud events, etc.
Ensure very high availability and integrity of our internal analytics platform by monitoring and maintaining data flows.
Contribute to the continuous development of our data deployment and automation systems.
Requirements:
You are the jack of all trades, willing to master a wide range of technologies in order to get things done reliably.
3+ years experience in a data engineer or software engineer role, involving the development and operations of data processing systems.
Excellent software engineering skills and coding proficiency in Python, Scala or Java.
Familiar with data warehousing and modeling best practices.
Proficient in modern Big Data and ETL technologies (AWS EMR, Spark, Airflow, etc.)
Working proficiency in English.
Great team player with a can-do attitude, committed with a high level of initiative.
Nice-to-haves
Exposure to machine learning techniques.
Experience with cloud computing platform such as AWS or Google Cloud Platform.
Gamer at heart and passionate about our industry.
Application in French and English will be accepted."
Paris (75),,,GroupM | Data Analyst (H/F),GroupM,- Paris (75),"Qui Sommes nous?
GroupM, leader mondial en conseil et en achat d’espaces publicitaires a pour activité principale l’accompagnement des annonceurs dans la promotion de leurs marques.
GroupM est présent dans 80 pays via des réseaux internationaux et travaille avec des clients de renom dans des secteurs d’activité diversifiés tels que le Luxe, l’Automobile, l’Agroalimentaire, les Services ...
En France, GroupM est présent au travers des agences KR Wavemaker, MediaCom, Mindshare, Neo et Keyade (1000 collaborateurs).
Missions :
Rattaché(e) au département GroupM - Business Media Science, votre rôle sera de développer des outils permettant de faciliter la compréhension des données issues des dispositifs de communication mis en place par nos annonceurs. A ce titre, vous serez en relation avec les agences du groupe KR Wavemaker, MediaCom, Mindshare, Neo et Keyade afin de récolter leurs besoins en outils et leur fournir ainsi la solution la plus adaptée.
Vos principales missions seront donc les suivantes :

Collecter, traiter et analyser des données marketing

Créer des Dashboards pour rendre ces données facilement compréhensibles et exploitables

Élaborer des présentations de résultats destinées aux clients

Participer activement au développement du département, en identifiant de nouvelles opportunités de croissance ou en proposant de nouvelles approches/nouveaux produits

Le profil que nous recherchons devra (idéalement & notamment) répondre aux critères suivants :
Issu(e) d'une formation Bac+5 en statistique / informatique / analyse de données / système d'information, vous justifiez d’une expérience d’au moins 2 ans à un poste équivalent dans un domaine analytique

Très à l'aise avec les chiffres, vous maîtrisez Excel et avez un esprit synthétique

Vous maîtrisez SQL, T-SQL, connaissez Python et/ou R, et avez idéalement une connaissance sur les services cloud Amazon (AWS)

Doté(e) d'une bonne compréhension des enjeux marketing, vous avez également une connaissance d'un outil de BI (Tableau, Datorama, Power BI ou Qlikview)

A l'écoute, structuré, rigoureux et autonome, vous aimez travailler et savez être force de proposition

Enfin, une première expérience dans l’usage d’applications de Data Visualisation, idéalement Tableau et/ou Datorama, serait un plus.

Rejoindre GroupM c’est :
Partager notre engagement pour l’innovation, l’éthique et la transparence
Bénéficier d’une culture collaborative, apprenante et d’un portefeuille de clients très variés
Profiter de notre cadre de travail privilégié"
Le Plessis-Robinson (92),,,Chef de Projet Data F/H,TRIMANE,- Le Plessis-Robinson (92),"TRIMANE est une société de service spécialisée dans les systèmes d’information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l’information au sein de leur entreprise. En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d’expertise de nos consultants.Nous accompagnons nos clients (CAC 40 et SBF 120) sur des prestations de Conseil, MOA et MOE, autour du traitement et l’analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique. TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d’outils d’Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique. Dans le cadre de la mise en place et le développement de projets data, vous accompagnerez nos clients autour de la mise en place de solutions décisionnelles, Vos missions consisteront en: Coordonner et animer l’équipe MOEVeiller au bon déroulement de vos différents projetsAnalyse des besoins des utilisateurs et métiersRédaction des spécifications techniquesGestion de projets et coordination d'équipe : chiffrage, planning, conduite de réunion, propositions...Participer à la conception du SI décisionnel et analyse de sa cohérenceCommunication : promotion autour de la solution et collaboration étroite avec les responsables métiersSoutien / renfort de l’équipe technique au besoinVeille technologiqueVous êtes de formation ingénieur / Bac+ 5, avec une spécialisation décisionnelle et une expérience de 5 ans minimum. Vous disposez de plusieurs expériences significatives en tant que Chef de projets. Posséder des connaissances dans ce secteur d’activité serait fortement apprécié.Vous êtes passionné par la Data et vous effectuez une veille permanente autour des sujets suivants : Data Mining, Intelligence Artificielle, Deep Learning, Machine Learning ;Langages de programmation et Scripting data science (Python, R, Java, Scala) ;Langages de requêtage (SQL, NoSQL, MDX, DAX etc.)Recherche opérationnelle et bonnes connaissances en statistiques ;Gouvernance des données ;Data Visualisation : Tableau Software, Qlik Sense, PowerBI, Tibco, Microstrategy, Oracle Data Visualisation etc. ;Bases de données relationnelles & NoSQL (MongoDB, Cassandre, Hbase,..) et langages de requête (Hive, Pig) ;Architecture technique des environnements Big Data (Hadoop, Spark, Scala, Hive…)Environnements Cloud (Microsoft Azure, Google Cloud, AWS) ;

Data"
Paris (75),,,CONSULTANT CHEF DE PROJET BIG DATA / DATA SCIENTIST,Penwick,- Paris (75),"Description
Engagé dans des projets de transformation digitale, vous prendrez en charge des missions de transformation.
Vos missions
Contribuer à la montée en compétence de ses collaborateurs
Récupérer et analyser les données pertinentes liées au processus de l’entreprise, afin de construire des algorithmes permettant d’améliorer les résultats de recherches et de ciblage conformément aux attentes des métiers,
Élaborer des modèles prédictifs afin d’anticiper l’évolution des données et les tendances relatives à l’activité de l’entreprise,
Modéliser les résultats d’analyse des données pour les rendre lisibles et exploitables par les métiers,
Être force de proposition dans la recommandation d’indicateurs auprès des métiers afin d’améliorer la prise de décision. En effet l’équipe décisionnel doit faciliter le travail d’interprétation des données au travers de la création de tableau de bord spécifique, analysant les données traitées afin de conseiller les métiers dans l’élaboration de leurs stratégies,
Définir des solutions de stockage relatif au traitement de grands volumes de données afin de contribuer à l’élaboration d’une plateforme de Big Data
Concevoir, développer et maintenir des traitements de données suivant les besoins exprimés par le métier,
Alimenter et maintenir le référentiel de traitements,
Déterminer et concevoir des interfaces de restitutions au travers d’API ou de Dashboard.
Participer à la conception de la plateforme BigData
Développer des systèmes d’ingestion de données (Requête en base, ingestion de fichier plat, requête sur API, écoute de bus de messages) en stream ou batch pour alimenter le DataLake,
Développer des traitements de digestion de données en stream ou batch des données souhaitées pour création de DataMart,
Développer des systèmes de restitutions (API ou Dashboard),
Maitriser l’ordonnancement et l’exécution des traitements sur la plateforme,
Rédaction de documentation.
Votre profil
Compétences souhaitées : Technique
Connaissance approfondie des solutions de gestion de bases de données No Sql (Couchbase, MongoDb, ),
Connaissance approfondie dans la modélisation et l’architecture des bases de données décisionnelles (data warehouse SQL),
Connaissance approfondie sur plusieurs langages de développement (Python, R, Scala, Play, JavaScript, ),
Connaissance approfondie des technologies du Big Data (Hadoop, Hive, Spark, Machine Learning, ),
Connaissance approfondie dans les outils d’analyse (Jupyter, Zeppelin, H2O, MATLAB, ),
Connaissance approfondie dans les outils de visualisation de données (Kibana, Superset, Metabase, ),
Connaissance approfondie des systèmes d’échange de données Temps-réel (Kafka),
Connaissance approfondie en mathématique (algèbre linéaire, probabilités et statistiques) afin d’être en capacité de construire des algorithmes d’analyse prédictives et statistique à partir des différentes bases de données,
Connaissance générale de la sécurité des SI,
Maitrise des méthodes agiles (Scrum, Lean, ) et de la démarche DevOps,
Vous participez à des activités de la communauté Data Science : Kaggle, Hackaton, Meetups, GitHub.

Métier : Connaissance approfondie des cas d’utilisation de l’analyse prédictive,
Connaissance approfondie de la gouvernance des données dans un cadre réglementaire (Solvency II, GDPR, )
Compréhension et capacité à décliner la stratégie de l’entreprise dans le SI"
La Défense (92),,,Chef de Projet Modélisation des Risques et Data Science-(H/F),Société Générale,- La Défense (92),"Vos missions au quotidien


Le chef de projet est responsable de la réalisation complète d’un projet de modélisation : du cadrage au livrable. Pour cela, il assure la mise en œuvre de l’organisation et des travaux sous sa responsabilité, identifie les priorités et les échéances, oriente la conception et le calibrage des modèles quantitatifs en s’assurant de la pertinence des choix techniques.
Il est responsable de développer et maintenir la documentation projet, assure le contrôle de cohérence et de conformité des résultats, développe la relation avec nos partenaires (Front Office, direction financière, autres départements des risques etc.) et accompagne le déploiement opérationnel des solutions.

Et si c’était vous ?
De formation supérieure de type école d'ingénieurs ou 3ème cycle avec une spécialisation en statistiques/économétrie/data science, vous disposez d’une expérience de 3 ans minimum vous ayant permis de démontrer une connaissance approfondie des modèles quantitatifs
Vous maitrisez les langages de programmation (Python, R) ainsi que les techniques de modélisation des risques : modèles économétriques, modèles statistiques, modèles probabilistes, machine learning, techniques de data visualisation, etc…
Vous justifiez éventuellement par ailleurs d’une expérience en management de projets et d’équipes. Votre anglais est courant aussi bien à l’écrit qu’à l’oral.

Plus qu’un poste, un tremplin
Rejoindre une telle équipe constitue une opportunité tant en terme d’acquisition d’expertises nouvelles que de perspectives d’évolution au sein d’un groupe qui déploie ses activités à l’échelle internationale.
Pourquoi nous choisir ?
Au sein de Société Générale, vous rejoindrez la Direction des Risques.

La Direction des Risques est au cœur de l’activité du Groupe avec pour principale mission de contribuer au développement des métiers et de leur rentabilité par la mise en œuvre de l’appétit au risque.

Travailler au sein de la Direction des Risques, c’est exercer un métier intellectuellement passionnant et vivre un quotidien stimulant, rythmé par l’actualité économique. C’est, en tant que partenaire clé du business, être en proximité avec l’ensemble des métiers du Groupe. Enfin, nous rejoindre, c’est intégrer une filière d’excellence pour acquérir une expertise au cœur de la banque et accéder à de nouvelles opportunités de développement.

Nous sommes un employeur garantissant l'égalité des chances et nous sommes fiers de faire de la diversité une force pour notre entreprise.
Le groupe s’engage à reconnaître et à promouvoir tous les talents, quels que soient leurs croyances, âge, handicap, parentalité, origine ethnique, nationalité, identité sexuelle ou de genre, orientation sexuelle, appartenance à une organisation politique, religieuse, syndicale ou à une minorité, ou toute autre caractéristique qui pourrait faire l’objet d’une discrimination.
Référence: 19000OSC
Entité: Fonctions centrales groupes
Date de début: Immédiat
Date de publication: 18/05/2020"
Paris 17e (75),CDI,,Lead Data Scientist / Machine Learning Engineer,Manomano,- Paris 17e (75),"Dès son lancement, le site ManoMano a développé ses propres algorithmes de machine learning, qui représentent aujourd’hui un vrai avantage compétitif. Les chantiers, nombreux et passionnants, touchent à l’ensemble des activités de l’entreprise. En voici une liste non exhaustive :
Optimisation de l’efficacité des campagnes marketing
Moteurs de recommandation
Moteur de recherche
Catégorisation des produits
Extraction des attributs des produits
Prévision des ventes
La diversité des projets et l’autonomie des data scientists font de ManoMano l’un des meilleurs terrains de jeu de Data Science en France (si ce n’est le meilleur !).
Aujourd’hui, une petite dizaine d’algorithmes sont en production. Ils reposent sur une grande diversité d'approches (business rules, régression linéaire et logistique, gradient boosted trees, product2vect, ...)
Ton travail aura un impact considérable sur la trajectoire de croissance de ManoMano.
Enfin, tu seras un mentor pour les membres moins expérimentés de l’équipe.
Profil recherché
Pour ce poste, nous recherchons un Lead Data Scientist ayant au moins 3 ans d’expérience capable de porter un sujet de data science de bout en bout (de la conception à la mise en production en passant par le prototypage), ce qui requiert les qualités clefs suivantes :
une appétence forte pour l’informatique et des bonnes pratiques de software engineering
une capacité à comprendre et modifier le code des programmes existants,
une ou plusieurs expérience(s) significative(s) de Machine Learning en production,
une passion pour l’intelligence artificielle et le Machine Learning avec un vrai enthousiasme pour explorer et apprendre : cours en ligne, papiers de recherche, compétitions Kaggle, portfolio Git, etc.
une compréhension des enjeux de l’entreprise afin de créer et développer de nouvelles solutions adaptées,
une approche pragmatique des problèmes, pour créer des outils utilisables en production rapidement, notamment en s’appuyant sur l’existant,
une capacité à tester et expérimenter,
de la pédagogie pour expliquer des concepts complexes à des audiences non techniques.
Tu feras partie de l’équipe Data Science et auras des contacts fréquents avec les équipes IT et Produit. Tes missions seront transverses à l’ensemble de la société.
Vie de l’équipe
Six data scientists expérimentés ayant des profils variés (Université, école d’ingénieur, recherche) qui aiment partager et apprendre
Point hebdomadaire avec l’équipe pour partager et échanger sur les sujets de chacun
Point hebdomadaire avec son manager direct
Lab technique bimensuel où un membre présente un sujet de son choix
L’équipe Data Science est incluse dans une équipe Data plus large, avec des Data Engineers, des Data Analysts, et des Growth Hackers
Environnement technique : Airflow, Python, AWS S3, Gitlab, 2 serveurs 256 Go de RAM avec 24 coeurs et un GPU pour l’expérimentation.
Quelques exemples d'articles écrits par l'équipe : https://medium.com/manomano-tech/tagged/data
Ce que nous offrons
Un environnement de start-up made in France en hyper croissance
Equilibre vie pro / vie perso
Télétravail possible (1 jour par semaine)
Implication communautaire (temps alloué à la communauté, blog technique, etc.)
Des Crafternoons pour se former sur des sujets aussi divers que passionnants
Sponsoring de MM pour assister à des talks et conférences
De l’autonomie avec un champ d’action très large
Une immersion dans le data-driven e-commerce
Environnement Agile & international avec des collègues brillants et sympathiques
Carte de restaurant, mutuelle, transport, 7 semaines de vacances
Process de recrutement
Echange téléphonique avec un Talent Recruiter
Entretien physique avec deux Data Scientists de l'équipe
Test technique à faire à la maison
Entretien physique avec deux autres Data Scientists de l'équipe
Entretien physique ou téléphonique avec le VP Data ou le CMO
Informations complémentaires
Type de contrat : CDI
Date de début : 01 mars 2019
Lieu : Paris, France (75017)
Niveau d'études : Bac +5 / Master
Expérience : > 5 ans
Télétravail ponctuel autorisé"
Fontenay-sous-Bois (94),CDI,,DATA SCIENTIST TRAITEMENT D'IMAGES (H/F),Crédit mutuel,- Fontenay-sous-Bois (94),"« L’expertise technologique au service de la clientèle est au cœur de la stratégie de développement du groupe Crédit Mutuel qui enrichit régulièrement son offre de services innovants et sécurisés. C’est dans cet esprit précurseur que l’OCR Factory a été fondée : sa mission consiste à développer, déployer et intégrer des solutions permettant le traitement de documents numérisés pour le compte du groupe Crédit Mutuel et de ses filiales.
L’équipe, localisée à Val De Fontenay (Paris), a vocation à répondre à l’ensemble des demandes OCR, depuis l’optimisation de la reconnaissance de documents, pièces jointes ou photos, jusqu’à l’implémentation d’outils de paramétrage, d’interface ou de statistiques.
En tant que Data Scientist, vous serez garant(e) de l’expertise sur les sujets liés au traitement de données documentaires : évaluation de la pertinence des modèles OCR, élaboration de modèles ad hoc, pré-traitement des documents, etc. »
Activités et tâches spécifiques
En tant que Data Scientist, vous serez garant(e) de l’expertise sur les sujets liés au traitement de données documentaires :
Maîtriser l’état de l’art des techniques d’OCR.
Capacité à réaliser une veille scientifique et technologique concernant les techniques utilisées dans les solutions mises en œuvre.
Tester et livrer des algorithmes (en Python ou C#) sous fortes contraintes d’industrialisation.
Evaluer de manière critique, avec une démarche statistique, les performances de chaque solution.
Communiquer son travail avec des parties prenantes aussi bien techniques que fonctionnelles
Connaissances et compétences
Vous disposez de compétences en Data Science : Machine Learning, Deep Learning, traitement d’images et statistiques.
Des connaissances en OCR seraient un plus.
Vous maitrisez C#, .NET et Python.
De formation supérieure Bac+4/+5, vous justifiez au minimum d’une première expérience sur un poste similaire.
Un niveau d’anglais courant est souhaité.
La maitrise de la méthodologie agile est souhaitée.
Savoir-être - savoir-faire
Vous savez faire preuve d’initiative dans la conduite et la communication de projets techniques.
Vous êtes reconnu pour votre esprit d’analyse, de méthodologie & de synthèse, votre rigueur dans l’analyse et le développement.
Vous avez le souci du respect des normes et standards de qualité.
Vous êtes doté d’un bon relationnel avec un véritable esprit d’équipe, le sens du service clients et l’envie de vous investir dans des projets.
Autres informations
Le poste basé à Fontenay-sous-Bois est à pourvoir en CDI immédiatement.
Vous bénéficierez d’avantages « Convention Collective Banque » comme :
13ème mois,
RTT,
Prime d’intéressement et de participation,
Abondement,
Conditions bancaires avantageuses,
Régime de Frais de Santé et de Retraite très attractif,
Et encore plein d’autres avantages à découvrir…

Vous évoluez dans un environnement stimulant basé sur un management de proximité. Un Groupe qui s’engage pour ses salariés par la formation et l’évolution professionnelle.
Vous recherchez un projet innovant ? Alors Rejoignez la Team EI en postulant!
Retour"
Paris (75),,,Data Miner - Inspection Générale H/F (CDI),La Banque Postale,- Paris (75),"Présentation de l'entreprise
Rejoindre La Banque Postale, c'est intégrer une banque citoyenne, dynamique et innovante, qui poursuit un développement accéléré sur les marchés de la banque de détail, de l’assurance et de la gestion d’actifs.

Banque de service public, La Banque Postale accompagne ses clients dans une relation bancaire durable : 10,7 millions de clients particuliers et 400 000 clients entreprises, professionnels, acteurs de l’économie sociale et du secteur public local lui font confiance.

Attentive à ses collaborateurs, elle leur propose des parcours diversifiés et investit dans leur formation tout au long de leurs parcours professionnel.

Vos missions
L'Inspection Générale
Directement rattachée au Directoire, l’Inspection Générale (IG) assure le contrôle périodique des activités du Groupe La Banque Postale. Par ses missions d’audit réalisées en toute indépendance sur l’ensemble des domaines de la banque, elle veille à la pertinence des dispositifs de maîtrise des risques, à la conformité aux différentes normes en vigueur, ainsi qu’à l’efficacité opérationnelle du Groupe.
Au sein de la Direction Qualité et Ressources de l’Inspection Générale, l’équipe Solutions et Datamining :
Répond aux besoins en exploration de données des différentes missions : expertises sur les outils et données des SI de la banque et de ses filiales
Traite des données complexes
Gère les besoins informatiques en interface avec la DSI
Dans ce contexte, le dataminer apporte son expertise aux équipes de mission afin de les éclairer sur les SI et les données des domaines audités.
Dans le cadre des missions d’Inspection ou pour le compte de l’Inspection Générale, le dataminer est amené à :
Préparer et constituer les échantillons de données.
Rédiger le rapport relatif aux extractions et traitements de données réalisés.
Contribuer à la cohérence globale des données et à la gestion de leur connaissance ainsi qu’à la connaissance des outils SI.
Contribuer de manière continue à l’acculturation des équipes d’inspection à la connaissance de l’informatique décisionnelle de la Banque.
Assister le responsable du pôle dans le cadre des contrôles et reporting internes à l’Inspection Générale.
Former les équipes d’inspection aux outils spécifiques.
En fonction des missions, le dataminer pourra être, partiellement ou totalement, intégré à l’équipe l’inspection et participer aux réunions et travaux. Notamment, il réalise lui-même les traitements de données les plus complexes pour le compte de la mission.

Votre profil
De formation supérieure (Bac+3 option datamining ou Bac +5 option informatique/ analyses statistiques), vous maitrisez les langages SAS, SQL, Python et R ainsi que les outils de bureautiques (fonctions avancées d’Excel).
La connaissance des systèmes d’informations bancaires ainsi qu’une expérience confirmée en matière d’administration des données bancaires seraient un plus.
Vous êtes autonome, rigoureux.se et avez une excellente capacité d’analyse ? N’hésitez pas à postuler.
Rejoignez la Banque Postale, Banque et Citoyenne !

Job Reference: LGLBP00288"
Clichy (92),,,Senior Data Engineer,L'Oreal,- Clichy (92),"Contexte :

L’équipe Global IT Data a pour mission de conduire et d’opérer la plateforme au bénéfice du groupe tout en délivrant les use cases de BeautyTech L’Oréal.
Vous rejoindrez l’équipe de Data Engineering dont le rôle est :
Depuis l’exploration jusqu’à la mise en place de data pipelines industriel
le développement de capacités analytiques avancées
le développement d’une pratique de data engineering orientée qualité et vélocité

Missions :

Le Head of Data Engineering / Senior Data Engineer a pour mission de :

le design et la creation des data pipelines pour alimenter les produits analytiques (dashboard, ML models)
l’expansion et l’optimisation de ces data data pipelines pour tendre vers du temps réel et pour toute source de données (base, fichiers, API)
de travailler avec les architectes data fonctionnel pour définir la solution et le modèle de données
d’être en support des data scientist dans la construction, le training et la mise en production des modèles.
De participer à la vie de l’équipe de data engineering en documentant et développant les outils et le framework data engineering.



Profil recherché :


Formation :


Ecole d’ingénieur ou Master dans les technologies de l’information, Data science ou du Data Engineering.


Expérience :


Plus de 5 ans d’expérience dans ce rôle.


Compétences techniques :


Experience dans le développement avec une maîtrise à minima de Python et de SQL
Maîtrise des environnement Big Data et plus particulièrement dans le cloud (Google Cloud Platform de préférence)
Certification Google Cloud Platform (Data Engineering) est un plus
Très bonne connaissance du mode de fonctionnement en agile
Bonne connaissance d’environnement applicatifs divers


Compétences générales :

Capacité à travailler en équipe et capacité de communication
Appétence pour la data et les sujets métier.
Capacité à travailler dans un environnement multicultural



Compétences comportementales :


Flexibilité/ouverture d'esprit; capacité d'alerte et d'argumentation ; diplomatie, relationnel ; qualités rédactionnelles tant en français qu’en anglais ; esprit de synthèse.
Capacité à piloter et challenger des prestataires extérieurs


Poste basé à Clichy avec des déplacements en région parisienne à prévoir pour des réunions, possibles déplacements à l’étranger sur des périodes relativement courtes et sur une fréquence occasionnelle (de 1 à 5 jours ouvrés)."
Gennevilliers (92),,,Data Analyst,PRISMA MEDIA,- Gennevilliers (92),"1er groupe bi-média de France en audience print-digital, Prisma Media est aussi l'acteur N°1 en presse magazine et en audience vidéo. Un leadership qui assure à Prisma Media un potentiel optimal d'audience de plus de 40 millions de personnes chaque mois sur ses différents médias.
Avec un portefeuille de 25 marques incontournables, le groupe est présent sur les principaux segments grand public (féminin, cuisine, télé, people, découverte, économie…).
Porté par la mission de devancer les besoins et envies de ses lecteurs et utilisateurs sur tous les supports, Prisma Media adopte une stratégie offensive de développement et d'innovation dans les secteurs en forte croissance tels que la monétisation de la data, la vidéo et le mobile, avec une ambition d'avoir toujours UN MÉDIA D'AVANCE.
Rattaché(e) au manager du service BI / Analytics / Data science, vous intervenez en tant que Data Analyst afin de développer l’analyse de données chez Prisma.

Ce service a pour vocation d'optimiser l’utilisation des données client et business par les différents services de l’entreprise, pour aider à la prise de décisions, améliorer la compétitivité de l’entreprise et participer activement à la transformation digitale. Tout cela s’effectue au travers des deux leviers que sont l’activité Analytics (BI) et la Data science.

Missions :
Vous exploitez les données disponibles via l’analyse de données et la présentation de recommandations auprès des équipes métier chez Prisma
Vous intervenez sur l’ensemble du projet : collecte et compréhension des besoins métier, extraction, transformation et préparation des données, analyse des données (analyse statistique, exploratoire, descriptive ou prédictive), interprétation et restitution des résultats
Vous développez des dashboards et data visualisations afin de mettre la donnée à disposition de l’ensemble des métiers pour les aider à piloter leurs performances et optimiser leurs activités
Vous apportez une aide à la décision qui s’appuie sur les enseignements tirés des analyses et vous fournissez des recommandations actionnables aux métiers, via l’interprétation et la présentation des résultats aux équipes
Vous intervenez notamment sur les données issues de la diffusion (des magazines), du trafic digital et de la base CRM (Users accounts qui représente environ 2 Millions d’utilisateurs actifs et 3 Millions d’utilisateurs flottants) : analyse des ventes, analyse des comportements pour identifier des leviers et des opportunités de croissance, parcours client, fidélité, valeur client, churn, etc
Vous collaborez avec l’ensemble des départements (pôles marques, marketing, RH, régie publicitaire, …) en les accompagnant dans l’identification de leurs besoins et la structuration de la problématique, ainsi que dans l’appropriation des analyses
Vous collaborez avec les équipes IT, data engineers et data scientists et participer aux différents projets data (collecte de nouvelles sources de données, transformation de la donnée, déploiement des analyses)
Vous assurez une veille technologique sur les solutions d’advanced analytics et les solutions de gestion de données, les tendances et nouvelles pratiques

De formation supérieure (de type BAC+5, École d’Ingénieur ou équivalent universitaire Master), vous disposez de solides connaissances techniques en matière de data et avez également une réelle aptitude à comprendre les enjeux business et plus particulièrement ceux engendrés par la data
Vous disposez d’une expertise dans le domaine de l’analyse de données et des statistiques (analyse factorielle multivariée, tests statistiques, scoring, segmentation)
Vous possédez une expérience professionnelle de 3 ans minimum dans la mise en oeuvre d’analyses statistiques et d’un écosystème data au sein de systèmes complexes sur un grand volume de données et de trafic.
Vous êtes familier avec les méthodes agile (SCRUM / Kanban) et le cycle de vie du produit / projet.
Au-delà de vos compétences techniques, vous avez une approche business-centric.
Une connaissance des nouvelles réglementations de protection, et exploitation des données (GDPR, data cleaning, data delivery) serait un plus.
Vous êtes un bon communicant (la restitution des résultats aux équipes est clef) et aimez le travail en équipe.
Vous avez la capacité de présenter des notions complexes de manière simple et claire.

Compétences techniques:
Bases de données Oracle / SQL
Data visualisation (Salesforce, Tableau, PowerBI, QlikView)
Compétences cloud AWS ou GCP
Python (NumPy, SciPy, Pandas)
Vous respectez l’éthique en matière d’usage de la data.

Prisma Media propose tous ses postes aux personnes en situation de handicap en privilégiant une logique de compétence et d'emploi pérenne. Le groupe est signataire de la Charte de la Diversité et partenaire de l'association Adapt.
Exercice de vos droits
Conformément à la réglementation en vigueur, vous pouvez exercer vos droits d'accès, de rectification, d'opposition, de suppression, de limitation du traitement, et à la portabilité des données à caractère personnel, en adressant votre demande au DPO du Groupe Prisma Media, soit à dpo@prismamedia.com soit par courrier à Prisma Media - DPO, 13 Rue Henri Barbusse. 92230 Gennevilliers.
Entreprise: Prisma Media SNC
Pays: France
Etat/Région: Hauts-de-Seine
Ville: GENNEVILLIERS
Code Postal: 92230
Emploi ID: 76366"
Clichy (92),,,Senior Data Scientist / ML Engineer Supply Chain,L'Oreal,- Clichy (92),"CONTEXT :
Within the Beauty Tech Factory, the Tech Accelerator has to support and accelerate the transformation of L’Oréal on new technologies: Data Science & AI, IoT, Blockchain, UX / UI...
You will join the Data Science team for Supply chain use cases, whose defines the Group' Data Science & AI standards and implement them by delivering strategic and high priority projects for the group.

Its 4 main missions are:

Delivery :
Ensure the Data Science developments of Supply chain projects and develop scalable tech assets, starting with Demand Sensing project
Enrich a portfolio of data & analytics micro services at a global level
Standards :
Stimulate IT transformation by applying standards in terms of methodology, code, MLOps…
Manage an ecosystem of data science & tech partners and ensure high level of expertise
Data Culture :
Build, lead and orchestrate the global data science community
Scale and share technical assets
Tech Academy :
Ensure consistency of HR strategy through strong support for recruitments & academic partnerships
Contribute to learning journey definition and contents


You will evolve in a favorable environment:
Development of projects with many experts in their respective fields: Data Science, AI, Agility, Business experts, UX/UI, Data engineering, Big Data and Cloud architecture ;
Diversity of Data (internal / external, structured or not) and missions (marketing, supply, retail, ...) ;
International environment


MISSIONS :
As a Senior Data Scientist you will use Machine learning approaches to develop Data Science and AI solutions.
You will define and implement guidelines and best practices within Delivery teams, in collaboration with IT and business on strategic use cases.
You will design and develop Data Science solutions for strategic business cases with support of external Tech partners, and ensure the consistency of Tech guidelines within these projects.

Your mission will be to develop a Demand Sensing solution at group level with the main missions bellow:
Increase demand forecast accuracy by developing models, with huge code quality, based on time series, internal and external features ;
Coach and mentor L’Oréal Data Scientists and external Tech partners in an agile delivery squad ;
Ensure consistency of Tech Accelerator standards within the squad ;

SKILLS :



Tech skills :

More than 3 years of practical experience applying ML / DL to solve challenging problems ;
Extensive knowledge and practical experience on at less 2 projects deployed in Production, mainly Supply chain projects ;
Experience working effectively with engineering teams ;
Advanced programming skills : Python, Tensorflow, PyTorch, Keras, Spark or other frameworks ;


Soft skills

Excellent verbal and written communication (French and fluent English) and presentation skills, ability to convey technical concepts and their implications to non-experts
Flexibility and open-mindedness; alertness and argumentation; entrepreneurial spirit; relationship skills;
Collaborative mindset with different Tech profiles (data scientists, engineers & architects) and business (data owners & stewards, business owners)"
Paris (75),CDI,,Data Engineer big data H/F,direct energie,- Paris (75),"Contexte :
Dans le cadre de renforcer l’équipe BigData et d’internaliser les compétences au sein de Total Direct-Energie, nous souhaitons renforcer l’équipe avec un Data-Engineer .
Au sein de la direction des Systèmes d'Information, rattaché au responsable de pôle BigData, vous aurez pour mission :
Le recueil des besoins
L’analyse et la rédaction des spécifications techniques et fonctionnelles
L’élaboration du cahier des charges
De développer des programmes d'intégrations de données (Talend), Algos Machine learning ( PySpark) et modélisation des solutions pour le métier.
D'assurer les projets (BUILD), Industrialiser les solutions, mais également la maintenance (RUN) sur ces briques techniques,
De rédiger les spécifications techniques ainsi que toute la documentation d'exploitation,
D'assurer le déploiement sur les différents environnement

Profil
Formation
Formation informatique de niveau BAC+4/5 – Ecole d’ingénieur ou Université.
Qualités personnelles :
Autonomie
Dynamisme
Adaptabilité
Esprit d’équipe / bon relationnel
Bonnes capacités rédactionnelles
Un esprit de synthèse et une capacité à prioriser les problèmes

Compétences :
Solides connaissances Spark, et technos BigData ( Hadoop, Hbase, Hive)
Fort apprécié : connaissance de l’outil Talend
Bonnes pratiques Dev (JAVA, Python), et Industrialisation des solutions ( GIT, Jenkins, Maven )
En option : Connaissances Plateforme Azure.
Localisation du poste
Localisation
France, Ile-de-France, Paris (75)
Lieu
Paris"
Paris 10e (75),CDI,55 000 € par an,Data Engineer - H/F,FairMoney,- Paris 10e (75),"Python / Amazon-web-services / Google-cloud-platform / Scala / Spark
Data Engineer, Big Data Developer, Data Analyst, Big Data Analyst / CDI / Environ 55k€ / 3 - 6 ans / Paris

Le poste
Vous travaillerez en tant que DATA ENGINEER au sein de notre division technique, qui compte désormais 11 personnes. Vous serez dans notre équipe DATA avec Jadd et Loic qui sont nos Data Scientist. Comme vous pouvez le comprendre, vous serez notre premier Data Engineer ! Votre mission sera de gérer nos pipelines de données afin d'optimiser leur utilisation pour nos équipes de data science, de finance et d'analyse. Par exemple, votre travail nous permettra d'itérer plus rapidement sur les fonctionnalités utilisées dans notre algorithme de notation de crédit afin d'être plus compétitif sur le marché et de contribuer à notre rapide croissance .
Les responsabilités
L'amélioration de notre infrastructure de données (data warehousing);
Permettre l'accès aux gestionnaires de risques (data scientist / finance) à un catalogue de fonctionnalités facilement utilisables, quel que soit le volume de données brutes;
La mise en place de bonnes pratiques concernant les données afin de s'assurer que le pipeline est reproductible.
Pourquoi venir chez nous?
FairMoney est en train de construire la première banque mobile pour les marchés émergents. Nous avons commencé par une application numérique de microcrédit sur Android, et nous déployons actuellement des services financiers supplémentaires (compte courant, épargne, carte de débit) tout en étendant le produit à l'Afrique de l'Ouest et à l'Asie du Sud-Est. Nous avons déboursé près de 500 000 microcrédits et accordons plus de 5 000 prêts par jour. Nous sommes soutenus par des investisseurs américains et européens de premier plan et avons levé 15 millions d'euros + du capital-risque pour soutenir notre croissance."
Paris (75),CDI,,CHEF DE PROJET DATA SCIENCE (H/F),Epsilon France,- Paris (75),"EPSILON accompagne la transformation business des entreprises grâce à la data. Nous sommes le plus grand acteur datamarketing en France, avec 750 talents Adtech et Martech qui aident les entreprises à stimuler leur croissance et améliorer leur efficacité opérationnelle grâce et autour de la data.
Au sein du pôle Data Science, constitué de 90 personnes, qui réalisent des études statistiques (intervention directe chez le client ou au siège) afin d’apporter des réponses opérationnelles aux problématiques marketing de nos clients : fidélisation, recrutement, attrition, valeur, durée de vie, appétence, satisfaction, prévision, moteurs de recommandation liés à la DMP, accompagnement au changement, formation.
QUE FAIT UN CHEF DE PROJETS DATA SCIENCE
Gérer et piloter les projets Data Science. A ce titre, vous êtes en charge de la relation client et garant de la qualité de la prestation (respect du planning, du budget, des méthodologies mises en place et des restitutions aux clients),
Assurer le support méthodologique et technique pour les consultants. Vous êtes source de conseils tout en participant à la réalisation effective des travaux (machine learning, deep learning, random forest, segmentations, modélisation, veille technologique …),
Assurer un rôle commercial : détection des besoins et réalisation de propositions commerciales,
Assurer un rôle de formateur et d’expert.
Exemple de missions confiées à des Chefs de Projets :
Grand groupe de presse : mise en place d’un moteur de recommandation sur Internet dans un environnement big data.
Distribution spécialisée : Construction d’une segmentation client permettant de personnaliser la relation client.
Banque de détail : Construction de persona via des méthodes de Random Forest sur un environnement Big Data.
VOUS MARQUEZ DES POINTS SI
De formation supérieure en statistiques, vous avez déjà conduit plusieurs projets Data Science chez l’annonceur ou en prestation de services, sur des problématiques marketing.
Vous appréciez la collaboration avec des interlocuteurs variés issus d’univers différents : marketing, intégration CRM, équipe Big Data… De plus, vous êtes reconnu pour votre capacité à fédérer, coordonner et motiver vos équipes.
Vous maîtrisez les méthodes statistiques standards et leurs applications opérationnelles sur un environnement Big Data, ainsi que l’un des principaux logiciels statistiques du marché : Spark, R, SAS, Python.
Vous avez déjà piloté un projet ou la réalisation d’études datamining. La connaissance de gestion de projet en mode agile serait un plus."
Carrières-sous-Poissy (78),Apprentissage,,Exploration des innovations PowerTrain permises par le BigData et deep learning H/F,PSAPeugeotCitroen,- Carrières-sous-Poissy (78),"Vous intégrerez la Direction de la Recherche et de l'Ingénierie Avancée du groupe PSA et en particulier le pôle Advanced PowerTrain & Energy qui est en charge de développer des innovations dans les domaines des chaines de traction thermiques et électriques.

Notre équipe évalue le potentiel des systèmes de connectivité du véhicule pour optimiser le pilotage et les prestations des chaines de tractions grâce à une meilleure connaissance des habitudes de conduites de nos clients.

Pour cela nous avons identifié des besoins de développement de modèles de prédiction basés sur l'apprentissage des habitudes du client.

Les usines, les véhicules en développement et en série produisent chaque jour un flux important de Data qui sont collectées dans un data lake PSA. Conjointement à ce stockage de masse, un cluster de serveur du type Hadoop est mis à disposition des data analystes afin de mettre en place des dashboard de suivi de la production et de la qualité des usines et des véhicules produits. Ces serveurs sont également mis à disposition des datascientistes rattachés au différents domaines techniques afin de mener à bien des travaux d'exploitation de ces données au travers d'analyse statistiques ou machine learning.

Les missions du pôle data innovation powertain sont :
Exploiter les données recueillies pour analyse potentialité de sujet techniques innovants
Imaginer, identifier, explorer de nouvelles fonctionnalités ou services clients permises par la data, que ce soit en débarqué dans le Cloud PSA ou en embarqué au travers du véhicule connecté.
Évaluer également de nouveaux services ou fonctionnalités liés à l'exploitation de la data s'adressant à des acteurs business tels que les gestionnaire de flottes (exemple de la maintenance prédictive du Powertrain)

Ainsi, la mission proposée pour cet apprentissage se déroulera en plusieurs étapes adaptées au cursus académique d'un ingénieur datascientistes :
Formation aux outils et process d'exploitation BIG DATA, suivi de l'évolution de l'outillage.
HADOOP, GPFS, SPARK, Python, Jupyter, SQL, Oracle Exadata, Hbase,
Respect du cadre juridique RGPD : Anonymisation et floutages
Exploitation des bases de données et synthèses pour les sujets innovants
Power BI, Excel, PowerPoint, Word
Veille sur les techniques Intelligence et Artificielle, mise en place de tutoriels pour diffusion à l'équipe et participation à un workshop IA organisé en interne groupe.
Elaboration de référentiels DATA Science sur différentes problématiques
Sujet datascience appliqué au powertrain : exemple maintenance prédictive
Identifier les paramètres influants sur l'apparition des pannes / défauts / vieillissement prématuré
Modélisation RUL (Remaining Useful Life), Machine learning à partir des base de données défaut
Deep learning, analyse séries temporelles à partir des données remontées par les véhicules, Plan d'expérience sur les principales méthodologies de machine learning existantes
Profil
Profils : Datascience, DataAnalyst
Spark, Python, HADOOP, Jupyter
SQL, environnement hadoop et base Oracle Exadata, ainsi que Hbase
PowerBI
Durée du contrat
36 mois
Localisation du poste
Pays
Europe, France, Ile-de-France, Yvelines (78)
Ville
Carrières-sous-Poissy
Critères candidat
Niveau de diplôme préparé
Bac+5
Langues
Anglais (C1 - Courant (3,5 - 4,4 Bright))"
Paris (75),"Temps plein, Freelance / Indépendant",700 € par jour,Lead Data consultant / Freelance,Gentis Recruitment SAS,- Paris (75),"Bonjour,

Nous sommes à la recherche d’un lead data consultant :
Doté d’une double casquette : expertise Data + compétences de consulting, vous intervenez comme Sénior Data consultant / Subject Matter Expert sur les grands comptes de Publicis Sapient France pour construire et opérationnaliser la vision Data des programmes de transformation digitale de nos clients.

RESPONSABILITES

Appuyer les équipes commerciales pour :
o Identifier et affiner des opportunités commerciales sur l’ensemble des applications Data (Performance Digitale, l’IA et l’Engineering Big Data)
o Penser, produire et défendre le volet Data de propositions commerciales

Intervenir comme Subject Matter Expert sur des grands comptes pour :
o Interagir avec les décideurs et les leads du programme pour comprendre leurs enjeux, proposer des solutions et présenter l’impact de l’intervention des experts Data
o Construire et opérationnaliser la vision Data au sein des programmes de transformation digitale sur lesquels tu interviens
o Guider les experts data impliqués sur tes projets pour s’assurer qu’ils délivrent de la valeur

Collaborer avec la manager de l’équipe data et lui donner de la visibilité sur les comptes sur lesquels vous intervenez pour :
o Mobiliser les experts en fonction des demandes clients
o Avancer sur les axes de développement stratégiques
o Partager des learnings et bonnes pratiques
PROFIL
Excellentes capacités de communication avec les décideurs et les C-level en français et en anglais
Excellentes capacités à traduire des cas d’usage business en solutions Data concrètes
Excellentes capacités à valoriser et orchestrer l’ensemble des expertises Data de l’agence (Performance Digitale, Machine Learning et Engineering Big Data)
Team player capable d’intégrer la Data au sein des autres expertises du digital
Expérience approfondie dans l’une des expertises : Performance Digitale, Machine Learning et Engineering Big Data.
Expérience des grands providers du marché (cloud providers et services managés pour la Data Science, outils d’analytics, d’AB testing et de personnalisation pour l’analytics )
Expérience de consulting dans le domaine de la transformation digitale
Expérience dans l’une des verticales suivantes (Retail, Energie, Automotive, Financial Services, CPG, Travel & Hospitality)

COMPETENCES APPRECIEES
Au moins 5 ans d’expérience dans le conseil

Au plaisir d’échanger avec vous au ou par mail en cliquant sur postuler.

Bonne journée,
Mamoune OUAZZANI"
Paris (75),CDI,,Consultant Data et Digital Integration,ASTRAKHAN,- Paris (75),"Vous participerez au choix de nouvelles plateformes, au développement de nouvelles technologies (Java/ JavaEE) et spécifications techniques des besoins exprimés par le client.

Vous aurez également l’occasion d’adresser toutes les problématiques d’intégration digitale : API Management, Micro Services, Cloud, iPaaS…

Vous avez un savoir-faire sur une ou plusieurs des thématiques des données et vous vous sentez capable d’étendre vos compétences sur toute la Data Science : Big Data, Gouvernance des données, Analyse des données, Data Vizualisation…

Au sein d’Astrakhan vous aurez également la possibilité de développer de nouvelles offres, d’explorer de nouvelles technologies et de participer activement à nos travaux de communication.

Profil
Bac+5

Vous êtes passionné(e) de nouvelles technologies.

Vous possédez de fortes capacités à communiquer et à animer.

Vous maitrisez l’anglais.
Région Paris
Contrat CDI
Statut Cadre du secteur privé
Niveau d'expérience 0 – 2 ans d’expérience"
Paris (75),CDI,,Directeur(trice) Innovation Data Science & Intelligence Artificielle,SOCIO DATA MANAGEMENT,- Paris (75),"Contexte
Leader reconnu pour le traitement des études, Socio Data Management se positionne comme le partenaire de référence pour la valorisation des données. Nos consultants experts accompagnent les grandes entreprises et administrations durant toutes les étapes de leurs projets Data. Nos équipes les conseillent pour le déploiement de solutions techniques innovantes afin de répondre aux enjeux du Big Data et œuvrent à leur transformation digitale.
Depuis l’intégration des données jusqu’à leur mise à disposition sur des plateformes en ligne, nous mettons notre savoir-faire au service de nos clients sur toute la chaîne de valeur de la Data. Spécialistes des traitements et analyses complexes de données, nous les aidons à les exploiter efficacement pour prendre des décisions optimisées.
Acteur d’un marché en pleine révolution, notre cabinet souhaite recruter un(e) Directeur(trice) Innovation Data Science & Intelligence Artificielle afin de l’accompagner dans sa croissance.
Missions
En tant que Directeur(trice) Innovation Data Science & Intelligence Artificielle, rattaché(e) à la Direction Générale, et en lien avec nos équipes d’experts, vous êtes porteur de l’innovation et de l’évolution des projets dans le domaine de la Data science et de l’Intelligence Artificielle.
Fort de votre expérience et de votre charisme, vous êtes acteur majeur dans le recrutement et le management de l’équipe Innovation.
Vous endosserez, bien entendu, le rôle de référent Data Science et Intelligence Artificielle au sein de l’entreprise. Vous êtes le(la) garant(e) de la réalisation des projets, à ce titre vous avez en charge :
Le pilotage des projets :
Data science : algorithmie, IA, analyse descriptive et prédictive, machine learning…
Data visualisation : construction de dashboards adaptés aux enjeux opérationnels et managériaux ;
Le recueil des besoins & définition des cas d’usage business ;
La manipulation et l’analyse avancée de données ;
Le respect des délais et de la qualité de service attendue.
Vous êtes le(a) responsable de la formation des consultants et/ou clients.
Accompagnement ;
Formation ;
Veille sur l’état de l’art et les méthodes adéquates.
En étroite collaboration avec notre équipe commerciale, vous avez également pour responsabilités :
Le support et l’accompagnement des équipes commerciales sur les outils, analyses et méthodologie d’analyses de données ;
Le conseil dans l’élaboration des parties fonctionnelles et techniques des propositions commerciales.
Vous êtes force de proposition concernant les choix stratégiques du développement de notre activité.
Profil recherché
Diplômé(e) d’une grande école d’ingénieurs ou équivalent, vous possédez au moins 8 ans d’expérience.
Vous avez été exposé(e) à des sujets majeurs de traitements de données et avez acquis une bonne compréhension des enjeux stratégiques data ainsi qu’une bonne vision des tendances du marché.
De plus, vous justifiez d’une solide expérience technique en matière de traitement de données et d’encadrement de ce type de projets.
Vous êtes reconnu(e) pour votre capacité à prendre du recul, mais également pour votre vision à moyen et long terme du marché de la Data Science, votre leadership et votre autonomie, vous appréciez le travail en équipe et la relation client.
Fort(e) de votre expérience professionnelle, vous avez à cœur d’être acteur(trice) du développement d’une activité et d’en assurer la croissance en adéquation avec les enjeux du marché.
Nous rejoindre
Rejoindre l’équipe Socio Data Management c’est :
Un engagement de proximité : entreprise à taille humaine, nous restons proches de nos collaborateurs afin de les accompagner de façon pertinente dans leurs carrières.
Une garantie de diversité : nous intervenons sur des projets divers, enrichissants, innovants et à forte valeur ajoutée pour nos clients dans différents secteurs d’activités.
Une promesse d’innovation : en tant qu’expert Data, nous faisons partie du Data Lab, un véritable pôle R&D qui a pour vocation de faire émerger des initiatives innovantes.
Un gage d’intégration : faisant partie intégrante d’un groupe, nos collaborateurs ont la possibilité de créer et de tisser du lien, tout en développant leurs connaissances sur des sujets transverses (cybersécurité, gestion des risques, IT…).
Bénéficier de nos avantages : accès à notre plateforme CE, attribution de chèques-cadeaux, tickets-restaurants, prime vacances…"
Paris (75),"Temps plein, CDI",,Data Analyst Senior H/F,JOHN PAUL,- Paris (75),"A PROPOS DE JOHN PAUL
Leader des services de conciergerie, John Paul aide les marques et les entreprises à fidéliser leurs clients et leurs collaborateurs. Depuis 2008, nos concierges privés accompagnent nos membres dans leur quotidien, pour répondre à tous leurs besoins et à toutes leurs envies, 24h/24 et 7j/7, partout dans le monde.
John Paul fait partie du groupe Accor depuis novembre 2016.

Les avantages à rejoindre John Paul :
Évoluer dans une entreprise innovante et un secteur dynamique en pleine croissance
Avoir des opportunités d’évolution en interne et la possibilité de continuer l’aventure dans l’un de nos bureaux à l’étranger
Faire partie d’une famille avec un fort esprit d’équipe
Travailler dans un environnement idéal : bureaux neufs au cœur de Paris, vue rooftop à 360°, cafés à volonté, espaces collaboratifs…
Pouvoir participer toutes les semaines à des activités entre collaborateurs (challenges, petits-déjeuners, afterworks, jeux…)
Bénéficier d’avantages et de tarifs préférentiels réservés à nos membres

MISSIONS
Au sein du Pôle Digital et intégré à l’équipe Data, votre rôle sera de :
Collecter, comprendre et traduire les besoins des équipes métiers (client success, marketing, operations, partenariat…)
Proposer la meilleure réponse / les options possibles en fonction du besoin (reporting, machine learning, segmentation, scoring, analyse textuelle…), dans une recherche continue d’efficacité et d’excellence
S’assurer de la fiabilité de la réponse, son adéquation au besoin, ainsi que du respect des plannings
Connaitre sur le bout des doigts les données disponibles chez JohnPaul, leurs qualités et leurs défauts
Savoir proposer des méthodologies innovantes pour mieux comprendre le comportement de nos membres
Etre force de proposition pour augmenter l’utilisation de la data chez JohnPaul, en quantité et en qualité
Vous aimez travailler la donnée sous toutes ses formes (structurée et non structurée), de tous origines (conciergerie, web-analytique, CRM, téléphonie, réseaux sociaux, open data…), sur tout son cycle (collecte, transformation, utilisation, amélioration). La transmission de cette connaissance aux autres équipes, l’utilisation concrète de vos conclusions et l’impact de votre travail sur la stratégie de l’entreprise sont pour vous une source de motivations et pour nous une preuve de succès.
Vous intégrerez une équipe exigeante et dynamique, soucieuse d’offrir à ses clients un service répondant aux très hautes exigences du secteur du luxe.

PROFIL
De formation supérieure en statistiques, data science ou mathématiques appliquées, le candidat idéal devra :
Faire preuve de rigueur, d’autonomie, de curiosité, d’écoute
Être capable de mettre en pratique ses connaissances techniques sur des problématiques et des données réelles, en échange avec les équipes business
Être force de proposition et dans une démarche positive
Avoir une première expérience des données Web Analytics (mise en place de tracking ou exploitation)
Avoir des connaissances en bases de données (manipulation, aspects fonctionnels)"
Paris (75),CDI,,Consultant Senior Data Science (F/H),OCTO Technology,- Paris (75),"Vous faites partie de ceux qui pensent que même avec 7 ans d’expérience, on peut toujours apprendre et être challengé ? A la croisée des compétences entre mathématiques, statistiques et développement, vous apportez une vision dans la valorisation des data de nos clients.
Profil recherché
F/H
Vous disposez d’au moins 7 ans d’expérience en développement ou en architecture sur des projets avec un focus sur les données (voire de data science).
Vous souhaitez maintenir et développer votre expertise tout en apportant votre vision sur des missions de cadrage et de conseil en data
Vous êtes tourné vers le pilotage de projets (avec une forte appétence agile),
Vous avez de l’écoute et aimez partager. Passionné par les sujets technologiques, vous êtes à l’aise pour conseiller voire challenger les demandes de vos clients,
Vous souhaitez vous confronter et contribuer à une communauté d’experts, pour qui l’évolution des pratiques et l’apprentissage continu font particulièrement sens.

Mais ce que nous cherchons avant tout, ce sont des personnalités qui enrichiront OCTO. Nous les reconnaissons à leur volonté de participer à l’amélioration de la vie de l’entreprise, de construire la vision et les offres de demain, de partager leurs connaissances pour faciliter la montée en compétences réciproque. De rejoindre, enfin, une communauté qui n’a pas peur d’affirmer sa différence.
Détails de l'offre
Type de poste : CDI
Lieux : Paris, Île-de-France (FR)
Descriptif du poste
Votre mission sera de permettre la réalisation de projets agiles qui comportent des enjeux majeurs autour du traitement de données, ont du sens, répondent à un besoin métier et s’inscrivent dans la durée.

En tant que référent au sein des équipe data d’OCTO, vos missions sont multiples :



Conseil
Vous apportez votre expertise auprès de nos clients en adoptant une posture conseil.
Vous participerez à des problématiques de transformation vers la data driven company.

Conception
Vous développez et améliorez de manière continue de nouveaux modèles prédictifs alliant Big Data et Machine Learning.
Vous participez à la conception d’architecture BIG DATA.

R&D/communication
Vous développez vos domaines d’expertise en participant à la R&D d’OCTO (rédaction d’articles ou d’ouvrages, conférences de référence).
Vous travaillez sur des POCs.

Management et partage
En tant que senior, vous partagez votre expérience et votre expertise auprès des data scientists juniors, sur les projets où vous intervenez
En parallèle, vous êtes amené à manager des Octos que vous coachez, et développez (savoir-faire / savoir-être)"
Paris (75),CDI,,Consultant.e BIG DATA,INSYCO,- Paris (75),"Créée en 2007, INSYCO est une ESN indépendante qui accompagne ses clients, grandes organisations de tous secteurs d'activités, dans l'optimisation de leurs systèmes d'information et transformation digitale. Société à dimension humaine, INSYCO privilégie les partenariats de long terme et de qualité fondés sur la confiance et la dynamique du partage.

Dans le cadre de son développement, Insyco Data recherche des consultant.e.s Big Data.

Rattaché.e au Manager Data/BI, vous interviendrez d'une façon générale sur les différentes phases d'un projet Big Data.

Valoriser et analyser les données de l'entreprise (cartographie)
Classer les informations recueillies en fonction des besoins métier
Concevoir et gérer l'architecture Big Data : DataLake, Datamart/Datawarehouse, cloud (AWS,AZURE...)
Mettre en place et configurer les clusters (ex:Hadoop/Kubernetes)
Réaliser les tests techniques et les spécifications techniques
Faire de la veille technologique
Rédiger des rapports

De formation Bac +5, vous bénéficiez idéalement d'une expérience réussie de 2 à 3 ans en Big Data et/ou en BI.
Vous êtes un profil technico-fonctionnel sur les sujets Big Data.

Vous êtes familier avec certaines des technologies/concepts suivants:
Bases de données : No SQL, SQL ...
Systèmes d'information : ERP, CRM, SAP ...
Modélisation de données : DataLake, Datawarehouse, Datastream, Datamart
Stockage de données : HDFS, Snowflake, Redshift, Parquet files, etc..
Cloud :AWS, AZURE, GCP...
Languages : Python, Java, HTML ...
R
ETL
Logiciel d'analyse de données : Pentaho, PowerBi, Tableau,
Etc.

Dynamique, rigoureux, doté.e d'un bon relationnel ainsi qu'une bonne capacité d'analyse, vous souhaitez vous investir dans un poste évolutif dans une entreprise dynamique aux valeurs humaines. Nous intervenons dans des grands comptes avec des grosses volumétries dans des contextes innovants.

Poste à pourvoir en CDI chez Insyco.

La maîtrise de l'anglais est requise.

Avantages :
Titre-restaurant
RTT
Mutuelle
Ordinateur portable / téléphone
Prise en charge du pass navigo (100/100)"
Paris (75),"Temps plein, Stage",,Stage - Assistant Chef de Projet Big Data,Pernod Ricard,- Paris (75),"STAGE A POURVOIR A PARTIR DE JUILLET 2020
PENSEZ A LA LETTRE DE MOTIVATION
Identité :
Co-leader mondial des vins et spiritueux, leader du segment Premium, Pernod Ricard dispose d’un portefeuille 14 Marques stratégiques. Avec un chiffre d’affaires de 9.2 milliards d’euros, le Groupe coté au CAC 40 est présent dans 70 pays et compte près de 19 000 collaborateurs .
Présentation du département : Direction des Systèmes d’Information du Groupe, pôle IT BI Solutions
Finalité du poste : Assister le chef de projet Big Data dans la conduite de nouveaux projets Big Data et participation aux processus de support des applications, l’assistance aux utilisateurs et le pilotage des évolutions applicatives.
Rôles et responsabilités :
Valoriser l’ensemble des données collectées via le déploiement de projets « data-driven » afin d’améliorer la connaissance consommateurs et clients.
Créer les pipelines de données nécessaires à l’alimentation de la plateforme (collecte, formatage et traitement)
Permettre la diffusion et la restitution des données collectées (solution de dataviz, API, applications web ou mobiles).
Elaborer une documentation des travaux réalisés.
Participer à l’élaboration et au déploiement de l’architecture data de Pernod-Ricard (bases NoSQL, analyse de données en temps-réel, serverless architecture, Cluster Hadoop/Spark)
Effectuer une veille technologique active afin d’anticiper les nouveautés liées au Big Data.
Apports du stage :
Acquisition d’une vue d’ensemble de différents domaines métiers au travers des applications Big Data : Reporting, Finance, Marketing, Digital, supplychain, Front et Back office.
Introduction au métier de chef de projet
Implication du stagiaire dans les projets stratégiques globaux et opérationnels locaux
Travail au siège d’une entreprise du CAC40 à dimension internationale
Compétences requises :
Savoirs et référentiels : Appétence forte pour les sujets « Data » et compréhension des enjeux métiers.
Savoir-faire et outils : Maitrise de la programmation, agilité avec les systèmes d’information. Des compétences en data-science seraient un plus.
Savoir-être : capacité d’adaptation et de résolution de problèmes, excellentes capacités d’analyse et de communication
Profil recherché :
Formation initiale requise : Ecole d’ingénieurs avec options/expériences en Gestion de projets, Ecole d’ingénieurs généraliste (BAC +4/+5)
Expériences professionnelles demandées : 1ère expérience en Systèmes d’Informations souhaitée
Langues à maitriser : Anglais courant
Job Posting End Date:
Target Hire Date :
2020-07-15-07:00
Target End Date :
2020-12-25-08:00"
Paris (75),"Temps plein, CDI",,Data Scientist with a PhD in Computer Science,Dreamin,- Paris (75),"Who we are
*
Founded in 2016, Dreamin is an expert of user acquisition for international app developers. The startup's know-how combined with our proprietary technology allows us to target the most engaged users across the world, the ones who will be the most profitable for our clients. With a ROI-centric approach, we at Dreamin have invested in the development of our own unique platform, allowing real-time optimizations of our ad campaigns and results. Our main intention and aim is to establish ourselves as a mobile advertising expert in the international market.
Dreamin is a Paris based company with a dynamic and fast growing global team with a thriving success of our new Berlin and Bucharest offices.
Who you are
We are looking for a talented Data Scientist with a PhD in Artificial Intelligence (entry-level/no previous working experience is required). In this position you will be responsible for incorporating machine learning algorithms on our SaaS Platform.
But moreover, we are looking for a person with enthusiasm and confidence who would like to make a valuable contribution to our business by building a R&D culture from scratch. This work will involve close interaction with our international Development team composed of 5 strong personalities.
As a Data Scientist you will have the opportunity to work with the latest technology and the most exciting trends in the marketplace. Imagine your Mondays are as exciting as your Fridays because you are part of a team that builds value-added solutions that customers really love.
If you are passionate about Data & Technology, always positive and willing to do more in order to improve yourself, join our team!
What are we looking for
Recommendation System and Deliver optimized campaigns: the bulk of the work will be in areas of data exploration and preparation, data collection and integration, machine learning (ML) and statistical modeling and data pipe-lining and deployment.
Data Exploration and Preparation: Apply statistical analysis and visualization techniques to various data, such as hierarchical clustering; generate and test hypotheses about the underlying mechanics of the business process; network with domain experts to better understand the business mechanics that generated the data
Data Collection and Integration: Understand new data sources and process pipelines; catalog and document their use in solving business problems; create data pipelines and assets the enable more efficiency and repeatability of data science activities
Machine Learning and Statistical Modelling: Apply various ML and advanced analytics techniques to perform classification or prediction tasks; integrate domain knowledge into the ML solution (for example, from an understanding of financial risk, customer journey, quality prediction, sales, marketing); testing of ML models, such as cross-validation, A/B testing, bias and fairness
Operationalization: Collaborate with ML operations (MLOps), data engineers, and IT to evaluate and implement ML deployment options; (help to) integrate model performance management tools into the current business infrastructure; (help to) implement a champion/challenger test (A/B tests) on production systems; continuously monitor the execution and health of production ML models; establish best practices around ML production infrastructure
Qualifications
PhD in Computer Science - Artificial Intelligence/ Machine Learning/ Deep Learning
Relevant project experience in successfully launching, planning, executing data science projects
Experience of working across multiple deployment environments including cloud, on-premises and hybrid, multiple operating systems and through containerization techniques such as Docker, Container Service, and others
Experience with distributed data/computing and database tools. Postgres is a plus
Adept of agile methodologies and well-versed in applying DevOps/MLOps methods to the construction of ML and data science pipelines
Specialization in text analytics, graph analysis or other specialized ML techniques such as deep learning, etc.
Coding knowledge and experience in Python
Knowledgeable with SQL and experience working with large data sets.
Good English communication skills, both verbal and written. French would be a plus.
Your profile
Confident, energetic self-starter, with strong moderation and communication skills
Strong analytical, problem solving and critical thinking skills
Ability to work under tight timelines for multiple project deliveries
Ability/flexibility to travel and work abroad for international projects
Develop novel statistical / machine learning approaches to real world, large scale problems
As a member of our team you get
A motivating and competitive compensation package that rewards your performance and the value you bring to our business
A unique career opportunity in one of the most promising startups in the market, as the first member of our new R&D team
Plenty of training opportunities
A clear path for progression, tailored to your own unique talents and ambitions
Exposure to colleagues and senior stakeholders across the business
The freedom and flexibility to handle your role in a way that’s right for you
Flexible working (times and location) is part of our culture where your hours can facilitate your personal work-life balance
More info on the company environment here :
https://www.welcometothejungle.com/en/companies/dreamin
Here, you have also a small video explaining the values of Dreamin mainly :
https://www.welcometothejungle.com/en/companies/dreamin#play-video
*
Job Types: Full-time, Permanent
Experience:
data scientist with a phd in computer science ou similaire: 1 year (Preferred)
Work Remotely:
Temporarily due to COVID-19"
Levallois-Perret (92),"Temps plein, CDI",,FULL REMOTE Senior Data Scientist H/F - CDI,Jellysmack,- Levallois-Perret (92),"Nous continuons de recruter et avons adapté notre processus de recrutement. Tous nos entretiens, ainsi que l’onboarding, se déroulent désormais en full remote.
Cette offre d'emploi est proposée en FULL REMOTE
Jellysmack est une entreprise spécialisée dans la création de contenus vidéos originaux sur les réseaux sociaux. Avec plus de 3 milliards de vues par mois, Jellysmack a connu une ascension fulgurante, ne cesse de grandir et ambitionne de devenir le leader mondial dans son domaine. La recette de ce succès repose sur la qualité de nos contenus, mais aussi sur la technologie opérant en arrière-plan. Jellysmack a développé une suite d'outils propriétaires, propulsés par l'IA, permettant à nos équipes de contenu de publier, s'inspirer, comprendre la trend, analyser les résultats, mais bien plus encore, des outils qui analysent le contenu en ligne, les réactions des gens devant ce contenu, et déterminent ce que sera la tendance demain.
Après plus de 2 ans de développement technique, Jellysmack propose une technologie unique articulée autour de 3 produits qui visent à optimiser la création et la distribution sociale de vidéos.
L'équipe Tech œuvre pour la mise en place d’outils utilisés en interne par les équipes contenu afin de déterminer les sujets qui buzzent, les aider dans la création de contenu, suivre les performances des vidéos internes etc... en injectant dans chacun de ces produits une dose conséquente d’algorithmie, de statistiques et de machine / deep learning.
En lien direct avec le Head Of Data (basé en Corse), vous serez amené à travailler sur différentes problématiques - prioritairement axées autour du NLP - et sur des projets de taille très différentes, impliquant d’importantes quantités de données (plusieurs centaines de millions de vidéos stockées en base à date avec leur métadata textuelles, plus de 21 milliards de commentaires...).
Au sein d’une équipe de sept data scientist, vous serez le référent de l’équipe sur ces sujets d’analyse et de compréhension du langage et vous aurez un rôle consultatif.
Missions principales
Passer d'une problématique métier à un algorithme de data science
Passer d'un POC à un algorithme en production
Vulgariser un algorithme à l'état de l'art et être référent de l'équipe Data Science
Etre autonome sur les outils comme Git, avoir déjà travaillé sous docker - idéalement sous AWS
Quelques exemples de sujets :
Analyse de sentiments sur les commentaires des vidéos
Extraction de topics à partir des titres, descriptions, commentaires des vidéos
Catégorisation de vidéos en thématique à partir de l’ensemble des éléments textuels dont nous disposons
Génération automatique de titre/tag de vidéos...
Création d’un algorithme d’identification des meilleurs créateurs sur une thématique donnée
Analyse de vidéos (contenu et metadata) pour mieux comprendre la rétention des utilisateurs
Optimisation de coût sur l’acquisition de fans
Génération automatique de montage de vidéos...
Profil recherché
Docteur en computer science ou diplômé d’une maîtrise en data science, vous disposez d’au moins 5 ans d’expériences,
Une autonomie sur le passage en production d’algorithmes sera indispensable,
Vous êtes pédagogue sur la transmission de votre savoir,
Vous avez un très bon niveau de SQL (MySQL et PostgreSQL).
Avantages :
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
full remote senior data scientist h/f - cdi ou similaire: 1 an (Souhaité)"
Paris (75),CDI,,Data Scientist senior,MAWENZI PARTNERS,- Paris (75),"Présentation du cabinet
Mawenzi Partners est un cabinet de conseil en stratégie focalisé sur les leviers de croissance, qui s’appuie sur la recherche de sens pour développer le leadership de ses clients et la valeur ajoutée de ses consultants.
Situé à Paris, le cabinet est dirigé par trois associés issus de grandes écoles de commerce et d’ingénieur, ayant réalisé tout leur parcours professionnel dans des cabinets de conseil réputés.
Mawenzi Partners compte aujourd’hui plus de 45 consultants accompagnant des clients de tout secteur et de toute taille, et conserve intact les valeurs et l’esprit entrepreneurial qui l’animaient dès ses premières heures, il y a plus de 7 ans.
L’offre du cabinet se décline en 4 thématiques :
Stratégie : Fixer des orientations stratégiques à 3-5 ans et contribuer à leur mise en œuvre
Marketing et ventes : Soutenir & développer le chiffre d’affaires
Innovation client : Innover pour accroître la valeur client
Organisation et transformation : Piloter et accompagner les transformations internes

Présentation de la mission
Afin de répondre à une demande toujours plus importante de ses clients concernant l’exploitation de leurs données et fort de ses compétences reconnues sur le marché, Mawenzi Partners cherche à structurer son équipe de data scientists via la création d’un DataLab, qui interviendra en support des missions et aura pour objectifs de :
Comprendre les problématiques clients et proposer des méthodologies d’analyse permettant d’y répondre
Construire un modèle de données stable et exploitable à partir des sources de données clients à retraiter, enrichies de données externes à identifier
Mener les analyses statistiques pertinentes en regard de l’objectif recherché, élaborer des modèles prédictifs et d’extrapolation
Interpréter les résultats pour tirer les conclusions pertinentes en regard des problématiques du client et de les mettre en forme
Livrer au client un modèle pérenne doté d’une interface utilisateur simplifiée
Nous cherchons une personnalité expérimentée d’entrepreneur capable de structurer et d’incarner le DataLab Mawenzi Partners auprès de nos clients. Son rôle consistera à :
Etre le garant des livrables du Data Lab dans le cadre des missions clients auxquelles il participera, notamment en encadrant l’équipe de data scientists juniors qui composera le Data Lab : il s’agira de les former aux statistiques et à l’utilisation des outils nécessaires, mais également d’encadrer la production de leurs livrables dans le cadre des missions clients
Structurer et développer le Data Lab:
Identifier les outils et compétences statistiques pertinents à acquérir au sein du Data Lab
Documenter des supports de formation interne à ces outils et statistiques
Effectuer les recrutements de data scientists en fonction des besoins
S’impliquer auprès des équipes managériales du cabinet pour :
Déceler les opportunités commerciales liées à l’exploitation statistique de la data auprès des clients
Insuffler les méthodologies du Data Lab dans toutes les missions où l’enjeu en serait pertinent
Estimer la charge nécessaire et rédiger la méthodologie des propositions commerciales
Par ailleurs, comme tout Mawenzien, le candidat sera également invité à participer au développement et à la vie du cabinet en s’impliquant sur les différents chantiers et évènements internes.

Compétences requises
Mawenzi Partners recherche un candidat motivé, possédant aussi bien de solides compétences analytiques que managériales.
Diplômé d’une grande école d’ingénieur (ENS, Polytechnique, ENSAE, Mines, Ponts, Télécom, Centrale-Supélec, ENSTA) ou titulaire d’un doctorat en statistiques, il justifiera d’une expérience de 5 à 10 ans et sera doté des compétences suivantes :
Management de projet (évaluation de charge, suivi des livrables, …)
Fondamentaux business, stratégie et marketing
Compréhension des problématiques business et enjeux de la donnée (dont les cas d’usage)
Structure d’une démarche de résolution des problèmes par la data
Esprit ouvert sur les usages de la données
Encadrement d’une équipe de data scientists
Engagement et esprit d’équipe
Esprit d’initiative
Compétences techniques :
Modélisation, Mathématiques et Statistiques appliquées
Algorithmique: machine learning, modélisation prédictive, data mining
Programmation R et Python
Analyse de données, dont big data
Maîtrise d’Excel (dont VBA), Access, Powerpoint
Utilisation des logiciels de visualisation (Tableau Software, Toucan Toco …)
Nous recherchons un profil à la fois de data scientist de haut niveau et d’entrepreneur ayant envie de participer au développement du DataLab et plus largement au développement d’un jeune cabinet de conseil en pleine croissance.
Lieu : Paris
Type d’offre : CDI
Pour postuler : Remplissez le formulaire ci-dessous"
Vélizy-Villacoublay (78),Stage,,STAGE - Ingénieur Data Science (H/F) - Construction de cartes de connaissance pour la ...,Dassault Systèmes,- Vélizy-Villacoublay (78),"Imaginez demain…
Utiliser les mondes virtuels pour soigner les patients et améliorer leur qualité de vie est un défi qui anime Dassault Systèmes. Une opportunité de stage est disponible au sein de l'organisation BIOVIA R&D France de Dassault Systèmes. Cette organisation est axée sur le développement de nouvelles technologies pour les industries des sciences de la vie et les chercheurs.

IDMIT « Infectious Disease Models and Innovative Therapies » (CEA / Université Paris-Saclay / INSERM) est une infrastructure nationale pour la biologie et la santé, dédiée aux recherches précliniques.
C’est une équipe de chercheurs avec une expertise approfondie contribuant au développement de vaccins de prochaine génération.

L'organisation BIOVIA R&D Living Map et l’IDMIT unissent leurs forces pour un objectif ambitieux : construire une carte de connaissance qui prédit le comportement des cellules immunitaires afin de concevoir et améliorer les vaccins de demain.

L'organisation R&D de BIOVIA fournira la puissance de la modélisation et l’approche prédictive avec les applications Living Map et Pipeline Pilot dans le contexte de la 3DEXPERIENCE Platform. L'IDMIT apportera les données expérimentales et leur expertise reconnue en immunologie. Les données traitées sont des résultats pré clinique expérimentaux in vitro et in vivo de la réponse immunitaire et de biomarqueurs de l’inflammation. En combinant les données expérimentales et des algorithmes de prédiction, il sera possible de concevoir des vaccins plus performants tout en réduisant leurs coûts de développement.

Vos futurs défis…
Vous serez en mi-temps entre les deux organisations. Vous conduirez des études pour construire des cartes de connaissance à partir de données expérimentales, (OMICs, Cytométrie, biomarqueurs), produites par l’IDMIT.
Votre capacité à sélectionner un ensemble de données expérimentales, les transformer mathématiquement et les fédérer dans une carte prédictive de l'effet biologique observé sera clé pour le succès du projet.

A cette fin, vous utiliserez et évaluerez des outils et prototypes d’analyse de données, développés par l’équipe R&D de BIOVIA. Vous serez également en charge de proposer et d’implémenter de nouvelles méthodes conduisant à l’amélioration du workflow de traitement des données et de prédiction.

Imaginez pouvoir comprendre, modéliser et simuler une réponse inflammatoire à un vaccin avec autant de précision, de sécurité et d'efficacité que dans le corps humain. Dassault Systèmes et l’IDMIT sont profondément convaincus que l'union de leurs forces et collaboration transformera et élèvera l'avenir des vaccins.
Vous êtes à la recherche d'un stage de 5 à 6 mois à partir d'avril 2020, vous êtes très motivé(e) et pensez que le data science sert les valeurs de la recherche médicale, alors postulez pour relever le défi !

Vos atouts pour réussir…
Etudiant(e) en Ecole d’Ingénieurs ou en Université, vous vous spécialisez en Bio-informatique ou en data sciences avec un goût prononcé pour la biologie, la recherche et le développement.
Vous avez de robustes connaissances en mathématiques et statistiques
Des connaissances en machine learning seraient appréciées
Vous êtes à l’aise avec un langage de programmation.
L’utilisation d’un outil d’ETL est un atout (Extract Load Transform, par exemple Pipeline Pilot)
Vous êtes intéressé(e) par la modélisation et la représentation de cartes de connaissance.

Motivé(e) par les data science, vous êtes :
Autonome et motivé(e) par l'apprentissage de nouvelles technologies,
Capable d’aller chercher l’information et de vous appuyer sur vos collègues
Force de proposition
Organisé(e) et rigoureux(se)
Anglais courant, à l’écrit et à l’oral"
Paris 10e (75),Temps partiel,,Mentor Data Science,OpenClassrooms - Mentorship Team (FR),- Paris 10e (75),"Vous souhaitez former les futurs professionnels des métiers de la science des données ? Vous avez une passion pour la data et vous souhaitez la communiquer ? Nous recherchons quelqu'un comme vous pour accompagner nos étudiants.

Votre mission : accompagner vos étudiants vers le succès de leur parcours au moyen de sessions hebdomadaires de suivi en visio-conférence.

Quelles sont les compétences communes à tous nos mentors ?
Passion : Dynamique et enthousiaste, vous partagez votre énergie et votre motivation est communicative
Pédagogie : Vous savez vous adapter aux profils et aux besoins de chacune de vos étudiants, et mettre en place un mentorat en adéquation
Communication : Vous vous placez toujours dans une attitude de dialogue, vulgarisez des concepts complexes, donnez des feedbacks constructifs
Coopération : Vous réalisez un suivi rigoureux et structuré de vos étudiants, en lien avec OpenClassrooms
Avec OpenClassrooms, vous apprenez continuellement, auprès de vos étudiants, ainsi qu’en vous tenant informé des évolutions de votre univers professionnel.



Quels sont les pré-requis pour mentorer sur ce parcours ?

Vous disposez d’au moins 2 ans d’expérience professionnelle en tant que data scientist, data analyst ou Ingénieur machine learning ?
Vous maîtrisez les statistiques, les probabilités, l'algèbre linéaire, l'analyse de données et la programmation numérique en Python ou R ?Vous maîtrisez les bases de données, les statistiques, l’algèbre linéaire et la programmation numérique (pandas, numpy...) ?
Vous êtes à l’aise avec des librairies de machine learning telles que scikit-learn, theano, torch, etc. ?
L’aventure vous tente ? Rejoignez-nous !

Pour postuler, vous aurez besoin de :
Remplir les informations demandées dans le formulaire ci-après
Valider le cours ""Devenez mentor chez OpenClassrooms"" et pouvoir en attester
Fournir une vidéo de 2 minutes présentant un projet en lien avec le parcours pour lequel vous postulez"
Paris (75),CDI,,CONSULTANT SENIOR DATA SCIENCE (H/F),Epsilon France,- Paris (75),"EPSILON accompagne la transformation business des entreprises grâce à la data. Nous sommes le plus grand acteur datamarketing en France, avec 750 talents Adtech et Martech qui aident les entreprises à stimuler leur croissance et améliorer leur efficacité opérationnelle grâce et autour de la data.
Vous intégrerez le pôle Data Science, constitué de 90 personnes, expertes dans l’exploitation des datas et le développement d’algorithmes basés notamment, sur des méthodes de Machine Learning et dont l’ambition est de répondre aux problématiques de nos clients :
Segmentation (style de consommation, valeur, omnicanal…),
Moteurs (de recommandations, de substitution…),
Analyse des parcours (omnicanal, d’équipement, de résiliation…)
Webanalytics
Analyse des sentiments (commentaires issus des réseaux sociaux, d’enquête, d’appels au service clients…)
Géomarketing (optimisation de réseau de points de ventes, typologie de zones d’implantation…)
Prédiction (de l’attrition, de l’appétence, de la valeur future, de la satisfaction…),
Prévision (de la durée de vie, des ventes, du trafic...)
QUE FAIT UN CONSULTANT SENIOR DATA SCIENCE
Cruncher, analyser et exploiter tous types de données (CRM, Produits, Digitales, Logistique, Yield, Open data…),
Déployer les méthodes de Machine Learning adaptées pour répondre aux problématiques posées,
Restituer les résultats au client dans le respect des engagements de qualité et de délai,
Animer et gérer la relation au quotidien avec le client,
Participer au développement de nouvelles approches.
En fonction de votre expérience et de vos missions, vous pourrez évoluer vers la gestion de projet.
VOUS MARQUEZ DES POINTS SI
De formation supérieure en statistiques, vous avez acquis au moins 5 ans d'expérience en Datamining / Data Science, chez l’annonceur ou en prestation de services.

Vous maîtrisez les méthodes statistiques et leurs applications opérationnelles, ainsi que l’un des principaux outils statistiques du marché SAS, SPSS Modeler, R, Python…

Curieux, ouvert, vous avez à cœur de mettre votre passion pour le Datamining et/ou la Data Science au service de la réussite opérationnelle de vos projets."
Ivry-sur-Seine (94),CDI,,Data Scientist Fidélisation & Animation Clients F/H,Siège Fnac Darty,- Ivry-sur-Seine (94),"Description et profil
Rejoignez-nous et inventons l'avenir du groupe Fnac-Darty !
Fnac-Darty est un groupe au rayonnement mondial. C'est aussi et surtout une dynamique d'innovation et une vision stratégique : apporter à nos clients la meilleure expérience omnicanale. Pour s'imposer durablement en champion de la distribution, nous avons annoncé, en décembre 2017, notre nouveau plan stratégique Confiance+. Cette offensive stratégique se repose notamment sur un écosystème clients enrichi et des programmes de fidélité innovants.

Pour déployer cette stratégie, la direction marketing clients recrute un(e) Data Scientist en charge d'apporter des réponses opérationnelles aux problématiques marketing et business de nos interlocuteurs internes.

Vos missions :
Rattaché(e) au Responsable Innovation Datascience, au sein de l'équipe Data & Analytics, vos principales missions :

Développer des outils datascience pour augmenter la pertinence des actions business avec une vision multicanal, multidevice et multi-enseignes

Développer de nouvelles approches Big Data : démarche test & learn sur 1er cas d'usage, ….

Accompagner la direction marketing en tant qu'expert sur différents sujets stratégiques : cadrage, méthodologie, formations, outils…

Contribuer à la refonte de nos différents systèmes (Datalake, RCU, DWH, Datamart) et à la recherche de nouvelles données, calcul de nouveaux indicateurs, avec un lien privilégié avec les équipes IT sur les problématiques data

Vous êtes soucieux de la qualité des données clients et vous êtes pro-actif pour trouver des pistes d'enrichissement de la data.



Votre profil :

Diplômé d'un Bac+5 en école d'ingénieur et/ou Université avec une spécialisation en statistiques, mathématiques ou data science, vous disposez idéalement d'au moins 1 an d'expérience dans les secteurs Retail/Ecommerce/Services.

Vous maîtrisez R et SAS et les principales méthodes de modélisation statistique et machine learning.
Vous avez une réelle sensibilité marketing digital et vous savez vous montrer créatif et innovant.
Localisation du poste
Localisation du poste
France, Ile-de-France, 94 - VAL DE MARNE
Ville
Ivry sur Seine
Critères candidat
Niveau d'études min. requis
BAC +5"
Paris (75),,,"PhD Student, CIFRE",Facebook,- Paris (75),"Facebook is seeking PhD Students through CIFRE contracts to join Facebook AI Research (FAIR) in Paris. We are committed to advancing the field of artificial intelligence by making fundamental advances in scientific methods and technologies to help interact with and understand our world. We are seeking individuals passionate in areas such as deep learning, computer vision, audio and speech processing, natural language processing, machine learning, reinforcement learning, computational statistics, computational cognitive (neuro)science, and applied mathematics. CIFRE positions (Industrial Agreements for Training through Research) are 3-year fixed term for PhD students in France who will work in collaboration with a public research lab. Facebook partners with the Ministry for Higher Education and Research and the National Association for Research and Technology (ANRT) to implement the program for individual students. CIFRE positions will be awarded on a rolling basis and candidates are encouraged to apply early in their search for PhD programs. Applicants are expected to be pursuing a PhD in one of the areas listed above. To learn more about our research, visit: https://research.fb.com/category/facebook-ai-research-fair.
PhD Student, CIFRE Responsibilities
Perform research to advance the science and technology of intelligent systems.
Perform research that improves computational understanding and representing of data.
Devise data-driven models of human behavior.
Influence progress of relevant research communities by producing publications.
Collaborate and increase productivity on existing research projects.
Minimum Qualifications
Knowledge in Machine Learning.
Knowledge in a programming language.
Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorisation during employment.
Preferred Qualifications
Bachelors or Masters degree in a technical field such as Computer Science, Applied Mathematics, or equivalent practical experience.
Experience building systems based on machine learning and/or deep learning methods.
Research and software engineer experience demonstrated via an internship, work experience, coding competitions, or open-source contributions.
Knowledge in Python, Lua, C++, C, C# and/or Java.
Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities — we're just getting started.
Facebook is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com."
Paris 8e (75),CDI,,Lead Data Scientist (H/F),June Partners,- Paris 8e (75),"Février 2020
Missions :
Le/la Lead Data Scientist aura plusieurs missions, d’ordre managérial et technique. Son premier rôle sera de diffuser une culture, des compétences et des solutions quantitatives dans les environnements où interviennent les consultants de June Partners, ainsi qu’au sein du cabinet.
Ces solutions quantitatives interviendront dans trois chantiers principaux :
– L’automatisation éclairée des process,
– Le traitement automatique de données pour comprendre et prévoir,
– Et l’évaluation quantitative du progrès réalisé.
Pour avancer efficacement sur ces chantiers, le/la Lead Data Scientist devra identifier ses besoins en ressources matérielles et computationnelles, et en moyens humains.
Il/Elle se chargera du recrutement des autres data scientists, data engineers et développeurs qui constitueront son équipe, et animera l’équipe quantitative de June. Il/Elle sera l’intermédiaire entre son équipe, les autres équipes de June et les équipes des entreprises clientes.
Automatisation éclairée des process
Les équipes de June Partners interviennent dans des contextes diversifiés, dans des périodes de forte criticité. Dans ces moments, l’optimisation de process peut débloquer les potentiels des personnes présentes. Cette optimisation et automatisation doit fortement s’appuyer sur les compétences et le savoir des opérateurs et spécialistes de l’entreprise cliente. Le/la Lead Data Scientist devra être à l’aise dans un environnement très pluridisciplinaire.
A titre d’exemple :
– Tâche : Evaluation de coûts de réparation de véhicules
Données : Images de dégâts, types de dégâts, coûts des réparations semblables précédentes
– Tâche : Edition de devis de produits personnalisés, avec contraintes physiques et légales sur le couplage d’options.
Traitement automatique des données pour comprendre et prévoir
Les équipes de June doivent comprendre rapidement leur environnement d’intervention.
L’équipe quantitative développera des modèles et des dashboards pour éclairer la structure des entreprises clientes à l’aune de l’intervention de June.
Evaluation du progrès réalisé
Le/la Lead Data Scientist et son équipe collaboreront avec les équipes clientes (à tous niveaux de la hiérarchie) pour définir des KPIs et Dashboards pour évaluer l’évolution de l’entreprise cliente au fur et à mesure de leur intervention. Ils aideront les équipes de l’entreprise cliente à prendre conscience de ces KPIs et resteront critiques sur leurs limitations.
Profil
Le/la Lead Data Scientist a au moins 2 postes d’expérience dans des équipes à dominante quantitative (doctorat compris). Il/Elle a mené des projets avec une équipe du début à leur mise en production.
Compétences et technologies maîtrisées
Langages et libraires : Python scientifique (numpy, pandas), scikit-learn, pytorch/tensorflow."
Paris (75),CDI,,Data Scientist -NLP & Computer Vision,Sept Lieues,- Paris (75),"Fintech française qui qui facilite la digitalisation en supprimant tous les processus papiers pour les services financiers en B2C.

Cette start up propose un tout-en-un digital: gestion de documents automatisée, signature électronique, entre autres => développement constant à l'international

Avantages : Variable, mutuelle, CE, flexibilité horaires, tickets Restaurant, évènements d'entreprise...
LE POSTE / LES MISSIONS
Tes missions seront les suivantes :
amélioration des modules existants et être force de proposition pour les futurs
traitement de données et d'images
conception, mise en production et suivi

Collaboration avec les data engineers et les devOps
PROFIL RECHERCHÉ
Profil :
Bac +5 et équivalent
Minimum 2 années d'expérience
Maîtrise de Python, notamment Python 3
Compétences en Deep Learning

Le plus : compétences/connaissances en MongoDB"
Paris (75),,,Data Scientist Lead (Manager Position),MOTION-ISE,- Paris (75),"What We Do

Motion! is a Paris and New York-based start-up company. We are building the AI and smart intelligence platform from the ground up for a cloud-powered future. A Smart Platform that empowers stakeholders of innovation and start-up ecosystems for effective global connectedness, minimize the risk of failure and optimize opportunities for investment on innovation and propel the successful development and growth of new start-up businesses.

We have no shortage of fascinating challenges in data science, machine learning, and software engineering. To tackle them, we are assembling a team of experienced super-heroes who have already proven their ability to turn bleeding edge research and tech into practical applications and services.

At Motion!, we combine our strengths—ecosystem stakeholders network, modern technology, advanced analytics, data visualization, and industry specialist’s insights—with the expertise of our, corporate, venture capitalists and start-up partners. The results are, players in these ecosystems can tap into a worldwide circulation of ideas, knowledge, diligently vetted-innovation, talent, and capital. A powerful platform for the global start-up ecosystem network, uniquely prepared to provide smart solutions and services to our partners and customers.

What You'll Do
Collaborate with our Vertical Lead’s to develop a Data Science roadmap
Manage projects consisting of cross functional teams including Data Scientist, Software Engineering and Solutions Engineering
Work on building out Motion’s suite of cutting-edge data science tools
Collaborate with the Data Science team members to identify common problems and areas for automation and standardization
Apply cutting-edge machine learning techniques at large scale to streaming data
Conduct research into advancements in algorithms, computing and statistics and apply those insights to Motion !
Communicate results to clients and end users. Incorporate their feedback into future Data Science projects
Depending on candidate's experience level and demonstrated level of proficiency, may manage team up of up to 20 data scientists, machine learning-algorithms experts, data analysts, data modelling.

Qualifications

Required:
PhD (preferred) or MS in computer science, statistics, physics or mathematics
A minimum of 3 years experience working on data science/machine learning projects outside of academia
Proven experience as a Data Scientist, Predictive Modeler, Analytics Professional or similar role
In-depth understanding of various machine learning algorithms (e.g. SVM, neural networks), and techniques (e.g. cross-validation, feature selection, etc)
Deep knowledge of open source statistical modeling tools such as R or Python
Expert knowledge of at least one common data science framework, e.g., Python pandas/scikit-learn (preferred), TensorFlow or similar
Strong communication skills
Ability to define and execute a clear plan for data exploration, experiments, and conclusion
Knowledge of Git or ability to learn it quickly
Ability to frame problems and execute them independently is a must

Preferred:
Industry experience in one of the following areas:
Retail
Healthcare
Media & Publishing
Financial
Cybersecurity
One or more published academic papers
Previous contributions to patents are a plus
Masters or Phd in a quantitative field, such as:
Statistics
Computer Science
Physics
Industrial Engineering
Operations Research
Previous experience with Scala, Java, Spark, and/or MongoDB

Ideal job opportunity in Paris or remote work for professionals and expats seeking employment opportunities with English as the main working language.

The Data Scientist must be French native language speaker and/or fluent in English (able to lead and manage local and global teams and communicate in English with virtual teams from different locations).

Compensation:

This is a paid position commensurate with experience (a combination of equity, cash, and bonuses).

Please apply via the job portal or send your CV / Resume along with a cover letter to talent (Code DSL).

** LOCAL CANDIDATES ONLY - NO VISA SPONSORING **
About Us:

Motion ! is an early-stage technology start-up company based in Paris, France and New York City, U.S. We are building the best ""all-in-one"" platform to access innovation easier, faster and more efficiently from anywhere, anytime, anyplace."
Paris 3e (75),"Temps plein, CDI",30 000 € - 45 000 € par an,Ingénieur SIG (GIS) Data Manager,OneSide Consulting,- Paris 3e (75),"Pour le compte d'un acteur majeur du secteur de l'offshore oil & gas - énergies marines renouvelables, au sein d'un service dédié aux Systèmes d'Information Géographique (SIG) :
Rédiger des procédures de standardisation des bases de données SIG
Assurer la réception des données contractuelles issues des pre-engineering (études préalables)
Compléter les geodatabases internes/externes en fonction des standards en vigueur
Vérifier la complétion des tables attributaires (tags, attributs, métadonnées, hyperliens, données horaires)
Utilisation des outils de Trackings pour suivre les mises à jours
Réalisation des analyses sur des données géographiques en produisant des documents cartographiques ou des rapports
Croiser et superposer les données spatiales, attributaires et horaires entre-elles afin de faire ""parler"" les données (big data)
Développer ou utiliser potentiellement des scripts FME
Gestion des interfaces internes et externes
Profil :
Ingénieur ou Master SIG (GIS), Data Management, Géomatique, minimum 3 ans d'expérience
Maitrise du logiciel ArcGIS for Desktop 10.2 et extensions
Maitrise des SIG (Géoréférencement, modélisation de base de données, I/O, ...)
Maitrise de la géodésie et des systèmes de coordonnées
Maitrise des bases de données Access (.mdb), Geodatabase ESRI (.gdb)
Connaissance des standards et normes pour les données et métadonnées géographiques (OGC, OGP, ISO, INSPIRE, FGDC, ...)
Programmation Python, SQL, VBA serait un plus
Gestion de projet SIG
Maitrise de l'anglais (écrit et oral)
Profils Oil & Gas Offshore / Onshore appréciés
Expérience dans des sociétés d'ingénierie type EPC appréciée
Type d'emploi : Temps plein, CDI
Salaire : 30 000,00€ à 45 000,00€ /an"
Vélizy-Villacoublay (78),,,Data Scientist H/F,Altran,- Vélizy-Villacoublay (78),"TESSELLA est le World Class Center (WCC) Analytics du groupe Altran. TESSELLA est leader dans le domaine de la Data Science et de l’Analytics, composé de 350 des meilleurs data scientists. Depuis 30 ans, nous avons développé une réputation solide par notre capacité à accompagner nos clients à résoudre des défis complexes et à libérer la puissance de leurs données. Notre travail est à la pointe de la R&D et nos projets sont variés et stimulants. Plus d’informations sur notre site internet https://www.tessella.com/

Vos responsabilités

Vous serez en charge de la conception, du développement et du déploiement de solutions data driven pour accompagner nos clients à surmonter de nombreux défis scientifiques ou d’ingénierie. Pour cela vous serez capable de:

Vous engager auprès de nos clients pour comprendre leurs défis et opportunités et développer des approches créatives et innovantes.
Appliquer un large éventail de compétences techniques: l’apprentissage machine, les statistiques, les mathématiques, la modélisation, le traitement de texte, le data-mining, etc…
Véritable facilitateur, vous conseillez les clients et les équipes pour mieux comprendre les problématiques ou les débloquer tant sur l’aspect technique que fonctionnel et opérationnel.
Guider et accompagner des équipes composées de docteurs et d’experts en Data Science.
Votre profil

Pendant votre carrière chez TESSELLA, vous allez développer de nouvelles compétences, mais pour cela vous devez maîtriser à minima:

Master ou Doctorat en Data Science, Mathématiques, Science informatique ou un diplôme d’ingénieur.
Au minimum 5 ans d’expérience dans un rôle similaire.
Comprendre comment les données complexes sont interprétées à l'aide d'une variété de techniques analytiques, statistiques ou d'apprentissage automatique.
Développement d’algorithmes et/ou Software engineering dans des langages tels que Python, R, Java, C# ou C++.
Réussir à vulgariser des concepts complexes.
Vous intégrer aisément dans une équipe scientifique multiculturelle, composée à majorité de chercheurs chevronnés.
L’envie et les dispositions pour transmettre vos connaissances et recevoir celles des autres dans l’objectif de faire progresser l’équipe.
Aussi, vous aimez évoluer dans un environnement international. De ce fait, vous parlez parfaitement anglais.
Poste ouvert aux personnes en situation de handicap."
Paris (75),CDI,,Data Analyst Monetization,Happn,- Paris (75),"Description du poste
Tu aimes faire parler la donnée, lui donner du sens, la rendre compréhensible de tous ?
Tu as envie d’avoir un réel impact sur la croissance de happn ?
Tu excelles dans l’interprétation des indicateurs permettant à l’équipe produit d’améliorer le taux de conversion à l’abonnement?
Rejoins l’équipe data centralisée de 15 personnes, regroupant data engineers, data analysts et data scientists.
Ton rôle en tant que data analyst monetization sera d’accompagner les équipes produit au quotidien en leur fournissant les études et dashboards adéquats.
Ton challenge :
Réaliser des études d’aide à la décision pour définir les bonnes priorités de la roadmap monétisation et améliorer la compréhension de notre business / comportements utilisateurs
Identifier les indicateurs de performance à industrialiser pour permettre le suivi de nos revenus et de notre conversion
Développer les tableaux de bord sous Tableau offrant les visualisations et usages nécessaires à l’exploitation optimale des KPIs et de leurs dimensions
Développer les scripts SQL optimisés pour BigQuery permettant le calcul industrialisé et standardisé de ces KPIs
Définir le périmètre des AB tests à mettre en place et la méthodologie pour les analyser. Développer les scripts permettant de tester la significativité des résultats
Accompagner les équipes à la mise en place d’un tracking de qualité permettant de suivre l’efficacité de notre boutique
Suivre les chiffres au quotidien permettant d’alerter l’équipe produit et le COMEX si tu observes des comportements inhabituels
On attend de toi que tu sois force de proposition dans l'équipe, qui est toujours à la recherche d'idées nouvelles !
Profil recherché
Ton profil :
De formation supérieure d’une grande école d’ingénieur / de commerce / de statistiques
Tu as un minimum de 2 ans d’expérience dans l’analyse de données dans le domaine de la monétisation / des revenus
Tu as de solides compétences mathématiques et analytiques pour comprendre notre écosystème
Tu as l’esprit d’équipe, un bon relationnel, tu aimes le partage et le challenge
Tu es owner de tes projets : tu prends des initiatives, tu fais preuve de flexibilité et d'autonomie, et la rigueur est ton fer de lance !
Tu es synthétique, clair(e), avec de bonnes qualités de communication
Tu es doué(e) en SQL ; une expérience sur BigQuery est un plus
Tu maîtrises : Python / R / Tableau / Qlikview
On veut de la curiosité et un goût prononcé pour les chiffres
Alors tu nous rejoins ?"
Paris (75),"Apprentissage, Contrat pro",,Alternance - 1 an - Data Analyst Connaissance Clients (H/F) - Paris 13ème,BPCE SEF,- Paris (75),"Le Groupe BPCE, avec son modèle de banque coopérative universelle, représenté par 9 millions de sociétaires, est le deuxième acteur bancaire en France. Avec 105 000 collaborateurs, il est au service de 30 millions de clients dans le monde, particuliers, professionnels, entreprises, investisseurs et collectivités locales. Il est présent dans la banque de proximité et l’assurance en France avec ses deux grands réseaux Banque Populaire et Caisse d’Epargne ainsi que la Banque Palatine. Il déploie également, avec Natixis, les métiers mondiaux de gestion d’actifs, de banque de grande clientèle et de paiements.
Détenue à parité par les deux réseaux, BPCE est en charge de la stratégie, de la coordination et de l’animation du groupe, qu’elle représente notamment auprès du régulateur. Les expertises de ses équipes sont mises au service du groupe, de ses entreprises et de leurs clients.
BPCE Financement, filiale du Groupe BPCE et 3ème acteur sur le marché du crédit à la consommation en France, commercialise ses produits par l’intermédiaire des réseaux bancaires du Groupe et en assure la gestion.

Poste et missions
Au sein de la Direction CRM (« Customer Relationship Management ») et Marketing Digital de BPCE Financement composée de 20 personnes, vous serez rattaché au service Connaissance Client.
Au sein de ce service, vous accompagnerez les Data Analysts de l'équipe dans :
le développement des analyses produits et clients et la mise en place de tableaux de bord automatiques (comportements et utilisation des produits, usage des canaux, profils clients...)
l'analyse de performance des actions marketing;
le développement et l'industrialisation des modèles prédictifs utilisés par le marketing opérationnel (scores d'appétence).

Profil et compétences requises
C’est avant tout votre personnalité et votre état d’esprit qui nous intéresse.
Vous préparez un diplôme universitaire ou d’école de commerce de niveau BAC+5, avec une spécialisation en Statistiques, data science, informatique décisionnelle et/ou économétrie.
Vous avez un bon niveau d’anglais (utilisation ponctuelle sur le poste). Vous maîtrisez les techniques et les méthodes d'analyse statistiques, savez manipuler des données et interpréter des résultats. Vous maîtrisez le Pack Office (notamment Excel), les outils et les langages statistiques et de data science (SAS, Python, R, SQL). Vous portez un intérêt pour le Marketing.
Si vous êtes rigoureux, fiable, précis, avez le sens de l’organisation et une aisance relationnelle, alors n'hésitez pas à postuler à cette offre d’alternance.
Vous bénéficierez d’un accompagnement dédié pour vous donner toutes les chances de réussir cette nouvelle mission.
Pour un meilleur traitement de votre candidature, nous vous remercions de préciser le type de contrat recherché (apprentissage ou professionnalisation), l’intitulé et le numéro de diplôme préparé ainsi que le rythme d’alternance de votre formation."
Paris 9e (75),CDI,,Data Analyst à Paris (75) en CDI à PARIS F/H,MUTUELLE INTERIALE,- Paris 9e (75),"En tant que Data Analyst, vous intégrez l'équipe Connaissance Clients au sein de la Direction Marketing et Communication. Votre rôle sera d'exploiter les données pour aider les métiers à mieux comprendre leur business et à prendre des bonnes décisions. Vous utilisez des outils et des techniques statistiques afin d'organiser, de synthétiser et de traduire les informations pour faciliter la prise de décision. Vos analyses s'appuient sur une compréhension des métiers et en particulier des activités marketing (offres, parcours et interactions adhérents, campagnes marketing)

Vos principales missions :
1 - Automatisation des reporting

Construire et automatiser des tableaux de bord pour aider les équipes Marketing à prendre les meilleures décisions.

Collaborer avec les équipes techniques et métier pour définir les besoins et expliciter les résultats

2 - Etudes / Analyses exploratoires / Connaissance Clients

Mener des analyses exploratoires, des études statistiques profondes et des projets datamining à partir des données disponibles

Participer à la mise en place de segmentations adhérents et réaliser des études prédictives : score de churn, score de multi-équipement...

Synthétiser les analyses en les rendant abordables pour des non-initiés

3 - Marketing relationnel

Mesurer et suivre les performances des campagnes marketing

Optimiser, adapter et collaborer au ciblage de nos campagnes de fidélisation

Aider les équipes à améliorer ses campagnes via notamment des campagnes d' AB tests

Profil recherché Profil :
Niveau d'études souhaité : BAC + 4/5 avec a minima 5 ans d'expérience

Formation / Spécialisation : Master 2 à dominante Mathématiques / Statistiques / Analyse de données / Techniques de Décisions / MIAGE / Big Data ou ENSAI

Compétences techniques indispensables : Excel, SAS EG, SQL

Compétences techniques souhaitables : R, Cognos, Tableau, Power BI, Google Analytics

Autres compétences :
o Esprit de synthèse, sens analytique, rigueur et goût prononcé pour les chiffres

o Capacité à donner de la perspective aux chiffres, les faire parler

o Grande ouverture d'esprit, communications régulières avec les autres services

o Organisation, capacités à gérer votre temps et prioriser vos tâches

o Forte envie de vous investir dans un environnement dynamique et en perpétuelle évolution

o Une connaissance de l'environnement mutualiste serait un plus.
Entreprise Intériale est l'un des leaders de la protection sociale complémentaire. Elle accompagne près de 500 000 agents publics et leurs familles pour leur santé et leur prévoyance. Fortement tournée vers la prévention, l'innovation et le digital, elle s'inspire à la fois du mutualisme historique et de l'univers high-tech. C'est ainsi qu'elle fait vivre ses valeurs : créativité, fiabilité, solidarité."
Paris (75),CDI,120 000 € - 140 000 € par an,Directeur Data Science pour porter l'offre data science,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Head of data management
Lead manager responsable
Technologies Bigquery
Technologies Data studio
Technologies Google cloud plateform
Technologies Machine learning
Technologies Nlp
Technologies Python
Technologies Qlikview
Technologies Tableau
Expérience 6 à 10 ans
Statut CDI
Min 120k€
Max 140k€
LA STARTUP : UN ACTEUR DU CONSEIL SPÉCIALISÉ DANS LE MARKETING DIGITAL ET LA DATA
Une top équipe : grandes écoles et anciens de cabinets de conseil
Une clientèle diversifiée auprès de différents acteurs : La Française des Jeux, Groupe Bayard, Kenzo, OVH,
Boardriders, Vente-Privée.com, …
Des locaux au coeur de Paris
Un cabinet en pleine croissance, intégré à un grand groupe en 2018 (agence digitale présente dans 15 pays)
Une dimension entrepreneuriale forte (culture, autonomie sur les missions, valeurs, petit effectif)
Un projet early stage où avoir de l’impact (10 à 30 personnes)
Créé en 2015
Environnement technique : NLP, Machine Learning, BigQuery, Google Cloud Platform, QlikView, Tableau, Data Studio, SQL, Python
VOTRE MISSION : PILOTER UNE EQUIPE DE 2 DATA SCIENTIST ET DRIVER DES PROJETS DATA SCIENCE
En relation directe avec les associés, vous prenez en charge le pôle data science et assurez son
développement notamment l’encadrement des missions, le développement des compétences RH, la gestion de charge, les démarches commerciales, la communication, …
Vous pilotez (selon le niveau d’expertise requis) les missions chez les clients relevant de la manipulation et l’analyse avancée de données :
Recueil des besoins & définition des cas d’usage business
Architecture et mise en place des solutions techniques :
Data engineering : construction d’infrastructures de données basées sur le cloud, flux de données entre différents outils de l’écosystème data-marketing, …
Data science : algorithmie, analyse descriptive et prédictive, machine learning, …
Data visualisation : construction de dashboards adaptés aux enjeux opérationnels et managériaux
Vous gérez les appels d’offres / benchmarks de technologies
Vous êtes le responsable de l’évangélisation et la formation aux enjeux data-marketing et data science
Encadrer et faire évoluer votre équipe de 3 personnes
VOTRE PROFIL : DIRECTEUR DATA SCIENCE
Vous êtes diplômé d’une grande école de commerce, d’ingénieurs ou équivalent, vous disposez :
Vous avez 7 années minimum d’expérience dans le conseil sur des enjeux digitaux ou sur un poste lié au marketing digital,
Vous avez été exposé à des sujets de traitements de données
Vous avez acquis une bonne compréhension des enjeux data et avez une bonne vision des tendances du marché
Vous justifiez d’une solide expérience technique en matière de traitement de données et d’encadrement de ce type de projets
Vous êtes familier des outils Google Cloud Platform et des langages SQL et Python
Rigoureux, vous savez adopter une approche analytique structurée et une posture conseil
Dans un contexte d’entreprise en croissance, vous avez pour ambition d’être un élément clé du cabinet et souhaitez assurer, en plus de votre rôle opérationnel, des fonctions de management et de développement commercial
MODALITÉS :
Package 120 à 140K€ (80K€ fixe, variable selon profil – à discuter sur les objectifs)
RTT : 10 jours
Jours de congés offerts ponctuellement
Petit déjeuners tous les lundis et panier de fruits
Carte Lunchr
Mutuelle
Sélectionné par Deborah Peter
Spécialiste Infra / DevOps / QA
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),CDI,,Data Engineer - Machine Learning,Sept Lieues,- Paris (75),"Startup en forte croissance, spécialisée en intelligence artificielle.
LE POSTE / LES MISSIONS
Vous rejoindrez l'entreprise en tant que data engineer au sein de l'équipe Big Data / DevOps.

Vos principales missions:
Infrastructure distribuée à déployer sous Spark / Kafka
Pipelines à développer (Spark)

Environnement distribué // Traitements à effectuer en batch & en streaming
PROFIL RECHERCHÉ
- Formation d'Ingénieur - Bac +5
Développement sous Spark et Python
Sensibilité DevOps"
Paris (75),CDI,,Consultant Big Data H/F (Paris),Keyrus,- Paris (75),"Le Big Data c’est plus qu’un buzzword ?
L’interaction avec des experts du Big Data c’est bien, avec toute une communauté d’experts Data (Consultant Cloud, Data Scientists, Experts Dataviz, Coach Agile, Expert BI, Consultant en Data Management et bien d’autres) c’est mieux ?
Nous aussi, nous pensons pareil.
Le job :
Les principales missions qui vous seront confiées seront les suivantes:
Conception et mise en œuvre de plateformes basées sur des technologies Big Data ;
Installation et déploiement de clusters logiciels ;
Conception et mise en œuvre de flux d’intégration (mode batch ou temps réel) de données structurées/non structurées et volumineuses ;
Optimisation technique et fonctionnelle en termes de performance et de qualité logicielle ;
Mise en œuvre de la stratégie d’exploitation des plateformes Big Data (gestion des sauvegardes, procédures de récupération des données, mises à jour et montées de version logicielles,…) ;
Transfert de compétences et animation de formations ;
Préconisation d’outils et/ou technologies et veille technologique continue.

Vous :
Vous disposez d’un profil Ingénieur Informatique (BAC +5) et avez déjà réalisé des projets ou missions Big Data. L’écosystème Hadoop (HDFS, Pig, Hive, Sqoop, Flume,…), Spark ou encore Elasticsearch sont vos technologies de prédilection.
Les langages orientés objet types Java, C++,… et de scripting (python, shell,…) n’ont plus aucun secret pour vous.
Démarquez-vous : vous avez déjà programmé en Scala ou travaillé sur des algorithmes de Machine learning.
Mais aussi…
Parce que nous ne sommes pas attachés qu’à la technique, nous recherchons avant tout des personnes motivées, créatives, capables de challenger les solutions.
Habitué à l’univers des nouvelles technologies, vous êtes toujours en veille et vous pensez qu’il est important de se renouveler."
Paris (75),,,Data Analyst Smart Factory,WeSmart,- Paris (75),"Introduction de la société - WeSmart
WeSmart est une plate-forme en nuage qui collecte les données de compteurs intelligents et d'appareils connectés et engage les utilisateurs avec les données. WeSmart associe l'intelligence humaine, la participation collective et les technologies de l'internet des objets pour réduire la consommation d'énergie et les émissions de CO2. WeSmart se concentre sur la fourniture de solutions de gestion de données hautes performances basées sur le cloud pour les entreprises de toutes tailles et de toutes spécialités. Fondé par des spécialistes ayant une longue expérience dans le secteur de l'énergie et de l'environnement en tant qu'ingénieurs en logiciel, experts en données et consultants stratégiques, WeSmart est à la pointe de la révolution écologique.
Site web: www.wesmart.com
Description de l'emploi - Data Analyst Smart Factory
WeSmart est à la recherche de scientifiques spécialisés dans les données pour synthétiser et exploiter notre vaste ensemble de données sur l'énergie afin d'améliorer l'analyse de la solution.
Il s’agit d’une occasion unique de faire partie d’une nouvelle équipe multidisciplinaire d’individus créatifs et passionnés, vouée à changer le visage de la gestion de l’énergie et des données IOT. Nous nous concentrons sur le programme de la société et travaillons sur des projets à fort impact utilisant l’analyse de données volumineuses et l’apprentissage automatique pour améliorer les solutions énergétiques.
Nous formons une équipe expérimentée, alliant expertise et ingénierie, afin d’identifier et d'interpréter des informations sur les processus de gestion de l’énergie. L'équipe travaille par itérations rapides, en utilisant les techniques et les algorithmes les mieux adaptés pour résoudre les problèmes difficiles de la gestion de l'énergie.
Vous allez défendre, évangéliser et construire des produits alimentés par des données qui aident nos clients à améliorer leurs solutions énergétiques. Vous allez vous impliquer et devenir un expert de nos jeux de données sur l'énergie et l'IOT. Vous donnerez un aperçu des pratiques analytiques de pointe, concevrez et dirigerez des cycles d'apprentissage et de développement itératifs, et aboutirez à la création de solutions analytiques nouvelles et créatives qui feront partie de nos principaux livrables.
Vous travaillerez avec les membres de l'équipe interfonctionnelle pour identifier et hiérarchiser des informations exploitables à fort impact dans divers domaines d'activité essentiels. Vous dirigerez des initiatives d'analyse appliquée qui sont exploitées dans l'ensemble de nos solutions de gestion de l'énergie. Vous allez rechercher, concevoir, mettre en œuvre et valider des algorithmes de pointe pour analyser diverses sources de données afin d'obtenir des résultats ciblés.
En tant que Data Scientist Smart Factory, vous apporterez une expertise des concepts mathématiques à l’ensemble de l’équipe d’analyse appliquée appliquée et inspirerez l’adoption de l’analyse avancée et de la science des données sur des projets d'Industrie 4.0.
Nous recherchons:
Vous êtes passionné par le fait de poser et de répondre à des questions dans de grands ensembles de données et vous êtes capable de communiquer cette passion aux chefs de produits et aux ingénieurs. Vous avez un vif désir de résoudre les problèmes de votre entreprise et vous vivez à la recherche de modèles et d'informations dans des données structurées et non structurées. Vous proposez des stratégies et des solutions analytiques qui stimulent et élargissent la réflexion de tous ceux qui vous entourent.
Vous souhaitez un environnement d'ingénierie itératif, collaboratif et itératif au rythme rapide. Vous aimez apprendre, les données, l'échelle et l'agilité. Vous excellez à rendre les concepts complexes simples et faciles à comprendre par ceux qui vous entourent.
Langages et outils utilisés :
Python, Keras, Power BI"
Paris (75),CDI,,Consultant Data Geek (F/H),OCTO Technology,- Paris (75),"A la croisée des compétences entre mathématiques, statistiques et informatique, vous apportez une vision dans la valorisation des data de nos clients.
Profil recherché
F/H
Diplômé d'une Grande Ecole d'Ingénieur généraliste, informatique ou Master spécialisé Data Science/Intelligence artificielle,
Vous justifiez au moins d'une première expérience soit dans un contexte professionnel, soit en compétition de Data Science et vous vous définissez comme un vrai data geek.
Vous avez de solides compétences en langages statistiques de références tels que Python et R.
Vous disposez de solides compétences scientifiques et techniques sur le principaux algorithmes non linéaires : ensemble, boosting, réseaux de neurones et êtes débutant ou confirmé(e) sur les nouvelles avancées en machine learning (notamment en deep learning).
Vous êtes à l'aise dans la manipulation et l'analyse de données complexes à haute dimensionnalité.
Idéalement, vous maîtrisez les techniques inhérentes au datamining et à l’ingénierie statistique appliquée à de grands volumes de données (frameworks de calcul Hadoop, Spark,...).
Vous êtes curieux et ouvert, vous assurez une veille régulière sur les nouveaux usages et n’hésitez pas à envisager des solutions en rupture et dans l’innovation.
Bon communicant, vous vous adaptez à vos interlocuteurs et vous avez le sens de la relation client.

Mais ce que nous cherchons avant tout, ce sont des personnalités qui enrichiront OCTO. Nous les reconnaissons à leur volonté de participer à l’amélioration de la vie de l’entreprise, de construire la vision et les offres de demain, de partager leurs connaissances pour faciliter la montée en compétences réciproque. De rejoindre, enfin, une communauté qui n’a pas peur d’affirmer sa différence.

Détails de l'offre
Type de poste : CDI
Lieux : Paris, Île-de-France (FR)
Descriptif du poste
Vous avez envie de rejoindre l’équipe de Data Scientists de référence en France.

Votre compréhension des enjeux stratégiques et business d’aujourd’hui, vous permet d’accompagner nos clients sur des sujets :

Conseil
Vous apportez votre expertise auprès de nos clients en adoptant une posture conseil.
Vous participerez à des problématiques de transformation vers la data driven company.

Conception
Vous développez et améliorez de manière continue de nouveaux modèles prédictifs alliant Big Data et Machine Learning.
Vous participez à la conception d’architecture BIG DATA.

R&D/communication
Vous développez vos domaines d’expertise en participant à la R&D d’OCTO (rédaction d’articles ou d’ouvrages, conférences de référence).
Vous travaillez sur des POCs."
Paris 14e (75),CDI,,Data Engineer F/H,ANALYSE INFORMATIQUE DE DONNEES,- Paris 14e (75),"AI&Data recherche aujourd'hui des Data Engineer

Nos consultants aident les entreprises à tirer le meilleur parti des données, à mettre en place des solutions opérationnelles, à identifier et mettre en œuvre les projets liés à la transformation digitale.

Sur ce poste, vous serez intégré(e) à une équipe de projet et participerez à la mise en place de projets Big Data en intervenant notamment sur les missions suivantes :

Analyser les besoins clients et formaliser les cas d'usages correspondants,

Participer activement à la conception et à la réalisation des solutions Big Data,

Développer des solutions d’ingestion de données depuis des sources multiples pour les déverser dans un data lake : Nifi, Sqoop, Kafka, … etc.

Passer de la donnée brute à de la donnée propre (inférer les schémas de données, nettoyer, normaliser et publier les données)

Consolider les données au fur et à mesure de leur alimentation récurrente dans le data lake.

Exploiter les résultats pour atteindre la finalité business : exposition de business view, réintégration des résultats dans le SI, service de scoring, …

Mettre en place et garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de développement et d’industrialisation (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc.)

Industrialiser des pipelines d’analyse et de machine learning

Profil recherché De formation technique :
Vous avez une première expérience réussie d’au minimum 1 an en développement big data :

Spark : PySpark et Scala

Hadoop,

Kafka

Spark Streaming / Storm,

Hbase / MongoDb

Elasticsearch

Vous avez l'habitude des cycles de développement & outils associés (intégration & déploiement continu avec Git, Jenkins, Sonar, Nexus, NUnit ...)

Ces connaissances supplémentaires seraient un plus : distribution Hortonworks, Cloudera ou MapR, outils de data viz, librairies de Machine Learning, création d'API

Vous faites preuve d'une grande curiosité et de capacité d'innovation.

AI&Data, partenaire de nombreuses grandes entreprises françaises depuis plus de 45 ans, est une entreprise innovante qui utilise des technologies récentes. Vous collaborerez avec des data Scientist, data Engineer, data architecte, Product Owner, ...

L’AI&Data Academy vous fera bénéficier de ses formations les plus innovantes, et vous serez amené vous-même à animer des séminaires ou formations pour nos clients ou collaborateurs.

La société est depuis quelques années en pleine croissance et cultive son esprit start up et son ambiance conviviale. Baby foot, table de ping pong, workshops internes et afterworks font partie de nos rituels d'entreprise.

Vous baignerez alors dans un environnement de travail idéal pour développer votre créativité et prendre des initiatives.

Je vous invite à consulter notre site et nos réseaux sociaux (Cf ci-dessous) et à revenir vers moi pour échanger sur nos opportunités.
Entreprise AI&Data, Agence Data et Datascience

AI&Data possède trois domaines d'expertise : Datascience, CRM et Big data.

1er hébergeur de bases de données marketing et de datalakes en France cumulant plus de 220 millions de clients et plus de 45 milliards d’interactions.

AI&Data offre une chaine de valeur complète autour de l’analyse, du traitement, de l’exploitation et de la transformation des données en performance marketing.

Opérant des données clients dans plus de 12 pays, AI&Data travaille avec les plus grands des secteurs des télécoms, de l’énergie, de la banque, de l’ hôtellerie, des jeux et des loisirs."
Paris (75),"Apprentissage, Contrat pro",,Alternance - 1 an - Data Analyst Connaissance Clients (H/F) - Paris 13ème,Groupe BPCE,- Paris (75),"Description de l'entreprise
Le Groupe BPCE, avec son modèle de banque coopérative universelle, représenté par 9 millions de sociétaires, est le deuxième acteur bancaire en France. Avec 105 000 collaborateurs, il est au service de 30 millions de clients dans le monde, particuliers, professionnels, entreprises, investisseurs et collectivités locales. Il est présent dans la banque de proximité et l’assurance en France avec ses deux grands réseaux Banque Populaire et Caisse d’Epargne ainsi que la Banque Palatine. Il déploie également, avec Natixis, les métiers mondiaux de gestion d’actifs, de banque de grande clientèle et de paiements.
Détenue à parité par les deux réseaux, BPCE est en charge de la stratégie, de la coordination et de l’animation du groupe, qu’elle représente notamment auprès du régulateur. Les expertises de ses équipes sont mises au service du groupe, de ses entreprises et de leurs clients.
BPCE Financement, filiale du Groupe BPCE et 3ème acteur sur le marché du crédit à la consommation en France, commercialise ses produits par l’intermédiaire des réseaux bancaires du Groupe et en assure la gestion.

Poste et missions
Au sein de la Direction CRM (« Customer Relationship Management ») et Marketing Digital de BPCE Financement composée de 20 personnes, vous serez rattaché au service Connaissance Client.
Au sein de ce service, vous accompagnerez les Data Analysts de l'équipe dans :
le développement des analyses produits et clients et la mise en place de tableaux de bord automatiques (comportements et utilisation des produits, usage des canaux, profils clients...)
l'analyse de performance des actions marketing;
le développement et l'industrialisation des modèles prédictifs utilisés par le marketing opérationnel (scores d'appétence).

Profil et compétences requises
C’est avant tout votre personnalité et votre état d’esprit qui nous intéresse.
Vous préparez un diplôme universitaire ou d’école de commerce de niveau BAC+5, avec une spécialisation en Statistiques, data science, informatique décisionnelle et/ou économétrie.
Vous avez un bon niveau d’anglais (utilisation ponctuelle sur le poste). Vous maîtrisez les techniques et les méthodes d'analyse statistiques, savez manipuler des données et interpréter des résultats. Vous maîtrisez le Pack Office (notamment Excel), les outils et les langages statistiques et de data science (SAS, Python, R, SQL). Vous portez un intérêt pour le Marketing.
Si vous êtes rigoureux, fiable, précis, avez le sens de l’organisation et une aisance relationnelle, alors n'hésitez pas à postuler à cette offre d’alternance.
Vous bénéficierez d’un accompagnement dédié pour vous donner toutes les chances de réussir cette nouvelle mission.
Pour un meilleur traitement de votre candidature, nous vous remercions de préciser le type de contrat recherché (apprentissage ou professionnalisation), l’intitulé et le numéro de diplôme préparé ainsi que le rythme d’alternance de votre formation.

Job Reference: BPCESEF00483"
Suresnes (92),,,Big Data Developer - Pipeline Designer,Talend,- Suresnes (92),"WHO WE ARE:

Talend, a leader in data integration and data integrity, enables every company to find clarity amidst the chaos.

Talend Data Fabric brings together in a single platform all the necessary capabilities that ensure enterprise data is complete, clean, compliant, and readily available to everyone who needs it throughout the organization. It simplifies all aspects of working with data for analysis and use, driving critical business outcomes.

From Domino’s to L’Oréal, over 4,250 organizations across the globe rely on Talend to deliver exceptional customer experiences, make smarter decisions in the moment, drive innovation, and improve operations. Talend has been recognized as a leader in its field by leading analyst firms and industry publications including Forbes, InfoWorld and SD Times.

Talend is Nasdaq listed (TLND) and based in Redwood City, California.

As part of its growth, Talend is looking for a Big Data Developer for its Pipeline Designer team based in Suresnes, France.
Pipeline Designer is the new data integration Cloud application developed at Talend. It brings a rich Web application where users can interactively design, manage and run their data integration pipelines at cloud scale. Pipeline execution is managed by the next generation Talend batch & streaming runtime, leveraging Apache Beam, Apache Spark and Talend components kit providing a full Cloud / on-premise hybrid solution. Pipeline Designer is developed in Scala (play, akka), JavaScript React and Java, and deployed using Docker, Kubernetes and modern CI / CD technologies.
Key responsibilities
Actively enhancing and maintaining the Pipeline Designer runtime engine
Participating in the review and the implementation of new processing functionalities in the product
Actively collaborating with Talend Apache team members on integrating Apache Beam features into the product
Contributing in requirements analysis and sprints planning
Contributing in the integration and deployment phases
Collaborating with other team members in investigating and resolving technical or performance issues and performing root cause analysis
Maintaining technical documentation
Skills and experience
BSc or MSc degree in Computer Science or equivalent experience.
At least around 5 years of practical experience in software development
Strong knowledge in either Java or Scala
In-depth knowledge and practical experience in batch and real-time Big Data processing (Spark or any other distributed computing technology, Kafka, Hadoop ecosystem, ...)
Experience with Big Data cluster setup and administration (Databricks, EMR, CDH, HDP, …)
Good understanding and hands-on experience with Kubernetes and Docker
Familiarity with Agile development methodologies
Ability to communicate effectively and clearly in English, both verbally and in writing.
Nice to have
Experience with Akka and Play!2 frameworks in Scala
Experience with a public cloud platform such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform
Experience in working within a distributed & international agile team environment.

AND NOW, A LITTLE ABOUT US:

Talend has received some pretty impressive accolades along the way:
""2018 Best Public Cloud Computing Companies To Work For"" by Glassdoor
Named a Leader for Data Integration Tools in the Gartner Magic Quadrant
Named a Leader in Big Data Fabric for the Forrester Wave
Ranked in the DBTA “100 Companies that Matter Most in Data”
Listed in the CRN Big Data 100 Companies

We are passionate about helping companies become more data driven; and, if we can be honest, we are all geeks at heart who pride ourselves on the vibrant company culture that we have built.

As a global employer, at Talend, we believe our success depends on diversity, inclusion and mutual respect among our team members. We seek to recruit, develop and retain the most talented people from a diverse candidate pool. We are committed to making all employment decisions on the basis of business need, merit, capability and equality of opportunity. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin."
Paris 9e (75),CDI,,"Data Analyst, Retail Media (French speaker)",Criteo,- Paris 9e (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

As a member of the EMEA Analytics team, a part of the rapidly expanding Criteo Retail Media Platform, you will utilize our MASSIVE set of shopper data to provide actionable insights and recommendations for some of the largest retailer in EMEA (Bol, ASDA, Argos, La Redoute, Auchan,...). We leverage our unique position to provide our retailer with visibility into shopper behavior, market trends, and product performance that can't be found anywhere else. The scope of this role involves technically rigorous work, including the use of leading-edge data analysis technologies and daily interaction with other cross-functional business units and external clients.

Criteo’s high-growth business model brings both opportunities and challenges. This position requires working with large sets of data to solve complex business problems by thinking strategically and proposing innovative solutions. The ideal candidate functions with minimal oversight and has the ability to learn new concepts quickly.
What you'll do
You are part of the EMEA Analytics team under Criteo Retail Media
Build tools and reports using Python, query languages (Hive/Presto/Vertica/SQL), Tableau, and other technologies to satisfy the needs of internal and external clients
Focus on creating scalable solutions that give autonomy to the end-user and minimize ad hoc work
Serve a central role with a global scope that bridges the gap between Sales & Operations and Research & Development
You identify high-value business, insight, and reporting needs then prioritize, scope, and build solutions.

Who you are
You have a bachelor’s degree or higher in a quantitative field (Data Science, Engineering/Computer Science, Economics, Mathematics, Statistics, Finance, etc.)
You have a first experience working with a SQL-like query language, Python and/or R
You're a great communicator who can explain and understand complex problems while dealing with both non-technical and highly-technical teams
Ability to structure and solve difficult problems with minimal supervision
You are fluent in English and French (C1 level at least required).

Why you'll love us
Fun and passionate work environment
35+ annual holidays days
Health insurance
Discounted transport
Private nursery
Maternity and paternity leave
Competitive compensation package
Central location in Paris and amazing rooftop!

Join us to contribute to one of the fastest growing, leading edge technologies in online industry. We work hard, play hard and we share the same passion for e-Commerce, Advertising and Technology. We value team work, openness, technical innovation, and results-orientated thinking.

#LI-JS1

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Paris 17e (75),CDI,,Data Engineer Scala - Pyspark - Spark - h/f,Huntiz,- Paris 17e (75),"Vous mettez en œuvre vos compétences en termes de manipulation de données Big Data nécessaires aux différentes missions client. Vous travaillez au sein des équipes de Data Scientist, aussi bien en réalisation qu’en tant que conseil sur les missions suivantes :

Audit et cadrage de projets sous l’angle des data

Réalisation/accompagnement de projets impliquant la mise en place de flux de transformation de données

Participer à la structuration/l’automatisation de nos processus internes pour rendre les équipes de Data Scientist plus efficaces dans l’accompagnement client

Former et évangéliser sur les différentes technologies que nous utilisons.
Profil recherché Maîtrise du framework Spark (pyspark, scala)

Maîtrise des SGBDR, NoSQL

Capacités de synthèse, de communication et de vulgarisation

Qualités d’organisation et de rigueur et le goût du travail en équipe

Vous assurez une veille technologique

Compétences Technos :
Versioning de code (Git)

Testing

Systèmes distribués

Système Hadoop, Map Reduce

Bonne connaissance du Machine Learning (cloud solutions, Azure, AWS, Google = au moins une d'entre elles)
Entreprise Huntiz est le cabinet de recrutement digitalisé nouvelle génération, 100% connecté ! Nous recrutons pour des startups, PME et grands groupes en France et à l’international. Avec Huntiz, postulez en quelques clics seulement.

Nous recherchons actuellement

un(e) Data Engineer

, pour notre client, une entreprise de conseils Big Data en pleine expansion."
Paris (75),,,Consultant Data Marketing H/F M13h recrute !,M13h,- Paris (75),"À propos
M13h est une start-up en forte croissance, plongée au cœur d’un monde digital en pleine ébullition, où marketing et technologies sont devenus indissociables. M13h adresse les enjeux de l’expérience client et des business models de demain au travers des technologies big data.
Nous menons des projets innovants avec nos clients, directions marketing de grands comptes, e commerçants et groupes média. Notre ADN est au croisement d’un cabinet de conseil et d’une agence web, de l’IT et du marketing.
Travailler chez M13h, c’est :
Intégrer une équipe à taille humaine et ambitieuse, qui challenge les cabinets et agences établis par son positionnement et ses méthodologies agiles,
Décrypter et expérimenter les innovations technologiques du marketing digital et de la data,
Travailler pour des clients prestigieux comme Fnac-Darty, La Française des Jeux, Vente-Privée.com, Groupama, OVH, Total, Boardriders, Dior, Onatera, Le Point, BFM TV, Libération, …
M13h fait partie depuis 2018 du Groupe Labelium, agence internationale présente dans plus de 15 pays.
Descriptif du poste
En tant que Consultant Digital & Data Marketing, vous intervenez sur les offres phares du cabinet :
Construction et alignement de stratégies marketing & technologiques orientées consommateur, construction de business models data, mise en place de partenariats BtoB data
Challenge des opérations marketing, définition et animation d’expérimentations data, mise en place de démarches test & learn, refonte de la gouvernance des directions marketing
Construction de parcours et expériences client orientée data, pédagogie consommateur, création de confiance entre marques et consommateurs
Conception et animation de formation aux enjeux du data-marketing
Vous êtes encadré par les associés et consultants senior du cabinet.
Polyvalent, vous contribuez activement au développement de la société en relation directe avec les associés : prospection, réponse à appel d’offres, knowledge management, visibilité web du cabinet, newsletters, …
Profil recherché
Issu d’une grande école de commerce, d’ingénieurs ou équivalent, vous êtes jeune diplômé ou disposez d’une première expérience professionnelle réussie.
Attiré par les métiers du conseil, du marketing digital et de la data, vous faites preuve d’autonomie, de curiosité, et êtes capables de construire des points de vue argumentés sur des sujets innovants.
Une première expérience sur un ou plusieurs des sujets suivants sera un plus apprécié :
Stage ou première expérience en cabinet de conseil,
Implémentation ou utilisation d’outils data marketing : web analytics, TMS, DMP, AB Testing, …
Analyse de données : langage R/Python/SQL, SPSS, data visualisation, outils BI, écosystème Hadoop & outils Big Data, …
Développement web : HTML/CSS/JavaScript, PHP/Ajax
Process de recrutement
Le processus commence généralement par un court entretien vidéo. Il est suivi de 2 entretiens et d’une étude de cas.
Informations complémentaires
Type de contrat : CDI
Lieu : Paris, France (75002)
Niveau d'études : Bac +5 / Master
Expérience : > 6 mois
Télétravail ponctuel autorisé"
Paris (75),,,Data Engineer (H/F),Dailymotion,- Paris (75),"Company Description
Dailymotion’s mission is to connect publishers and advertisers with engaged viewers who turn to Dailymotion for videos that matter. Through partnerships with leading publishers and creators, including CBS, CNN, Fox Sports, GQ, Mashable, Universal Music Group, VICE and others, Dailymotion commands 3 billion monthly page views across its mobile app, desktop and connected TV experiences. Dailymotion is owned by Vivendi, one of the largest mass-media corporations in the world, and has recently launched a proprietary ad platform to gain better control of its monetization value chain and deliver a premium advertising experience.
Dailymotion is a global champion of diversity and inclusion. We pride ourselves in being an equal opportunity employer that provides an environment of mutual respect.

Job Description
Dailymotion is seeking a Data Engineer to join the Data team. Our team is responsible for all the Data products in Dailymotion; your work will have an impact throughout Dailymotion’s business and help make data-driven decision on products and strategy. We deliver data as database tables, data streams, APIs, dashboards, report files and UIs to all teams from Finance to Content teams and clients.
You will be part of a team made up of Data Engineers and Machine Learning Engineers that has built software that handles hundreds of terabytes of data in our data lake, billions of events streamed, hundreds of batch tasks on Airflow and millions of API calls every day, A/B testing, multiple machine learning projects including recommender systems, semantic annotations, fraud detection, spam detection, etc.
All our stack runs on Google Cloud Platform. And you will work within an environment made of: high-volume data lake (BigQuery, etc.), streaming platforms (Beam/Dataflow, Apex, Flink, etc.), orchestration tools (Airflow), APIs, deployment (Docker, Kubernetes, Jenkins), SQL & data modelling and turning requirements into actual code and pipelines..

Your tasks, among others, will be to :
Build large-scale batch and stream data pipelines processing billions of daily events that fuel analytics dataset and machine learning flows.
Drive optimization and testing, write documentation, build tools, define or apply best practices, to improve and maintain data quality.
Develop API services for data collection from internal and external sources
Work closely with machine learning engineers to construct creative solutions for their analysis tasks

Qualifications
Required development experience in a language such as Python, Go or Java
Confident with SQL
Passion for data: moving it, transforming it, extracting it and understanding it
Familiar with ETL workflows and good practices: partitioning, idempotency, deterministic processing, etc.
Technology savvy, fluent in unix environment: ability to connect to remote servers, edit files, perform curl, run ab benchmark, analysis running processes, etc.
Ability to define requirements and technical specifications for new features and , and to develop them into scalable and performant services.
Knowledgeable of technology constraint, performance bottleneck of systems (CPU, Memory, network, disk, etc.) and how to overcome them.

Additional Information
Technical stack
Analytics ETL: Airflow, Python, SQL, BigQuery, Presto/Druid, Exasol
Machine Learning Flows: Python, Golang APIs, Apache Beam, Json RPC/gRPC apis, Tensorflow model training, Docker/Kubernetes for deployment
Google Platform Services: BigQuery, Cloud Storage, PubSub, Dataflow, GKE
Location: Paris (France)
Start Date: depending on your availabilities
Contract Type: Full-time and Permanent contract"
Paris 9e (75),,,Data Engineer,Fideliz,- Paris 9e (75),"Le poste
En tant que Data Engineer, vous contribuez au développement de l’équipe Data Intelligence. A ce titre, vous intervenez auprès de nos clients du monde tertiaire ou industriel sur des projets stratégiques de transformation, liés à la valorisation des données de l’entreprise.
Les missions
Vous analysez les besoins avec les équipes Métier Marketing et Data Analyse.
Vous concevez et développez les traitements de données et réalisez les tests de validation.
Vous maintenez et développez l’alimentation des données, et structurez le stockage des données.
Vous garantissez la qualité des traitements des données et leur intégrité.
Vous réalisez les ordonnancements des traitements.
Vous développez et industrialisez les flux de traitement et d’enrichissement de données.
Enfin, vous assurez l’interface avec les équipes Métier de l’entreprise.
Vous
Vous possédez idéalement une expérience en analyse de données sur Hadoop/Spark (ou Cloudera/HortonWorks) et maîtrisez les langages de gestion des bases de données SQL et de programmations, comme Python ou Scala. Vous possédez des notions sur les ETL de type Talend.
Vous êtes un bon communicant qui fait preuve d’inventivité face aux problématiques client.
Votre diplomatie dans le dialogue fait de vous une personne reconnue et attentive au client ainsi qu’à vos collègues."
Paris 1er (75),CDI,,Data Scientist F/H,SCIENT,- Paris 1er (75),"Nous cherchons notre Data Scientist

La Mission :
c

omprendre le métier et le traduire en spécifications techniques.

En étroite collaboration avec une petite équipe vous serez en charge :

Elaboration de projet et programmation en Data-Science

Participer au développement des solutions

Mise en place des technologies d’IA et de NLP

Profil recherché Les prérequis :
Vous justifiez impérativement d’une

première expérience en Python/JS

, vous êtes diplômé d’un

Master en Informatique

ou d’un

diplôme d’ingénieur

(Ingénieur Informaticien) et vous maîtrisez au moins deux des compétences suivantes :

Algo : Python (tornado, flask), Javascript (NodeJS)

Data : MongoDB, ArangoDB, PostGreSQL, ElasticSearch, RabbitMQ

Linux, Docker

La maîtrise des

compétences

suivantes serait un plus pour ce poste :
Algo : Go, Java, Spark, Redis, Django

Front : AngularJS, ReactJS, D3JS

Data-Science : Machine Learning algorithms (SVM, RandomForest, XGBoost, Logistic...), connaissance des réseaux de neurones et Python / APIs (Numpy, Pandas, Scikit Learn, Keras...)

Vous souhaitez rejoindre une équipe passionnée d’informatique, d’IA et d’innovations et que vous maîtrisez les compétences nécessaires :

Alors rencontrons-nous !
Entreprise Chez Scient nous sommes des Project Makers.

Grâce à une

approche innovante

et

non-conventionnelle centrée sur les

usages

, les

méthodes agiles

et notre

expertise data

, nous transformons les challenges de nos clients en succès.

Notre team-spirit orienté sur le

développement personnel

de nos collaborateurs

et sur les

valeurs du sport

nous confère une place toute particulière dans notre écosystème.

Rejoindre notre aventure, c’est rejoindre une entreprise en forte croissance et pleine d’ambitions avec des projets passionnants dans un cadre idéal à Paris et à Aix-en-Provence."
Paris 9e (75),CDI,,Ingénieur Big Data F/H,MERITIS TECHNOLOGIES,- Paris 9e (75),"Notre client, un acteur majeur du ferroviaire, recherche un ingénieur Big Data pour la construction d’un outil de reporting et d’analyse concernant les données d’exploitation de son réseau GSM-R (radio sol-train). Le but est de mettre en place l’automatisation des règles de calculs pour repérer les anomalies qui pourraient survenir sur le réseau. Vous travaillerez dans un environnement big data, avec des tâches aussi bien techniques que fonctionnelles.

Vos missions seront les suivantes :
Développement en Python ou Scala et en Spark

Mise en place d’API

Développement d’algorithmes pour repérer les anomalies et leurs impacts

Présentation des résultats sous forme de prototypes

Gestion et suivi du projet via des tableaux de bords, …
Profil recherché Vous êtes diplômé(e) d’une école d’ingénieur ou équivalent Bac +5

Vous avez une bonne maitrise de Python/Scala, Spark

Vous justifiez d’une expérience dans la mise en place d’outils big data

Vous possédez des compétences transversales, notamment en gestion de projet

Vous avez, dans l’idéal, une formation orientée gestion de données
Entreprise Notre structure, MERITIS Technologies intervient sur les enjeux de la mobilité, de la santé, de l'environnement ou des médias.

Venir chez MERITIS Technologies c'est rejoindre la GreatPlaceToWork 2017 et la garantie de trouver :

Un accompagnement dans votre évolution de carrière
Une ambiance fun, dynamique avec un esprit d’équipe solide. Des afterworks tous les mois et demi, des teams building, des meet-up, des workshops et des soirées d’agence.
Un respect de l’équilibre vie pro/vie perso avec notamment notre philosophie : « Happiness Gives Success »."
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community
Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
La Défense (92),,,DATA Engineer Datalake FULL Cloud (AWS / Spark / Python),INSYCO,- La Défense (92),"Nous recherchons un consultant Datalake pour renforcer une équipe Cloud AWS chez notre client grand compte.
Cette équipe est en charge des activités du Datalake, son administration, l’intégration et le traitement de nouvelles sources de données et des usages Métiers.
Le consultant doit avoir de solides compétences sur le framework Spark, une grande autonomie sur les services AWS associés et une appétence pour la gestion du cycle de vie des données.
Il/Elle aura aussi une grande appétence pour la gestion des données, un excellent relationnel et une bonne communication. Il/Elle travaillera en autonomie et sera force de proposition.

Il/Elle travaillera au sein de l’équipe sur les activités suivantes :
Ingestion et traitement des sources de données
Préparation des données (transformation fonctionnelle et technique)
Exposition des données et mise en place des usages de données
Opérabilité des différents traitements
Assurer l’observabilité des différentes chaines

Compétences techniques indispensables :
Framework Spark (Développement et Optimisation de cluster)
Python (Pyspark) Maitrise Spark DF et Pandas
Usage du service EMR pour le déploiement des clusters
Intégration avec les services connexes d’AWS (Lambda, Batch, ECS)
Notebook
SQL
Base Nosql (DynamoDB)
Gestion du format Parquet

Compétences souhaitées
Terraform
Gitlab CI
Git
Stack Elastic
Pentaho
Apache Atlas"
Paris (75),,,Software Engineer – Machine Learning Platform,Criteo,- Paris (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

What is it like to work in our R&D ?

Most of all, we are creators. From designing ground-breaking products to finding unique ways to solve technical challenges at an exceptional scale, our tech teams work with state of the art methodologies to shape the future of advertising.

The Criteo AI Lab brings together researchers, machine learning engineers, software engineers and data scientists. Our mission is to develop advertising solutions that provide value to Internet users around the world. We do so by pushing state-of-the-art ML methodologies into our products to drive better performance, and act as center of Machine Learning research and engineering excellence.
What You'll Do
You will join our team of machine learning researchers and software engineers to develop and design build scalable big-data distributed data processing systems that will be used to power experimentation and production ML applications at Criteo.
Your responsibilities will include building libraries, services and datasets that will be used by ML researchers and practitioners across Criteo.
You will then contribute directly to the development of Criteo’s infrastructure for experimentation / productionizing of ML applications.

Who you are
MS / PHD in Computer Science or relevant experience.
You have at least 3 years of programming experience in a OOP language such as C#, Python, Java or Scala (or equivalent) and a rock-solid foundation in Computer Science (data structures, algorithms) as well as the basics of machine learning.
Ideally, you have already dealt with large scale big-data processing in the Hadoop ecosystem, using industry standard services like Hadoop MapReduce / Apache Spark / Presto / Hive in languages like Java and Scala.
You have strong hands-on skills in sourcing, cleaning, manipulating and analyzing large volumes of data.
You are fluent in english (written and spoken) and also a team player who can work efficiently with others, with strong sense of ownership and taking pride in your work.

What we offer
Competitive compensation package
35 annual holidays days (25 + 10 RTT)
Health insurance
Personalized relocation package if moving from abroad
Private nursery
Discounted transport
Maternity and paternity leave
2 conferences per year of your choice (1 International + 1 national)
Internal mobility programs
Tailored educational resources (Courseras, MOOC, Internal trainings ...)
Annual cross teams hackathon

Want to know more?
What does it feel like to be part of something big? Get a snapshot
Get the story directly from our R&D engineers, check our Medium R&D blog
Interested in discovering your Criteo community first? Let’s meet

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Paris 14e (75),CDI,,Développeur Java Big Data F/H,ANALYSE INFORMATIQUE DE DONNEES,- Paris 14e (75),"AI&Data recherche aujourd'hui des développeurs JAVA Big Data .

AI&Data est partenaire de nombreuses grandes entreprises françaises et utilise depuis plus de 40 ans des technologies liées à la data à la pointe de l’innovation.

Il s’agira d’intégrer notre pôle produit datakili ® constitué de près d’une dizaine de développeurs, datascientists, product-owner et commerciaux, collaborateurs passionnés évoluant ensemble dans un esprit Start Up en mode agile.

Vous participerez au développement de notre solution en mode SaaS datakili® qui permet aux grandes entreprises - à travers le traitement de grands volumes de données - de connaître finement les comportements de leurs clients lors de l’achat et de l’utilisation des produits et des services pour améliorer l’expérience clients.
Le logiciel permet de visualiser, d’analyser et de monitorer les « parcours clients » sur la base de données en provenance de tous les points de contacts : sur le web, en magasin, etc. pour mettre en place les bonnes actions au bon moment.

Vous contribuerez à de nombreux challenges techniques et fonctionnels, dans un environnement agile SCRUM , pour garder le caractère innovant du produit sur son marché.
Notre plateforme et notre équipe d’experts vous permettront de développer des compétences diverses dans un environnement :

Backend : Hadoop / Spark / Cassandra / Parquet

Langages : Java / Scala

Framework : Spring

Frontend : AngularJS / D3

Brique ETL temps réel : Kafka / Storm

Calculs et approches statistiques, Machine Learning en environnement distribué

DevOps : Ansible / Jenkins / Docker / Visant le déploiement continu
Profil recherché Nous recherchons des personnes proactifs(-ves), passionnés(es), rigoureux(-ses)

Vous êtes débutant ou avez déjà de l’expérience

Vous aimez travailler en équipe et créer des produits logiciels de bonne qualité

vous êtes habile avec : Java 8, Spring, Angular, Maven et Git

vous pratiquez une veille technologique régulière et êtes passionnés par l’évolution des technologies qui vous entourent.

Alors rejoignez nous !

Vous souhaitez vous investir dans des projets challengeants, monter rapidement en compétences, avec la possibilité de gagner en responsabilités, ce poste n'attend que vous.
Entreprise AI&Data, Agence Data et Datascience

AI&Data possède trois domaines d'expertise : Datascience, CRM et Big data.

1er hébergeur de bases de données marketing et de datalakes en France cumulant plus de 220 millions de clients et plus de 45 milliards d’interactions.

AI&Data offre une chaine de valeur complète autour de l’analyse, du traitement, de l’exploitation et de la transformation des données en performance marketing.

Opérant des données clients dans plus de 12 pays, AI&Data travaille avec les plus grands des secteurs des télécoms, de l’énergie, de la banque, de l’ hôtellerie, des jeux et des loisirs."
Paris 10e (75),,,Python developer / Data Engineer,OpenClassrooms,- Paris 10e (75),"There’s a revolution currently taking place in the education and training field and you want to be a part of it. You feel strongly about access to education and you may have even taken a few MOOCs or online classes yourself. Come help us make education accessible to all.

OpenClassrooms is looking for a Python developer / Data Engineer, in charge of designing and implementing automation of our business services. We are seeking a problem-solver and an idea-generator who is able to anticipate both technical and business issues and to implement solutions. You will be at the crossroads of data and development.

What will you do?

You will design, build, and maintain our automation platform
You will gather and provide readable data ensuring consistency and security
You will interact with your teammates via peer programing and review, development workload refinement, and evaluation
You will contribute ideas to improve our engineering standards and processes

You might be a fit for this position if:
You have at least 4 years experience as a backend Python developer or data engineer
You are passionate by best practices, work in TDD and use to CI/CD
You are proficient in Python and SQL
You are familiar with ETL
You are able to build clean transformed and readable datasets
You love to learn, improve yourself, and give and receive feedback
Reliability and kindness are part of your mindset
You can communicate both orally and in writing in both French and English

Hiring process
After your application you will:
Get in touch with our Engineering Manager over the phone
Discuss your technical skills with the Tech Team in our office
Meet HR and team members from outside of the Tech Team (Student Success, Revenue, Marketing, etc.) to learn about our values and our company culture
Meet with our CTO to understand Tech vision: this is an opportunity for you to understand our upcoming challenges and to ask all the remaining questions you may have

You will also be asked to provide us with professional references.

What do we offer?
Pass Navigo paid in full by OpenClassrooms
Additional health insurance through a mutuelle paid in full by OpenClassrooms.
Meal vouchers (Employer contribution at the max authorized by law)
Gym membership (GymPass paid in full by OpenClassrooms)
Unlimited days off and a €1,000 bonus once a year for those who take 15+ days of vacation in a row (bonus available after 1 year of employment)
Ability to work remotely up to 4 days a month
A company MacBook
A work environment and a strong culture built on agility, openness, respect, and high-quality
Salary transparency which ensuring fairness

Feel free to get the gist of who we are : https://openclassrooms.com/courses/how-do-we-work-at-openclassrooms
If you want to know more about the Tech team: https://medium.com/openclassrooms-product-design-and-engineering

More about us
We value diversity and welcome everyone who wants to join us and make education accessible. We are at an exciting moment and we deeply believe that various backgrounds and experiences will lead to a better product for our students.

OpenClassrooms is a French hyper-growth company eligible to the French Tech Visa program. Non EU candidates may benefit from an accelerated procedure to apply for a ""Talent Passport"" residence permit. There is also a simplified accompanying family procedure available for immediate family members of the sponsored employee (spouse and dependent minor children).

More information: https://visa.lafrenchtech.com/4/french-tech-visa-for-employees"
Neuilly-sur-Seine (92),CDI,,Data Engineer F/H,TEOLIA,- Neuilly-sur-Seine (92),"Dans le cadre de notre développement, nous recherchons un(e) Data Engineer pour nos clients intervenant autour des problématiques de Big Data et ayant pour missions principales :

La conception de solutions permettant le traitement de volumes importants de pipelines de données.

L'animation d'équipes sur toutes les étapes du traitement de la donnée.

La mise à jour permanente sur les technologies et langages utilisés dans le but de partager ses connaissances et aider à l’avancement du projet.

Compétences techniques :
Javascript, Scala, Python...

UNIX, Linux, Solaris

SQL, NoSQL

Forte expertise sur le stockage de données et les outils ETL

Hadoop, Spark, Kafka

Anglais courant.
Profil recherché De formation BAC +5, issu(e) d’une école d’Ingénieur

idéalement vous possédez a minima une première expérience acquise en stage ou en alternance.

Côté personnalité, vous êtes aussi : force de proposition, rigoureux(/se), réactif(/ve) avec un esprit analytique et de synthèse, l'envie de travailler en équipe ainsi qu'un excellent relationnel, sans oublier le sens de l’organisation.

Mais vous êtes surtout un(e) passionné(e), vous effectuez régulièrement de la veille sur les nouvelles technologies et êtes curieux(/se).

Vous vous reconnaissez dans cette annonce?
Entreprise Envie de rejoindre un collectif de passionnés réunis autour d'un projet d'entreprise où l'excellence dans le service rendu au client se conjugue avec épanouissement personnel ? Envie de participer à la co-construction d'une société en pleine expansion dont la force repose sur ses collaborateurs ?

Alors rejoignez Teolia !

Notre ADN est clair :
expertise, convivialité, proximité et partage.

Plus concrètement :
L’expertise c'est quoi chez Teolia ?

Des consultants expérimentés (7 ans d’expérience minimum) passionnés par leur métier engagé au service du client. Et réunis au sein de notre Talent Hub.

La convivialité c’est quoi chez Teolia ?

Un langage commun.

Une communauté de Teoliens.

Un échange de bonnes pratiques.

La proximité c’est quoi chez Teolia ?

Un suivi personnalisé et individualisé des collaborateurs.

Un respect de la vie privée et professionnelle.

Un respect de la zone géographique des consultants.

La transparence c’est quoi chez Teolia ?

Partager son apprentissage :
Dire quand on est content.

Dire quand ça ne va pas.

Prévenir quand on s’est trompé

Nous accompagnons nos clients sur :
Le pilotage de projets stratégiques et optimisation de la performance opérationnelle

Les prestations d’assistance de proximité pour la conception et réalisation des nouveaux services applicatifs et/ou infrastructures

Les projets de transformation digitale

Envie de rejoindre l'aventure ?

jeune entreprise lauréate 2019 du Grand Prix des Entreprises de Croissance ! Une croissance continue de 100% par an."
Paris 9e (75),,,Data Engineer,Numberly,- Paris 9e (75),"Company Description
Numberly helps its customers collect, analyze and leverage their data across all marketing channels. To do this, we are more than 100 engineers (a quarter of Numberly) divided into teams with a human dimension, where we ensure that everyone develops a positive influence and can be autonomous. Our sustained growth forces us to constantly question our technical and organizational choices.
With seven offices worldwide and clients in more than fifty countries, our challenges are global.
Due to our wide range of interconnected products, our technical challenges are very varied and often complex. Our daily missions consist of processing thousands of requests per second, distributed throughout the world, operating databases of several petabytes (Big Data™), automating our entire bare-metal infrastructure, and building the digital marketing interfaces of tomorrow.

Job Description
Numberly is looking for a Data Engineer to join its dedicated team to Big Data and RTB.
As a Data Engineer you will:
Create and maintain pipeline jobs that transfer client data to/from our database diverse infrastructure (Hive, MongoDB, ScyllaDB).
Nurture our large Hadoop cluster, optimize distributed Data Operations and Storage.
Participate in decision making concerning efficient & ethical use of data and technological evolution at Numberly.
Work alongside Data Scientists, DevOps, and many other talented techs.
Suggest your own technological solutions and try them out (our latest successful POCs include Apache Kafka and ScyllaDB) .
Join a great multicultural team filled with wonderful people

Qualifications
You :
Like data in all its forms: raw, reworked, refined, calculated, analyzed, reused…
Like work well done and pay attention to detail
Dream of being able to develop and manage website databases with strong traffic
Want to work with various, prestigious clients on different problems
Are on the lookout for new languages/technologies and test the latest open source trends before others
You love the following stack ?
Hadoop ecosystem (HDFS, Hive, Impala, HBase, ...)
Apache Spark
ETL (Apache Airflow or equivalent)
SQL Databases (MySQL, SQLServer)
NoSQL databases (MongoDB, ScyllaDB, ElasticSearch, ...)
Apache Kafka
Python, Java, Scala
Git
Linux
Even better if you know :
Cloud Solutions (AWS, GCP, …)
API REST, WebServices
Docker
Kubernetes
Apache Druid
Data Science and Machine Learning
Message Queuing (RabbitMQ, Celery, …)

Additional Information
Even with 500 people we like to spend time together!
Participate to “Happy Meetings’” where we share the Group’s news with everyone from around the world
Get to know your “Jedi Master”, your ‘go to guy’ when you arrive
Go to yoga classes, cross-training, barbecues, internal parties...
Find the most incredible fancy costume for the next party"
Paris (75),42 000 € par an,,Data Engineer - H/F,emagine Consulting,- Paris (75),"emagine recrute en CDI son ou sa future Data Engineer afin d’accompagner ses clients majeurs dans le cadre de leurs projets Big Data.
Vous participez à l’évolution et l’optimisation du système d’information décisionnel existant, en accompagnant les équipes opérationnelles.

Votre mission :
Résolution des problèmes de traitement des données
Amélioration de Solutions
Analyse des causes conjointement avec les opérationnels
Mise en place de modèle de données avec l’équipe de Data Architect, à disposition des Data Scientist.
Optimisation des flux de données
Réalisation de Test
Industrialisation des process
Développant des pipelines de traitement de données.
Garantir la sécurité, la disponibilité et la scalabilité des données.

Vos atouts pour ce poste:
Expérience de 2/3 ans minimum
Anglais Technique Courant
Autonomie, curiosité et transparence
Maîtrise du Code : Python, C / C ++, Java, Perl
Connaissance approfondie de SQL et autres languages de base de donnée
Stockage de données et outils ETL : La maîtrise des outils de stockage de données (Hadoop) et des ETL (Talend, Nifi ) sont essentielles.
Connaissance divers systèmes d’exploitation : UNIX, Linux et Solaris
Une bonne compréhension de l’analyse de donnée basée sur Hadoop"
Paris (75),,,Big Data Engineer,AB TASTY,- Paris (75),"The data team, composed of 7 members who work closely with both the DevOps and the DataScience teams, is in charge of developing and monitoring the data collect pipeline. The collect, which processes a few terabytes of data per day, has been deployed on a Google Cloud Platform environment and is critical to AB Tasty. Different GCP environments are available to ensure the good development and deployement of features as well as data modelisation and documentation.
What you will do :
Create or update features of the processing data collect using GCP components as dataflow, bigquery, bigtable
Develop a new environment with services, dashboard to ensure the data quality in real-time and design a moniting process
Participate in the design phases and implementation of new micro-services and machine-learning features plugged into the pipeline
Explore and implement new data sources
Monitor the pipeline
What we're looking for :
Strong knowledge of at least one of the following technologies: Apache Beam / Spark / Hadoop
Knowledge in Java, Python, and/or Golang
A least 2 years of experiences as a (Big) Data Engineer
Experience with cloud platform is a plus
Good level of English (written and spoken)"
Levallois-Perret (92),"Temps plein, CDI",,FULL REMOTE Senior Data Scientist H/F - CDI,Jellysmack,- Levallois-Perret (92),"Nous continuons de recruter et avons adapté notre processus de recrutement. Tous nos entretiens, ainsi que l’onboarding, se déroulent désormais en full remote.
Cette offre d'emploi est proposée en FULL REMOTE
Jellysmack est une entreprise spécialisée dans la création de contenus vidéos originaux sur les réseaux sociaux. Avec plus de 3 milliards de vues par mois, Jellysmack a connu une ascension fulgurante, ne cesse de grandir et ambitionne de devenir le leader mondial dans son domaine. La recette de ce succès repose sur la qualité de nos contenus, mais aussi sur la technologie opérant en arrière-plan. Jellysmack a développé une suite d'outils propriétaires, propulsés par l'IA, permettant à nos équipes de contenu de publier, s'inspirer, comprendre la trend, analyser les résultats, mais bien plus encore, des outils qui analysent le contenu en ligne, les réactions des gens devant ce contenu, et déterminent ce que sera la tendance demain.
Après plus de 2 ans de développement technique, Jellysmack propose une technologie unique articulée autour de 3 produits qui visent à optimiser la création et la distribution sociale de vidéos.
L'équipe Tech œuvre pour la mise en place d’outils utilisés en interne par les équipes contenu afin de déterminer les sujets qui buzzent, les aider dans la création de contenu, suivre les performances des vidéos internes etc... en injectant dans chacun de ces produits une dose conséquente d’algorithmie, de statistiques et de machine / deep learning.
En lien direct avec le Head Of Data (basé en Corse), vous serez amené à travailler sur différentes problématiques - prioritairement axées autour du NLP - et sur des projets de taille très différentes, impliquant d’importantes quantités de données (plusieurs centaines de millions de vidéos stockées en base à date avec leur métadata textuelles, plus de 21 milliards de commentaires...).
Au sein d’une équipe de sept data scientist, vous serez le référent de l’équipe sur ces sujets d’analyse et de compréhension du langage et vous aurez un rôle consultatif.
Missions principales
Passer d'une problématique métier à un algorithme de data science
Passer d'un POC à un algorithme en production
Vulgariser un algorithme à l'état de l'art et être référent de l'équipe Data Science
Etre autonome sur les outils comme Git, avoir déjà travaillé sous docker - idéalement sous AWS
Quelques exemples de sujets :
Analyse de sentiments sur les commentaires des vidéos
Extraction de topics à partir des titres, descriptions, commentaires des vidéos
Catégorisation de vidéos en thématique à partir de l’ensemble des éléments textuels dont nous disposons
Génération automatique de titre/tag de vidéos...
Création d’un algorithme d’identification des meilleurs créateurs sur une thématique donnée
Analyse de vidéos (contenu et metadata) pour mieux comprendre la rétention des utilisateurs
Optimisation de coût sur l’acquisition de fans
Génération automatique de montage de vidéos...
Profil recherché
Docteur en computer science ou diplômé d’une maîtrise en data science, vous disposez d’au moins 5 ans d’expériences,
Une autonomie sur le passage en production d’algorithmes sera indispensable,
Vous êtes pédagogue sur la transmission de votre savoir,
Vous avez un très bon niveau de SQL (MySQL et PostgreSQL).
Avantages :
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
full remote senior data scientist h/f - cdi ou similaire: 1 an (Souhaité)"
Levallois-Perret (92),,,Cloud Data Engineer (H/F),Devoteam,- Levallois-Perret (92),"DESCRIPTION DU POSTE
Tu auras pour mission d’accompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l’écosystème solutions open source associé.
Intégré(e) à une équipe d’experts techniques, tu auras pour missions de :
Analyser les besoins clients
Animer des ateliers afin d’étudier et cadrer les besoins clients
Préconiser les solutions et architectures cibles
Définir les méthodologies de déploiement et plans de migration
Rédiger les dossiers d’architecture et spécifications techniques
Construire les architectures de données
Concevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels)
Construire et déployer les pipelines de données (ETL)
Assurer la migration des données vers les nouveaux environnements
Analyser les données
Analyser les données sources afin d’identifier et évaluer des cas d’usage métier
Mettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio…)
Sélectionner, entraîner, évaluer et déployer des modèles prédictifs en s’appuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn)
Accompagner et former
Assurer une veille technologique continue sur les solutions cloud
Accompagner et former les équipes clients aux méthodes et concepts du cloud
Tu seras accompagné(e) en interne pour monter rapidement en compétences sur GCP dans l’objectif de devenir certifié Google sur ta practice.
QUALIFICATIONS
Diplômé(e) d'une école d'ingénieurs ou d'un Master 2 en Informatique, tu disposes d'une expérience significative au sein de projets Data : architecture, traitement ou analyse de données.
Tu maîtrises au minimum un langage de programmation appliqué à l’analyse de données (Scala, R, Python, Java).
Tu as de bonnes compétences dans de l’architecture des systèmes, bases de données, méthodologies d’analyse
Tu es passionné(e) par la Business Intelligence, le Big Data, l’Internet des objets (IoT) et le Machine Learning
Une connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, …) est un plus.
Tu as une solide compréhension de la dimension technique et fonctionnelle des projets IT
Curieux(se), autonome et à l’écoute, tu possèdes un réel esprit d’analyse
Ta maîtrise de l'anglais te permettra de gérer des projets en contexte international"
Paris (75),Stage,,Stagiaire Data Engineer (H/F),Avanade,- Paris (75),"Vous aimez manipuler La Data ? Rejoignez notre équipe de consultants experts en Data Engineering ! Cette dernière a pour responsabilité de répondre aux besoins clients en termes d’Architecture et de de mise en place des solutions Big Data.

Vos missions

Au sein de notre équipe Enterprise Technology Architecture (ETA), dans le cadre de projets Big Data nationaux et/ou internationaux pour des grandes entreprises, sous la responsabilité de votre maître de stage, vous participerez aux missions suivantes :

Développement du traitement des données streaming avec Spark Scala, Python, Java
Développement des APIs pour alimenter des données dans le Data Lake (Kafka, Spark Streaming, Azure…)
Monitoring de l’environnement Big Data et l’optimisation de performance
Veille technologique autour des solutions Big Data (POCs sur les dernières technologies).
Vous êtes

Vous êtes passionné(e) par les Nouvelles Technologies et intéressé(e) par les métiers de la Data. Vous êtes un étudiant de niveau Bac+5 en Ecole d'ingénieur, Université avec une dominante informatique et/ou Big Data. Vous connaissez une ou plusieurs de ces technologies : Java, Python, C/C++/C#, Spark Scala, Linux, Cloud (Azure/AWS/GCP), HDFS, Kafka, Base(s) de données SQL, Base(s) de données NoSQL, outils de visualisation des données (Kibana, Grafana…)

Un bon niveau d’anglais à l’écrit comme à l’oral est indispensable.

Vous recherchez un stage de pré embauche."
Paris 8e (75),CDI,,Data Engineer F/H,CAPFI VITA DATA,- Paris 8e (75),"Vous accompagnez nos clients grands Comptes sur les phases de prototypes et/ou d’industrialisation de leurs projets Big Data.

Selon les projets, vous pourrez intervenir sur les phases suivantes :

Identification et formalisation de Business Cases
Contribution au tuning des plateformes Big Data
Conception, développement et optimisation des algorithmes de collecte et de traitement de données
Conception, développement et optimisation des algorithmes de Machine Learning, Deep Learning
Datavisualisation
Profil recherché Description du profil

Diplômé(e) d’une école d’Ingénieur, d’un Bac+5 Informatique ou Statistique/Mathématique avec une spécialisation en Big Data

Vous maîtrisez le développement Python et l’écosystème Hadoop, Spark, Java, Scala, R, SQL, ...

Vous avez une expérience de 2 ans minimum sur des projets analytics nécessitant leur implémentation en Python, Java ou C++

Une connaissance sur l’un des clouds AWS, Azure ou GCP est un plus
Entreprise Capfi VITADATA est la start-up du groupe Capfi spécialisée en Data Science et Big Data. Nous accompagnons nos clients grands comptes sur leurs projets Data afin de :

Transformer leurs données en intelligence métier

Construire une architecture Data Centric contrôlée et évolutive

Nous répondons aux enjeux analytiques et prédictifs des Directions Digital, Marketing, Risque, Actuariat et Innovation de nos clients des secteurs Banque/Assurance, Energie, Retail, Media, Transport,… Et apportons une expertise aux Directions des Systèmes d’Information sur leurs projets de développements en méthodologie Agile, avec une tendance forte à décliner la culture DevOps."
Paris (75),Stage,,Stagiaire ML Engineer - Septembre 2020,Axionable,- Paris (75),"À propos
Axionable est l'unique spécialiste du conseil en Intelligence Artificielle durable et responsable.
Rejoindre Axionable, c'est évoluer dans une entreprise technologique à taille humaine et en croissance avec des projets concrets et durables d'intelligence artificielle.
C'est non seulement bénéficier de formations mais aussi et de possibilités d'évolution de carrière dans un environnement de travail agréable et nativement international permettant d'allier sens et carrière.
Passionné.e.s de technologie, les collaborateurs d'Axionable travaillent sur l’ensemble des phases d’un projet d’IA, allant du cadrage métier à la préparation de la donnée ou encore à la mise en production des modèles algorithmiques. Ainsi Axionable utilise les dernières stacks techniques de distributed computing, de NLP, des cloud providers, de langages/Librairies, d’explicabilité, de storage et/ou visualisation, de microservices ou encore de web programing. Son équipe est également investie dans la recherche appliquée avec son laboratoire de recherche entre Paris et Montréal.
Par ailleurs, les collaborateurs d'Axionable trouvent du sens au travail à travers des cas d’usage à finalité durable pour leurs clients, en lien avec les objectifs de développement durable des Nations Unies : détection des fragilités, anticipation du changement climatique, finance responsable, chaîne d'approvisionnement durable, … Axionable est aussi engagé dans l’inclusion des diversités, notamment des femmes et dans la réduction de son empreinte carbone, à travers des initiatives de projets développés en interne.
De plus, son équipe pluridisciplinaire est composée d’experts (scientifiques, développeurs, PhD, consultants, spécialistes en développement durable, juriste) et travaille dans une ambiance transparente et bienveillante. Axionable attache beaucoup d'importance à la formation, notamment grâce à nos méthodologies et nos solutions de conseil en IA responsable (Responsible Machine Learning), et à la montée en compétences avec notre programme AxioCareer.
Fondée en 2016 par 4 cofondateurs et depuis toujours autofinancée, Axionable connaît depuis une forte croissance et compte 50 collaborateurs répartis entre Paris et Montréal. Elle intervient dans les secteurs de la banque/assurance, de l'industrie, des médias, du luxe et de l'immobilier pour divers cas d’usages conciliant la performance économique et les impacts sociaux et environnementaux à travers trois piliers interconnectés : sustainable strategy, sustainable research, sustainable solutions.
Descriptif du poste
Nous recherchons un(e) Stagiaire ML Engineer (H/F) contribuer à la réalisation d’architecture (Big) Data et Intelligence Artificielle (IA) *permettant de répondre aux besoins métiers de nos clients. En support de nos Data Engineers :
Tu accompagnes la *définition et la mise en œuvre de plateforme, des flux et des traitements de données,
Tu soutiens l’industrialisation des solutions grâce au outils Devops,
Tu intéragis avec nos experts data science et métiers et assurez la veille technologique dans votre domaine d’expertise
Axionable s’engage en faveur de l’égalité des chances, de la diversité et de l’équité. Nous encourageons tout(e) candidat(e) ayant l’expérience requise à postuler à nos offres.
Profil recherché
Stage de fin d’étude ou de césure, grande école d’ingénieurs ou master spécialisé en Big Data
Connaissances dans le développement : Shell, python, Java, C, SQL
Connaissance théorique des outils de stockage de la donnée : BDD, DatawareHouse, HDFS, NoSQL
Connaissance d’environnement DevOps.
Autonome, curieux(se) et passionné(e) des sujets Data.
La connaissance des solutions cloud est un plus.
Capacité à synthétiser rapidement et à proposer des solutions innovantes
L’Anglais courant est également un plus
Process de recrutement
2 entretiens + 1 test technique
Informations complémentaires
Type de contrat : Stage
Date de début : 01 septembre 2020
Lieu : Paris, France (75003)
Niveau d'études : Bac +5 / Master
Expérience : < 6 mois"
Paris,45 000 € - 55 000 € par an,,Développeur sénior Python | Secteur de l’énergie / big data,In-Team,- Paris,"Vous recherchez un nouveau challenge Python avec de fortes problématiques data science ?
Alors, rejoignez cette société spécialiste de la gestion énergétique au sein de parcs immobiliers !
Existant depuis plus 3 ans, cette entreprise développe une solution Saas qui, à travers la collecte de grande quantité de données, propose des solutions innovantes et impactantes d’optimisation énergétique. Vous l’aurez compris, au cœur de ce projet : la data.
Leurs clients ? JCdecaux, Picard, les plus grands groupes bancaires… leur font déjà confiance
Venant de lever 2.5 millions d’euro, il recherche pour renforcer leur équipe technique de 5 personnes, un développeur Python sénior, afin de travailler sur le développement back-end de leur solution, mais également sur la manipulation de grandes quantités de données.
La stack technique ? Python (Flask) ; JS (VueJS) ; MongoDB ;
Vous êtes curieux d’en savoir plus ?

Votre mission :
Au sein de cette entreprise d’une trentaine de personnes, vos missions seront :
Développement en Python – Flask et JS – VueJS
Créer des architectures logicielles
Travailler avec les SGBD non relationnel
Travailler sur la manipulation de grandes quantités de data
Monter en compétence sur du management (sélection, formation et encadrement des profils juniors)
Veille technique
Votre profil :
Bac +5 école d’ingénieur
2-5 ans d’expérience en développement Python / JS
Vous êtes exigeant sur la qualité de votre code et l’architecture logiciel car c’est quelque chose que vous jugez important
Opportunité :
Travailler sur un poste hybride avec des problématiques de développement et de data science
Être en contact direct avec le top management de l’entreprise
S’épanouir au sein d’une structure pérenne avec un esprit startup, reconnue pour son innovation
Salaire et avantages :
45-55k€
Contrat en CDI
Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !
Si vous souhaitez avoir d’autres informations sur cette opportunité je vous invite à me contacter également."
Issy-les-Moulineaux (92),,,INGÉNIEUR BIG DATA,Pandores,- Issy-les-Moulineaux (92),"Pand’Ores recherche un Ingénieur Big Data

Activités :
Conception et architecture de solutions informatiques Big Data
Développements informatiques et intégration des technologies Big Data au sein d’un ou plusieurs projets
Veille technologique

Compétences techniques
Solides compétences en Java, Python, Scala et Linux
Connaissances des technologies Big Data : Hadoop, Spark, Storm, Flink ou frameworks équivalents
Connaissances des systèmes de messagerie distribués kafka, nifi..
Connaissances des Bases de Données (MongoDB, Cassandra, OrientDB ou PostgreSQL, Oracle)

Aptitudes personnelles
Bon niveau d’autonomie
Bonnes qualités de communication et de pédagogie
Bon niveau rédactionnel, esprit de synthèse
Bac+4/5"
Paris (75),"Temps plein, CDI",,Data Engineer Senior H/F,Alchimie,- Paris (75),"Qui sommes-nous :
Alchimie est une société technologique et marketing qui possède un catalogue de près de 40 000 heures de contenus audiovisuels grâce à la confiance de centaines d’ayants-droit tels que Mediawan, Arte Sales, ITV, Turner, Viacom, ZDFe. Ces contenus sont distribués et valorisés à travers différentes plateformes media, opérateurs télécom, constructeurs de TV connectées et retailers mondiaux.
Grâce à ses 120 experts, Alchimie permet aux créateurs/producteurs de contenus vidéo de générer de nouveaux revenus et de rencontrer de nouvelles audiences.
Elle offre également l’opportunité aux influenceurs, célébrités ou media, de faire découvrir leur univers auprès de leurs communautés via la création de leurs propres Channels.
Pour accompagner notre fort développement autour de nos nouveaux projets de distribution de contenus digitaux, nous recherchons un Senior Data Engineer !
Votre mission :
Au sein de l’équipe Data et en lien avec le Data Architect, votre mission consiste à prendre le lead technique du développement.
Vos missions seront les suivantes :
Guider les best-practice de développement, testing et déploiement du code
Proposer, tester et choisir avec le Data Architect les solutions techniques de demain
Mettre en place des solutions de Data Quality et Data Lineage pour préparer les futures uses cases de Machine Learning
Plus précisément, vous serez en charge de :
Préparer avec l’équipe le passage vers une plateforme Cloud Hybride alimentée en temps réel
Améliorer l'ingestion des données provenant aussi bien du “bus de donnée” de l'entreprise (event sourcing) que de fichiers de logs
Intégrer les données externes des partenaires et clients via un bridge d’events et ETL cloud
Mettre en place une couche API Graph-QL et un stream d’évènements en output pour faciliter le feedback vers les systèmes des production (sites, produits, applications)
Votre profil :
De formation supérieure, universitaire ou école d’ingénieur, vous avez une expérience d’au moins 5 ans sur un poste de Data Engineer dans une entreprise du digital dynamique, idéalement en startup ou scale up avec des enjeux de données importants.
Vous avez l’attitude et l'expérience du tech lead (gestion d’une base de code, versioning, refactoring, déploiement).
Vous maîtrisées SQL, Python et Spark, et vous avez une culture informatique importante (design patterns, architecture du code, architectures data, data flow design).
Vous avez une expérience d’environnement cloud data, en préférence sur AWS.
Vous maîtrisez ces outils :
Airflow
Kafka
DBT
Stitch
AWS Glue
Snowflake
Databricks
Vous êtes force de proposition, faites preuve d’autonomie et de curiosité, vous avez envie d’apprendre des nouvelles technologies et surtout envie de contribuer activement au succès d’Alchimie.
La pratique de l’anglais est nécessaire pour ce poste.
Si vous voulez participez au développement d’une expérience audiovisuelle différenciante, rendez-vous sur Welcome to the Jungle
------------------------------------------------------
Alchimie, c'est un environnement digital très dynamique, c'est un lieu de travail accueillant et stimulant, une rémunération attractive, une participation aux bénéfices, 15 jours de RTT, un restaurant inter-entreprises, une couverture santé et une très belle équipe.
Ce poste, situé à la Porte d'Aubervilliers, est à pourvoir immédiatement en CDI.
Si vous vous sentez prêt à développer votre passion tout en innovant, dans un environnement technique hyper stimulant, postulez vite en nous transmettant votre CV !
Vous pouvez également trouver Alchimie sur LinkedIn, Facebook ou www.alchimie.com.
Avantages :
Participation au transport
RTT
Statut : Cadre
Job Types: Full-time, Permanent
Experience:
development: 7 years (Required)"
Paris (75),CDI,,Data Engineer (H/F),Happn,- Paris (75),"Description du poste
Environnement
Vous aimez exploiter plus de 100 To de données sur des technologies de Big Data innovantes telle que BigQuery ?
Vous aimez faire parler la donnée, lui donner du sens, la rendre compréhensible de tous ?
Vous souhaitez avoir un impact sur l’architecture data chez happn et mettre à disposition des analystes et data scientistes une plateforme robuste, performante et facile d’exploitation ?
Rejoignez l’équipe data centralisée de 15 personnes, regroupant data ingénieurs, data analystes, BI ingénieurs, et data scientistes.
Votre rôle en tant que data ingénieur sera de faire évoluer la plateforme data et maintenir sa stabilité et son usage.
Pipelines de données
Vous mettrez en place les flux de streaming (Apache BEAM/Dataflow) ou batch (Apache Airflow/Cloud Composer) permettant de collecter les données nécessaires pour des besoins de dashboarding, d’analyses et A/B tests;
Vous récolterez les événements envoyés par le back-end, le front-end et des APIs externes;
Vous mettrez à disposition les sources données au sein de BigQuery tout en garantissant son accessibilité et sa cohérence.
Traitements de la donnée
Vous nettoierez la donnée collectée (déduplication, normalisation ...etc.), transformerez la donnée de sa forme brute à sa forme fonctionnelle en appliquant les règles métier et assurerez les tests unitaires;
Vous mettrez en place les bonnes pratiques pour le stockage et le requêtage de la donnée;
Vous serez garant de l’orchestration du calcul des données (monitoring quotidien de jobs, reprise sur erreur, alerting, SLA non respecté ...etc.) .
Evolution de la plateforme data
Vous serez responsable de faire évoluer la plateforme data afin d’améliorer sa robustesse, d’optimiser ses coûts et ses performances;
Vous serez l’interlocuteur privilégié pour mettre en place l’architecture permettant de lancer la data science chez happn (projection de revenu, lifetime value, scoring des users, ciblage intelligent pour des campagnes d’emailing, ...) en collaboration étroite avec l’équipe back-end;
Vous ferez de la veille technologique permettant de tester de nouvelles fonctionnalités, nouveaux outils améliorant l’efficacité de l’équipe data et la fiabilité des données;
On attend de vous que vous soyez force de proposition dans l'équipe, qui est toujours à la recherche d'idées nouvelles !
Profil recherché
Formation
Vous avez été formé(e) en école d’ingénieur ; Formation supérieure Bac+4 / Bac+ 5 ;
Vous avez un minimum de 2 ans d’expérience en tant qu’ingénieur data ;
Vous êtes extrêmement rigoureux(se), avec un excellent sens du service et un bon relationnel;
Vous avez un très bon niveau en python/java et SQL ; une expérience sur BigQuery est un plus;
Vous êtes une personne technique avec une forte sensibilité à l’analyse de données et la BI;
Vous êtes curieux et avez une forte appétence pour les chiffres;
Vous communiquez clairement et faites preuve d’un esprit de synthèse ;
Notre environnement technique : BigQuery, Google Cloud Composer, Google Cloud Dataflow,Google Cloud Pub/Sub, Tableau, Apache BEAM, Apache Airflow, Python 3, Java 8, SQL 2011.
Déroulement des entretiens
Entretien avec l'équipe
Test
Entretien Manager et DRH"
Levallois-Perret (92),CDI,,Data Engineer Confirmé - Big Data F/H,Micropole,- Levallois-Perret (92),"Groupe international spécialisé en conseil et solutions innovantes dans le domaine de la Data et du Digital. Aujourd'hui, plus de 1250 experts métiers et ingénieurs accompagnent nos clients sur 3 offres complémentaires : Digital Experience, Data Intelligence & Performance et Data Gouvernance & Architecture.
Depuis 30 ans, nous sommes tous animés par une volonté commune : aider les entreprises à se transformer en tirant le meilleur parti de l'innovation.

Micropole recrute des Data Engineers F/H :
Vous interviendrez sur différentes missions en tant que Consultant(e) :
L’étude, l’analyse et le cadrage des besoins métiers
Analyse des données sources afin d’identifier les cas d’usages métiers
Conception et mise en place de solutions résilientes et sécurisées (Data Lake, systèmes temps-réels,…)
Migration fiable et maitrisée des données vers les nouveaux environnements Cloud
Mise en place en œuvre des outils de monitoring, suivi et visualisation (PowerBi, Tableau, QlikView, …)
Sélection, évaluation et déploiement des modèles prédictifs en s’appuyant sur les outils standards du marché (SageMaker, DataBricks…)
Veille technologique pour être à la pointe sur les solutions cloud & Data

Votre profil :
Diplômé(e) d'une école d'ingénieurs ou d'un Master 2 en Informatique ou équivalent, vous avez une expérience significative sur des projets Data : architecture, traitement ou analyse de données
Vous maitrisez au minimum un des langages de programmation suivants : Python, Scala, Java, R
Vous avez des bonnes compétences dans l’architecture des données, bases de données, modélisation
Vous êtes passionné(e) par le Cloud et le Big Data
Une connaissance des briques/services Cloud Providers publiques (Microsoft Azure, AWS…) est un vrai plus !
Vous êtes passionné(e),curieux(se), autonome et à l’écoute
Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale
Depuis 2015, Le Groupe Micropole est labellisé Happy Trainees et happy at Work for Starters.
En 2018, le Groupe est une nouvelle fois propulsé dans le top 10 des entreprises françaises où il fait bon de démarrer sa carrière !

#LI-SA1"
Paris 10e (75),,,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong

Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris 10e (75),,,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community

Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Neuilly-sur-Seine (92),CDI,,CDI – Data Engineer Java,One2Team,- Neuilly-sur-Seine (92),"La Société One2Team:
Spécialiste reconnu dans l’édition de solutions SAAS de pilotage de projets nouvelle génération, One2Team sécurise le succès opérationnel de projets complexes et stratégiques en apportant une solution innovante à ses utilisateurs.
Référencé comme ‘Visionnaire’ des solutions PPM Cloud.
Présents à l’international, One2Team, c’est plus de 20 000 utilisateurs dans plus de 50 pays, et 130 milliards de budgets de projets gérés via notre plate-forme.
One2Team, c’est aussi :
L’intégration des meilleures pratiques de développement et des toutes dernières technologies de pointe.
Une Société en plein essor, créée en 2000, basée en France et à San Francisco et attachée fortement à son esprit « startup ».
Une équipe pluridisciplinaire portée par des valeurs communes, de la passion, de l’agilité et de l’énergie.
Une société attentive au ‘vivre ensemble’ et à la convivialité comme en témoigne la mise en place depuis quelques années d’un comité ‘SSB’ (Se Sentir Bien) et d’ateliers de partage de compétences.
Des locaux, reflets de notre culture : « L’atelier » à Paris et « The Kitchen » à San Francisco.
Poste et missions:
Concevoir des algorithmes.
Modéliser des fonctionnalités.
Prototyper de nouveaux systèmes d’analyse et de traitement de données.
Développer une architecture Big Data.
Épauler la R&D dans ses décisions techniques.
Vous évoluerez dans une équipe de technophiles chevronnés qui feront leur maximum pour partager avec vous leur passion et vous travaillerez dans un environnement avec de très fortes volumétries de données.
Environnement : Kafka/Storm/Rest Service/TDD Development/Méthode Agile/GIT/MAVEN
Profil recherché:
Vous êtes diplômé(e) d’écoles d’ingénieur et développez en Java8 et/ou Python.
Vous maîtrisez les concepts de modélisation (design patterns).
La connaissance de Cassandra, Elastic Search, Hadoop serait un plus.
Vous contribuez à des communautés et vous allez régulièrement à des Meetups.
Vous aimez les challenges ambitieux, l’esprit d’équipe est important pour vous."
Paris (75),CDI,45 000 € - 60 000 € par an,Data Engineer - Possibilité Remote,Sept Lieues,- Paris (75),"Entreprise leader européen sur le marché de la data électorale qui développe des outils afin de comprendre et convaincre l'opinion à un niveau local.
LE POSTE / LES MISSIONS
Le data engineer participera à la mise en place et l'enrichissement du pipeline du traitement de donnée.
Intégrant une équipe pluridisciplinaire (produit/dev/data) dans le but de développer les produits. Les missions sont les suivantes :

Travail en collaboration avec les data-scientist afin de mettre en production de manière robuste et scalable des algorithmes de NLP et de machine learning
Conception, Implémentation et automatisation en Python
Contribution à la conception et implémentation d'une architecture de traitement et de stockage des données performante et résiliante
Aide à l'architecture des données afin qu'elles soient exploitable par l'équipe tech-product
Participation à la mise en place de l'infrastructure cloud

80% Conception et implémentation python / data
20% Infra / devops
PROFIL RECHERCHÉ
Bac +5 ou équivalent en informatique. Vous avez un minimum de 2 ans d'expérience professionnelle avec idéalement une première expérience de Data Engineer sur des architectures complexes.
Vous avez déjà travailler sur des problématiques de traitement de gros volumes de données (architecture de données, collecte, transformation...)

Vos compétences techniques sont les suivantes :
Python et son écosystème
Conception et implémentation de micro-services / API
Expérience sur des use-cases qui impliquent la manipulation de donnée non structurée
Base de données
Optimisation et performances BDD relationnelles

Les + :
Connaissances en Infra / DevOps
Conception et implémentation de systèmes de collecte de donnée (scraper/crawlers)
Architecture Serverless"
Montrouge (92),CDI,,Data Scientist Confirmé H/F,CA CIB FRANCE,- Montrouge (92),"Crédit Agricole CIB est la banque de financement de d'investissement du groupe Crédit Agricole, 12e groupe bancaire mondial par les fonds propres Tier1 (The Banker, juillet 2018). Près de 8300 collaborateurs répartis en Europe, Amériques, Asie-Pacifique, Moyen-Orient et Afrique du Nord, accompagnent les clients de la Banque dans la couverture de leurs besoins financiers à travers le monde. Crédit Agricole CIB propose à ses clients grandes entreprises et institutionnels une gamme de produits et services dans les métiers de la banque de marchés, de la banque d'investissement, des financements structurés, de la banque commerciale et du commerce international. Pionnier dans le domaine de la finance Climat, la Banque occupe aujourd'hui une position de leader sur ce segment avec une offre complète pour l'ensemble de ses clients.

Pour plus d'information : www.ca-cib.fr

Twitter: https://twitter.com/ca_cib
LinkedIn: https://www.linkedin.com/company/credit-agricole-cib/
Référence
2019-38671
Date de parution
18/05/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Organisation / Qualité
Type de contrat
CDI
Poste avec management
Non
Cadre / Non Cadre
Cadre
Missions
La mission de l''équipe “Innovation & Transformation Digitale” est de supporter la banque dans la définition et l’implémentation de sa transformation sur les 4 piliers suivants:
l’Innovation Disruptive,
l’Expérience Client,
l’Expérience Collaborateur,
l’Excellence des Processus.
A ce titre, l'équipe ""Innovation & Transformation Digitale"", directement rattachée à la Direction Générale, doit constituer et déployer des offres de service autour des expertises Digitales : Data/AI, Canaux, API, Blockchain, RPA, …
Vous intégrerez l’équipe Data Management & Analytiques (DMA) au sein de Innovation & Transformation Digitale en charge de l'organisation de la gouvernance des données et de l'accompagnement des métiers dans leur stratégie Data.
Sur le sujet analytique, cette équipe est composée de chef de projet, de data scientistes, et recherche un data engineer.
L’objectif principal de l’équipe est de permettre l'émergence de nouveaux business models ou l'amélioration de l'efficacité opérationnelle, notamment grâce à l'utilisation de la data science et de l’intelligence artificielle et de mettre en place la gouvernance et l’organisation adéquate pour la réalisation et l’industrialisation des projets d’intelligence artificielle lié à la data science au sein de la Banque.

Descriptif de la mission
En tant que Data Scientist confirmé, vous serez amené(e) à vous inscrire comme référent data science et à rapidement vous inscrire comme véritable relai auprès des data scientists de l’équipe :

Afin d’accompagner les chefs de projets et les différents métiers et fonctions de la banque dans leur montée en compétences, leurs réflexions, PoC / projets data et industrialisation des projets, vous apporterez votre expertise data et analytique.
Vous assurerez le suivi technique des travaux des data scientists stagiaires et juniors de l’équipe et accompagnerez leur montée en compétences ainsi que l’animation et le suivi de leurs activités
Vous participerez à la définition et mise en place et amélioration continue des processus, outils de l’équipe data analytique en vue d’en optimiser la performance et l’efficacité
Vous participerez au processus de recrutement (interne / externe) des ressources de l’équipe
Vous participerez à des problématiques de transformation vers la data driven company
Vous animerez et Participerez à la veille scientifique et innovation sur le sujet de l’intelligence artificielle
Vous animerez une communauté de compétences Data Science au Sein de la Banque et contribuerez à la communauté d’innovation smart data.
Vous serez également en charge de la réalisation de cas d’usages data sciences en réponse à une problématique opérationnelle remonté par un département de la banque et serez notamment amené(e) à intervenir sur l’ensemble des étapes d’un projet data sciences : étude d’opportunité et cadrage du besoin, formalisation de l’approche et feuille de route du projet, suivi et reporting d’avancement, Proposition e
Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 92 - Hauts-De-Seine
Ville
Montrouge
Critères candidat
Niveau d'études minimum
Bac + 5 / M2 et plus
Formation / Spécialisation
Ecole d'ingénieur
Formation supérieure dans le domaine du traitement de l'information, de l'ingénierie statistique et de l'économétrie
Spécialisation :Data science , Machine learning , Statistique
Niveau d'expérience minimum
6 - 10 ans
Expérience
Vous avez plus de 7 ans d'expérience dans le domaine de la data et avait démontré un intérêt pour le métier de data scientiste au travers d'une première expérience de 3 ans minimum.
Compétences recherchées
Capacité à comprendre des enjeux et problématiques business et à en déduire des axes d'optimisation grâce à la Data.
Autonomie, curiosité et réel intérêt pour les sujets IA et Data
Grande rigueur, capacité d'analyse, réactivité, sens critique
Capacité à synthétiser rapidement et à proposer des solutions innovantes
Capacité à collaborer et à être orienté résultats
Leadership et bonne relation client
Outils informatiques
Connaissances indispensables : Python de préférence à R, SQL, Power BI, Git, GitLab et connaissances data mining, Machine Learning et/ou text mining, NLP, gestion de projet informatique (agile si possible) et processus de tests et déploiement
Des connaissances Docker, Java, Bases No SQL, écosystème digital et data, connaissances d'un ou plusieurs métiers de la BFI, architecture applicative et technique seraient un plus
Langues
anglais courant"
Paris (75),"Temps plein, Freelance / Indépendant",,Data scientist Freelance– Secteur bancaire,LFZPartners,- Paris (75),"ASAP, nous recherchons un data scientiste pour le secteur bancaire (pôle gestion des données)
Cadrage des cas d’usage et gouvernance des projets
Cadrage des cas d’usage
Compréhension fine des enjeux métier et des problématiques adressées
Modélisations des solutions et scénarios type de leurs applications finales
Estimations des gains envisagées (ROI, productivité, etc.)
Inventaires des bases de données impliquées dans le cas d’usage
Scorings a priori des cas d’usage par la valeur métier et la faisabilité du projet
Gouvernance des projets
Constitutions des groupe projet : product owner, data analyst, data engineer
Comitologies des projets : comité de projet et de pilotage, nombre de comité, fréquence
Calendriers de mise en œuvre : phases, nombre d’itérations, durée des phases, pré-industrialisation
Livrable attendu
Fiches projets, documentations sur les données utilisées (sources, définition, …)
Supports de présentations pour les comités de pilotage
Calendriers de mise en œuvre
Préparation des données impliquées dans les cas d’usages
Extraction et entreposage des données
Demandes d’autorisation pour extraction des données (RSSI, Métier, DPO, DSI…).
Mise en place « d’environnements analytiques » pour la préparation des données : serveur de stockage, outillage de préparation, outillage de visualisation, habilitations à l’environnement de travail, etc.
Extractions et dépôts des données
Préparation des données
Profiling des données déposées (complétude, unicité, cohérence, fraîcheur…)
Analyses des données : analyses factorielles, réduction des données corrélées
Validation des définitions sur les données (Métier vs IT)
Préparation des jeux de données à analyser puis modéliser (analytical dataset)
Livrable attendu
Documentations sur le profiling des données dictionnaires des données, statistiques descriptives et méthodologies pour la constitution des analytical dataset.
Construction des modèles mathématiques et des visualisations correspondants aux cas d’usage
Analyses exploratoires et visualisations des données
Construction des variables à expliquer (cibles)
Construction des variables explicatives
Construction de datavisualisations (tableaux de bords, cartes, …) adaptées et favorisant les taux d’adoption des modèles explicatifs et des applications finales
Entrainement des modèles prédictifs
Préparation des échantillons pour apprentissage et test
Mise en concurrence de plusieurs modèles prédictifs (random forest, SVM, gradient descent, …)
Sélection des meilleurs modèles prédictifs. Lee client valide les modèles sur la présentation des métriques de performance (courbes, ROC, AUC et courbes lift).
Validation des modèles prédictifs
Optimisation des critères de précision et de robustesse
Matrice de confusion et métriques de performance (courbes ROC, Lift, …)
Livrable attendu :
Datavisualisations, modèles prédictifs
Documentations sur les méthodologies mises en œuvre
Documentations sur les métriques de performance des modèles
Comités de validation avec le Métier
Le consultant travaillera en étroite collaboration avec les équipes du DataLab et de la DSI.
Compétences
Solides compétences en programmation informatique (Python, R…) et une bonne compréhension des structures de données
Expertise en algorithmie et gestion des bases de données (Hadoop, NoSQL, Cassandra…)
Maîtrise de l’architecture des bases de données décisionnelles (data warehouse)
Mathématiques appliquées : construire des algorithmes pour améliorer les résultats de recherches et de ciblage
Statistiques : capacité à réaliser des analyses prédictives et statistiques à partir des différentes bases de données
Connaissances juridiques et réglementaires de la gestion des données
Capacité à proposer une stratégie et des choix de scénarios alternatifs adaptés
Expérience avérée dans la gestion de projets d’analyse avancée des données et de projets de datavisualisations pour des organisations du secteur public
Qualités relationnelles, capacité à animer des réunions, à présenter en comité de direction ou en public et capacité à gérer une communication adaptée dans la conduite du changement
Qualités rédactionnelles, esprit d’analyse et de synthèse, et aptitude à travailler en mode projet.
Durée
4 Mois avec possibilité d’extension
Tarif :
600 e par jour ( A négocier pour les consultants plus expérimentés)
Type d'emploi : Temps plein, Freelance / Indépendant
Expérience:
data scientist secteur bancaire: 3 ans (Souhaité)
Télétravail:
Temporairement en raison du COVID-19"
Paris (75),,,Data engineer F/H,Saagie,- Paris (75),"Data engineer F/H
Paris
CDI
Postuler
Retour
Data engineer F/H
Saagie recrute !
À propos
Saagie (which means Heron in Japanese) is a french startup of 75 people with offices in Paris, Normandy (Rouen) & New York City.
Saagie provides a ready to go DataOps Orchestrator.
Saagie is leading the way in big data analytics by providing DataOps Orchestration that accelerates and operationalizes analytic projects. Their mission is to unify people, process and technology enabling organizations to deliver projects from raw data to production in weeks. Saagie delivers unmatched time-to-value, is “open by design” with isolated containers, strong network engineering as well as transparent security and governance bringing trust, privacy, audit and traceability to analytic projects. Saagie includes best-in-class integration with open source and commercial technologies to support today’s Big Data/AI and analytic use cases enabling global companies to realize value from their data intensive initiatives. Ultimately, Saagie provides a Plug and Play Orchestrator for DataOps that accelerates the distribution of Artificial Intelligence (AI) and Big Data to give companies a competitive advantage across industries.
Descriptif du poste
Nous recherchons notre Data Engineer pour rejoindre notre team service !
MISSIONS :
Travailler sur des projets bigdata en collaboration avec les autres membres de l'équipe
Acquérir, extraire, transformer, gérer et manipuler de larges quantités de données avec notre DataFabric
Accompagner, conseiller nos clients et partenaires
Préparer et donner des formations sur les technologies Big Data
Accompagner la force commerciale et vulgariser les technologies de Saagie auprès de nos clients
Participer au cadrage des projets et à l’élaboration de propositions d’accompagnement
Vous rejoindrez une équipe pluridisciplinaire composée de développeurs expérimentés, de data scientists et de data engineers.
Le télétravail est tout à fait possible de façon occasionnelle !
Profil recherché
Une expérience sur un/des projets Big Data d'envergure (clusters conséquents, architecture temps réél critique...)
Bonnes connaissances de Hadoop et son écosystème (Spark, Hive, Impala, Parquet, ORC, Sentry ...)
Bonnes connaissances en base de données (MySQL, SQL Server, Oracle, MongoDB par exemple) et en SQL
Langages : Scala et/ou Python
Une expérience sur de la récupération/traitement de données en temps réel (Kafka, Spark Streaming, Flink ...) serait un plus
La connaissance d'un outil d'orchestration (Mesos, Kubernetes) serait également appréciée
Intéressé(e) par le Machine Learning (car collaboration avec des data scientists)
Curieux(se)
Autonome
Avec le sens du service (accompagnement, support, formation client)
Process de recrutement
Call puis entretien avec notre Talent Acquisition Manager
Entretien avec un-e Manager de la team Service
Entretien technique sur les différentes technologies Big Data
Une immersion au sein de l'équipe pourra également être mise en place (1/2 à 1 journée)
Informations complémentaires
Type de contrat : CDI
Lieu : Paris, France (75008)
Niveau d'études : Bac +5 / Master
Postuler"
Paris 8e (75),CDI,,Data Engineer – CDI - F/H,Margo,- Paris 8e (75),"En rejoignant Margo, vous pourrez par exemple intervenir sur l’un de nos projets de mise en place d’un datalake au sein d’un grand acteur en Asset Management.

L’objectif est d'assurer la distribution de la donnée pour avoir une couche de distribution, recentrer le datalake autour de la data afin de proposer aux Data Scientists un bon environnement de travail.

Vous aurez ainsi l’opportunité d’évoluer dans un environnement data science et au sein d’une équipe d’experts, travaillant en méthodologie agile.

Stack techno :
Hadoop/Cloudera

Spark / Scala / Python / Java

Cloud/Azure

Impala; Hbase

En rejoignant l’équipe comme Data Engineer, vos missions seront :

Développer en mode agile les usages métier reposant sur le Datalake Hadoop.
Identifier et modéliser des données nécessaires à l'usage.
Sélectionner le stockage le plus adapté à l'usage parmi les technologies de l'écosystème Hadoop
Développement en Spark et Scala des traitements de transformation et de production de données.
Développement d'API RESTful (Scala / Play) permettant l'accès aux données produites.
Amélioration continue et refactoring de code.
Problem solving/ troubleshooting.
Profil recherché Etre collaborateur chez Margo c’est aussi...

...devenir acteur de notre transformation ! Vous êtes ainsi invité(e) à vous impliquer dans la vie de l’entreprise à différentes échelles : faites-vous reconnaître en tant qu’expert en rédigeant des articles techniques pour notre blog et pour la presse spécialisée, représentez Margo lors de forums écoles, conférences et Meetups, recrutez vos futurs collègues en proposant des cooptations, montez en compétences grâce à des retours d’expériences et des formations régulières,...

Vous êtes un(e) futur(e) Margo si :
Vous êtes Ingénieur ou de cursus Universitaire Bac + 5

Vous êtes curieux

Vous aimez coder

Vous êtes passionné(e) par l’informatique

Vous parlez anglais
Entreprise Vous êtes passionné(e) par la tech ? Vous souhaitez intégrer une petite équipe, très outillée et proche du business ? Rejoignez Margo en tant que Data Engineer et intégrez une équipe à la pointe des nouvelles technologies sur l’un de nos projets en Haute Performance IT !

Nous sommes un cabinet de conseil en transformation digitale à taille humaine, spécialisé dans les problématiques à forte complexité technologique. Notre objectif est d’offrir à nos collaborateurs les projets les plus intéressants, présentant une forte complexité technologique (multithreading, temps réel, optimisation des performances, grosse volumétrie de données…) afin de les faire évoluer et monter en compétences rapidement."
Paris (75),,,Data Engineer,Content Square,- Paris (75),"Contentsquare is a dynamic SaaS technology startup based in Paris seeing explosive growth following $122million of funding. Recognised by Gartner as one of the four most innovative ecommerce technologies in the world, and Wired Magazine as one of Europe’s hottest startups, Contentsquare is a Digital Experience Analytics Platform helping brands to create better experiences online.
We work with 600+ clients globally including Unilever, L'Occitane, GoPro, Hertz, Avon and Club Med to empower their teams with behavioural insight.

As a Data Engineer, you will join a team of passionate and talented developers, designing and developing a new data architecture. Do not hesitate to check on our YouTube video to see what it's like to be a Data Engineer at ContentSquare!

We collect several billions events per day, and query hundreds of terabytes in real time.

Your daily work will consist of:
Designing efficient architectures to store and analyze petabytes of data
Leading large scale projects and mentoring other developers
Implementing complex acquisition workflows
Thinking of smart data formats to serve the functionalities of the product, while minimizing the cost
Developing tools to help data-scientists
....by using some open source technologies such as Kafka, Spark, Akka, ClickHouse, Elasticsearch, etc.

With a minimum 2-3 years of experience, you are proficient in either Scala or Java, and ideally several other backend languages. You practice or have an interest in functional programming and seek to develop your skills in Scala.

Kafka, Akka, Spark, AWS… You have had the chance to discover or work with these big data technologies. Ideally, you have some experience on a wide range of databases and you are interested in streaming. You would like to challenge yourself developing distributed infrastructure with a real time and data-intensive environment. You would like to share your skills and take part in technical choices.

Why join ContentSquare’s Data Engineering team?
You are looking for a variety of cool projects, which will revolutionize analytics and UX with big data
You are interested in contributing to open source projects as well as investing in the tech scene by organizing meetups and presenting at conferences
You are looking for an environment where you’ll have the occasion to be a technical referent on your areas of expertise, all while taking responsibilities on strategical corporate axes.

If the above sounds like a great fit to you, then join us at ContentSquare and be a part of this awesome adventure. With tech teams that are as passionate as you are, cultivate knowledge sharing and strive for team cohesion. Through hackathons, and cross team innovation days, we are committed to innovate towards tomorrow’s user experience.

You’ll also have: a choice of PC or Mac, flexible working hours, remote days; soccer, handball, yoga, and many other activities; after work beers provided every Friday, monthly parties…and a very friendly team! Join our adventure where together we go beyond ourselves and conquer the next big challenge!

As well as the opportunity to have a tangible impact on the success of the global business here’s what else we offer:
Plenty of opportunities for training and development
Flexible approach to working hours and holidays
Attractive people care approach with good health insurance
Fun office culture and strong team spirit, with beers every Friday and quarterly parties
Regular breakfasts and fruit in the office each week
25 days PTO + 10 days RTT
Many benefits via our CSE such as reductions on gym membership and leisure activities

Does this sound like it was written for you? Excellent! Please apply and let’s explore this together."
Paris (75),CDI,,Data Engineer CRM,AI & DATA,- Paris (75),"· Analyse des besoins clients et formalisation des cas d’usages
· Participation à la conception et à la réalisation de solutions Big Data
· Développement de solutions d’ingéestion de données depuis des sources multiples pour les déverser dans un Datalake : Nifi, Sqoop, Kafka…
· Passage de la donnée brute à la donnée propre (inférer les schémas de données, nettoyer, normaliser et publier les données)
· Consolidation des données au fur et à mesure de leur alimentation récurrente dans le Data Lake.
· Exploitation des résultats pour atteindre la finalité business : exposition de business view, réintégration des résultats dans le SI, service de scoring
· Mise en place et garantie du respect d’un processus de qualité sur l’ensemble du cycle de développement d’industrialisation (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc…)
· Industrialisation des pipelines d’analyse et de Machine Learning
Les compétences techniques attendues :
· Développement big data : Spark, PySpark et/ou Scala, Hadoop, Kafka Spark, Streaming / Storm, Hbase, MongoDB, Cassandra, ELK…
· Cycles de développements et outils associés (intégration et déploiement continu avec Git, Jenkins, Sonar, Nexus…)
Les connaissances complémentaires appréciées :
· Distribution Hortonworks, Cloudera ou MapR
· Outils de DataViz
· Librairies de Machine Learning
· Création d’API
Les qualités requises :
· Curiosité et soif d’apprendre
· Capacité d’adaptation et d’innovation
· Force de proposition
· Travail en équipe
Type d'emploi : CDI
Expérience:
data engineer crm ou similaire: 4 ans (Souhaité)"
Paris (75),"Temps plein, Freelance / Indépendant",500 € - 550 € par jour,BLU_Data Analyst confirmé/ Senior / Freelance,Bluescale,- Paris (75),"Data Analyst confirmé/ Senior

Dans le cadre d’une réponse à un besoin de notre client, je suis à la recherche d’un Data Analyst ayant les compétences ci-dessous :

Proposer des solutions techniques performantes et innovantes.
Expérience sur les ETL (Talend, informatica)
Expérience sur PowerBI (avec DAX)
Expérience sur technologies BIGDATA/Hadoop
Expérience sur les outils de reporting ou de visualisation de données comme Tableau Software
Maîtrise des langages de programmation suivant: Scala, Python, Java, Shell et requêtes HQL;
Expérience dans le développement ou optimisation de requêtes SQL.
Expérience dans la préparation et la réalisation de recette (rédaction des cahiers de recette, réalisation des jeux de données, de recette/tests fonctionnels, tests techniques, d’assemblage, de bout en bout et de non régression, ),
Avoir développé en mode Agile/Scrum Connaissance des outils DEVOPS (Jira, Jenkins, Gitlab / Github)
Missions :
Développement script SQL dans PostgreSQL :
 1/ la modélisation générique (création de Database, des tables et de leurs champs ainsi que les liens entre les tables si besoin).
 A partir de la modélisation mise en place, mettre à jour par Script le modèle de données sur la base des échanges réalisées avec les équipes métiers lors des ateliers.

 Extraire, transformer et charger les données dans les nouveaux modèles BI créés pour accueillir les données des rapports

 Réaliser le calcul des indicateurs complexes en Python/Script Shell afin d’alimenter la base de données et optimiser le temps de chargements des rapports complexes

Développement et mises à jour dans PostgreSQL/Datalake

 Développement de nouveaux rapports sur PowerBI avec les données et modèles nouvellement créés avec les ETL

 Développer le connecteur permettant d’alimenter la base Elasticsearch du DataLake IT.

 Développer les procédures Get et Put sur la base Elastic Search du DataLake

 Comprendre le fonctionnement Datalake IT (Hadoop, Hive) et être capable d’intégrer des données dans cette base."
Montrouge (92),CDI,,Data Analyst H/F,Crédit Agricole Leasing & Factoring,- Montrouge (92),"Crédit Agricole Leasing & Factoring (CAL&F) est un acteur majeur du crédit-bail et de l'affacturage en France et à l'international.

Filiale experte du groupe Crédit Agricole, CAL&F propose des financements spécialisés destinés aux entreprises, aux professionnels, aux agriculteurs et aux collectivités locales.

Présent dans 9 pays en Europe et au Maghreb, CAL&F s'appuie sur les réseaux bancaires du groupe Crédit Agricole (Caisses régionales de Crédit Agricole, LCL et Crédit Agricole Corporate and Investment Bank), sur des partenaires non bancaires (constructeurs, distributeurs de matériel, courtiers et assureurs crédits).

CAL&F compte 2 360 collaborateurs dont 1 230 à l'international et gère 21,5Md€ d'encours (données à fin 2017).

CAL&F s'engage à promouvoir la diversité et l'égalité des chances dans le domaine de la mixité sociale, l'égalité professionnelle homme/femme et l'intégration professionnelle des personnes en situation de handicap.
Référence
2020-46238
Date de parution
28/03/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Systèmes d'information / Maîtrise d'Ouvrage
Type de contrat
CDI
Date prévue de prise de fonction
01/03/2020
Poste avec management
Non
Cadre / Non Cadre
Non cadre
Missions
Au sein de la Direction de la Stratégie, du Marketing et de la Communication et rattachée directement au Directeur de projet, CAL&F recrute un Lead data Analyst dans le cadre de la refonte de l’outil Batica.
Batica est l’outil utilisé au quotidien par l’ensemble du Groupe Crédit Agricole. Il propose plus de 6 000 champs de données indispensables aux différents métiers du Groupe dans le cadre des processus commerciaux, dans les ciblages marketing ou encore dans les suivis juridiques.
Batica en quelques chiffres :
16 millions de données consultées chaque année
18 000 utilisateurs actifs par mois
Plus d’une trentaine de SI connectés à la plateforme
Face aux enjeux liés aux technologies de la Data, aux besoin d’informations et de mise en conformité des dossiers clients toujours plus pregnants au sein d’un environnement bancaire, Crédit Agricole Leasing & Factoring a lancé un projet ambitieux de refonte de son offre Batica avec pour objectifs de :
1- Moderniser le socle technique pour se doter d’une architecture « data-centric » appuyé sur le datalake de Crédit Agricole Leasing & Factoring
2- Améliorer le parcours utilisateur et l’adéquation des services rendus avec les besoins métiers
3- Enrichir la data en se basant sur des sources open data, du web scrapping et de nouvelles sources de données
4- Utiliser cette mine de données pour créer des services et de la donnée à valeur ajoutée pour les métiers bancaires
C’est dans le cadre de cette refonte que Crédit Agricole Leasing & Factoring souhaite constituer une équipe data qui aura pour rôle d’être garant de la donnée Batica, de créer, d’administrer et d’enrichir la donnée afin de constituer une offre Batica qui réponde aux enjeux des métiers du Groupe Crédit Agricole.
Le data analyst aura un rôle prépondérant à jouer que ce soit dans la phase projet (pilotée en mode agile) puis ensuite dans la vie et le développement de l’offre Batica.

Dans le cadre du projet :
Définir les règles de gestion pour le croisement de la donnée entre les différents fournisseurs de données externes (Open data, Infogreffe, banque de France.) et préparer l’intégration des données au datalake (création des bases de données)
Étudier la fiabilité des règles de gestion établies
Définir les nouvelles données et nouveaux croisements de données à créer pour mettre en place des outils de data visualisation et de géolocalisation par exemple
Etre le garant de la data Batica, et le pivot entre les équipes techniques et métiers sur ces sujets
Créer et enrichir le catalogue de données / code de la donnée, et mettre en place des outils de data visualisation de suivi de la qualité des données
Participer à la constitution des premiers services à Valeur Ajoutée pour les métiers bancaires

Après projet, en phase de « RUN »
Effectuer une veille sur les évolutions des sources de données
Mettre à jour les règles de récupération de la donnée
Etre en support des utilisateurs data, du Groupe.

Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 92 - Hauts-De-Seine
Ville
Montrouge
Critères candidat
Niveau d'études minimum
Bac + 5 / M2 et plus
Formation / Spécialisation
Une première expérience réussie dans la gestion de la data
Bac +5 soit avec une formation en data Science, de Data Engineering ou d'ingénierie statistique.
Niveau d'expérience minimum
3 - 5 ans
Expérience
Une expérience dans le conseil ou la gestion de projets et un niveau d'anglais opérationnel constitueraient un plus à votre candidature
Compétences recherchées
Rôle de conseil, force de proposition et autonomie
Qualités de leadership pour fédérer les différents acteurs de l'équipe projet
Bonne capacités de communication et de pédagogie permettant d'interagir en transverse efficacement avec vos interlocuteurs
Pragmatisme, réactivité & agilité
Outils informatiques
Connaissances des technologies et outils informatiques : Big data (hadoop) et base de données SQL (Spark)
Connaissances sur les techniques de référence en terme d'analyse de données, de méthodologie et langages de programmation statistique (Python et/ou SAS)"
Gennevilliers (92),,,Data Analyst,Prisma Media SNC,- Gennevilliers (92),"1er groupe bi-média de France en audience print-digital, Prisma Media est aussi l'acteur N°1 en presse magazine et en audience vidéo. Un leadership qui assure à Prisma Media un potentiel optimal d'audience de plus de 40 millions de personnes chaque mois sur ses différents médias.
Avec un portefeuille de 25 marques incontournables, le groupe est présent sur les principaux segments grand public (féminin, cuisine, télé, people, découverte, économie…).
Porté par la mission de devancer les besoins et envies de ses lecteurs et utilisateurs sur tous les supports, Prisma Media adopte une stratégie offensive de développement et d'innovation dans les secteurs en forte croissance tels que la monétisation de la data, la vidéo et le mobile, avec une ambition d'avoir toujours UN MÉDIA D'AVANCE.
Rattaché(e) au manager du service BI / Analytics / Data science, vous intervenez en tant que Data Analyst afin de développer l’analyse de données chez Prisma.

Ce service a pour vocation d'optimiser l’utilisation des données client et business par les différents services de l’entreprise, pour aider à la prise de décisions, améliorer la compétitivité de l’entreprise et participer activement à la transformation digitale. Tout cela s’effectue au travers des deux leviers que sont l’activité Analytics (BI) et la Data science.

Missions :
Vous exploitez les données disponibles via l’analyse de données et la présentation de recommandations auprès des équipes métier chez Prisma
Vous intervenez sur l’ensemble du projet : collecte et compréhension des besoins métier, extraction, transformation et préparation des données, analyse des données (analyse statistique, exploratoire, descriptive ou prédictive), interprétation et restitution des résultats
Vous développez des dashboards et data visualisations afin de mettre la donnée à disposition de l’ensemble des métiers pour les aider à piloter leurs performances et optimiser leurs activités
Vous apportez une aide à la décision qui s’appuie sur les enseignements tirés des analyses et vous fournissez des recommandations actionnables aux métiers, via l’interprétation et la présentation des résultats aux équipes
Vous intervenez notamment sur les données issues de la diffusion (des magazines), du trafic digital et de la base CRM (Users accounts qui représente environ 2 Millions d’utilisateurs actifs et 3 Millions d’utilisateurs flottants) : analyse des ventes, analyse des comportements pour identifier des leviers et des opportunités de croissance, parcours client, fidélité, valeur client, churn, etc
Vous collaborez avec l’ensemble des départements (pôles marques, marketing, RH, régie publicitaire, …) en les accompagnant dans l’identification de leurs besoins et la structuration de la problématique, ainsi que dans l’appropriation des analyses
Vous collaborez avec les équipes IT, data engineers et data scientists et participer aux différents projets data (collecte de nouvelles sources de données, transformation de la donnée, déploiement des analyses)
Vous assurez une veille technologique sur les solutions d’advanced analytics et les solutions de gestion de données, les tendances et nouvelles pratiques

De formation supérieure (de type BAC+5, École d’Ingénieur ou équivalent universitaire Master), vous disposez de solides connaissances techniques en matière de data et avez également une réelle aptitude à comprendre les enjeux business et plus particulièrement ceux engendrés par la data
Vous disposez d’une expertise dans le domaine de l’analyse de données et des statistiques (analyse factorielle multivariée, tests statistiques, scoring, segmentation)
Vous possédez une expérience professionnelle de 3 ans minimum dans la mise en oeuvre d’analyses statistiques et d’un écosystème data au sein de systèmes complexes sur un grand volume de données et de trafic.
Vous êtes familier avec les méthodes agile (SCRUM / Kanban) et le cycle de vie du produit / projet.
Au-delà de vos compétences techniques, vous avez une approche business-centric.
Une connaissance des nouvelles réglementations de protection, et exploitation des données (GDPR, data cleaning, data delivery) serait un plus.
Vous êtes un bon communicant (la restitution des résultats aux équipes est clef) et aimez le travail en équipe.
Vous avez la capacité de présenter des notions complexes de manière simple et claire.

Compétences techniques:
Bases de données Oracle / SQL
Data visualisation (Salesforce, Tableau, PowerBI, QlikView)
Compétences cloud AWS ou GCP
Python (NumPy, SciPy, Pandas)
Vous respectez l’éthique en matière d’usage de la data.

Prisma Media propose tous ses postes aux personnes en situation de handicap en privilégiant une logique de compétence et d'emploi pérenne. Le groupe est signataire de la Charte de la Diversité et partenaire de l'association Adapt.
Exercice de vos droits
Conformément à la réglementation en vigueur, vous pouvez exercer vos droits d'accès, de rectification, d'opposition, de suppression, de limitation du traitement, et à la portabilité des données à caractère personnel, en adressant votre demande au DPO du Groupe Prisma Media, soit à dpo@prismamedia.com soit par courrier à Prisma Media - DPO, 13 Rue Henri Barbusse. 92230 Gennevilliers.
Entreprise: Prisma Media SNC
Pays: France
Etat/Région: Hauts-de-Seine
Ville: GENNEVILLIERS
Code Postal: 92230
Emploi ID: 76366"
Paris 17e (75),CDI,,Data ingenieur H/F,Orange,- Paris 17e (75),"Mission
Le/La data ingenieur incarne l'offre d'Orange Applications for Business dans le domaine de la « Data ». Il/Elle participe à son développement et à son évolution en relation avec les équipes marketing et opérationnelles. Il/Elle est le garant de la mise à disposition des données de bonne qualité, en cohérence avec le besoin client
Enjeux -objectifs
L'activité d'Orange Applications for Business se développe dans le domaine de la donnée. Ce développement est porté par la mise en avant de la vision d'Orange Applications for Business concernant la Data. Cette vision est le reflet de l'expérience du groupe Orange sur le domaine et du savoir faire d'Orange Applications for Business dans la conduite d'activités dans ce domaine.
Contenu de l'activité
1)Tests de package sur VM
Installer des outils et des environnement pour les langages R et python ( Rstudio server Pro et open source , Rstudio connect et shiny server (pro et open source), Anaconda, jupyter et jupyterHub)
Adapter les installations aux normes de sécurité (reverse proxy (ex : apache sws), ajout de certificats, ajout de l'authentification SSL, etc…)
2)documentation technique à destination des développeurs en charge de l'automatisation du déploiement de la solution et des utilisateurs finaux pour les former sur l'utilisation de ces outils
3)développement d'applications blanches (type application shiny qui se connecte à différentes sources de données), et réalisation de démos avec ces outils de type user story
4)veille technologique, en testant, qualifiant et en proposant des nouveaux packages qui faciliteront la vie des utilisateurs des laboratoires
5)Participation à des projets data science et big data au sein de l'équipe
about you
Diplômé(e) d'un bac+5 minimum, vous avez au moins une première expérience dans le même domaine.
L'architecture big data (environnement hortonworks) et les aspects de sécurité (tickets kerberos, apache knox, spark livy) ne sont pas un secret pour vous.
Vous maitrisez Hadoop, sparklyr, rwebhdfs, rjdbc pour hive, Java, Oozie et avez des connaissances des outils Git, gitlab, mais également de R et / ou python.
Vous êtes dynamique, touche à tout et avez un bon relationnel !
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Paris (75),CDI,,Data analyst - h/f,FREE,- Paris (75),"Description entreprise :
Fondé en 1991, le groupe Iliad est également connu sous la marque commerciale Free. Depuis plus de 15 ans, ce groupe technologique basé à Paris, s'attèle à offrir les plus grandes innovations télécom du marché.
Description du poste :
Notre équipe
Nousaccompagnons nos interlocuteurs dans la construction et la modélisation deleurs besoins en matière de données analytiques. Riche en activité, nousproposons notre savoir-faire en BI, gestion base de données, analyse,statistique, développement et machine Learning à travers la valeur ajoutée denos divers reporting et application.
En tant que Data Analyst, vous avez pour missions principales de :
Participer à l’enrichissement de l’entrepôt dedonnées à travers l’identification des données manquantes.
Contribuer au prétraitement et à laqualification des données pour les besoins statistiques ou analytiques
Garantir la bonne cohérence, la fraicheur, et ladisponibilité des données
Recueil des besoins et définition desspécifications
Concevoir et industrialiser les rapports,représenter visuellement les données et mettre en valeur les indicateurs cléssur notre outil BI. (+1)
Comprendre le modèle de données analytiques etmaîtriser les volumes et les vélocités de nos métadonnées.
Développer, améliorer et évaluer les algorithmesde traitement de données, d’exploitation et de prédiction.
Maîtriser les différents modèles d’apprentissage(supervise, non supervisé, semi-supervisé (+1)
Savoir identifier les leviers de performances etde création de valeur au service des métiers
Rédiger des manuels utilisateurs et partage desmeilleures pratiques
Pourquoi nous rejoindre
Travailler dans une ambiance conviviale
Rejoindre une équipe jeune et polyvalente
Avoir des missions diversifiées
Avoir de l'autonomie d’exécution de vos missions
Profil recherché :
De formation supérieure (Bac+5 ou plus) avec une spécialisation en Parcours informatique orienté data/ Statistiques/ analystede données,...Vous faites preuve d'une :
Maîtrise parfaite de l’utilisation de l’un de ces langages (R, Python)
Connaissances en VBA
Maîtrise de l’un des outils de Data visualisation (Tableau, QlikView, PowerBI, etc) (+1)
Connaissances SQL, Excel (optionnel)
Maîtrise de l'anglais (oral et écrit)
Vous êtes également reconnu(e) pour votre :
Bonnes capacités analytiques
Autonomie et rigueur
Curiosité et capacité à être force de proposition
Fort rédactionnel
Adaptabilité et fort relationnel
Les plus :
Une expérience dans une entreprise de télécommunication
Double connaissance de l’écosystème IT & Télécom"
Paris (75),,,Data Consultant,MFG Labs,- Paris (75),"Your mission as a consultant is to design, implement and successfully deploy MFG Labs’ clients data-driven transformation. You’ll manage a multi-disciplinary team to deliver best in class algorithms and products tackling businesses’ more complex problems. You’ll play a key role as client’s key partner, technical team’s ambassador, and MFG Labs’ management right-hand person.
Opportunity details
Full time
Starting now
Place: Paris
Main objectives
1/ Help clients define their transformation and data strategy
2/ Manage a dedicated team and project to deliver the key assets of the strategy (systems, algorithms, analysis, products…)
3/ Efficiently deploy the assets within the client organisation and drive change to maximise value
4/ Guarantee the team delivers best-in-class deliverables within budget and timing
Skills (and mindset)
Must have at least 2 years of experience
Thriving in complex and highly technical environments
Strong interest and understanding of statistics and machine learning algorithms
Methodology, ability to prioritise and to make decisions
Unrivalled interpersonal and communication skills
Leadership
Adaptability
Tenacity and dedication
Autonomy and proactivity
Obsessed with details
Fluent in French
Strongly appreciated but not required
Mathematics and Statistics background
Knowledge of databases and SQL language
Knowledge in R, Python
Knowledge of Tableau software or equivalent
Experience with Agile methodologies and tools (Confluence, JIRA)"
Enghien-les-Bains (95),"Temps plein, CDI",4 000 € par mois,Data Engineer H/F,Octopeek,- Enghien-les-Bains (95),"Octopeek est une Data Fabric qui aide les entreprises à améliorer leur productivité et leur performance grâce à l’AI. Elle rend accessible le Big Data à toutes les entreprises et les aide à la prise de décisions grâce à des modules qui s’adaptent aux métiers.
Cette Data Fabric est constituée de 3 briques :
Big Data as a service (BDaaS) , Smart Data, AI as a service (AIaaS).
Cela permet de collecter, stocker, sécuriser les données, et en extraire toute la valeur grâce à des workflows Data Science (nettoyage, enrichissement, analyse, modeling, visualisation, traitements AI).
Cette Data Fabric fonctionne en libre-service. Toutefois pour des besoins très spécifiques, Octopeek aide les entreprises en proposant ses services de consulting et de formations.
Octopeek est agréée CIR et reconnue Organisme de Formation dans le cadre de vos financements OPCA.
Vous rejoignez une équipe d'experts afin d'intervenir sur des missions de Data Engineer.
Votre mission:
Réaliser la mise en œuvre des traitements des données (data pipelines) des différents projets.
Proposer des architectures data adaptées aux besoins de différents projets
Assurer le niveau de performance du traitement des données en fonction des besoins (batch ou temps réel) et leur intégrité.
Implémenter les outils de monitoring permettant de surveiller la chaine de traitement de bout en bout.
Documenter les chaines de traitement
Capitaliser sur les chaines de traitement et apporter une vision chaine de traitement « générique », transposable et scalable.
Assurer le support des chaines de traitement mises en œuvre.
Assurer la veille technologique dans votre domaine d'expertise et être force de proposition.
Compétences :
Programmation : java, Python, Scala ...
Mise en place de solution : Hadoop, HDFS, Yarn, solutions in-memory
Traitement des données : MapReduce, Hive, Pig, Spark, Storm
Développement d'API
Base système : GNU/Linux, réseau
Base de données : MongoDB, MariaDB, Cassandra…
Algorithmique : évaluation de la complexité, structure de données, parcours de graphe, calculs parallèles
Travail en équipe
Aptitudes / expériences souhaitées :
Vous faites preuve d’autonomie et de polyvalence et avez « l’esprit startup » (force de proposition, esprit d’équipe …)
Connaissance des ETL (Talend)
Forte autonomie et capacité à résoudre les problèmes
Capacité d'adaptation, résistance au stress et changement dans les projets
Avantages :
RTT
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Salaire : 4 000,00€ /mois
Expérience:
data engineer h/f ou similaire: 3 ans (Requis)"
Paris 17e (75),CDI,,Data Integration Engineer F/H,TRIMANE,- Paris 17e (75),"Dans le cadre de la mise en place et le développement de projets décisionnels, vous accompagnerez nos clients autour de la mise en place de solutions BI.

Vos missions principales consistent en :
Analyse des spécifications fonctionnelles fournies par la MOA
Conception de la solution technique
Enrichissement du modèle de données
Rédaction des spécifications techniques détaillées
Développement des flux d'alimentation avec un ETL
Bâtir les stratégies de recette, mener les tests d'intégration technique et fonctionnelle ainsi que leur validation par les référents métiers
Suivi de production des différentes applications.
Profil recherché Diplômé d'une école d'ingénieur ou d'un Master autour de la Data, vous bénéficiez d'une première de 2 ans minimum environnement dans ce domaine.

Vous êtes passionné par la Data et vous effectuez une veille permanente autour des sujets suivants :

Gouvernance des données ;

Data Intelligence : traitement ETL, modélisation datawarehouses, datamarts, analyse multidimensionnelle OLAP

Data Visualisation : Tableau Software, Qlik Sense, PowerBI, Tibco, Microstrategy, R Shiny, Oracle Data Visualisation etc. ;

Bases de données relationnelles & NoSQL (MongoDB, Cassandre, Hbase,..) et langages de requête (Hive, Pig) ;

Environnements Cloud (Microsoft Azure, Google Cloud, AWS) ;
Entreprise TRIMANE est une société de service spécialisée dans les systèmes d'information décisionnels (SID), nous proposons un ensemble de service sur mesure pour aider nos clients à gérer et rentabiliser l'information au sein de leur entreprise.

En tant que spécialiste du décisionnel, nous sommes reconnus pour le très haut niveau d'expertise de nos consultants.

Nous accompagnons nos clients (CAC 40 et SBF 120) sur des prestations de Conseil, MOA et MOE, autour du traitement et l'analyse des data, quel que soit l'environnement technique (BI, Big Data, Cloud, Machine Learning, Deep Learning, NLP, etc.) ou méthodologique.

TRIMANE accompagne la montée en compétences de ses collaborateurs grâce à sa casquette d'Organisme de Formation BI & Big Data (+ de 40 formations), et son DataLab acteur de la recherche scientifique orientée Data, impliquant entre autre la production d'outils d'Analyse de données & Dashboarding, d'Intégration de données et de Prédiction juridique."
Paris (75),,,Machine Learning Engineer (Paris or Berlin),PriceHubble,- Paris (75),"PriceHubble is a PropTech company, set to radically improve the understanding and transparency of real estate markets based on data-driven insights. We aggregate and analyse a wide variety of data, run big data analytics and use state-of-the-art machine learning to generate stable and reliable valuations and predictive analytics for the real estate market. We are headquartered in Zürich, with offices in Paris, Berlin and Tokyo. We work on international markets. We are backed by world-class investors. We have a startup environment, low bureaucracy and international team and business.As a machine learning engineer, you will work closely with data scientists to engineer ML valuation frameworks at scale. You will implement ML algorithms paying much attention to scalability and ease of use. You will own productionalization of models developed by the team. Furthermore, in order to help data scientists be more effective in their work, you will develop various tools ranging from monitoring of model performance to visualization of data.
Responsibilities
Implement and optimize scalable machine learning algorithms.
Extend existing internal ML libraries and frameworks.
Productionalize and serve models.
Develop tools to monitor models’ performance.
Develop tools to visualize data.
Enable industry standard CI/CD and reliable model versioning.
Your profile
Software engineer with experience in algorithms, data structures, and OOP.
Good understanding of ML fundamentals and existing ML libraries.
Experience in implementing end-to-end libraries following high-quality code standards.
Requirements
Msc in Engineering or Computer Science with at least 3 years of experience in algorithms / OOP, and a good understanding of data science fundamentals.
Strong programming experience in Python + at least one compiled language (C/C++, Java).
Ability to write high-quality production code. Familiarity with code best practices and design patterns.
In-depth understanding of data structures and algorithms.
Strong analytical and mathematical skills.
Knowledge of our tech stack (or similar technologies) is an advantage: pandas, luigi, (Py)Spark, tensorflow, postgreSQL, docker, kubernetes, GCP.
Comfortable working in English; you have a great read, good spoken command of it.
Benefits
Flexible work hours
Casual dress code
Free snacks, fruits, coffee, beers, sodas
Thursday drinks
✈️ Relocation package

L&D program
Well-located offices

Competitive salary"
La Défense (92),CDI,,Ingénieur DATA Senior F/H,Orange,- La Défense (92),"Chez Orange aussi on fait de la DATA. La filiale OBS Digital & DATA met aujourd'hui la donnée au coeur de son approche client.
Nos clients prennent conscience de la valeur business de leurs données et sont de plus en plus sensibles à la question de leurs exploitations efficaces. Nous sommes là aujourd'hui pour les accompagner et les conseiller dans une meilleure connaissance et maîtrise de leurs données.
Nous recherchons aujourd'hui, un Ingénieur DATA expérimenté à même d'intervenir chez nos clients pour les accompagner dans la structuration de leurs SI autour de la donnée.
Vos principales missions seront les suivantes :
Conception de solutions de traitement et collecte de volumes importants de données.
Participer à des études de cadrage pour collecter le besoin métier et concevoir les solutions qui répondent au besoin du client.
Encadrer des data ingénieur junior et participer à leur montée en compétence
Apporter son expertise sur des problématiques précises rencontrées chez les clients.
Participer à la veille techno
Rester informer et former sur les nouvelles solutions DATA
Contribuer aux phases d'avant-vente et au développement business.
Participer à la conception, l'évolution et la présentation de nos offres DATA.
about you
Profil de formation bac+5, vous justifiez de plusieurs expériences significatives en qualité de d'Ingénieur DATA, avec idéalement une connaissance des solutions Clouds d'AWS et d'AZURE. Vous êtes intervenus sur des projets intégrant des pratiques DevOps et AGILE.
Vos compétences :
Des langages objets ou scripts (Java, Javascript, Scala, Python…)
Divers systèmes d'exploitation : UNIX, Windows
Connaissances en solutions de bases de données (SQL, NoSQL…)
Expertise les outils ETL (TALEND, Informatica...)
Maîtrise des technologies du Big Data (Hadoop, Spark, Kafka…)
Autonomie, rigueur, curiosité, dynamisme et sens du service sont des qualités nécessaires pour ce poste.
La maîtrise de l'anglais (oral et écrit) est un plus.
Postes à pourvoir à PARIS.
Nous vous proposons d'intégrer des projets centrés sur les dernières technologies dans des équipes à taille humaine organisées à 60 % en mode forfait.
Vous recherchez un Groupe qui saura être à l'écoute de votre potentiel et qui vous permettra d'évoluer, alors rejoignez-nous !
Nous avons des projets pour vous.
Critères candidat
Niveau d'études min. requis Bac+5
Niveau d'expérience min. requis supérieur à 5 ans
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Levallois-Perret (92),"Temps plein, CDI",,FULL REMOTE Senior Data Scientist H/F - CDI,Jellysmack,- Levallois-Perret (92),"Nous continuons de recruter et avons adapté notre processus de recrutement. Tous nos entretiens, ainsi que l’onboarding, se déroulent désormais en full remote.
Cette offre d'emploi est proposée en FULL REMOTE
Jellysmack est une entreprise spécialisée dans la création de contenus vidéos originaux sur les réseaux sociaux. Avec plus de 3 milliards de vues par mois, Jellysmack a connu une ascension fulgurante, ne cesse de grandir et ambitionne de devenir le leader mondial dans son domaine. La recette de ce succès repose sur la qualité de nos contenus, mais aussi sur la technologie opérant en arrière-plan. Jellysmack a développé une suite d'outils propriétaires, propulsés par l'IA, permettant à nos équipes de contenu de publier, s'inspirer, comprendre la trend, analyser les résultats, mais bien plus encore, des outils qui analysent le contenu en ligne, les réactions des gens devant ce contenu, et déterminent ce que sera la tendance demain.
Après plus de 2 ans de développement technique, Jellysmack propose une technologie unique articulée autour de 3 produits qui visent à optimiser la création et la distribution sociale de vidéos.
L'équipe Tech œuvre pour la mise en place d’outils utilisés en interne par les équipes contenu afin de déterminer les sujets qui buzzent, les aider dans la création de contenu, suivre les performances des vidéos internes etc... en injectant dans chacun de ces produits une dose conséquente d’algorithmie, de statistiques et de machine / deep learning.
En lien direct avec le Head Of Data (basé en Corse), vous serez amené à travailler sur différentes problématiques - prioritairement axées autour du NLP - et sur des projets de taille très différentes, impliquant d’importantes quantités de données (plusieurs centaines de millions de vidéos stockées en base à date avec leur métadata textuelles, plus de 21 milliards de commentaires...).
Au sein d’une équipe de sept data scientist, vous serez le référent de l’équipe sur ces sujets d’analyse et de compréhension du langage et vous aurez un rôle consultatif.
Missions principales
Passer d'une problématique métier à un algorithme de data science
Passer d'un POC à un algorithme en production
Vulgariser un algorithme à l'état de l'art et être référent de l'équipe Data Science
Etre autonome sur les outils comme Git, avoir déjà travaillé sous docker - idéalement sous AWS
Quelques exemples de sujets :
Analyse de sentiments sur les commentaires des vidéos
Extraction de topics à partir des titres, descriptions, commentaires des vidéos
Catégorisation de vidéos en thématique à partir de l’ensemble des éléments textuels dont nous disposons
Génération automatique de titre/tag de vidéos...
Création d’un algorithme d’identification des meilleurs créateurs sur une thématique donnée
Analyse de vidéos (contenu et metadata) pour mieux comprendre la rétention des utilisateurs
Optimisation de coût sur l’acquisition de fans
Génération automatique de montage de vidéos...
Profil recherché
Docteur en computer science ou diplômé d’une maîtrise en data science, vous disposez d’au moins 5 ans d’expériences,
Une autonomie sur le passage en production d’algorithmes sera indispensable,
Vous êtes pédagogue sur la transmission de votre savoir,
Vous avez un très bon niveau de SQL (MySQL et PostgreSQL).
Avantages :
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
full remote senior data scientist h/f - cdi ou similaire: 1 an (Souhaité)"
Paris (75),CDI,,Data Engineer H/F (Paris),Keyrus,- Paris (75),"Vous êtes adeptes du Big Data et souhaitez participer à la croissance d’un groupe expert dans ce domaine ?
Notre team Data Strategy and Valuation recherche des Consultants Big Data Engineer (H/F) pour participer à des projets innovants mêlant sujets Big Data et Data Science.
Le job :
Les principales missions qui vous seront confiées seront les suivantes:
Conception et mise en œuvre de plateformes basées sur des technologies Big Data ;
Installation et déploiement de clusters logiciels ;
Conception et mise en œuvre de flux d’intégration (mode batch ou temps réel) de données structurées/non structurées et volumineuses ;
Optimisation technique et fonctionnelle en termes de performance et de qualité logicielle ;
Mise en œuvre de la stratégie d’exploitation des plateformes Big Data (gestion des sauvegardes, procédures de récupération des données, mises à jour et montées de version logicielles,…) ;
Transfert de compétences et animation de formations ;
Préconisation d’outils et/ou technologies et veille technologique continue.
Vous :
Vous disposez d’un profil Ingénieur Informatique (BAC +5) et avez déjà réalisé des projets ou missions Big Data.
L’écosystème Hadoop (HDFS, Pig, Hive, Sqoop, Flume,…), Spark ou encore Elasticsearch sont vos technologies de prédilection.
Les langages orientés objet types Java, C++,… et de scripting (python, shell,…) n’ont plus aucun secret pour vous.
Vous maitrisez les environnements Linux ou UNIX.
Le petit + qui fera la différence : Vous avez déjà programmé en Scala ou travaillé sur des algorithmes de Machine learning.

Mais aussi…
Votre cerveau est toujours en ébullition et vous êtes toujours en veille sur les nouvelles technologies.
Vous êtes bien entendu sympa et aimez partager vos idées.
D’ailleurs vous bouillonnez d’idées et aimez les mettre en application car vous pensez qu’il est trop facile de s’endormir sur ses acquis.
Vous souhaitez avant tout travailler sur l’architecture Big Data et travailler en étroite collaboration avec une équipe d’experts en Data Science.
Notre Team Big Data & Analytics est faites pour vous !
Nous sommes ? Une success story dans la Data et le Digital !
Notre mission ? Des projets à forte valeur ajoutée pour accroître la performance et la compétitivité des entreprises, faciliter et accélérer leur transformation.
Notre expertise depuis plus de 20 ans ? Le conseil et l'intégration de solutions innovantes autour de trois domaines :
Data Intelligence Business Intelligence et Big Data & Analytics
Digital Experience Conseil, Stratégie & Performance Digitales
Conseil en Management & Transformation Pilotage de la Performance & Accompagnement des Projets
Nous sommes plus de 3200 talents sur plus de 18 pays et 4 continents. Notre ADN ? Innover et entreprendre.
Pourquoi nous rejoindre ?
Pour intégrer une communauté d’experts curieux et passionnés et évoluer dans un environnement multiculturel, formateur et favorisant la mobilité internationale.
Parce que vous êtes #DataGeek, #DigitalAddict, #InnovationLover !
#KeyrusRocks #YouRock
Keyrus est une entreprise où il fait bon vivre et travailler !
Découvrez :
> La vie chez Keyrus en 60 sec
> Keyrus en 3 mots
> Nos animations pour nos collaborateurs sur Facebook et sur Instagram."
Neuilly-sur-Seine (92),,,Lead Data Scientist,ILLUIN TECHNOLOGY,- Neuilly-sur-Seine (92),"Data
Deep Learning
Machine Learning
Nos Data Scientists travaillent principalement pour les Labs d’Innovation de nos partenaires grands comptes sur des sujets innovants et pointus. Ils concoivent et industrialisent des algorithmes de Machine Learning & de Deep Learning robustes et innovants.
Description de poste
Qui sommes-nous ?
ILLUIN Technology est une jeune entreprise de 40 makers avec un réel esprit d’entraide ! Nous réalisons des projets stratégiques autour des nouveaux modes d’interactions Tech et de l’Intelligence Artificielle. Grâce à notre expertise scientifique et technologique, et à notre connaissance du Design Thinking et de l’UX, nous innovons en plaçant l’utilisateur final au cœur de la démarche.
Ton futur job
Les défis :
ILLUIN est une jeune entreprise en forte croissance, relevant des défis continus et offrant des perspectives significatives :
fiabilisation et préparation des données structurées (informations clients, produits, navigation web…) ou non structurées (verbatims, chroniques de contact…), internes ou externes (open data, médias sociaux…);
mise en oeuvre de techniques analytiques traditionnelles (segmentations, scores…) ou innovantes (machine learning, deep learning…);
conception des tests destinés à mesurer les gains de ces innovations analytiques;
conception et développement de différentes briques d’intelligence artificielle, génération d’algorithmes de machine learning;
collaboration avec les équipes de développement concernant la mise en place et le déploiement de systèmes de machine learning en production;
partage de ton expertise et promotion des méthodes d’analyses prédictives en communiquant régulièrement avec l’ensemble des Illuineurs lors des sweet talks hebdomadaires.
Environnement Technique :
Python
Bibliothèques de DL classiques : Keras / TensorFlow / PyTorch
Bibliothèques de ML classiques : Sk-learn / Statsmodels …
Compétences techniques approfondies souhaitées …
Machine Learning (Classification, Regression, Clustering)
Deep Learning (CNN, RNN …)
TimeSeries (Decomposition, ARIMA …)
Computer Vision (Classification, Object detection)
NLP (Analyse de sentiments, Lemmatisation …)
…et quelques atouts supplémentaires :
Tests unitaires et d’intégration, BDD, lint
Expérience avec Git
Expérience en CI/CD
Expérience avec R. / Scala appréciée
Spark / Hadoop
Notion de Front (HTML/JS/CSS)
Bases de données (SQL / NoSQL)
Pourquoi choisir ILLUIN ?

ILLUIN c’est :
une envie commune d’inventer une histoire différente, en apportant toute l’innovation indispensable aux défis technologiques que nous confient nos partenaires;
une équipe talentueuse techniquement avec un réel esprit d’entraide !
une organisation horizontale, libérée et responsabilisante où la prise d’initiative est fortement encouragée;
un cadre de travail convivial avec un grand jardin au calme et une terrasse agréable ou déjeuner le midi, table de Ping-Pong, terrain de pétanque …
un team building mensuel;
un salaire concurrentiel.
Type d'emploi
CDI"
Paris (75),CDI,,CONSULTANT BIG DATA/JAVA - F/H,Ingeniance,- Paris (75),"Contexte :
Cette mission se déroulera au sein de la DSI Finance Comptabilité & Ratios de la Direction des Opérations et des Systèmes d'Information de notre client.
La direction métier du domaine Finance – Comptabilité et Ratios de notre client est aujourd'hui en attente d'une solution et d'un support basé sur les technologies BigData et la notion associée de Datalake.

Le point de vue métier vis-à-vis de ce projet à réaliser est une attente très forte comme accélérateur de solution pour l'ensemble des futurs reportings règlementaires à mettre en place entre 2017 et 2020, mais également le premier instrument pour la mise en qualité des données Comptables – Prudentielles et Risques de notre client.

Missions:
La mission a pour objectif la construction d'un � datalake � Finance & Risque. Ce datalake s'appuiera sur la distribution Hadoop HortonWorks.
Par la notion de datalake, il existe une multitude de problématiques à adresser autour des thèmes suivants: audit, qualité, contrôle, gouvernance de la donnée.
Les éléments attendus par la création et la livraison du Datalake Finance & Risk, en tant qu'outil de production, à l'ensemble des métiers Comptabilité, Prudentiel, Risque, Pilotage financier sont multiples.
Le projet tant techniquement que fonctionnellement devra y répondre:
Industrialisation de l'alimentation des données sur la plateforme technique HortonWorks
Alimentation des Meta-données en parallèle des données brutes.
Monitoring de l'ensemble des flux (tenue de cette information en quasi temps-réel)
Le profiling automatique de la donnée intégrée (tag, distribution de valeurs )
Abstraction des données
Les notions de Business Glossary et Technical Glossary doivent permettre la passerelle vers les utilisateurs Business métier. Ils doivent pouvoir interroger le datalake avec une sémantique Finance et Risque et non avec des noms de tables ou de champs.
Interprétation du contenu – mise en correspondance des référentiels internes
Toutes les données intégrées devront être liées, enrichies, contrôlées avec l'ensemble des référentiels (Contrepartie, Desk/Book, Devise, Entité Comptable, etc) a priori en aval de la couche de stockage transversale
Application d'une sécurité forte dédiée à chaque profil utilisateur
La sécurité des données d'un datalake est une attente majeure des sponsors métiers.
Une matrice complexe doit pouvoir être définie par les outils du datalake pour y répondre. A cela s'ajoutant la dimension temporelle des politiques d'accès définies.
Piste Audit complète de la données pour tout le SI Finance & Risk
Traçabilité complète attendue, en terme de lineage de la donnée intra cluster Hadoop
Pouvoir suivre les données, leur transformation et leur contribution à quel reporting règlementaire.
Socle de Reporting / Traitement & Controles
Reporting statique donnant la situation des contrôles croisés inter-application
Production des nouveaux états réglementaires attendus (Anacrédit, MREL)
Mise en place d'une Zone d'échange Normalisée avec l'entité maison mère

Enfin, il est attendu par les Business métiers un ensemble d'outil d'interrogation � libre � de la donnée présente dans le datalake, la DataViz est donc une problématique majeure dans la construction de la solution.
Profil recherché:

Diplômé(e) d'une grande école d'ingénieurs ou de formation équivalente (Bac+5), vous avez un excellent relationnel et disposez d'une bonne capacité d'analyse.
Connaissance des méthodes et technologies de développement BigData pour les éléments Alimentation et Transformation de la donnée. En premier lieu une connaissance du moteur SPARK (avec implémentation Scala ou Python)
Capacité de modélisation via la technologie Hive (notion de partitionnement, tables externes ou managées etc )
Compétence pour implémenter une solution propriétaire Web de monitoring et audit des flux de données (DashBoard Kibana/Graphana, ou par Angular, ou autres techno Web)
Capacité à faire un benchmark des outils marchés de Data Vizualisation (ex: Tableau, Spotfire) ou Data Wrangling (ex: Trifacta)
Compétences techniques:


REST/ JSON
Java/J2EE
Hadoop
Familier avec les méthodes de travail agile / scrum ...
Environnement UNIX/LINUX, Script SHELL
Connaissance des états réglementaires (Surfi, Protide, BDP, Corep, Finrep)
Apache, Tomcat..., Reverse Proxy (gestion d'instance), Administration d'un serveur d'application Websphere
Big Data (Java, Python, Scala, ...)
Big Data (Pig, Hive, ..)
Connaissance des principes de modélisation d'une base de données relationnelle et du langage SQL
INGENIANCE est une société jeune et dynamique qui stimule l'innovation et la transformation digitale par l'accompagnement de ses clients dans leurs projets liés aux nouvelles technologies.

Spécialiste des secteurs Banque, Finance et Assurance, INGENIANCE est également une entreprise technology-oriented qui offre une expertise multi-sectorielle autour du Big Data, du développement informatique, de la Blockchain et de la philosophie DevOps.

Ceci permet à INGENIANCE de se positionner comme une entreprise leader du marché financier et avant-gardiste des technologies disruptives."
Paris (75),CDI,,Data Analyst Senior (h/f),SFR,- Paris (75),"Au sein de SFR, vous intégrerez le pôle B2C.
Le pôle Grand public a pour objectif d’améliorer l’expérience client dans tous les moments clé de la relation. Pour cela, nos équipes travaillent à développer la connaissance client en renforçant nos capacités de collectes de données sur tous les points de contacts. L’analyse de ces données permet aux équipes marketing et web de proposer des offres cohérentes et de développer des interfaces et des services digitaux pour répondre aux nouveaux usages clients.
Nous recherchons pour la Direction SFR Analytics de notre entité, un(e) « Responsable d'Etudes », sur son périmètre ""Analyse et recommandations business"".
La Direction SFR Analytics répond aux enjeux stratégiques de l’entreprise. La donnée est devenue, année après année, un atout à part entière pour SFR. Elle a de la valeur à la fois en interne pour mieux comprendre et appréhender nos clients mais également à l’externe pour la monétisation de cette donnée. SFR souhaite, via sa Direction SFR Analytics, accélérer cette transformation et accompagner l’ensemble des collaborateurs en interne sur ces sujets.

Vos principales missions sur ce poste seront les suivantes :
Cadrer le projet et la définition d'une méthodologie adaptée à la problématique
Extraire, à partir du Data Warehouse et du Big Data , et éventuellement de bases d'enquêtes, des données pertinentes et fiables
Fouiller des données et construire des indicateurs (data management )
Analyser des comportements pour identifier les leviers et les facteurs discriminants
Comprendre les logiques clients correspondantes
Identifier les solutions les plus pertinentes
Mettre en forme les documents de synthèse et présenter les résultats obtenus aux équipes Marketing et Gestion de la Relation Client (CRM)
Profil
Vous êtes reconnu(e) par votre entourage pour votre capacité à relever des challenges, votre curiosité, votre capacité à travailler en équipe et en autonomie, votre capacité de synthèse et de priorisation ainsi que votre sens des responsabilités.
L’ensemble de ces qualités et compétences sont pour vous autant d’atouts pour intégrer notre Direction SFR Analytics basée sur le site Altice Campus.
De Formation BAC+5 ou équivalent, avec une spécialisation en statistiques / datamining / datamining / data science / big data, vous avez au minimum 3 années d’expérience dans le domaine recherché sur un poste de Data Analyst.
Au cours de votre parcours, vous avez déjà démontré votre expertise en logiciels de traitement / modélisation statistiques, programmation et data visualisation (R, Python, Power BI, Tableau) Vous maîtrisez la gestion de base de données (SQL, modèle de données) ainsi que les outils Office."
Paris (75),,,Consultant Data Visualisation H/F,onepoint,- Paris (75),"Description de l'entreprise
Nous sommes des architectes de la transformation des entreprises et de la modernisation des Etats, courageux, authentiques, ouverts, engagés et élégants. L'organisation de nos
expertises en communautés ouvertes, permet d'apporter à nos clients une proposition de valeur depuis la réflexion stratégique jusqu’à sa mise en œuvre en intégrant les compétences métiers et tech les plus avancées.
Nous sommes aujourd'hui 2300 collaborateurs, répartis dans 15 implantations dans le monde (Paris, Bordeaux, Toulouse, Nantes, Lyon, Amsterdam, New-York, Bruxelles, Luxembourg, Melbourne, Singapour, Montréal, Tunis, Zele).
Mission : Nous aidons chacun de nos clients à dessiner concrètement un chemin d’avenir en étant audacieux, en allant au-delà de l’évidence, pour créer de nouvelles façons de travailler, de nouveaux modèles économiques et de nouveaux lieux. Autrement dit, chaque matin, nous nous levons pour contribuer à dessiner un nouveau monde.
C’est ainsi qu'est définie notre raison d’être – Design a New World – et notre signature : Beyond the Obvious, au-delà de l’évidence

Description du poste
Vous rejoignez notre cabinet en tant que Consultant Data Visualisation.
Nous rechercons des profils hybrides ayant à la fois une connaissance avancée d’une ou plusieurs solutions data visualisation, capables de travailler en relation directe avec des équipes métier et capables de piloter des projets data.
Vous pourrez être amenés à :
Être l’interlocuteur unique et privilégié d’une équipe métier pour le maquettage et la construction d’un reporting data visualisation dans une démarche de co construction avec le client
Être force de proposition sur des approches d’analyse, d’indicateurs de performance, de visualisation et d’expérience utilisateur en cohérence avec l’usage, les compétences et les attentes du client
Travailler en mode agile et en autonomie, avec des sprints très courts de quelques jours entrecoupés de restitutions client
Organiser des ateliers suivant la méthode design thinking pour faire émerger les besoins
Proposer une stratégie data moyen terme, notamment en termes de gouvernance de la donnée
Vous participerez activement à la capitalisation de nos connaissances ainsi qu’au développement de notre business unit data.

Vous serez formé(e) à nos méthodologies et aurez l'opportunité de travailler au sein d'équipes pluridisciplinaires.

Qualifications
Diplômé(e) d’une école ingénieur, vous justifiez d’une expérience réussie de 4 à 8 ans dans un grand groupe, cabinet de conseil ou start-up.
Vous possédez une forte appétence pour la Data, le BI et l’univers des starts-ups.
Vous travaillez en environnement agile
Vous savez créer et s’assurer de la bonne tenue de votre backlog.
Vous suivez les différentes cérémonies agiles comme : le sprint planning, les daily meetings, des rétrospectives, des démonstrations au client.
Vous avez une bonne compréhension et des expériences réussies dans un ou plusieurs domaines de la data
Déploiement ou exploitation d’écosystèmes data (Hadoop, ELK, etc.)
Analyse exploratoire ou mise en place d’une solution de visualisation de données (Qlikview, Tableau, Power BI, etc.)
Mise en place ou maintenance de data warehouse
Animation ou réalisation de développements spécifiques en Python, R, Scala ou autre langage spécifique
Une bonne compréhension des algorithmes data (modèles statistiques et prédictifs) est un plus.
Curieux et adaptable, votre rigueur et votre proactivité vous permettent de contribuer à l'excellence de notre service auprès des clients.
Votre capacité d'analyse et de synthèse, vos qualités d’écoute et de communication écrite et orale suscitent la confiance.
La maitrise d'un ou plusieurs outils de traitement de données (data quality, data cleansing, ETL, analytics, dataviz...) serait un plus

Informations complémentaires
Nous vous proposons :
Des missions et projets passionnants
Une communauté de consultants active
Un cabinet de conseil différent (« Startup spirit »), très qualitatif et à taille moyenne
Une opportunité unique de développement et d’évolution dans un esprit communautaire
Un suivi et une formation personnalisés"
Ivry-sur-Seine (94),CDI,,Data Analyst,E.Leclerc,- Ivry-sur-Seine (94),"Mieux nous connaître
Les 529 adhérents E.Leclerc exploitant 662 magasins indépendants en France, emploient 129.000 salariés. L’enseigne E.Leclerc a réalisé un chiffre d’affaires de 37,75 milliards d'euros (hors carburant) en 2018 et est le leader de la distribution française avec une part de marché de 21,6 %.

Faire partie de l'enseigne E.LECLERC, c'est intégrer une fédération d'entreprises dynamiques, en croissance et qui se démarquent autant par leur mode de fonctionnement que par leur capacité à innover et à bouleverser les idées reçues.
Descriptif de l'offre
Depuis plus de 3 ans, ConsoRégie, la régie publicitaire du Mouvement E. Leclerc valorise et commercialise les points de contacts publicitaires, physiques et digitaux de l'enseigne leader de la Grande Distribution en France.

Nous accompagnons les industriels dans leur stratégie marketing, grâce à une notre connaissance des clients E.leclerc et de leur comportements d'achat.

Venez rejoindre une équipe d'experts du retail media, dynamique et créative.

Dans le cadre du développement de son activité, ConsoRégie recrute en CDI un(e) DATA ANALYST.

Au sein du Département Marketing & Etudes, vos missions seront :

Mesurer la performance des campagnes publicitaires multicanales commercialisées auprès des industriels et des agences media. Réalisation de post test publicitaires et d’études ad hoc (traitement, analyse des résultats et développement du support de présentation). Vous pourrez être amené(e) à les présenter en rendez-vous client.

Travailler sur la qualification, la segmentation et la valorisation de nos données online et offline.

Analyser et comprendre les données internes (base clients, achat en physique et online, navigation sur nos sites internet, etc.) pour apporter un éclairage sur la connaissance client, et générer des insights au service d'une publicité plus ciblée et plus efficace.

Mettre en œuvre des outils de recueil des données, création de dashboard et sélection des indicateurs statistiques. Vous travaillerez sur la restitution visuelle des données, datavizualisation.

Accompagner l'équipe commerciale en amont (recommandations) et en aval (bilans) des campagnes publicitaires.

En collaboration avec la direction et le responsable data monétisation de la régie, être force de proposition dans les évolutions à apporter à notre offre data et à la mesure de l'efficacité publicitaire (outils, partenaires, etc.). Vous étudierez toutes les pistes (solutions internes, institut d'étude, etc.).

Etre l'interface des équipes marketing, communication et études au sein du Mouvement E.Leclerc sur les sujets liés à la donnée client.
Profil recherché
De formation supérieure en statistiques Bac +4/5 (Master en Informatique décisionnel et/ou Statistique), vous avez une expérience minimum de 3 ans dans des études statistiques et/ou datamining, si possible dans un contexte de régie publicitaire, agence media ou chez un industriel.

La maîtrise du logiciel d'analyses statistiques SPSS est indispensable. Vous appréciez également les nouveaux outils statistiques (Python, R), les outils de data visualization (BigQuery Tableau, Looker, Qlick) et les outils d'analyse de données (Google Analytics).

Une curiosité pour les nouvelles technologies data et une grande capacité d'adaptation sont essentielles pour ce poste. Maitrise indispensable des outils bureautiques du Pack Office.

Vous êtes rigoureux, adaptable et aimez le travail en équipe. Vous avez un intérêt prononcé pour la grande consommation.

Vous faites preuve de curiosité et d'ouverture d'esprit. Enthousiaste, vous avez déjà prouvé votre capacité à être force de proposition."
Paris (75),70 000 € - 90 000 € par an,,Data Scientist,digiRocks,- Paris (75),"Envie de travailler dans le luxe dans une ambiance conviviale ? De voyager régulièrement en Europe ?
Rejoins un groupe international prestigieux (CA 2018 : 11Mds) dans de superbes locaux à Paris 17ème !
Sandra recherche pour son client un(e) DATA SCIENTIST #Paris (CDI)
Maîtrise des langages Python et R, de la suite Google Cloud et de Google Data Studio
✅ MISSION : Définir la stratégie Data du groupe et piloter les projets Data au niveau central. Tu seras la personne référente data pour les 21 maisons du groupe présentes sur 45 marchés à l’international (niveaux de maturité sur les enjeux data très hétérogènes d’une maison à l’autre)

✅ RESULTATS attendus :
Délivrer les projets data de tes clients internes dans les contraintes de calendrier définies avec eux. Typologies de projets : analyses prédictives, segmentations clients, attribution modeling, marketing mix modeling, bots utilisant l’intelligence artificielle et le machine learning.
Structurer l’approche data-as-a-service du département et finaliser la mise en place de la Google Cloud Plateform.
Mettre en œuvre les projets pilotes en AI/ML (Artificial Intelligence/Machine Learning): premier projet de robot en collaboration avec une start-up californienne destiné à aider les vendeurs en boutiques à être plus performants.
Formuler des recommandations de gestion, de méthodes, d’outils et de valorisation des données dans le cadre de la stratégie data du groupe.
Piloter le volet data des partenariats stratégiques avec Google et Salesforce
Animer la communauté des data scientists et data analystes du groupe (une dizaine de personnes à date)
De formation ingénieur ou PhD, tu es un(e) expert(e) de l’analyse des données et tu as un goût prononcé pour la modélisation appliquée au marketing. Tu aimes traduire une problématique business en approche analytique et challenger le statu quo. Tu es à l’écoute de tes interlocuteurs, curieux(se), organisé(e), bon pédagogue et tu sais partager tes analyses de manière visuelle. Ton N+1 est le Directeur du Marketing Digital et de la CRM du groupe, ingénieur diplômé d’un MBA en Marketing du Luxe qui a 13 ans d’ancienneté dans le groupe. Tu travailles au sein de l’équipe « Digital Marketing & CRM » du groupe créée il y a 2 ans, avec le support d’un Data Engineer pour t’accompagner.
Postule en 2 mn si tu as envie de rejoindre une pépinière de Talents"
Paris (75),,,Data Ingenieur Junior,IPANEMA CONSULTING,- Paris (75),"Contexte
Dans le cadre de son développement d’activité, IPANEMA CONSULTING recherche data Ingenieur.
La mission sera en étroite collaboration avec les fondateurs du projet et le CTO.
Mindset ipanema
Notre Vision est que la Révolution Numérique est une opportunité à saisir pour chaque entreprise, que les entreprises ont le droit à développer une vision augmentée d’elles même, Nous croyons aux démarches de conduite du changement pour faire évoluer les organisations dans une culture « Data Centric »
A l’ère du Digital, notre vision est que les entreprises ont plus que besoin de se ré-inventer grâce à des solutions non fantasmées, alignées et coordonnées avec précision.
Intégrer une communauté de « Data Refiners » et de mettre la puissance de l’intelligence artificielle au cœur de la transformation des entreprises et des administrations.
Notre mission
IPANEMA CONSULTING est un cabinet d’accompagnement à la transformation Numérique qui fédère des talents autour de la stratégie, du change management et de la data.
En plaçant la technologie et l’humain au cœur de la transition, nos équipes proposent des solutions pour les challenges des entreprises de demain.
La force de notre écosystème
Nous avons développé un écosystème fort pour accompagner nos clients dans leurs enjeux d’innovation et pour leur adresser des solutions les plus complètes possibles.
(M&A spécialisé en Tech, lab de starts up, accélérateur de starts up, expertises stratégie, expertise Océan Bleu, expertise Design thinking, expertise Data et blokchain).
Talent recherche :
Issu d’un cursus statistiques, mathématique ou ingénieur école top 5,
Première expérience dans l’intelligence artificielle (Chatbots, RPA, NLG, etc.) ou la Data Science souhaitée
Compétences en : Java, Les langages statistiques (Python, R, etc.), le datamining, la connaissance des algorithmes de machine de learning et de deep learning, les langages NLG
Maitrise de techniques secrètes (frame patterns) de l’écosystème Hadoop, Spark, Kafka ainsi que son intégration dans une architecture d’entreprise, connaissances en bases de données SQL et NoSQL, et ETL
Sensible aux approches craftsmanship (CleanCode, TDD)
Familiarisé avec des Frameworks de tests tels que JUnit, Mockito, Gatling, JSON et les APIs REST
Bon relationnel équipe et client
Sens de l’écoute, force de propositions et envie de partager tes connaissances et savoir-faire et d’apprendre de tes pairs.
Missions :
Bien plus qu’un emploi, une véritable aventure humaine au sein d’un marché prometteur
Collaboration avec les équipes Big Data de nos clients pour concevoir et développer de nouvelles architectures de données
Mise en place ainsi qu’à l’enrichissement de datalakes basés sur l’écosystème Hadoop
Implémenteras des workflows complexes d’acquisition et d’analyse de la donnée pour faire émerger des possibilités métiers encore inexploitées
Travail de pair avec des Data Scientists dans un esprit de partage de compétences.
Début
Dès que possible
NB : Pour intégrer ses nouveaux collaborateurs, IPANEMA CONSULTING a conçu un programme spécifique d’intégration.
Rémunération
En fonction de l’expérience."
Paris (75),CDI,,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Data Scientist (H/F) pour renforcer ses équipes.
Dirigée par le Chief Data Officer et rattachée au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques met en œuvre la stratégie DATA avec comme principales préoccupations
D’améliorer la gouvernance des données ;
De contribuer à la data réputation de la Banque de France ;
De tirer le meilleur parti des masses et de la diversité des données disponibles au sein de la banque Centrale,
De développer des projets d’intérêt commun
De développer une culture de la donnée au sein des unités métier

Présentation du Service
Au sein de la DDSA, le SIAD (Service Industrialisation et Algorithmique des Données) a pour missions de construire et entretenir les socles techniques BIG DATA, de réaliser des prototypes de solutions basées sur les approches Data Science et IA et de mettre à disposition des solutions business intelligence pour les équipes métier.

Descriptif de mission
Le pôle « Data Science et IA » cherche à renforcer ses capacités en recrutant un(e) Data Scientist.
Les missions de ce pôle, partie intégrante du domaine « conseil et expertise », sont les suivantes :
Cartographier de façon continue, en relation avec les équipes d’innovation et les urbanistes, les processus métier pour lesquels une approche Data Science pourrait procurer un avantage compétitif ou préserver un territoire acquis
Épauler les métiers dans la définition et la stabilisation de leurs besoins
Mettre en place de façon continue les Proofs of Concept (POC) fonctionnels et techniques issus des analyses d’opportunité
Benchmarker de façon régulière les outils du Big Data
Préparer l’industrialisation des POC identifiés comme pertinents
Accompagner la montée en compétence des équipes métier et des équipes techniques sur le Big Data
Sous l’autorité du « Lead Data Scientist », vous serez en charge plus particulièrement :
De la prise en charge des besoins métier et de leur analyse ;
De l’identification des solutions potentielles et du choix de la solution la plus adéquate au regard des besoins et contraintes tant métier que techniques ;
De la conception et de la mise en œuvre de la solution (POC, prototype, MVP),
De l’accompagnement et du soutien aux équipes projets en charge de l’industrialisation des solutions.

Profil recherché
De formation supérieure en informatique ou métiers de la donnée (Ingénieur ou équivalent), vous avez minimum 2 ans d’expérience dans la mise en œuvre de solutions mobilisant des connaissances statistiques et/ou mathématiques avancées, y compris en contexte d’apprentissage/alternance dans des contextes de travail variés (recherche, entreprises commerciales, sphère publique ) constituera un avantage clé.
Vous disposez d’une forte appétence pour la concrétisation de solution dans un environnement Bigdata.Par ailleurs, vous avez la maîtrise :Des sous-jacents mathématiques aux approches Bigdata / Data Science (mathématiques et statistiques, Machine Learning, réseaux de neurones ) et des bibliothèques de Machine Learning (Scikit Learn, PyTorch, )
Du développement en Python
Seraient en outre appréciées, dans l’un ou plusieurs des domaines suivants :
Une très bonne connaissance en développement sur la stack Hadoop (Oozie, Sqoop, Hive, Hbase, ), sur les technologies Spark (MLlib, SQL, GraphX et Streaming), en langages PySpark, Java et R (SparkR).
Une très bonne maitrise des outils de Search (ElasticSearch) et de streaming (Kafka)
Une bonne connaissance des bases de données NoSQL telles que Mongodb et Neo4J
Une bonne capacité à intégrer des sources de données multiples, internes / externes, structurées / non structurées et des interconnexions entre les SGBD et Hadoop
Une bonne capacité à restituer les résultats visuellement à l’aide de Kibana ou PowerBI
Une facilité à développer dans un environnement innovant en méthodologie Devops et Scrum
Rigoureux et apte à anticiper, vous avez le sens du résultat au service du client et êtes doté d’excellentes capacités de communication pour faciliter le travail « en réseau » :
Force de proposition et aisance de communication pour démontrer la valeur ajoutée des solutions Big Data et Machine Learning.
Excellente méthodologie de travail et de gestion de projet, vous travaillerez en mode agile.
Très bon relationnel, capacité à s'adapter, esprit d’équipe, ouverture d’esprit et curiosité naturelle, vous suivez l’évolution des technologies et nouveautés relatives au Big Data, Datascience et IA
Une bonne pratique de l’anglais est nécessaire.
Ce poste, en contrat à durée indéterminée, est basé à Paris (1er), avec des déplacements ponctuels dans les sites banque de France à Paris et en régions.
La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes."
Saint-Denis (93),,,DATA ENGINEER JUNIOR (H/F),ITNOVEM.,- Saint-Denis (93),"Filiale privée technologique du groupe SNCF, ITNOVEM se positionne comme accélérateur des projets Digitaux, numériques et de la transformation des Systèmes d’information du groupe. Porteuse de grands projets de la révolution digitale, notre société est en constante recherche de profils pour rejoindre la grande aventure de l’Internet des objets, de la data science, de la cybersécurité et de l’accompagnement des projets digitaux. Qu’il s’agisse de maintenance prédictive, d’aide à la décision sur la maintenance des infrastructures, de gare 4.0, d’usine du futur, ou de sécurisation des assets, nos équipes font valoir à la fois une expérience métier et une expertise technique sans cesse renouvelée, dans le respect des valeurs du groupe : Excellence, Innovation, Collectif, Agile, Engagement.

Le pôle Data, IA et IT Big Data d’Itnovem. est une structure transverse qui réunit infrastructures Big Data et expertise Big Data pour l'ensemble du groupe SNCF. Ce pôle s'est constitué en juin 2015 afin de traiter avec les différentes entités les projets nécessitant des moyens, outils et expertise Big Data et IA pour être menés à bien.
Le pôle opère une plateforme Big Data pour le groupe SNCF, notamment un dalake et les outils de gouvernance et d’urbanisme associés, met en place et maintient les infrastructures cloud pour les projets hébergés sur la plateforme, gère les projets data qui lui sont confiés, réalise les projets data de bout en bout lorsqu’une expertise avancée Data Science, IA ou Data Engineering est nécessaire.

LE POSTE
Au sein de la division Data Science et Engineering, notre futur(e) data engineer junior (H/F) interviendra pour les projets de la Direction du Digital SNCF et notamment au sein la Big Data Fab. Structure transverse qui réunit infrastructures Big Data et expertise Big Data pour l'ensemble du groupe, la Fab s'est constituée en juillet 2015 afin de traiter avec les différentes entités les projets nécessitant des moyens Big Data pour être menés à bien. Elle se compose de 5 pôles : Pilotage et valorisation projet, Datascience et Developpement, Usine IT, Qualité de Service et Sécurité, Datalake.
Le pôle Data Science & Engineering d’ITNOVEM. recherche un(e) data engineer junior (H/F), en soutien du pilotage et du développement de son activité. Le pôle comprend environ 20 personnes (50% data scientists, 50% data engineers), dont la moitié est expérimentée. Vous travaillerez sur des thématiques très variées liées aux problématiques industrielles, opérationnelles et stratégiques des métiers du groupe SNCF, comme par exemple :
La maintenance du matériel roulant et l’optimisation des process ;
La maintenance des voies et caténaires ;
La surveillance du réseau et des cartographies déclinées sur les problématiques prioritaires ;
L’analyse du langage naturel, notamment sur des enquêtes et rapports techniques
L’optimisation des plans horaires, la prévision de perturbations ;
L’analyse des données IoT.

MISSIONS
Travailler sur des analyses Data Science / Data Engineering en réponse aux problématiques des métiers du Groupe SNCF portées par les clients internes de la Fab Big Data (POC, prototypes et industrialisation) ;
Participer comme expert à la démarche de conseil technique et scientifique du pôle d’expertise auprès des métiers du groupe SNCF ;
Industrialiser les projets ou les services data en développant une chaîne de traitement de données robuste et automatisée :
Spécifications techniques,
Release plan des différents livrables,
Ingestion et mise en qualité des données selon les bonnes pratiques de la Fab,
Traitement, agrégation et sauvegarde des données avec spark-scala, spark-python ou python,
Intégration continue (versionning, packaging, tests et déploiement) avec Git-SBT-Nexus-Jenkins,
Exposition des APIs sous forme de webservices Rest,
Configuration des briques logicielles,
Monitoring des briques logicielles avec OMS (Azure) ou Nagios,
Etroite collaboration avec le chef de projet, PO, OPS et architectes,
Participation aux activités d'architecture, conception et développement,
Recette et mise en production ;
Contribuer proactivement à la veille scientifique et technique, aux projets R&D, et à la construction d’assets et de services techniques orientés data ;
Participer à l’animation de la filière Data et à l’implémentation des pratiques Data au sein des métiers (formations, conseil et expertise) ;
Participer aux autres activités du pôle Data Science & Engineering (reporting d’activité, communication interne et externe, collaboration avec les universités et laboratoires associés).

LE PROFIL RECHERCHE
Compétences techniques
Maîtrise théorique et utilisation appliquée :
Langages Scala et/ou Python
Framework Spark
Intégration continue (sbt/maven, Gitflow, jenkins, nexus) et des pratiques DevOps
Une ou plusieurs bases de données NoSql (Cassandra, mongoDB)
Connaissances théoriques :
Technologies Big Data : Hadoop (Hortonworks, HDF), sécurité et ressources (Yarn, Ranger), monitoring (Ambari, Datadog)
Elasticsearch et Kibana
APIs REST
Composants Azure (HDInsight, Azure Databricks, Azure Function, ACI, AKS, OMS, etc.) ou leur équivalent Cloud concurrent
Cycles de vie des données
Architecture microservice
Gouvernance des données, notamment personnelles (Traçabilité, Sécurité (Authentification et Autorisation), Audit)

Qualités personnelles et compétences fonctionnelles
+ Transversalité et capacité à travailler avec des équipes pluridisciplinaires
+ Orienté client, qualité et résultat (jusqu’à l’industrialisation des projets)
+ Rigueur, autonomie et organisation
+ Implication dans la communauté des data engineer (meetups, etc.)
+ Qualité et sérieux dans le développement de code
+ Bonne communication scientifique et bon sens de la pédagogie

Expériences et formations
+ Bac +5 (école d’ingénieur ou/ master spécialisé en data engineering)
+ Ou titulaire d’un doctorat en informatique / data engineering

Vous avez acquis une première expérience sur des projets data engineering (stages, projets étudiants ou personnels, et jusqu’à 2 ans d’expérience professionnelle), idéalement sur des cas d'usage industriels. De plus, vous savez programmer en suivant les bonnes pratiques et avez une première expérience de travail en équipe.

Poste basé à La Plaine Saint Denis (RER D, Saint Denis Stade de France) avec des déplacements ponctuels à prévoir, généralement en Ile-de-France."
Paris (75),,,Data architecte Junior,IPANEMA CONSULTING,- Paris (75),"Contexte :
Dans le cadre de son développement d’activité, IPANEMA CONSULTING recherche data architecte.
La mission sera en étroite collaboration avec les fondateurs du projet et le CTO.

Mindset ipanema :
Notre Vision est que la Révolution Numérique est une opportunité à saisir pour chaque entreprise, que les entreprises ont le droit à développer une vision augmentée d’elles même, Nous croyons aux démarches de conduite du changement pour faire évoluer les organisations dans une culture « Data Centric »
A l’ère du Digital, notre vision est que les entreprises ont plus que besoin de se ré-inventer grâce à des solutions non fantasmées, alignées et coordonnées avec précision.
Intégrer une communauté de « Data Refiners » et de mettre la puissance de l’intelligence artificielle au cœur de la transformation des entreprises et des administrations.

Notre mission :
IPANEMA CONSULTING est un cabinet d’accompagnement à la transformation Numérique qui fédère des talents autour de la stratégie, du change management et de la data.
En plaçant la technologie et l’humain au cœur de la transition, nos équipes proposent des solutions pour les challenges des entreprises de demain.
La force de notre ecosysteme :
Nous avons développé un écosystème fort pour accompagner nos clients dans leurs enjeux d’innovation et pour leur adresser des solutions les plus complètes possibles.
(M&A spécialisé en Tech, lab de starts up, accélérateur de starts up, expertises stratégie, expertise Océan Bleu, expertise Design thinking, expertise Data et blokchain).
Talent recherche :
Issu d’un cursus statistiques, mathématique ou ingénieur école top 5, justification d’une première expérience dans l’intelligence artificielle (Chatbots, RPA, NLG, etc.) ou la Data Science,
Compétences en : Les langages statistiques (Python, R, etc.), le datamining, la connaissance des algorithmes de machine de learning et de deep learning, les langages NLG
Maitrise de l’écosystème Hadoop, Spark, Kafka ainsi que son intégration dans une architecture d’entreprise, connaissances en bases de données SQL et NoSQL, et ETL
Bon relationnel équipe et client
Sens de l’écoute, force de propositions et envie de partager tes connaissances et savoir-faire et d’apprendre de tes pairs.
Missions :
Bien plus qu’un emploi, une véritable aventure humaine au sein d’un marché prometteur
Assurer une veille technologique
Concevoir des architectures et infrastructures Big Data
Encadrer les data ingénieurs et data scientists dans leur implémentation
Optimiser en continu des infrastructures Data existantes
Etre capable de donner des formations et gérer des partenariats, faire du conseil.

Début :
Dès que possible
NB : Pour intégrer ses nouveaux collaborateurs, IPANEMA CONSULTING a conçu un programme spécifique d’intégration.
Rémunération :
En fonction de l’expérience."
Paris (75),,,"Research Scientist, AI (EMEA)",Facebook,- Paris (75),"Facebook is seeking a Research Scientist to join Facebook AI Research (FAIR), a research organization focused on making significant progress in AI. Individuals in this role are expected to be recognized experts in identified research areas such as artificial intelligence, machine learning, computational statistics, and applied mathematics, particularly including areas such as deep learning, graphical models, reinforcement learning, computer perception, natural language processing and data representation. The ideal candidate will have a keen interest in producing new science to understand intelligence and technology to make computers more intelligent. To learn more about our research, visit https://research.facebook.com (https://research.facebook.com/).
Research Scientist, AI (EMEA) Responsibilities
Lead research to advance the science and technology of intelligent machines.
Lead research that enables learning the semantics of data (images, video, text, audio, speech and other modalities).
Devise better data-driven models of human behavior.
Work towards long-term ambitious research goals, while identifying intermediate milestones.
Influence progress of relevant research communities by producing publications.
Contribute research that can be applied to Facebook product development.
Lead and collaborate on research projects within a globally based team.
Minimum Qualifications
Currently holding a faculty, industry, or government researcher position.
Ph.D. and publications in machine learning, AI, computer science, statistics, applied mathematics, data science, or related technical fields.
Experience leading a team in solving analytical problems using quantitative approaches.
Experience manipulating and analyzing data from different sources.
Experience in theoretical and empirical research and for answering questions with research.
Ability to communicate research for public audiences of peers.
Knowledge in a programming language.
Ability to obtain and maintain work authorization in the country of employment in 2018.
Preferred Qualifications
1+ year(s) of work experience in a university, industry, or government lab(s), in a role with primary emphasis on AI research.
Experience driving original scholarship in collaboration with a team.
First-author publications at peer-reviewed AI conferences (e.g. NIPS, CVPR, ICML, ICLR, ICCV, and ACL).
Experience in developing and debugging in C/C++, Python, C# and/or Java.
Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities — we're just getting started.
Facebook is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com."
Paris (75),,,CDI - SGL - Core Data Scientist,SCOR,- Paris (75),"EMEA
Paris France (FR)
|
CDI - SGL - Core Data Scientist
Permanent
Actuarial
About SCOR
SCOR, the 4th largest reinsurer in the world, provides insurance companies with a diversified and innovative range of solutions and services to control and manage risk. Using its experience and expertise, “ The Art & Science of Risk ”, SCOR provides cutting-edge financial solutions, analytics tools and services in all areas related to risk – in Life & Health insurance as well as in P&C insurance. Our specialist teams operate in over 120 countries, developing value added and innovative products and services and making long-term commitments to their clients, namely insurers and large corporations.
SCOR's aim, as an independent global reinsurance company, is to develop its Life and P&C business lines, to provide its clients with a broad range of innovative reinsurance solutions and to pursue an underwriting policy founded on profitability, supported by effective risk management and a prudent investment policy, in order to offer its clients an optimum level of security, to create value for its shareholders, and to contribute to the welfare and resilience of Society by helping to protect insureds against the risks they face.
- Department
Data Analytics Solutions
- Job Summary
The Gobal Data Analytics Team has the responsibility to increase our Data Science knowledge (survival analysis, interpretability, …) and to spread data science knowledge within the division. The Global Data Analytics Team provides technical assistance (algorithmic, ML, …) in business projects. The Core Data Scientist will develop and manage advanced statistical, predictive, and machine learning models as well as provide technical expertise to a growing cross-functional team of data scientists, underwriters, and actuaries. Help innovate the underwriting process by creatively applying cutting edge data science techniques.
The candidate will be based in Paris, as a member of the Gobal Data Analytics Team you will participate in cross-countries projects to bring your expertise and develop cutting-edge analytic solutions.
The Core Data Scientist will fully integrate the Data Science Chapter lead by the Head of Data Science.
- Key duties and responsibilities
Global thought leader for exploring cutting edge Machine Learning methods and tools
Core contributor on global infrastructure like SCOR’s Data Analytics Solutions Platform (AutoML, visualization, templates, …)
Collaborate with SCOR’s thriving global data science community by being a key contributor on research projects
Drive the advancement of data analytics projects in close collaboration with different parties including marketing managers, underwriters and actuaries.
Present results to stakeholders; clearly communicate complex topics
Contribute to the dissemination of our skills amongst SCOR Global Life clients, notably through seminars and publications
Key distributor of knowledge within SCOR globally, increasing the interpretability of models through advanced understanding of artificial intelligence and machine learning
- Required experience & competencies
Personal Competencies
1-4 years’ experience in data science with strong programming capacities and advanced knowledge of text mining, artificial intelligences, and supervised/unsupervised machine learning techniques
Deep understanding (academic knowledge) of predictive modeling concepts, machine-learning approaches, clustering, classification and crowdsourcing techniques (e.g GLMs, Decision Trees, SVM, Random Forests, GBM, PCA, Bayesian Networks, Neural Networks, etc.)
Ability to communicate, educate, and advise members of global data science community on, predictive modeling concepts, machine-learning approaches, clustering, classification and crowdsourcing techniques (e.g GLMs, Decision Trees, SVM, Random Forests, GBM, PCA, Bayesian Networks, Neural Networks, etc.)
Basics in software development best practice and code versioning (git usage, docstring, etc.)
High degree of technical expertise on cloud computing platforms such as AWS or Microsoft Azure is a plus
Expert knowledge of common data science programming languages such as R and Python
Experience using ML and NLP to develop high-quality and practical solutions
Experience with database query tools such as SQL is a plus
Insurance industry experience is preferred, but not required
Actuarial exam progress is a plus
Digital Competencies
You have a thorough knowledge of R/Python.
- Required Education
Master’s degree in Science, Technology, Engineering, Mathematics, Computer Science, Actuarial or similar quantitative field
#LI-FK1"
Paris (75),,,Data Engineer - Collection Technologies,FactSet Research Systems,- Paris (75),"Role/Department Description:
The Content Engineering department is responsible for all data collection within FactSet as well as making this available to our clients and other departments. The department is looking into fostering cloud infrastructure and technologies to revamp the processes and leverage the Datalake concept as a unique storage for all acquired/extracted documents to source all collection systems whatever their core content. The team aims at providing APIs and services to feed the datalake, to browse its contents in a structured way but also to cross check and data mine any valuable information that would be tagged already of interest for another content. This will ultimately allow for better material and servicing for cognitive computing, data analysis and data collection processes to filter, select and extract other metadata.
Responsibilities:
Develop, test and deploy software and/or content to solution end users
Continued learning through additional trainings and code review sessions
Improved quality and productivity of output
Communicate and collaborate with product developers, direct manager and engineering peers to develop the correct solutions Effective project planning and development of expected solutions
Respond to bugs and requests for product development through internal systems Effective engagement in development and feedback lifecycle
Required Skills:
1 to 3+ years of working experience in software development
1 to 3+ years of relevant experience in Data Science or Data Engineering
Strong experience and proficiency with Python, Pandas, Numpy
Experience in cloud technologies, specifically AWS
Ability to learn and apply internal systems and processes for developing and deploying software
Ability to apply code review feedback and improve future design and development quality and productivity
Ability to communicate effectively with peers within the organization"
Paris (75),"Temps plein, CDI",,Data Engineer,AI & DATA,- Paris (75),"A.I.D recherche aujourd'hui des Data engineer
Nos consultants aident les entreprises à tirer le meilleur parti des données, à mettre en place des solutions opérationnelles, à identifier et mettre en œuvre les projets liés à la transformation digitale.
Sur ce poste, vous serez intégré(e) à une équipe de projet et participerez à la mise en place de projets Big Data en intervenant notamment sur les missions suivantes :
Analyser les besoins clients et formaliser les cas d'usages correspondants,
Participer activement à la conception et à la réalisation des solutions Big Data,
Développer des solutions d’ingestion de données depuis des sources multiples pour les déverser dans un data lake : Nifi, Sqoop, Kafka, … etc.
Passer de la donnée brute à de la donnée propre (inférer les schémas de données, nettoyer, normaliser et publier les données)
Consolider les données au fur et à mesure de leur alimentation récurrente dans le data lake.
Exploiter les résultats pour atteindre la finalité business : exposition de business view, réintégration des résultats dans le SI, service de scoring, …
Mettre en place et garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de développement et d’industrialisation (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc.)
Industrialiser des pipelines d’analyse et de machine learning
De formation technique :
Vous avez une première expérience réussie d’au minimum 1 an en développement big data :
Spark : PySpark et/ou Scala
Hadoop,
Kafka
Spark Streaming / Storm,
Hbase / MongoDb / Cassandra,
Elasticsearch / SolR.
Vous avez l'habitude des cycles de développements & outils associés (intégration & déploiement continu avec Git, Jenkins, Sonar, Nexus, NUnit ...)
Ces connaissances supplémentaires seraient un plus : distribution Hortonworks, Cloudera ou MapR, outils de data viz, librairies de Machine Learning, création d'API
Vous faites preuve d'une grande curiosité et de capacité d'innovation.
AID, partenaire de nombreuses grandes entreprises françaises depuis plus de 45 ans, est une entreprise innovante qui utilise des technologies récentes. Vous collaborerez avec des data scientist, data engineer, data architecte, product owner, ...
L’AID Academy vous fera bénéficier de ses formations les plus innovantes, et vous serez amené vous-même à animer des séminaires ou formations pour nos clients ou collaborateurs.
La société est depuis quelques années en pleine croissance et cultive son esprit start up et son ambiance conviviale. Baby foot, table de ping pong, workshops internes et afterworks font partie de nos rituels d'entreprise.
Vous baignerez alors dans un environnement de travail idéal pour développer votre créativité et prendre des initiatives.
Je vous invite à consulter notre site et nos réseaux sociaux (Cf ci-dessous) et à revenir vers moi pour échanger sur nos opportunités .
www.aid.fr
Type d'emploi : Temps plein, CDI
Type d'emploi : Temps plein, CDI
Expérience:
data engineer ou similaire: 1 an (Souhaité)"
Rueil-Malmaison (92),"Apprentissage, Contrat pro",,ALTERNANCE - DATA GOVERNANCE OFFICER (H/F),Arval,- Rueil-Malmaison (92),"ALTERNANCE - DATA GOVERNANCE OFFICER (H/F) (NUMÉRO DE L'EMPLOI : ARVAL20_ALT_17)

ALTERNANCE - Data Governance Officer (H/F)

ARVAL BNP PARIBAS est le leader en France de la location de véhicule d’entreprise. Filiale de BNP Paribas, présente dans 29 pays, ARVAL propose à ses clients des solutions visant à optimiser la mobilité de leurs collaborateurs et à externaliser les risques liés à la gestion de leur flotte automobile.
Nous recherchons à Rueil Malmaison (92), un(e) Data Gorvernance Officer H/F

Concrètement votre quotidien ?

1) Outil de gestion de données.
Vous supporterez l’équipe Data Strategy dans la réalisation d’un appel d’offre et d’un projet pilote en vue de l’acquisition d’un outil de gestion de données en collaboration étroite avec le départment IT, afin d’aider la communauté Arval à se doter de l’outil qui correspond le mieux à nos besoins.
2) Arval Data Journey :
Vous collaborerez à la mise en œuvre de la ""Arval Data Journey"", un nouveau parcours pour mieux comprendre, gérer et faciliter l’usage des données :
En contribuant à l’implémentation du process
En aidant à la création de formations spécifiques sur ce nouveau process
En accompagnant le business dans la réalisation de celles-ci.
3) Inventaire des problems de qualité des données:
Vous contribuerez à la mise en place d’un process pour détecter et rapporter des problèmes de qualité de données au sein d’Arval, vous en informerez les acteurs clés et mettrez en place avec eux des plans d’action afin de résoudre les problèmes de qualité de données.
4) Evènements autour de la donnée
Vous contribuerez à l’organisation de divers évènements autour de la donnée et notamment du séminaire Data Governance, réunissant l’ensemble de nos relais locaux, qui se tiendra aux alentours du mois d’octobre/novembre 2020.
5) Reporting sur les activités du département Data Strategy:
Vous proposerez un format permettant un reporting optimisé des activités du départment Data Strategy (nombre de projets réalisés, facteurs clés de succès, retour sur investissement des projets…) et assurererez la bonne diffusion de celui-ci au sein d’Arval.

L’environnement de travail c’est important !


La nouvelle stratégie d’Arval s’appuie sur 4 piliers : Data, Digital, People et Process. Pour ce faire, un département « Data Strategy » a vu le jour en octobre 2018.
Les missions de ce département sont les suivantes :
Créer un environnement favorable pour améliorer la qualité des données, en assurer l’intégrité et la protection.
Créer de la valeur ajoutée des données pour l’intérêt général.
Embarquer l’ensemble des collaborateurs Arval dans la « Arval Data Journey » qui est un parcours visant à mieux comprendre, gérer et utiliser les données.
Le département Data Strategy se compose de deux piliers :
l’équipe Data Governance composée de 3 personnes au siège central et de 26 personnes dans les entités qui vise à couvrir les questions de qualité, d’intégrité et de protection des données.
l’équipe Data Intelligence composée de plus ou moins 10 data scientists au siège et d’approximativement 40 data analysts/data scientists répartis dans l’ensemble de nos entités. Ce département aide l’ensemble des autres départements Arval a généré de la valeur au travers des données.
Vous rejoindrez comme alternant l’équipe Data Governance centrale, située au siège d’Arval, dans un environnement international situé à Rueil-Malmaison.



Parce que nous avons besoin de vos compétences !


Vous préparez une formation supérieur de niveau bac+4/5 en école d’ingénieur avec une spécialisation en Data

Compétences techniques :

Domaine d’expertise: Data, Mathématiques, Statistiques, Actuariat
Connaissance des outils: Open source (R, Python, ..), Spark, SAS, SQL, ETL, MS, etc
Anglais Courant"
Paris 7e (75),CDI,,INGENIEUR QUANTITATIF SENIOR DATA SCIENTIST F/H,CAISSE DES DEPOTS ET CONSIGNATIONS,- Paris 7e (75),"Le recrutement à la Caisse des Dépôts est fondé sur les compétences, sans distinction d'origine, d'âge, ni de genre. Tous nos postes sont ouverts aux personnes en situation de handicap.

Afin de développer son pôle modélisation, le service recherche un modélisateur du risque de crédit, dont les principales missions porteront sur :

Le développement de modèles de notation basés sur les fondamentaux de l'analyse financière, et le management des modèles existants (backtestings annuels, maintenance applicative, etc.) ;

Le développement de modèles de probabilités de défauts et de recouvrement (paramètres bâlois et IFRS9) et le management des modèles existants : PD, LGD et CCF ;

Le développement d'outils de scoring, notation et/ou probabilités de défaut pour des émetteurs non conventionnels (Fonds) ;

L'adaptation des processus de modélisation aux recommandations règlementaires ;

La mise en place et/ou la maintenance d'une infrastructure sécurisée et automatisée (formalisation et maintenance des bases de données, travaux statistiques sous SAS et Matlab) ;

La représentation du service dans le cadre du stress testing transversal, sur le volet crédit ;

La diffusion des connaissances réglementaires auprès des interlocuteurs de la Direction des Risques du Groupe ;

La participation à la refonte des systèmes d'information et projets transversaux ;

La maintenance des outils informatiques : analyse des besoins, élaboration de cahiers des charges, suivi des réalisations informatiques (projets & maintenance) ;

Une veille scientifique sur les techniques candidates, en lien avec les technologies big bata et machine learning.

Vous pourrez par ailleurs être amené(e) à participer à des projets transversaux liés à votre activité.
Profil recherché BAC+5 de formation mathématique,

Expérience avérée en modélisation statistique, en particulier du risque de crédit

Compétences mises en oeuvre :
Bonne maîtrise d'au moins un des langages de programmation : Python, SAS, R

Connaissance de la réglementation bâloise,

Excellent niveau rédactionnel

Motivation, autonomie, esprit d'équipe, disponibilité

Notre organisation est attachée à promouvoir au quotidien un mode de travail collaboratif. Au-delà, vous pourrez nous apporter

Vos connaissances financières et ainsi que votre d'esprit d'analyse et de synthèse et vos qualités rédactionnelles.

Votre excellent relationnel qui vous permet de vous adapter facilement à des environnements divers et exigeants.
Entreprise Etablissement financier Public, la Caisse des Dépôts est un investisseur de long terme au service de l'intérêt général et du développement économique des territoires. Elle agit en appui des politiques publiques conduites par l'Etat et les collectivités locales.

Elle assure également la gestion de grands mandats publics et intervient comme banquier du service public de la justice et de la sécurité sociale.

L'ENVIRONNEMENT DU POSTE

Le poste est rattaché au responsable du Service Ingénierie Financière de la Direction des Risques du Groupe (DRG).

Le service est chargé de l'évaluation et du suivi de la qualité de crédit des contreparties de prêts (organismes de logements sociaux et collectivités locales notamment) et des contreparties de portefeuilles financiers (grandes banques, groupes industriels et commerciaux, Etats, titrisations) qui émettent sur les marchés de taux. A ce titre, le service est chargé de la conception et du management des outils de notation interne et de calibrage des probabilités de défauts et probabilités de recouvrement.

Le poste est basé à Paris 7ème."
Paris (75),CDI,,Data Scientist Senior H/F (Paris),Keyrus,- Paris (75),"#DataEnthusiast, mordu d'innovation et explorateur de données, vous souhaitez rejoindre une équipe d’Experts exigeants, créatifs et #InnovationCentric ?
N’hésitez plus ! Cette offre est faite pour vous!
L’Equipe:
Au sein de notre équipe de Conseil, d’expertise et de Delivery Data, notre team Data Science accompagne nos clients dans la résolution de leurs problématiques métier. Véritables chefs d’orchestres de la Data, ils utilisent leur créativité, des algorithmes de Machine Learning et de Deep Learning, de l’intelligence artificielle pour répondre à ces problématiques.
Leurs défis ?
Proposer de nouvelles approches méthodologiques, mettre en place des POCS, tester leur faisabilité
Identifier et proposer de nouveaux cas d’usages à nos clients
Former, évangéliser, partager leurs connaissances

Vos missions :
Conseil et Expertise Data science
Accompagner nos clients dans la formalisation de leurs besoins métier sous forme de problématiques Data Science claires et réalisables
Explorer de larges volumes de données hétérogènes et complexes afin d’en extraire des connaissances utiles pour la prise de décision et les restituer aux métiers
Mettre en place des modèles de Machine Learning et de Deep Learning permettant de modéliser des phénomènes complexes et de répondre aux besoins variés de nos clients (détection de fraude, maintenance prédictive, etc.)
Participer, en étroite collaboration avec les Data Engineers, à l’industrialisation et la mise en production des modèles et des pipelines de transformation de données développés
Veille technologique et formation
Chez Keyrus, vous serez toujours incité à améliorer vos connaissances et stimuler votre créativité. Vous participerez à la présentation de notre approche Data Science en interne, mais également auprès de nos clients et partenaires.
Contribuer aux activités R&D de Keyrus autour de l’Intelligence Artificielle (rédaction de blogs et d’articles techniques, participation à des conférences et des événements autour de l’IA, implication dans des projets IA en interne, etc.)
Veille technologique et animation de la communauté IA de Keyrus : vous serez toujours incité non seulement à améliorer vos connaissances mais également à les partager avec vos collègues"
Paris (75),"Apprentissage, Contrat pro",,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
Dirigée par le Chief Data Officer et rattachée directement au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques (DDSA) se compose de cinq services. Elle met en œuvre la stratégie définie par le Chief Data Officer afin que la Banque transforme ses données en un capital pleinement valorisé.
La DDSA a pour missions essentielles la gouvernance, le partage et la valorisation des données, le développement de projets d'intérêts communs, le développement d'une culture de la donnée et la contribution à la data réputation de la Banque.

Présentation du Service
Au sein de la Direction des Données et des Services Analytiques (DDSA), le Service des analyses quantitatives et méthodes avancées (QUANTIM) développe un savoir-faire en matière d'analyse quantitative des données en s’appuyant plus particulièrement sur les méthodes innovantes issues de la data science et offre son expertise dans le cadre de travaux menés en coopération avec les autres services de la Banque sur des problématiques métier très variées.
Le QUANTIM contribue également à la mise en œuvre de la plateforme analytique du Datalake de la Banque ainsi qu’à l’animation de communautés dédiées aux méthodes de traitement des données et à l’accompagnement de tous les utilisateurs de R.

Descriptif de mission
En tant qu’Alternant Data Scientist au sein du QUANTIM, vous serez intégré(e) à une équipe de 10 personnes.
Les missions qui vous seront confiées pourront notamment porter sur l’une ou l’autre des thématiques suivantes :
• À partir des bases de données disponibles à la Banque (sur le portail statistique public Webstat ou, en interne, le Datalake de la Banque), développer des outils permettant de recommander automatiquement des séries explicatives (à partir de différentes corrélations, corrélations glissantes, cohérences d'ondelettes, etc.) s'apparentant à l'ancien outil de Google appelé Google Correlate ;
• À partir des bases de référentiels disponibles à la Banque, mettre en place des outils de visualisation des groupes bancaires et financiers en s'appuyant sur les méthodes d’analyse des réseaux ;
• À partir des articles de presse quotidienne disponibles sur Internet, contribuer à l’analyse de l'information textuelle afin d’estimer le niveau d'incertitude économique en général et, à la discrétion des autorités de la Banque, liée à une problématique précise (coronavirus par exemple).

Profil recherché
Formation recherchée : Grande école ou Master 2 en data science ou en économétrie / statistiques avec une forte appétence pour la data science
Compétences : machine learning, text mining, webscraping, datavisualisation, graph mining, séries temporelles, programmation R/Python, connaissances en anglais (littérature académique)
Qualités : rigueur, réactivité, autonomie et curiosité ; esprit d’initiative, sens aigu de l’innovation
Une première expérience significative (stage de 6 mois, projet annuel en groupe ou mémoire ) dans la pratique de la data science constituera un atout.

La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes recrutées."
Paris (75),,,Visiting Scientist (AI),Facebook,- Paris (75),"Facebook is seeking Visiting Scientists to join our Facebook Artificial Intelligence Research team. Individuals in this role are expected to be recognized experts in identified research areas such as artificial intelligence, machine learning, computational statistics, and applied mathematics, particularly including areas such as deep learning, graphical models, reinforcement learning, computer perception, natural language processing and data representation. The ideal candidate will have a keen interest in producing new science to understand intelligence and technology to make computers more intelligent. Term length would be considered on a case-by-case basis and is often fulfilled during a faculty sabbatical term.
Visiting Scientist (AI) Responsibilities
Perform research to advance the science and technology of intelligent machines.
Perform research that enables learning the semantics of data (images, video, text, audio, and other modalities).
Devise better data-driven models of human behavior.
Contribute research that can be applied to Facebook product development.
Influence progress of relevant research communities by producing publications.
Contribute research that can be applied to Facebook product development.
Collaborate and increase productivity on Research Scientists' projects as a contributing team member.
Minimum Qualifications
Currently holding a faculty or government researcher position with intention of returning after conclusion of contract.
Ph.D. and publications in Machine Learning, AI, computer science, statistics, applied mathematics, data science, or related technical fields.
Has defined a short-term project to work on within FAIR for the duration of the contract.
Experience in theoretical and empirical research and for solving problems with research.
A track record of driving original scholarship in collaboration with a team.
Ability to communicate research both in writing and for public audiences of peers.
Knowledge in a programming language
Academic publications in the field of machine learning.
Ability to obtain and maintain work authorization in the country of employment in 2018.
Preferred Qualifications
First-author publications at peer-reviewed AI conferences (e.g. NIPS, CVPR, ICML, ICLR, ICCV, and ACL).
Experience mentoring junior scientists within an academic, industry, or government lab.
Previous full-time research experience in an AI research organization.
Experience in developing and debugging in C/C++, Python, C# and/or Java.
Facebook's mission is to give people the power to build community and bring the world closer together. Through our family of apps and services, we're building a different kind of company that connects billions of people around the world, gives them ways to share what matters most to them, and helps bring people closer together. Whether we're creating new products or helping a small business expand its reach, people at Facebook are builders at heart. Our global teams are constantly iterating, solving problems, and working together to empower people around the world to build community and connect in meaningful ways. Together, we can help people build stronger communities — we're just getting started.
Facebook is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations-ext@fb.com."
Paris (75),"Apprentissage, Contrat pro",,ALTERNANCE - Chargé d'actuariat produit - Data Scientist H/F,Credit Agricole Assurances,- Paris (75),"Crédit Agricole Assurances, premier assureur en France, rassemble les filiales assurances du Crédit Agricole. Le groupe propose une gamme de produits et services en épargne, retraite, santé, prévoyance et assurance des biens. Ils sont distribués par les banques du groupe Crédit Agricole en France et dans 9 pays dans le monde, par des conseillers en gestion patrimoniale et des agents généraux. Les compagnies de Crédit Agricole Assurances s'adressent aux particuliers, professionnels, agriculteurs et entreprises. A fin 2018, Crédit Agricole Assurances compte 4 600 collaborateurs et son chiffre d'affaires s'élève à 33,5 milliards d'euros (normes IFRS).
Référence
2020-47808
Date de parution
10/05/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Assurances
Types de métier complémentaires
Types de métiers Crédit Agricole S.A. - Analyse financière et économique
Types de métiers Crédit Agricole S.A. - Systèmes d'information / Maîtrise d'Ouvrage
Type de contrat
Alternance / Apprentissage
Durée (en mois)
12
Cadre / Non Cadre
Non cadre
Missions
Au sein de la Direction actuariat, vous serez rattaché à l'équipe actuariat produit épargne et retraite. L'équipe est en charge du suivi technique des produits d'assurance vie, de retraite individuelle et de retraite collective.

Le service a mis en place des lois strucutrelles sur les rachats, décès et arbitrages selon des méthodes statistiques classiques. Les nouvelles techniques utilisées par le Big Data pourraient permettre d'améliorer ces lois.

Vous serez chargé de poursuivre les travaux commencés par le CEDS sur les lois de rachat et mettre en œuvre les mêmes procédés pour de nouveaux risques.
Votre mission consistera à donner de la valeur ajoutée aux données collectées par Crédit Agricole Assurance. Pour cela le candidat prendra en charge l'intégration de la matière Big Data au sein de l'équipe et devra poursuivre les travaux initiés par le CEDS.

A ce titre, vos principales missions seront de :

Comprendre les données (statistiques descriptives)
Se familiariser avec l'algorithme actuellement développé en Python (rachats Euro)
Continuer les travaux en collaboration avec le CEDS sur les rachats UC
Déployer la méthodologie à d'autres risques

Enfin le candidat devra transmettre les informations et analyses recueillies au travers de différents moyens de communications : formations, évènements techniques, présentations.
Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 75 - Paris
Ville
Paris
Critères candidat
Niveau d'études minimum
Bac + 4 / M1
Formation / Spécialisation
Diplôme en Statistiques/actuariat ou Data Science/IT
Niveau d'expérience minimum
0 - 2 ans
Compétences recherchées
Compétences techniques :
statistiques / Probabilités avancées
goût prononcé pour les sujets alliant la R&D et l'IT

Compétences personnelles :
rigueur
créatif
proactivité

Compétences relationnelles :
capacité d'intégration
esprit d'équipe
bon sens rédactionnel
Outils informatiques
SAS / Excel
Python / PySpark

Le candidat doit être familier avec l'écosystème Python (Librairies Xgboost, Scikit-learn, NumPy, etc…)"
Paris (75),,,CDI - SGI - Referential Data Officer,SCOR,- Paris (75),"EMEA
Paris France (FR)
|
CDI - SGI - Referential Data Officer
Permanent
Asset Management
About SCOR
SCOR, the 4th largest reinsurer in the world, provides insurance companies with a diversified and innovative range of solutions and services to control and manage risk. Using its experience and expertise, “ The Art & Science of Risk ”, SCOR provides cutting-edge financial solutions, analytics tools and services in all areas related to risk – in Life & Health insurance as well as in P&C insurance. Our specialist teams operate in over 120 countries, developing value added and innovative products and services and making long-term commitments to their clients, namely insurers and large corporations.
SCOR's aim, as an independent global reinsurance company, is to develop its Life and P&C business lines, to provide its clients with a broad range of innovative reinsurance solutions and to pursue an underwriting policy founded on profitability, supported by effective risk management and a prudent investment policy, in order to offer its clients an optimum level of security, to create value for its shareholders, and to contribute to the welfare and resilience of Society by helping to protect insureds against the risks they face.
- Department
Investment Business Performance
- Job Summary
SCOR Global Investments (“SGI”) is the division of SCOR Group dedicated to asset management. SGI pursues two main missions:
defining centrally SCOR’s asset allocation, managing and monitoring its implementation and
developing a profitable third-party asset management activity through its portfolio management subsidiary, SCOR Investment Partners.
The Investment Business Performance department is part of SCOR Asset Owner functions. It aims at providing investment services to the Group, as well as financial analysis and controlling. It is composed of the following teams:
Investment Data & Projects;
Investment Record Keeping;
Investment Planning & Analysis;
Strategic Investments.
The Investment Data & Projects team’s mission is to centralize data acquisition, data management and data controls on investments for all SCOR stakeholders. It is in charge of managing, developing and maintaining the golden source of investment data which is used across the Group for all types of reports related to investments.
The team will also lead SCOR Asset Owner projects all along their lifecycle from the design to their roll out. It also ensures the relevance and consistency of the functional architecture across the data value chain. In addition, the team will be in charge of the production and corrective maintenance of legacy systems.
- Key duties and responsibilities
Key duties and responsibilities of the position include the following:
Securities creation and data entry (e.g. principal factors, pool factors, loans, etc.), cleaning and performing data management activities related to production in dedicated tools and systems;
Perform daily data management on securities, including first-level controls;
Manage investments pricing policy (ensure price feeding from various sources, gathering of contributed prices, pricing waterfall management);
Act as single point of contact for users and clients across the Group, respond to their queries for information, identify, assess and resolve issues and problems in a timely manner;
Seek advice and escalate issues when facing tasks / problems outside normal scope of role;
Establish and build knowledge of relevant processes (investment reporting, prudential and regulatory reporting) and related systems to effectively perform responsibilities, meet all quality and compliance standards and requirements;
Ensure adequate preparation for data management audits and answer questions that arise during audits;
Apply procedures to ensure accuracy of output and adopts continuous improvement approach;
Update data management documentation, participate in the development of standard operating procedures and guidelines.
The Referential Data Officer could also participate to SGI or Group projects on an ad-hoc basis.
- Required experience & competencies
Experience
At least 4 years of prior experience in a similar environment
Knowledge on market data and market instruments, accounting knowledge is appreciated
Personal Competencies
Global knowledge of Data / BI tools and uses cases
Strong attention to details
Strong customer focus and excellent teamwork abilities and relationship-building skills
Autonomy, rigor and dynamism
Good command of English (written and spoken)
Digital Competencies
Pack Office
Knowledge of SimCorp Dimension, Markit EDM and Bloomberg is appreciated
- Required Education
Bachelor’s or Master’s degree, with a specialization in Finance"
Paris (75),Stage,,Stage – 6 mois – Chargé(e) de data science H/F – Paris 13ème,Natixis,- Paris (75),"Because you deserve much more than just a job.
Bienvenue chez Natixis, l’entreprise qui vous offre bien plus qu’un job.
Avec 921,5 milliards d'euros d'actifs sous gestion au 31 décembre 2019, le modèle multi-affiliés de Natixis Investment Managers (« Natixis IM ») offre un accès unique à plus de 24 sociétés de gestion spécialisées aux Etats-Unis, en Europe et en Asie. Natixis IM se positionne parmi les plus grandes sociétés de gestion d'actifs au niveau mondial.
Signataire de la Charte de la diversité, Natixis veille à promouvoir tous les talents et à accompagner le développement de chacun. Elle est certifiée Top Employer France 2019 (pour la 3e année consécutive) et HappyTrainees.
Mission
Vous rejoignez notre équipe au sein de notre service d'audit interne, qui recherche un(e) chargée de data science, pour un stage de 6 mois à partir du 1er avril 2020.
En collaboration avec votre tuteur qui vous accompagnera tout au long de vos missions, vous :
Participerez à la création d'une plateforme data (ETL, DataFlow, Datawharehouse);
Participerez également à l’identification et au développement des apports de la Data Science dans l’amélioration de la pertinence des audits (analyses de gros volumes de données, analyses textuelles, smart sampling, identification de zones de risque, etc.) et de l'efficacité opérationnelle (automatisation de tâches, scripting etc..);
Accompagnerez et assisterez l’équipe d’audit dans ses travaux d’exploration et d’analyse des données lors des missions;
Animerez l’initiative Data-Science auprès des auditeurs (animation d'ateliers, formations etc...).
Profil recherché
Vous & Beyond
C’est avant tout votre personnalité et votre état d’esprit qui nous intéresse.
Etudiant de niveau bac+4, vous préparez un diplôme universitaire ou d’école de commerce, avec une spécialisation en informatique (CCA ou MIAGE).
Vous connaissez le langage informatique (SQL, VBA, Python)?
Vous maîtrisez les outils (Numpy, Scipy, Pandas, Scikit-learn, tensorflows, pytorch, keras,Pyspark, Elasticsearch,...) ?
Vous possédez des connaissances en mathématiques : Statistiques, Mesure, Probabilités, Processus Stochastiques, Séries Temporelles, Théorie des jeux ?
Vous maîtriser parfaitement le pack office ?
Vous avez les notions de base sur les algorithmes de Machine Learning ?
Vous détenez de bonnes capacités de recherche, d'analyse et de synthèse ?
Vous vous épanouissez dans un environnement jeune et stimulant ?
Alors vous êtes fait pour ce job et nous avons besoin de VOUS !
Vous bénéficierez d’un accompagnement dédié pour vous donner toutes les chances de réussir cette nouvelle mission."
Paris (75),"Temps plein, CDI",,Machine Learning Specialist,USA Recruitment,- Paris (75),"Machine Learning Specialist – Machine Learning / Transfer Learning / Causal Inference / High Dimensional Time Series / Optimization Methods:
Here is your chance to join a world renowned company and their team of deidcated machine learning researchers. You could be working in Paris and specialising in reinforcement learning and control, time series forecasting, anomaly detection, structured data and optimization.

There are two separate research positions open for this role, with these required specialialities:

1. Transfer learning and causal inference on high dimensional time series data.
2. Optimization methods for machine learning.

If you meet the criteria for either of these roles, then please apply below…

What You Would be Doing:
Performing research on one of the two topics outlines above, and publishing your findings in top machine learning conferences.
Applying these results to real projects, providing high quality solutions for 4G and 5G telecom network operation and maintenance including user behaviour prediction, device failure prediction and fault diagnosis.

What You Need:

Ph.D. in relevant field.
High quality publications in machine learning related conferences or journals.
Strong programming skills – Python, C/C++, Java etc.
Position 1 – Good knowledge in transfer learning (especially domain adaptation, multi-task learning, semi-supervised learning, weak supervised learning and small sample learning), casusal inference and time series data analysis.
Position 2 – Good knowledge in first-order optimization methods for machine learning, especially for the training of deep learning architectures.

Key Words:
Machine Learning / Transfer Learning / Causal Inference / High Dimensional Time Series / Time Series / Optimization / Reinforcement Learning / Forecasting / Anomaly Detection / Structured Data / Python / C / C++ / Java / Publications / 4G / 5G / Telecomms / Research / Deep Learning / Architecture

#Machine Learning Jobs

By applying to this role you understand that we may collect your personal data and store and process it on our systems. For more information please see our Privacy Notice https://eu-recruit.com/about-us/privacy-notice/"
Paris (75),"Temps plein, CDI",,Consultant(e) Data senior H/F,earlycareers-dentsuaegisnetwork,- Paris (75),"Pilotage de comptes clients et participation au développement de l'activité au sein du pôle créatif de Dentsu
Job Title:
Consultant(e) Data senior H/F
Job Description:
La mission couvre les sujets suivants :
Participer au design d’expériences innovantes faisant de la data un enjeu stratégique
CRM/PRM avec des problématiques de fidélisation , recrutement, attrition, appétence et performance commerciale
Plan d’animation avec une dimension opérationnelle et une dimension de conseil sur la stratégie relationnelle
Innovation, avec la création de nouvelles solutions pour répondre aux besoins de nos clients avec des propositions différenciantes sur le marché
Participer aux réponses aux appels d’offres
Profil
Vous êtes issu(e) d’une école de statistiques, d’une formation supérieure en économie / gestion / statistiques ou d’un cursus informatique avec spécialisation statistique. Vous avez 5 à 7 ans d’expérience en agence de communication ou chez un annonceur sur le sujet des datas appliquées au CRM et au e-CRM et de l’analyse de données.
Vous maîtrisez parfaitement les outils statistiques et bureautiques du marché (R, sas, Python...)
De nature dynamique, doté d’un bon relationnel, vous appréciez le travail en équipe, et vous souhaitez évoluer dans un contexte stimulant.
Rigueur, autonomie, sens critique, curiosité, leadership et sensibilité marketing et busines sont des qualités que vous avez pu éprouver lors de vos précédentes expériences.
Vous êtes sensible aux problématiques de digitalisation de notre monde et êtes attiré(e) par la mise en œuvre de nouvelles idées.
Vous parlez Français et Anglais couramment.
Location:
Paris - 4 Place de Saverne
Brand:
Isobar
Time Type:
Full time
Contract Type:
Permanent"
Paris (75),"Temps plein, CDI",,Machine Learning Specialist – AI / ML / DL / Linux,USA Recruitment,- Paris (75),"Machine Learning Specialist – AI / ML / DL / Linux / Reinforced Learning

This is the ability to join a exicting organization to work in a state-of-the-art R&D centre which will contribute to the development of disruptive apps/products.

The ideal candidate will have these key requirements & skills:

Ability to solve novel machine learning problems.
Strong knowledge and understanding of algorithms and data structures.
Detailed knowledge of ML evaluation metrics and best-practice
Prior experience of Python coding skills plus experience of a typed language (e.g., C++ and Java)
Ability to use existing deep / machine learning libraries (e.g., TensorFlow, Torch, Theano, Caffe, and scikit-learn).

Key Words: AI / Machine Learning / Deep Learning / Linux / Reinforced Learning / Algorithms / Data Structure / Python / C++ / TensorFlow / Caffe / Pytorch

By applying to this role you understand that we may collect your personal data and store and process it on our systems. For more information please see our Privacy Notice https://eu-recruit.com/about-us/privacy-notice/"
Paris 16e (75),,,ARCHITECTE BIG DATA,InnoValeur,- Paris 16e (75),"Vous êtes une licorne et avez l’esprit startup ? Vous cherchez une structure où l’on fait les choses sérieusement mais on ne se prend pas au sérieux ? Vous souhaitez participer à des projets ambitieux et évoluer sur une variété de problématiques ? Vous avez l’esprit de service et une vision en plus de vos compétences technologiques ? Vous cherchez l’excellence et à rester à la pointe de votre domaine ? Vous êtes animé par l’esprit d’équipe et souhaitez évoluer dans un parcours Fast Track ?
Nous cherchons des architectes Big Data capables de comprendre les enjeux métier de nos clients et de les traduire en solutions concrètes et pragmatiques.
VOTRE PROFIL
Vous avez au moins 7 ans d’expérience dans la gestion des données massives et leur exploitation en termes de prédictif et de DataViz.
Vous maitrisez les technologies ETL, ainsi que les bases de données relationnelles et Big Data. Vous avez une expérience probante sur une distribution Hadoop majeure du marché, et connaissez l’intégration avec les outils de data science et de BI.
Vous êtes expert sur les enjeux et outils Big Data ( MapReduce, Python, Spark, R, ElasticSearch, Kibana…) et NoSQL (MongoDB, HBase, Neo4j, Cassandra…). Vous maitrisez les moteurs de recherche et êtes capable de les interfacer avec les SI internes, autant qu’avec les API ou autres services externes.
Vous connaissez les langages de script et savez créer des interfaces pour l’acquisition en Data Lake, et pour l’exploitation des différentes sources (applicatives, web, logs, databases, bus de données, données non structurées au format texte, audio, video,…)
Vous connaissez les problématiques de gouvernance et d’interopérabilité des données en environnements massivement parallèles et en maitrisez les problématiques architecturales.
Vous êtes capable de définir les architectures cibles en fonction des infrastructures existantes, et de les intégrer aussi bien dans les systèmes existants de nos clients qu’en mode SaaS.
Idéalement vous avez déjà encadré des équipes et avez une expérience probante dans le domaine du conseil.
Une spécialisation sectorielle dans la banque-assurance, les FMNG et retail, le pharmaceutique, ou la logistique sera valorisée.
VOUS RESPONSABILITES
Concevoir des architectures et infrastructures Big Data.
Participer aux phases amont des projets : animation d’ateliers d’architecture, dimensionnement des infrastructures en lien avec les autres prestataires.
Identifier les problématiques de nos clients et définir les socles technologiques adéquats.
Réaliser des missions de conseil et d’accompagnement et aligner les enjeux de BigData avec ceux des intervenants en Data Science et Dataviz.
Interagir avec nos équipes de Data Scientists et experts en Machine Learning et Intelligence Artificielle pour prendre les meilleures options.
Assurer un suivi quotidien avec nos clients pour appréhender leurs besoins et être force de proposition.
Selon le contexte, mettre en œuvre de façon autonome les solutions et/ou encadrer les équipes pour les phases d’implémentation.
Encadrer techniquement des consultants et les équipes de nos clients, et les faire progresser sur l’usage des technologies de l’écosystème Big Data."
Paris (75),Stage,,Data Scientist : Analyste Sémantique Appliquée / Chatbot - Stage de fin d'études,Beijaflore,- Paris (75),"Fondé en 2000, Beijaflore est un cabinet de conseil opérationnel en stratégie digitale présent à l’international avec des bureaux à Paris, Bruxelles, Rio de Janeiro, Sao Paulo et New York. Il regroupe plus de 1250 collaborateurs animés par une mission commune : accompagner de manière opérationnelle les entreprises dans la mise en œuvre de leur stratégie digitale.
Avec son entité Graphène Advisory, Beijaflore accompagne les entreprises dans la valorisation de leurs données par des projets Intelligence Artificielle. En proposant des solutions complètes, partant de l’identification des use cases au développement de la solution et son déploiement, Graphène Advisory amène les entreprises à créer leurs business de demain. Ces solutions sont basées sur du Machine Learning et l’IA articulés sur des architectures flexibles, modulaires et scalables appelées architectures Big Data. L’analyse sémantique et ses nombreuses applications comme le ChatBot est devenue un enjeu majeur d’optimisation opérationnelle des entreprises. Au-delà de ces applications métiers, l’analyse sémantique atteint aujourd’hui une maturité permettant les interactions entre l’humain et l’intelligence artificielle.
Vous souhaitez rejoindre une équipe multidisciplinaire et complémentaire qui accompagne ses clients dans la réalisation de projets autour de l’IA et du Machine Learning ?
Dans le cadre du développement de solutions appliquées comme l’analyse de sentiments et de textes, vous serez en charge de développer un moteur d’analyse sémantique basé sur trois méthodes différentes et de l’appliquer au contexte de la finance de marché (activité de support, de recherche ou d’aide à la décision). Vous serez plus particulièrement chargé(e) de :
Etudier la bibliographie sur les nouvelles méthodes d’analyse de textes et de documents
Identifier trois méthodes d’analyse sémantique (statistique, réseau de Neurones, …)
Tester et appliquer ces méthodes au domaine de la finance de marché (courbe de taux, courbe de volatilité).

Afin de mener à bien vos missions, vous avez les compétences suivantes :
Maîtrise des techniques d’analyse sémantique et des agents conversationnels
Introduction aux réseaux de neurones et données non structurées
Maîtrise des méthodes de Machine Learning (classification et clustering)
Maîtrise des outils data science (R, Python, Scala)

Etudiant(e) Bac+5 d’une Grande Ecole d’ingénieur, vous suivez un Master ou une spécialisation en Data Science. Vous êtes autonome, persévérant(e) et rigoureux(se). Vous appréciez également le travail en équipe.
La qualité de nos stages a été récompensée par l’obtention du label Happy Trainees / Choose My Company. Parce que nous avons à cœur de développer les potentiels de chaque étudiant, nous vous formons pendant toute votre période de stage de fin d’études dans une optique d’embauche.
80% de nos stagiaires nous rejoignent en CDI.
Rejoignez Graphène !"
Paris 10e (75),,,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong

Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),Stage,,Stage 6 mois - Chargé(e) d’étude Gouvernance Data H/F,Allianz France,- Paris (75),"Rattaché(e) à la Direction Architecture d’Entreprise et Gouvernance de la Donnée au sein d'Allianz France.
Dans le cadre de la mise sous surveillance des données clés pour Allianz, vos principales missions seront de :

Concevoir et réaliser des analyses de profil (Complétude / Conformité / Précision).
Mise en place de Dashboard QDD (Qualité De Donnée) et analyse de risque pour restitution aux Data Owners
Automatisation des Dashboards et accompagnement de l’équipe Gouvernance de la Donnée pour la structuration des analyses
Cartographie et Mise sous surveillance des données dans un nouvel outil de gouvernance (configuration d'un logiciel de marché)
Les atouts du poste ?

> Equipe nouvelle, idéale pour un profil aimant les challenges !
> Vision très transverse de l’entreprise – la Gouvernance de la Donnée doit supporter tous les métiers (Distribution / Technique / Finance / Client & Communication / etc) de l’entreprise et tous les domaines assurentiels (Assurance de Biens et responsabilités / Assurances de Personnes))

Il sera attendu un niveau de bac +4/5 d'écoles telles que l'ISUP / ENSAE / CENTRALE - SUPELEC / TELECOM PARIS TECH / autres écoles d’ingénieur équivalente / avec une spécialité dans l’analyse de données et le Big Data

Une maitrise des techniques d’analyse statistiques pour traiter un grand nombre de données.
Une maitrise de SAS, Excel, Python et goût pour la programmation afin d’automatiser les analyses.
Une forte adaptabilité à des demandes exigeantes à court-terme.
Des compétences dans le domaine Big Data et Data visualisation.
Une capacité d’analyse, rigueur, organisation.
Une maîtrise de l'anglais.

Gout de la transversalité et le travail en équipe.
Curieux et intéressé par des problématiques très variées !

La connaissance de la modélisation en machine learning et IA est un plus."
Suresnes (92),"Temps plein, Intérim, CDD, Apprentissage, Contrat pro",,Alternance - Chargé(e) d'études statistiques (F/H),AXA Global Direct France,- Suresnes (92),"Rattaché(e) à l’équipe Claims Analytics de la Direction des Sinistres d’AXA Direct France, vous contribuerez au suivi et à l’amélioration des processus de gestion de la sinistralité des contrats automobile et habitation.

Vos missions principales sont les suivantes :

Participer à la stratégie de la direction des sinistres en dérivant des indicateurs robustes en lien avec les différents pôles de la direction ;
Comprendre et modéliser (GLM et Machine Learning principalement) des processus de sinistres pour simplifier l’expérience client et améliorer la rétention ;
Conduire des analyses innovantes permettant de donner davantage de visibilité au top management sur l’ensemble des postes d’indemnisations sinistres afin de maitriser la charge technique.

Qualifications
Nous recherchons un profil :
Etudiant(e) de formation supérieure de niveau Bac+4/5 en statistiques, data science ou actuariat avec les compétences suivantes ;
Très bonne connaissance en statistique inférentielle et en Machine Learning ainsi que des principaux concepts sous-jacents ;
Maîtrise de la gestion des bases de données, des principaux outils de développement statistiques (SQL, R, Python) et des outils de visualisation des données (Shiny, Rmarkdown, Flask...) ;
Vous possédez de fortes compétences analytiques et êtes curieux(se) ;
Vous avez un esprit de synthèse et des qualités de présentation et de communication.

Le poste est basé à Suresnes (92) à proximité de la Défense.
A propos d'AXA
Aimeriez-vous vous lever chaque jour motivé(e) par une mission inspirante et travailler en équipe pour permettre de protéger les personnes et leurs proches?
Chez AXA nous avons l’ambition de mener la transformation de notre métier. Nous cherchons des personnes talentueuses ayant une expérience diversifiée, qui pensent différemment, et qui veulent faire partie de cette transformation passionnante en challengeant le statu quo et faire d’AXA – marque globale leader et une des sociétés les plus innovantes dans notre secteur – une entreprise encore plus performante et responsable.
Dans un monde en perpétuelle évolution et avec une présence dans 64 pays, nos 165 000 salariés et distributeurs privilégiés anticipent le changement pour offrir des services et solutions adaptés aux besoins actuels et futurs de nos 107 millions de clients.
AXA Direct France, filiale à 100% du groupe AXA opère sur le marché français sous la marque commerciale Direct Assurance. Nous sommes le leader français de l’assurance en ligne, proposant une gamme de produits simple, claire et performante, construite avec, et pour nos clients (Auto, Auto connectée, Habitation, Moto et Emprunteur).
Dans un marché assurantiel très compétitif, AXA Direct France souhaite investir sur l’expérience client en proposant un parcours simple et un tarif adapté, grâce à l’expertise de nos équipes techniques.
Pourquoi nous rejoindre ?
Soucieux de nos collaborateurs, nous proposons des parcours de développement professionnel en adéquation avec la transformation digitale du secteur de l’assurance pour enrichir leur panel de compétences et développer leur employabilité. AXA Direct France, c’est aussi des locaux proposant un cadre de travail moderne avec une mise à disposition d’espaces de détente (baby-foot, cafétéria) et de services (espace forme, places en crèche…) pour une Expérience Collaborateur réussie !

L’Expérience Collaborateur est pour nous essentielle pour la réussite de notre entreprise.

AXA Direct France s'engage en faveur de la lutte contre les discriminations, et porte au quotidien la diversité et l'égalité des chances. Tous nos emplois sont ouverts aux personnes en situation de handicap.

Si ce poste vous intéresse et si la perspective de contribuer fortement au développement de l’entreprise dans un environnement innovant et dynamique vous motive, rejoignez-nous !"
Montigny-le-Bretonneux (78),"Apprentissage, Contrat pro",,Alternance Modélisation en Data Science F/H,Orano,- Montigny-le-Bretonneux (78),"Intitulé du poste

Alternance Modélisation en Data Science F/H
Type de contrat

Alternance
Durée du contrat en mois

12 mois
Vos missions

L’intelligence artificielle sous toutes ses formes connait un regain d’intérêt dans l’ensemble des industries de nos jours pour modéliser, analyser et prédire le comportement de systèmes complexes ne répondant pas à des lois de comportement « simples ». Le procédé de traitement des combustibles usés de La Hague met en jeu une multitude de physiques interagissant la plupart du temps entre elles et souvent sur des problématiques transitoires. Cette typologie rend complexe le développement d’un modèle représentatif basé sur les équations physiques pour reproduire les enregistrements des capteurs sur site. Dans ce contexte, Orano Projets souhaite tester la réponse d’un modèle d’apprentissage (Deep Learning) sur un équipement de La Hague en régime transitoire.
Au sein de la section « Modélisation du Procédé» du département « Procédé, Aménagement et Matériaux», le/ la stagiaire aura pour mission de tester des modèles d’apprentissage sur un équipement spécifique de La Hague afin d’évaluer le potentiel de ces nouvelles techniques et d’ouvrir des perspectives de développement futur.
Ce stage se déroulera selon les étapes suivantes : Prise en main de la problématique et compréhension du fonctionnement de l’équipement (physiques mises en jeu, etc.) ; Interfaçage avec le métier procédé pour extraire de la base de données les relevés sur différentes périodes afin de constituer une DB fiable pour l’utilisation du Deep Learning; Analyse des paramètres à considérer pour l’apprentissage ; Prise en main de l’outil de Deep Learning développé en interne et application sur l’équipement identifié ; Suivant l’avancement, perspectives d’évolution de l’outil et test d’outils plus « industriels » (Pseven par exemple) ; A l'issue du stage, un rapport résumant les compétences développées, la méthodologie mise en place, bonnes pratiques et les principaux résultats sera rédigé.

Le Service modélisation du Procédé intervient en support aux équipes Procédé, de Sûreté (démonstration de sûreté), au dimensionnement d'équipements divers et variés et à l'analyse de leur fonctionnement (situations incidentelles et accidentelles). A ce titre, elle met en œuvre des modèles physiques (Fluent, ANSYS, ACM - solveur d'équations algrébro-différentielles), etc …
Un des développements en essor chez Orano Projets porte sur la data science. Nous avons pour ambition de développer cette activité dans l'équipe en développant des outils d'aide à la prise de décision pour les métiers, de subrogeâtes modèles ou encore pour analyser le fonctionnement d'équipements.

Qui êtes-vous ?

Profil :
Vous disposez d'un niveau BAC+5 (diplôme d'ingénieur ou équivalent universitaire) avec double compétence en modélisation physique et mathématique (en relation avec l’intelligence artificielle) et préparerez à la rentrée prochaine un master spécialisé pour une durée d'un an.

Compétences recherchées:
autonomie et curiosité scientifique,
sens physique,
rigueur dans la démarche,
analyse critique des résultats,
qualités relationnelles (ouverture d'esprit, interactions avec les membres de l'équipe et les experts Orano, etc.),
proactivité pour contourner des difficultés,
bonne expression orale et qualité rédactionnelle,
une connaissance en informatique et machine Learning (Python, Scikit-Learn, Keras, etc.),
bon niveau d'anglais indispensable.
Poste basé sur le site de Saint Quentin en Yvelines (78), établissement soumis à enquête administrative.

Rythme de travail

A définir
Métier

Etudes, conception et ingénierie Localisation du poste à pourvoir
Localisation du poste

Europe, France, Ile-de-France, Yvelines (78)
Ville

Montigny le Bretonneux

Sites d'Orano

Saint Quentin en Yvelines (78) Informations complémentaires
Poste soumis à enquête administrative

oui
Exigences réglementaires

Non spécifié
Poste autorisant le dépistage des stupéfiants dans le cadre de la prévention des addictions

Non Critères du poste demandé
Niveau d'études min. requis

Grande Ecole, Master 2, DESS, DEA
Déplacement

Non
Type de profession

Etudes, conception et ingénierie
Organisation

OP - DTI"
Paris (75),,,Consultant.e Data (F/H),Accenture,- Paris (75),"Au sein d’Accenture, nous vous proposons de rejoindre Accenture Interactive, où vous accompagnerez vos clients pour exploiter le potentiel du digital, afin de doper leur croissance et créer de nouveaux leviers de valeur pour transformer leur activité.
Accenture Interactive cherche à renforcer ses équipes d’experts en data marketing au sein de Sutter Mills, sa dernière acquisition.
Leader en data marketing, Sutter Mills intervient sur l'ensemble de la chaîne de valeur Data, Digitale et Technologique afin d'accompagner ses clients dans la sélection, le déploiement et l’opération d’outils adtech/martech pour mieux exploiter leurs données, améliorer leur connaissance client, accroître l’efficacité de leurs stratégies médias et optimiser leurs investissements marketing.

En tant que Consultant.e Data, quelles seront vos missions ?
Votre rôle
Opérant pour des comptes internationaux dans des secteurs très variés vous travaillerez sur des missions d’envergure pour des clients grands comptes. Vous deviendrez donc un ambassadeur Accenture Interactive en termes d’implémentation de projets big data, gouvernance de données, BI et stockage de données et devrez :

Être en contact avec les parties prenantes clients afin de comprendre les besoins opérationnels, travailler en collaboration directe avec des équipes cross-fonctionnelles data & produits et aboutir sur la construction de solutions data efficientes
Implémenter des data warehouse & data lakes et s’assurer de la délivrabilité des projets
Faire le lien entre les équipes technique et business et savoir agir sur les deux tableaux
Exécuter des analyses des architectures de données et fournir des recommandations basées sur l’expertise acquise

Le métier de Consultant.e Data est fait pour vous si :

Votre profil
Diplômé.e d’études supérieures bac+5 (école d’ingénieurs, école spécialisée ou équivalent universitaire), vous avez au moins 5 ans d’expérience en Data/Big Data ainsi qu’une expérience confirmée en conseil ou en gestion de projet.

Vous avez les compétences suivantes :
Connaissance des technologies Big Data (Hadoop, Hive, Spark, MPP databases, distributed RDBMS)
Maîtrise des outils et concepts ETL (Talend, Informatica, etc.)
Solides connaissances des standards de modélisation de données
Connaissance des méthodologies de gestion de projet
Intérêt pour le cloud et les innovations appliquées au domaine de la data
Excellente communication orale et écrite en français et en anglais

Valeur ajoutée:
Expérience dans le développement informatique et automatisation
Connaissance d’au moins un langage de programmation (Python, Java, Scala, etc.)
GCP/AWS ou autres certifications cloud

Nous recherchons avant tout quelqu’un de passionné par la Data et le digital, qui fait preuve de curiosité intellectuelle et qui a le goût de l’innovation et de la collaboration.
Votre profil correspond et vous êtes en recherche d’un nouveau challenge excitant ? N’hésitez pas et venez à notre rencontre !

Ce que nous vous offrons:

Monter en compétences sur des outils et des sujets innovants
Assister à des workshops et des formations sur nos expertises
Faire partie d’une équipe soudée pendant et après le travail avec des événements réguliers (séminaires, sports, afterworks etc)
Votre créativité récompensée et de nouvelles opportunités
Une proximité avec l’ensemble des équipes Sutter Mills pour être force de proposition

Accenture, c’est une communauté de plus de 500 000 talents qui innovent ensemble afin d’améliorer nos modes de vie et de travail. C’est en combinant nos expertises en stratégie, digital, consulting, technologie, opérations et sécurité que nous servons les plus grandes entreprises mondiales et les aidons à se transformer et à dynamiser leur croissance.
Au sein d’Accenture, nous vous proposons de rejoindre Accenture Interactive, où vous accompagnerez les plus grandes entreprises mondiales et les plus grandes administrations pour exploiter le potentiel du digital, afin de doper leur croissance et créer de nouveaux leviers de valeur pour transformer leur activité.

Envie d’en savoir plus sur le quotidien des collaborateurs Accenture ? Posez-leur directement vos questions.

Déjà prêt.e à passer à la vitesse du changement ? Postulez."
Paris (75),CDI,,Consultant en organisation – Data Science (H/F),Exakis,- Paris (75),"La Data chez Magellan Consulting, très vite le cabinet a pris la mesure du « phénomène Data » avec la création d’une practice dédiée regroupant les activités régaliennes historiques (Gestion des données de référence, Gouvernance de la donnée, « Data management/architecture », Business Intelligence), mais surtout l’ensemble des pratiques innovantes et digitales : Data Science (Analytique, Machine Learning, Big-Data…), APIs, Blockchain, Open-Data et Data-Driven Company. Toujours avec un positionnement orienté Conseil (stratégique ou métier) et/ou Architecture.
Vous rejoindrez une équipe de consultants expérimentés reconnue pour son savoir-faire et vous accompagnerez nos clients dans leur transformation.
Ville : Paris
Type de contrat : CDI
Expérience : Moins de 3 ans
Poste et Missions
Réaliser des analyses à la demande de votre Manager en tenant compte des enjeux clients,
Produire des livrables répondant à notre niveau d’exigence,
Faire preuve d’autonomie, de curiosité et de proactivité dans la réalisation de vos missions,
Réaliser des synthèses claires et structurées avec une prise de recul,
Être reconnu par votre client et développer une relation de confiance avec vos interlocuteurs internes et externes,
Participer à la vie interne du cabinet : recrutement, formation, team building, capitalisation des connaissances acquises.
Sous l’encadrement d’un leader d’expérience qui aura pour charge d’accroitre le volume d’activité, vous interviendrez sur :
L’amélioration de l’offre,
La définition et le cadrage des problématiques et surtout sur la réalisation des projets de Data Science : aussi bien sous un angle Métier que technique,
Accompagnement de nos clients dans la formalisation de leurs problématiques Data, la réalisation de modèles et l’industrialisation.
Vous contribuerez aux projets par vos savoir-faire et serez attendus sur la qualité de vos productions, votre montée en compétences et votre capacité à gagner en autonomie et responsabilités pour évoluer au sein du cabinet.
Profil
De formation Bac+5, diplômé d’une école d’ingénieur, de commerce ou d’un Master spécialisé universitaire, vous justifiez d’une première expérience en rapport avec notre activité.
Vous connaissez les concepts (Big-Data, NoSQL, Machine Learning, Data-Viz…), et en partie :
Des algorithmes (supervisés, non supervisés, Random Forest, SVM, réseaux de neurones, etc.),
Des langages (R, python, scikit-learn, tensorFlow, MapReduce, D3.js,…),
Et des outils (Hadoop, Spark, Hive, HBase, Cassandra, ElasticSearch…).
Curieux, observateur et doté d’un sens critique, vous disposez de qualités vous permettant d’appréhender les problématiques de nos clients. Vous saurez délivrer des recommandations pertinentes au travers de savoir-faires fondamentaux du consultant (interviews, animation de réunions, conduite de projet, analyse, business-case, rédaction de supports à forte valeur ajoutée).
Votre esprit d’entrepreneur, votre approche innovante et votre appétence pour le travail en équipe vous permettront de contribuer au développement de notre cabinet en proposant des solutions sur mesure que ce soit à nos clients ou au sein de nos groupes de travail internes (innovation, formation, bien-être au travail, développement des offres).
Votre fort niveau d’exigence opérationnelle et votre sens du service client vous permettront de contribuer aux succès des missions sur lesquelles vous interviendrez, renforçant ainsi la renommée de Magellan Consulting, et plus largement de Magellan Partners, auprès de nos comptes clés.
Vous avez de très bonnes qualités rédactionnelles, maîtrisez les outils Office et parlez couramment anglais.
Vous avez un excellent relationnel, vous aimez aborder des problématiques différentes et apporter des solutions adaptées et innovantes dans un environnement dynamique, venez accompagner notre croissance en rejoignant nos équipes !"
Paris 11e (75),Stage,,Stage Big Data,Integrytis,- Paris 11e (75),"Domaine de Formation : Big Data et/ou informatique décisionnelle & prédictive (Bases de données).
Stage : DATA SCIENTIST Durée : 6 mois Lieu : Paris 11 Début : Février/Mars 2018.
CONTEXTE :
INTEGRYTIS est une ESN spécialisée en Business Intelligence & Big Data. Nous accompagnons nos clients Grands Comptes dans le développement de leur système d’information décisionnel par le biais de prestations à fortes valeurs ajoutées.


INTEGRYTIS, est une société de passionnés, qui privilégie le goût du challenge, l’esprit d’initiative, le partage, et l’écoute.


Dans le cadre du développement de ses activités DATA SCIENCE, INTEGRYTIS renforce son équipe et recherche des stagiaires data scientists.


Encadrés par des experts Big Data et des Data Scientists vous aurez la charge de participer à l'établissement de traitement de données en relations avec les problématiques de nos clients.


Les projets que nous déployons pour les entreprises sont complexes et souvent structurants pour elles. Partenaire de la transformation digitale des entreprises, nous recherchons des hommes et des femmes passionnés, pionniers, conquérants, et orientés clients.


DESCRIPTION :
Notre expertise : Business intelligence, Data Intelligence, Big Data et CRM .


Environnement technique : Hadoop, Horten Works, Spark, Nifi, Zepplin, Amberi, DATAIKU, LUCIAD, Python, JAVA-JEE …


Travailler sur des projets complexes et innovants vous permettant de manipuler les dernières technologies de pointe dans le domaine du Big Data.


Utiliser notre plateforme Big Data : EPOD basée sur Hadoop, DataIku, Vertica, Luciad, … Développer dans l'univers Hadoop (Spark, Scala, Hadoop, HBase, Hive, Kafka...) Maintenir une veille technologique vous permettant d'avoir une culture informatique importante.


Idéalement, vous avez des connaissances sur au moins 2 des environnements technologiques suivants : JAVA, Hadoop, Python. Intégrer les nouvelles avancées technologiques dans le domaine du Big Data pour répondre à des use-case toujours plus ambitieux.

D’autres projets innovants sur les transports, la santé, l’immobilier, les entreprises, …


exemple :
Pollution
Ciblage d’une population souffrant de maladie respiratoire
Rapport prédictif de zones à fort taux de pollution
Détection de la fraude
Traitement et exploitation de la donnée satellitaire

PROFILS :
Vous êtes en dernière année de formation spécialisée en informatique, mathématique ou statistique, vous justifiez d'une expérience sur des projets universitaires en informatique algorithmique ou de modélisation mathématique / statistique, ou réalisés au sein de votre école d'ingénieurs. Vous avez un intérêt fort pour l'Open Source, le Big Data et le traitement de la donnée (batch, temps réel). A l'aise avec les concepts d'architecture du système d'information, vous avez déjà une expérience significative sur le langage Java ou Python.
Diverses problématiques peuvent être traitées sur un seul sujet !!! Laissez libre cours à votre créativité, vos compétences, Vos idées nous intéressent…
Durée : 6 mois de stage avec possibilité d’embauche."
Paris (75),,,Data Scientist - Computer Vision,Sept Lieues,- Paris (75),"Start Up de 11 collaborateurs sur Paris qui a développée une solution innovante.
Située en plein coeur de Paris - Superbes Locaux avec une grande terrasse - Cuisine - Team Building - Remote possible.
LE POSTE / LES MISSIONS
Cette Start Up cherche un spécialiste de la Computer Vision pour intégrer l'équipe Data Science.
Au sein de l'équipe Innovation, qui est en pleine croissance, vous travaillerez sur des projets de reconnaissances faciales
PROFIL RECHERCHÉ
Profil :
Bac +5 ou +7
Expérience significative de 4 ans minimum
Compétences en Deep Learning
Expérience en Deep Learning appliqué à la Computer Vision
Maîtrise de Python
Anglais

Le plus : Connaissances en traitement de vidéos"
Arcueil (94),"Apprentissage, Contrat pro",,Data Analyst H/F (alternant),Aramisauto.com,- Arcueil (94),"L'équipe data d'AramisAuto c'est :
Une équipe jeune de 10 personnes motivée, innovante et très sympa.
Des Data Scientists, Architecte, Ingénieurs BI, Data analysts
Un levier de croissance pour AramisAuto
Des projets innovants dans un contexte métier passionnant : Pricing, scoring clients, recommandations en temps réel, ….
Un environnement technologique best in class « Amazon, Redshift, Elasticsearch, SnowFlake, Python, D3JS, Power Bi,.. »

Les Missions:
En tant que stagiaire Data Analyst vous serez amené à :
Recueillir, traiter et étudier les données (web/app, transactionnelles, CRM/PRM…) pour produire des analyses métiers et des recommandations,
Construire et faire évoluer des rapports de Business Intelligence / des DataViz pour permettre aux différentes équipes d'avoir une vision cohérente sur les résultats d'activité (product, business) et leur bon fonctionnement technique,
Elaborer des analyses et les restituer d'une manière visuelle pour permettre aux Business Leader / Product Manager de comprendre leurs offres, l'efficacité des actions marketing/commerciales, les parcours gagnants de nos site web / app mobiles aux 2 M de visiteurs uniques mensuels
Réaliser des analyses exploratoires (segmentation, prédiction…) pouvant nécessiter l'utilisation d'algorithmes de machine learning (arbre de décision, K-NN…)
Accompagner les Product Managers dans la mise en place d'AB-tests, leur monitoring et la restitution des résultats.

Les Outils:
Notre stack technologique est à l'état de l'art et est orientée vers la productivité et la scalabilité.
SQL, Python
Power Bi, Qlikview, Tableau
Infrastructure 100% Cloud Amazon (S3, Redshift, EC2, …)
Profil
Profil recherché:
Formation d'ingénieur généraliste ou à dominante mathématique et/ou informatique.(M1 ou avant dernière année)
Familiarité avec les outils informatiques communément utilisés en data analyse.
Curiosité, autonomie, attention aux détails et volonté d'apprendre
Des compétences en digital / e-commerce et web analyse sont un plus

Modalités Pratiques:
Encadrement par un Data Analyst
Démarrage à partir de septembre 2020
Poste basé au siège d'Aramis Auto"
Paris (75),,,Chief Data Officer (H/F),Microcred,- Paris (75),"About Baobab (Formerly Microcred)
Baobab is the leading digital financial inclusion group focusing on serving individuals, micro and small businesses in Africa and China. Our mission is to unleash the potential of our clients offering them simple and easy to use financial services. Founded in 2005 as Microcred, today Baobab has over 700,000 customers and 3,800 employees operating in Burkina Faso, China, Democratic Republic of Congo, Ivory Coast, Madagascar, Mali, Nigeria, Senegal, Tunisia and Zimbabwe.
The group is headquartered in Paris and has centralised a number of back office functions to Dakar, Senegal.
In a context of rapid growth and change we are looking for a
Chief Data Officer (H/F)
We are seeking an experienced data and machine learning scientist to help steer the next generation of algorithms and play a key role in the company’s data science initiatives, in particular, but not limited to, applying data-driven machine learning techniques and technologies to large data sets.
The role requires hands-on application of and in-depth knowledge of data science tools, involving combining traditional and non-traditional techniques to solve key business problems and opportunities. This role will also require strong business acumen, the ability to interact with distant subsidiaries and the delivery of end-to-end analytical solutions — from conceptualizing an analytical framework for a specific problem to translating the insights back to actionable business recommendations.
As Senior Manager for this function, your responsibilities include the design, execution, and delivery of analyses and data products ranging from algorithm creation, predictive modeling and forecasting, to dashboards and ad-hoc data pulls.
You will report to the Group Chief Risk Officer and will lead the data analytics unit of Baobab Holding. You will collaborate with all departments’ heads to deliver data analytics needs in particular you are expected to contribute to leveraging data to:
Improve credit risks within the group
Develop Digital Data based Marketing on specific population segments
You will demonstrate strong interpretative and analytical skills, with the ability to challenge constructively and provide a professional, objective and independent viewpoint. Previous experience in data management and analytics is sought for this role, including process documentation and controls.
You are passionate about analytics, an expert on the evolving trends and approaches for analyzing big data, and excel in problem-solving with a positive, can-do attitude. Other foundational qualities include creative thinking, flexibility, a strong analytical ability to address complex issues, hands-on experience working with large volumes of transaction data, and the desire to drive continuous improvement.
Responsibilities :
Manage data
Build and Enhance current Data Infrastructure based on existing data captured by Baobab
Identify and capture new data, from Baobab ecosystem and beyond, to support growth and digitalization objectives
Interpret data
Analyze all data to make sense to it and derive business decision engines
Design and launch innovative and complex analytic models, utilizing a blend of contemporary and traditional data mining techniques, to apply to both structured and unstructured data sets
Scopes, designs, and implements machine-learning models to support the business’s initiatives and programs with a view to achieving overall objectives and targets
Prepare for the future of digital financial services
Create new data sciences capabilities by envisioning and executing strategies that will deliver compelling business opportunities and influence improvement of the performance
Identify and respond to analytics / data trends and opportunities. Research and develop next-generation analytical techniques/tools where existing ones are not adequate to address business challenges.
Profile
Technical skills
A minimum of 10 years experience of leadership in data analytics, including, statistical modeling, machine learning, forecasting, Big Data, reporting.
Proven ability to translate operational and strategic challenges into data driven analysis enabling optimized decision making
Prior experience in financial inclusion services, in the area of credit risk and / or data analytics, in particular building machine learning models in credit risk landscape.
Exposure to Africa and / or China unbanked sectors
Written and spoken English
Experience with leading visualization tools (Tableau, BIME, Qlikview), MS Office and Google suite
Proficient in SQL and R statistical package, Python a plus; Familiarity with NoSQL databases (MongoDB)
Degree, MS, or PhD in a quantitative fields like Statistics, Economics, Mathematics, Computing and Engineering
Personal skills
A naturally multicultural player and leader: you know how to interact with people with different cultures and different background creating trust, respect and an environment open to problem solving
A good communicator, able to make analysis easy to understand thanks to compelling and clear arguments. You’re at ease in communication with overseas activities (phone, video calls). You love teamwork, and you understand what it takes to make the team succeed.
A pragmatic, you always try to handle complex projects and subjects through simpler tasks and solutions. You’re organized and have a strong ability to manage urgencies through effective priority management.
You have passion and energy. Because we love what we do, our enthusiasm is infectious. You can’t wait to get the virus as this is what makes you perform at your absolute best and see new challenges as an opportunity to contribute, make an impact, grow.
You value and demonstrate unyielding integrity.
Want to join us?
We cultivate the start up spirit and look for innovation and excellence. We welcome our new employees and ensure their integration into our environment.
Go for it!
Get in touch with us by sending your CV and cover letter with the following reference SEN-DATA-MGR to clara@microcred.com"
Paris (75),,,Machine Learning - Computer Vision Engineer,7 Sensing Software,- Paris (75),"As a Machine Learning - Computer Vision Engineer, you are responsible for growing our Machine Learning for Computer Vision portfolio, with a specific focus to bring scalable multi-modal sensing solution to life in AR and photography applications.
You aim at a highly technical role and you thrive in a dynamic environment that requires a unique blend of innovation, risk taking and speed of execution. You combine excellent oral and written communication skills and an ability to autonomously plan and organize your work assignments based on high-level team goals. You will be working with the team of experts in Machine Learning, Computer Vision, Digital Signal Processing and Embedded Software. You join a group of engineers with a very diverse skill set, but united by their passion for innovation and the excitement of turning wildly disruptive ideas into products that impact the industry at large. You will join our effort in building our next-generation machine learning platform for vision systems.
We love building products that change the consumer and automotive industries by combining edge computing and AI. Our technology stack includes the latest innovations both supervised and unsupervised learning, including the latest deep learning algorithms and machine learning frameworks such as TensorFlow, Caffe, Keras, FastAI, Spark and Go
Requirements
Agile, pragmatic, hardworking and a “can do” mentality. You also love to interact with data scientists, machine learning engineers, software engineers and domain experts in order to develop pipelines that process seamlessly large amounts of data. You love technology, innovation and building products with scalability in mind.
You hold a degree in computer science or a related field and you can demonstrate a consistent track record in the following areas:
Several years of experience architecting, building, developing and scaling ML and/or Computer Vision systems. Having implemented and deployed a variety of machine learning pipelines production environments would be a strong plus.
Good understanding and experience in technologies such as CGI, SLAM, AR, HDR
Excellent software development and scripting skills c/c++, Java and Python
Real-time processing of image and/or large amounts of sensor data
Hands-on experience, micro-service architectures (e.g., Docker, Kubernetes), and ML libraries (e.g., Scikit-Learn, TensorFlow, Keras)
Excellent English spoken and written skills
Experience with scalable cloud infrastructures such as AWS and Azure"
Paris (75),,,Transformation Data,Rhapsodies Conseil,- Paris (75),"Nous sommes un Cabinet de Conseil indépendant, à taille humaine, ayant pour objectif d’être un acteur de référence sur ses domaines d’expertises. Notre ADN est orienté autour de 5 sens : l’Expertise, la Transformation pour nous et pour nos clients, la Culture du partage et de la transmission des savoirs, l’Innovation et la Responsabilité par nature. Nous sommes un acteur engagé et citoyen.
Nos consultants évoluent au sein d’un environnement stimulant, bienveillant et convivial fondé sur le développement, le partage de connaissances, l’ouverture d’esprit ainsi que la valorisation des potentiels.
Ce que nous voulons aujourd’hui, c’est partager l’aventure avec les meilleurs d’entre vous !
Et n’oubliez pas, chez Rhapsodies, on se choisit !
Rencontrons-nous, nous aurons le plaisir de vous montrer que ce ne sont pas que des mots.

https://youtu.be/Lozjvj5G8YU

Dans un contexte en mutation rapide autour du numérique et du digital, plus que jamais la question de la gestion des données se pose comme étant au coeur des préoccupations des entreprises de tous secteurs. Le Cabinet Rhapsodies Conseil se positionne comme référence sur les sujets de Stratégie Data et de Data Management. Nous nous fixons pour ambition de guider et de conseiller nos clients autour des enjeux de la Transformation Data : Stratégie, Usages, Culture, et Maîtrise des données.
Dans ce cadre et pour accompagner notre forte croissance, nous recherchons un(e) Consultant(e) Senior Stratégie et Data Management pour mener des missions de Conseil auprès de nos clients et accompagner le développement de notre proposition de valeur.
Vos missions :
Construire et orienter la stratégie Data, à travers une vision et des convictions, pour valoriser et protéger les données des organisations,
Cadrer les usages Data et faire le design des chaînes de valorisation de données, des sources de données jusqu’aux usages des métiers,
Piloter des projets Data depuis les échanges avec les métiers jusqu’à leur concrétisation,
Contribuer à la construction et à la diffusion d’une culture Data au sein des organisations,
Construire le cadre de gouvernance et de régulation des données (modèle opérationnel, rôles et responsabilités, instances, processus, outils),
Accompagner les avancées réglementaires sur les données (cadrage RGPD, Solvabilité 2, BCBS…) et les transformer en opportunités pour les Métiers
Animer des ateliers Data (recueil des besoins, usages, formation…)
Faire de la modélisation des données un levier d’échange et de valeur avec les métiers, l’écosystème et les projets,
Accompagner les initiatives autour de la Data Science, de l’intelligence artificielle (Machine learning, Deep learning…), des algorithmes, du temps-réel,
Adopter des démarches frugales pour atteindre les résultats recherchés en utilisant de manière optimale les ressources disponibles.

Vous participerez au-delà de vos missions à l’effort commercial de l’équipe en participant à des propositions commerciales et à des soutenances orales afin de développer notre activité. Vous serez aussi un acteur du développement de l’activité de l’équipe en gérant des communications internes et externes et en travaillant à la conception, à l’évolution et à la présentation de nos offres data.

https://www.rhapsodiesconseil.fr/espace-carrieres

Votre profil :
De formation supérieure Bac+5, vous justifiez d’une expérience de 5 années minimum dans la conduite de projets de transformation digitale et/ou de valorisation des données.
Vous êtes reconnu pour vos qualités de rigueur, d’esprit de synthèse, d’organisation et par votre capacité à travailler en mode projet.
Votre sens du service client et votre relationnel vous permettront d’être un interlocuteur crédible auprès de nos clients.
Vous savez faire preuve d’autonomie, d’adaptabilité et de sens de la confidentialité,
Votre créativité et la compréhension du métier de nos clients vous amènera à proposer à nos clients des solutions innovantes et adaptées à leurs problématiques.
Vous parlez un anglais courant (environnement international)"
Paris (75),CDI,,Data Scientist modélisation H/F,Lincoln,- Paris (75),"Envie de rejoindre Lincoln pour expérimenter des solutions innovantes en data science et IA ?

Ce que l’on vous propose

Intégrer l’équipe data science de l’entité digitale d’un acteur majeur du secteur de l’énergie
Participer à un projet innovant : prédiction de performance, maintenance prédictive, détection d’anomalies et data quality dans le domaine des énergies renouvelables
Développer des algorithmes pour une mise en production cloud (Azure ou C3), être à la fois orienté prototypage (R ou Python) et déploiement / industrialisation (Shiny ou Kubernetes)
Progresser au contact d’une équipe de data scientists et faire la connaissance de 5 autres consultants Lincoln

Ce que l’on attend de vous, data scientist

Un peu de théorie : un cursus ingénieur ou universitaire orienté data
Entre 6 et 9 ans d’expérience sur R et Python, Git / GitHub, la programmation orientée objet et fonctionnelle, les algorithmes de machine learning et les séries temporelles
Un niveau d’anglais technique et un fort esprit d’équipe

Vos atouts pour mener à bien cette mission

Une connaissance des énergies renouvelables
La cerise sur le gâteau: connaître Shiny, Azure ML Service et Power BI

Le poste est à pourvoir immédiatement à Paris ou à Lyon.

Vous l’aurez compris : que vous soyez data scientist R (idéalement) ou Python, votre place est sans doute parmi nous… alors postulez et rencontrons-nous"
Paris (75),,,Data Center Technician (DCO),Amazon Data Services France SA,- Paris (75),"Solid Understanding of Linux/Unix Administration
Server Hardware Troubleshooting experience
Server Booting: POST, BIOS, PXE, Kickstart, GRUB/LILO, RAID
Some Experience with Network Protocols: TCP/IP, Ethernet, L2/L3 technologies
Network Hardware: Copper and Optical Fiber Cabling, Switches, Routers
Strong Communication Skills
Passionate about IT infrastructure and hardware!

Working proficiency English speaking is required, French is not mandatory.

This position also has a physical component requiring the ability to lift & rack equipment up to 18 kilos; it may require working in cramped spaces or in elevated locations while adhering to health & safety guidelines.

This role involves covering 24x7 shift rotation

Please send your CV in English.

Data Center Operations designs, installs & maintains the world’s largest Cloud Computing Infrastructure.

We are looking for skilled Data Center Technician with a passion for technology to help us expand our Cloud to the next level.
Amazon Web Services (AWS) offers an exciting, dynamic and challenging environment encouraging creativity and personal development while maintaining AWS computing environments in a secure, scalable, and cost-effective manner.
Mid 2013, AWS S3 web service accepted its 2 trillionth object and that the service is regularly peaking at over 1.1 million requests per second.. To keep up with this demand on both disk and network capacity, we continue to expand our Data Centers in every region. Also, our content delivery AWS service, CloudFront, has expanded its Data Centers presence by over 50% worldwide in the last 12 months and are expecting to increase by a similar number over the next 12 months. This requires talented people to build & manage. We hope it is you!

This role is a unique opportunity to work in some of the most cutting edge data centers in the world. Amazon data centers are large-scale high-density centers where you will be working on changing the face of Cloud technology in the region.

A Data Center Technician may be the primary point of contact for both internal customers (for example: Network Engineers, Systems Engineers, Software Developers, Database Engineers, Technical Operations) and external customers (Hardware Vendors, Contractors, Service Providers among others).

There is never a dull moment as each day presents itself with different challenges. Some of the key responsibilities you will undertake are:

Problem Solving:
Maintain a high level of system reliability by prioritizing and resolving trouble tickets efficiently, these include:
Escalation point and technical troubleshooter for all Systems and Network hardware problems
Deep diving into Linux server issues
XEN service virtualization troubleshooting
Technical:
Troubleshoot technical issues on various platforms ranging from Systems through Networking to Power/Mechanical
Remediation of physical layer outages, both Systems & Network
Remediation or recovery of physical power issues on racks
Participate in Data Center power & cooling events
Operations:
Meet 24x7 On-Call requirements and response during shift rotations.
Install & configure racks of hosts in line with internal SLAs
Triage & resolve trouble tickets for all devices in your region
Data Center point of contact for all High Severity issues
Physical replacement of server and network device parts
Ensure correct rotation of parts & spares
Help define metrics to increase our customer uptime
Enforcing Amazons Security Best Practices
Interact with third party vendors & contractors
Contribute ideas to improve operational efficiency
Engage with Remote Hands & Eyes in EU Regional Cloudfront POPs

Project Management:
Participate in and deliver on a number of high impact small to mid-scale projects
Participate in team meetings for metric analysis and project status updates
Help build the world’s largest Cloud infrastructure
Mentoring:
Share knowledge and help educate less technical staff on the best practices related to all service owner issues
Hiring:
Contribute towards building a great team by getting involved in the Amazon hiring process/candidate interviews

Remote Access: Console routers, IPMI, BMC
Network Equipment Installation and Configuration
Cisco IOS, NX-OS, JunOS
Redundancy: Power feeds, ATS, Server Hardware, RAID, Network Connectivity
Data Center Operations: Inventory Management, Hot/Cold Aisles, Security
Experience with Excel and the ability to manipulate data and create necessary charts and diagrams
Participated in Project Management
Experience or Knowledge of AWS products: EC2, EBS, S3 etc.
Scripting: Bash, Python, Perl, Ruby (or programming languages)

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We value your passion to discover, invent, simplify and build."
Paris (75),,,Perception Engineer,iFollow,- Paris (75),"Department Engineering
Location Paris, France
Job Type Full-Time

Description
THE ROLE
We are currently looking for a passionate engineer to join our fast growing team to make our logistic robots work robustly in warehouses & supermarkets with advanced perception abilities using laser, cameras, wifi and other sensors. The selected candidate will primarily design and implement algorithms to detect and track human beings using lasers and cameras. The candidate will also participate in the development of a robust robot localization system, reactive control and human-robot interaction strategies.

RESPONSABILITES
Develop state of the art algorithms to detect and track human beings and target objects in indoor environments.
Participate in the development of visual odometry for robust robot localization.
Participate in the development of vision based robot control.
Participate in the development of human-robot interaction strategies.
Participate in the development of SLAM algorithms.
Real conditions testing of the robot and the developed algorithms at iFollow, clients and partners.

MANDATORY REQUIREMENTS
Strongly dynamic engineer, motivated to work on a startup environment as well as in extreme robot testing conditions (-25 °C warehouses).
Master’s degree in Computer Science / Control / Vision / AI.
Experience in robotics and ROS framework.
Strong Software background with excellent C++ & Python programming & debugging skills.
Strong Linux background.
Hands-on experience with OpenCV.
Hands-on experience in cloud computing using Docker and AWS.
Hands-on Experience in LIDAR & vision sensors, data processing & sensor fusion.
Knowledge of developing robust vision algorithms with fault detection & recovery.
Hands on experience in Deep Learning particularly with design, training, evaluation and optimization of CNN architectures in the context of scene classification, scene segmentation, people detection and tracking.
Experience with at least one major deep learning framework Caffe, Theano, Torch or Tensorflow.
Good knowledge of cooperative software development with GIT.
Excellent written and verbal communication skills in English.
DESIRED TECHNICAL REQUIREMENTS
Hands-on experience in developing real time human detection and tracking algorithms.
Hands-on experience in robotic simulation (V-REP, Gazebo).
Experience in mobile robotics.
Experience in visual odometry, scan matching and SLAM algorithms
Experience with Cuda / OpenCL / OpenGL / shader programming.
Experience with Deep Neural Network compression for optimal size and speed."
Paris (75),CDI,45 000 € - 60 000 € par an,Data Engineer,Sept Lieues,- Paris (75),"Editeur de logiciel dans le domaine du retail.
Entreprise internationale (800 salariés dans le monde dont 200 en France) et des bureaux dans une dizaine de pays en Europe.
LE POSTE / LES MISSIONS
En tant que Data Engineer votre role sera de comprendre les données métiers exposées.
Vous devrez définir à la fois les données, l'organisation et le pré traitement nécéssaire à la proposition de solution en collaboration avec l'équipe Data Science et Machine Learning.

Construire les filtres de données
Manipuler et analyser la donnée sur des projets de gros volume de données
Réaliser les plateformes fonctionnelles pour la manipulation de données
Rédiger les spécifications visant à développer une solution logicielle utilisant ces données et modèles de données ;
Présenter, expliquer ces spécifications aux clients, équipes internes R&D ou projet
PROFIL RECHERCHÉ
Doctorat, Bac +5 ou équivalent en informatique avec un minimum de 3 ans d'expérience, vous maitrisez :

Développement Python
Outils de Data Engineer (Tensor Flow, SQL Elastic Search etc)
GPU, calculs parallèles
Anglais courant

Les + :
Compétence en recherche opérationnelle (être capable d'optimiser la donnée)"
Paris (75),CDI,,Manager en organisation – Data Science (H/F),Exakis,- Paris (75),"La Data chez Magellan Consulting, très vite le cabinet a pris la mesure du « phénomène Data » avec la création d’une practice dédiée regroupant les activités régaliennes historiques (Gestion des données de référence, Gouvernance de la donnée, « Data management/architecture », Business Intelligence), mais surtout l’ensemble des pratiques innovantes et digitales : Data Science (Analytique, Machine Learning, Big-Data…), APIs, Blockchain, Open-Data et Data-Driven Company. Toujours avec un positionnement orienté Conseil (stratégique ou métier) et/ou Architecture.
Vous rejoindrez une équipe de consultants expérimentés reconnue pour son savoir-faire et vous accompagnerez nos clients dans leur transformation.
Ville : Paris
Type de contrat : CDI
Expérience : Minimum 8 ans
Poste et Missions
Animer des ateliers avec des intervenants des différents métiers, faire converger les besoins et produire les livrables associés,
Apporter à votre client votre expertise des processus et métier,
Participer à l’amélioration et à l’enrichissement de l’offre Data Science de Magellan Consulting,
Piloter les plans d’action commerciaux,
Définir et cadrer les problématiques, surtout sur la réalisation des projets de Data Science : aussi bien sous un angle Métier que technique,
Accompagner nos clients dans la formalisation de leurs problématiques Data, la réalisation de modèles et l’industrialisation,
Participer à la vie interne du cabinet : recrutement, formation, team building, capitalisation des connaissances acquises.
Profil
De formation Bac+5, diplômé d’une école d’ingénieur, de commerce ou d’un Master spécialisé universitaire, vous justifiez de minimum 9 ans d’expérience réussie en conseil en management notamment autour des problématiques liées à la Gestion des Données.
Vous maitrisez le domaine de la Data Science : Modélisation, Machine Learning, Big-Data, Data-Visualisation, etc. Vous avez une bonne connaissance de l’écosystème Digital & Data : acteurs, solutions technologiques, tendances, etc. Vous disposez d’un réseau de contacts clients et experts/consultants. Votre leadership & Business development : vous permettent d’avoir une bonne vision stratégique, une capacité de gestion d’équipe et d’activité, ainsi que le sens du commerce.
Vous avez développé des compétences métiers grâce à des missions de conseil en organisation. Vous êtes capable d’analyser les problèmes et les enjeux de nos clients, et êtes capable d’apporter des solutions pertinentes. Vous êtes capable de piloter une mission et êtes force de proposition. Vous êtes capable d’assimiler rapidement des problématiques complexes et à y apporter des solutions
Doté d’un excellent relationnel, de très bonnes qualités rédactionnelles et des qualités de synthèse, vous maîtrisez aujourd’hui totalement les fondamentaux du Consultant : interviews, animation de réunions, conduite de projet, analyse, business-case, rédaction de supports à forte valeur ajoutée, et faites preuve de créativité. Vous êtes d’ailleurs capable de former, encadrer et piloter une équipe de Consultants.
Vous souhaitez participer à notre croissance en vous investissant, en créant et en développant nos offres. Vos réflexes commerciaux et votre sens de la proximité client vous aideront à atteindre les objectifs commerciaux du cabinet : entretenir et nourrir la base clients/prospects, obtenir des rendez-vous commerciaux au sein et en dehors de son réseau, rédiger et piloter la rédaction des propositions commerciales, susciter la suite de mission, identifier les besoins clients et savoir les pourvoir.
Vous êtes fortement autonome et avez preuve de responsabilités lors de votre parcours. Votre esprit d’entrepreneur, votre approche innovante et votre appétence pour le travail en équipe vous permettront de contribuer au développement de notre cabinet en proposant des solutions sur mesure que ce soit à nos clients ou au sein de nos groupes de travail internes (recrutement, innovation, formation, bien-être au travail, développement des offres).
Anglais courant impératif.
Vous êtes entrepreneur, organisé, créatif et faites preuve d’un esprit d’initiative, devenez un acteur de notre croissance en apportant votre expertise !"
Saint-Quentin-en-Yvelines (78),,,Ingénieur Data Scientist H/F,Expleo,- Saint-Quentin-en-Yvelines (78),"Expleo propose une offre unique de services intégrés d'ingénierie, qualité et conseil stratégique pour la transformation digitale. Dans un contexte d'accélération technologique sans précédent, nous sommes le partenaire de confiance des entreprises qui innovent.
Expleo est présent dans tous les secteurs à forte intensité technologique qui contribuent à une société plus connectée, plus durable et plus sûre. Nous nous appuyons sur une forte expertise sectorielle et accompagnons nos clients sur l'ensemble de la chaîne de valeur : conseil et business agility, conception, production et services post développement, management de la qualité.
Nos 15 000 collaborateurs interviennent dans plus de 30 pays et nous avons réalisé un chiffre d'affaires de 1,1 milliard d'euros en 2019.

Au sein du département Data Science, vous serez intégré à une équipe soudée réalisant une veille scientifique et technique dont le but est de produire des solutions de qualité intégrées à la pratique métier du client. A cet égard, vous mènerez des projets complets et variés en termes de problématiques clients (industrie, transport, banque, …) et de modélisation (NLP, Text Mining, séries temporelles, classification, régression, computer vision, …).
Vous collaborerez avec les experts métiers pour comprendre le besoin et accompagner les clients dans leur gain de maturité sur les sujets data science et big data.

Vous aurez pour missions de :
Comprendre les besoins clients
Extraire et joindre de données imbriquées
Élaborer et comparer de modèles mathématiques et statistiques
Visualisation de données : réaliser de Dashboards interactifs
Présenter et diffuser les résultats
Ingénieur ou Diplômé d'un Master 2 avec une spécialisation en Data Science, vous possédez une première expérience dans les domaines des mathématiques appliquées et de l’analyse de données.
Autonome et rigoureux, vous êtes doté d'un bon relationnel, d’un esprit de synthèse et un esprit innovant.
Vous maîtrisez l'anglais aussi bien à l’oral qu’à l’écrit.

Compétences techniques :
Mathématiques théoriques et appliquées
Machine Learning, Deep Learning, statistiques, recherche opérationnelle.
Maîtrise des langages Data Science : R, Python, Scala…
Capacités de synthèses et de vulgarisation
Notions en développement agile
Anglais technique
Maîtriser l’intégralité des compétences techniques précitées n’est pas un prérequis, nous sommes en mesure de vous former.
Discutons ensemble et venez écrire la nouvelle page de votre carrière dans notre groupe !"
Paris (75),CDI,40 000 € - 50 000 € par an,Data Engineer - Géolocalisation,Sept Lieues,- Paris (75),"Startup qui s'intéresse aux données de géolocalisation afin de définir et d'optimiser les emplacements commerciaux de ses clients.
LE POSTE / LES MISSIONS
Vous rejoindrez l'entreprise en tant que Data Engineer et votre role sera de mettre au point des algorithmes d'estimation

Vous travaillerez au sein de l'équipe technique (10 personnes : ingénieur produit, ingénieur data et data scientist).

Côté technique:
Plusieurs dizaines de Giga de données à traiter par jour, des problématiques d'optimisation et de passage à l'échelle

Exemples de problématiques sur lesquelles vous seriez amené à travailler:
L'estimation d'un flux piéton à une adresse donnée (en utilisant le signal gps)
La détermination de la provenance d'une personne se rendant dans une zone spécifique
La qualification des flux de personnes (sexe, âge, etc.)

Exemples de missions:
Récupération, traitement et stockage des données
Test unitaire
Mise en production d'algorithmes / Implémentation de modèles réalisés par les Data Scientists

Technos: Spark / Scala / AWS / Python
PROFIL RECHERCHÉ
0 à 2 ans d'expérience sur un poste similaire
Développement en Python / Spark / Scala
Connaissance sur une partie des services AWS
Gout pour travailler en équipe dans un environnement qui bouge rapidement"
Boulogne-Billancourt (92),,,Chef de Projet Statistiques & Data Sciences H/F,Roche,- Boulogne-Billancourt (92),"Qui sommes-nous?
Roche, c’est 88 500 collaborateurs à travers 150 pays qui repoussent quotidiennement les frontières de la santé pour agir à toutes les étapes et prendre soin de la vie des patients. Numéro un mondial de la biotechnologie, Roche produit des solutions innovantes dans l’oncologie, l’immunologie, les maladies infectieuses, l’ophtalmologie et les neurosciences.
Bien plus qu’un laboratoire pharmaceutique, nous sommes un partenaire de santé. Notre succès commun est basé sur l’innovation, la curiosité et la diversité. Proposer des solutions thérapeutiques et diagnostiques dès aujourd’hui tout en innovant pour l’avenir. Telle est
notre conviction, celle qui fonde notre identité, guide notre conduite et définit notre stratégie. Depuis toujours, l’excellence scientifique motive chacune de nos actions pour répondre aux enjeux médicaux et sociétaux. Rigueur scientifique, éthique et accès à l’innovation médicale pour tous : voilà notre engagement, aujourd’hui, pour demain.
Inspirée et tournée vers la satisfaction des besoins du patient, au contact quotidien avec les professionnels de santé et les experts, la Direction Médicale est garante de l&#39;excellence scientifique de Roche, elle affirme son ambition de renforcer son interaction avec tous les services de l'entreprise.
Au sein du Centre de Données Médicales et de Médecine Personnalisée de Roche France, le Chef de projet statistique est l’expert des activités statistiques de la filiale pour les études cliniques locales et les études en vie réelle. Vous êtes passionné des méthodologies et des design d’études innovantes que vous contribuez à identifier et à appliquer aux études de votre unité thérapeutique. Vous avez une expérience avec les données de vie réelle (SNDS, Cohortes et Registres, données cliniques) et des études de recherche clinique. Vous avez un
esprit d’innovation appliqué aux outcomes clinique ou économique. Vous êtes orienté impact et êtes curieux,
vous savez identifier et convaincre au sein d’une entreprise internationale où la donnée (plateformes, data et méthodes) est omniprésente. Vous aimez l’agilité et savez en tirer le meilleur parti pour construire la science des données de demain pour la filiale. Vous savez travailler avec des sous-traitants.
Vos missions principales sont:
Etre l’expert des activités statistiques des unités thérapeutiques dont vous aurez la charge.
Participer à la conception des études locales interventionnelles et en vie réelle (design, définition des
objectifs, critères d’évaluation de l’étude, taille d’échantillon, partie statistique, …), à l'interprétation des résultats et à la communication de ces résultats.
Revoir la partie statistique des notes d’intérêt thérapeutiques.
Participer à la revue et validation des projets soumis au comité interne d’approbation de la direction
médicale.
Assurer la supervision opérationnelle des activités statistiques sous-traitées associés à la génération
de données locales (plan d’analyse statistique, revue statistique des données, génération des tables).

Vos responsabilités et contributions consistent à:
Etre en capacité de répondre aux différentes questions méthodologiques sur tout type d’étude/analyse
de manière intelligible pour un non-statisticien.
Contribuer si nécessaire aux réflexions des équipes Globales.
Proposer des méthodologies &amp; analyses innovantes (comparaisons indirectes type MAIC/algorithme
de Machine Learning/…). en collaboration avec les autres chefs de projet statistiques.
Développer et animer un réseau d’experts interne (global, autres filiales, …) et externe
(académiques…) pour contribuer à faire évoluer l’utilisation des méthodes (statistiques, big data, datascience) et valoriser l’expertise Roche sur ce domaine.
Contribuer à développer une stratégie big data / data science / visualisation des données avec les autres chefs de projet statistiques.
Respecter les lois, règlements et règles de compliance, code de conduite, les politiques internes et procédures standards du Groupe Roche.
Idéalement, vous correspondez à la description suivante :
Master en statistique, ou expérience équivalente en statistique dans une structure exploitant des données de santé
Au moins 4 ans d’expérience dans la recherche clinique ou l’exploitation de données de santé en vie réelle
Des connaissances dans le domaine des nouveaux traitements des données (Data Science), de la médecine personnalisée et/ou de la neurologie seraient appréciées.
Connaissance du référentiel ICH/GCP, BPC, bonnes pratiques épidémiologiques, directives et réglementations relatives aux statistiques seraient appréciées
Capacité à travailler avec succès dans une organisation matricielle complexe nationale,
multifonctionnelle, à toutes les étapes des études cliniques.
Capacité à communiquer avec aisance à l’écrit et à l’oral.
Anglais courant à l’oral et à l’écrit.
Roche is an equal opportunity employer.
Research & Development, Research & Development > Biometrics"
Paris (75),CDI,,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Data Scientist (H/F) pour renforcer ses équipes.
Dirigée par le Chief Data Officer et rattachée au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques met en œuvre la stratégie DATA avec comme principales préoccupations
D’améliorer la gouvernance des données ;
De contribuer à la data réputation de la Banque de France ;
De tirer le meilleur parti des masses et de la diversité des données disponibles au sein de la banque Centrale,
De développer des projets d’intérêt commun
De développer une culture de la donnée au sein des unités métier

Présentation du Service
Au sein de la DDSA, le SIAD (Service Industrialisation et Algorithmique des Données) a pour missions de construire et entretenir les socles techniques BIG DATA, de réaliser des prototypes de solutions basées sur les approches Data Science et IA et de mettre à disposition des solutions business intelligence pour les équipes métier.

Descriptif de mission
Le pôle « Data Science et IA » cherche à renforcer ses capacités en recrutant un(e) Data Scientist.
Les missions de ce pôle, partie intégrante du domaine « conseil et expertise », sont les suivantes :
Cartographier de façon continue, en relation avec les équipes d’innovation et les urbanistes, les processus métier pour lesquels une approche Data Science pourrait procurer un avantage compétitif ou préserver un territoire acquis
Épauler les métiers dans la définition et la stabilisation de leurs besoins
Mettre en place de façon continue les Proofs of Concept (POC) fonctionnels et techniques issus des analyses d’opportunité
Benchmarker de façon régulière les outils du Big Data
Préparer l’industrialisation des POC identifiés comme pertinents
Accompagner la montée en compétence des équipes métier et des équipes techniques sur le Big Data
Sous l’autorité du « Lead Data Scientist », vous serez en charge plus particulièrement :
De la prise en charge des besoins métier et de leur analyse ;
De l’identification des solutions potentielles et du choix de la solution la plus adéquate au regard des besoins et contraintes tant métier que techniques ;
De la conception et de la mise en œuvre de la solution (POC, prototype, MVP),
De l’accompagnement et du soutien aux équipes projets en charge de l’industrialisation des solutions.

Profil recherché
De formation supérieure en informatique ou métiers de la donnée (Ingénieur ou équivalent), vous avez minimum 2 ans d’expérience dans la mise en œuvre de solutions mobilisant des connaissances statistiques et/ou mathématiques avancées, y compris en contexte d’apprentissage/alternance dans des contextes de travail variés (recherche, entreprises commerciales, sphère publique ) constituera un avantage clé.
Vous disposez d’une forte appétence pour la concrétisation de solution dans un environnement Bigdata.Par ailleurs, vous avez la maîtrise :Des sous-jacents mathématiques aux approches Bigdata / Data Science (mathématiques et statistiques, Machine Learning, réseaux de neurones ) et des bibliothèques de Machine Learning (Scikit Learn, PyTorch, )
Du développement en Python
Seraient en outre appréciées, dans l’un ou plusieurs des domaines suivants :
Une très bonne connaissance en développement sur la stack Hadoop (Oozie, Sqoop, Hive, Hbase, ), sur les technologies Spark (MLlib, SQL, GraphX et Streaming), en langages PySpark, Java et R (SparkR).
Une très bonne maitrise des outils de Search (ElasticSearch) et de streaming (Kafka)
Une bonne connaissance des bases de données NoSQL telles que Mongodb et Neo4J
Une bonne capacité à intégrer des sources de données multiples, internes / externes, structurées / non structurées et des interconnexions entre les SGBD et Hadoop
Une bonne capacité à restituer les résultats visuellement à l’aide de Kibana ou PowerBI
Une facilité à développer dans un environnement innovant en méthodologie Devops et Scrum
Rigoureux et apte à anticiper, vous avez le sens du résultat au service du client et êtes doté d’excellentes capacités de communication pour faciliter le travail « en réseau » :
Force de proposition et aisance de communication pour démontrer la valeur ajoutée des solutions Big Data et Machine Learning.
Excellente méthodologie de travail et de gestion de projet, vous travaillerez en mode agile.
Très bon relationnel, capacité à s'adapter, esprit d’équipe, ouverture d’esprit et curiosité naturelle, vous suivez l’évolution des technologies et nouveautés relatives au Big Data, Datascience et IA
Une bonne pratique de l’anglais est nécessaire.
Ce poste, en contrat à durée indéterminée, est basé à Paris (1er), avec des déplacements ponctuels dans les sites banque de France à Paris et en régions.
La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes."
Paris (75),CDI,,Manager Data Engineer,Greenflex,- Paris (75),"Pour consolider le développement de ses activités liées à l’analyse et la valorisation de données, GreenFlex recherche un Manager Data Engineer contribuant à l’accompagnement de grands comptes dans la réduction de leur empreinte énergétique et environnementale à travers des projets d’analyse de données, en particulier de séries temporelles.
Dans un environnement agile à l’échelle, en tant que manager, vos missions seront les suivantes :
Suivi et management d’une équipe d’une dizaine personnes regroupant, des Data Engineer et des data scientist. Ces équipes sont réparties dans différentes équipes de développement multi compétences (squads) travaillant en agile
Participer activement à toute la chaine de valeur d’un projet (création d’infrastructures et des plateformes, collectes des données, modèle de machine learning, configuration d’API, test et déploiement continue) en collaboration avec les autres compétences (devops, ETL, architecte…)
Supporter vos équipes et assurez l’homogénéisation des pratiques de codes au sein des
Définir une roadmap technologique et collaborer sur l’architecture pour la supporter
Coordonner la réalisation d’analyses spécifiques ainsi que le développement d’outils d’analyses en support à nos opérationnels opérant dans les différents secteurs d’activité où GreenFlex intervient.
Mettre en place des bonnes pratiques d’analyse.
Structurer la mise en œuvre des évolution techniques en vue de répondre à de nouveaux besoins
Profil recherché
Profil recherché :
Grandes écoles d’ingénieur ou université

Vous avez une connaissance approfondie sur python un fort intérêt pour l’architecture data.
Vous maitrisez les technologies de données tel que spark plus généralement la construction de pipeline de data.
Une expérience managériale dans le domaine de l’analyse de données est souhaitée.
Intérêt démontré pour les problématiques liées à l’énergie et plus particulièrement à l’efficacité énergétique.
Aptitudes particulières :
Profil polyvalent avec un fort esprit de synthèse et de communication.
Fortes capacités en analyse quantitative.
Aisance dans la manipulation d’outils d’analyse et de visualisation
La connaissance de Base de données est appréciée
Pragmatisme, rigueur, autonomie et forte capacité d’organisation et d’initiative.
Une expérience préalable réussi en management d’équipe est un préalable indispensable
Connaissances de R, Python, Spark, Scala, Kafka appréciée.
Informations complémentaires
Type de contrat : CDI
Lieu : Paris, France (75009)
Niveau d'études : Bac +4
Expérience : > 5 ans"
Paris (75),,,Manager Data Application Engineer,Artefact,- Paris (75),"Who are we ?

Artefact is a new generation of a data service provider, specialising in data consulting and data-driven information system, dedicated to transforming data into business impact across the entire value chain of organisations. We are proud to say we're enjoying skyrocketing growth.

Our broad range of data-driven solutions in data consulting and information system are designed to meet our clients' specific needs, always conceived with a business-centric approach and delivered with tangible results. Our data-driven services are built upon the deep AI expertise we've acquired with our 1000+ client base around the globe.

We have 1000 employees across 20 offices who are focused on accelerating digital transformation. Thanks to a unique mix of company assets: State of the art data technologies, lean AI agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client.

To support and develop its growth, Artefact is looking for the next talents of the data divizion to join the engineering team. Organized in feature team, you will work in project mode (ou pizza team) to advise your clients on their IA problematics, machine learning and Big Data. The projects you will work on can go from the migration of infrastructure to the Cloud (Deezer) to the construction of a predictive model of the water rises (Greenpeace).

Your assignments :
Management : You work within a team where mutual aid and development of competences are key, you coach interns and juniors, you carry out technological monitoring, you take part in technical training given by our partners such as Google or Azure.

Delivery : You are full owner of the front to back solution, responsible for devising, implementing and deploying it. You work within a team made up of engineers, consultants, data scientists, strategic planners to identify your client needs and define innovative solutions.

Project : You are a key actor to company success participating in pitches and securing deals. Your technical capacities will allow you forge ties with your clients while accompanying and guiding them in their data and digital transformation. You will contribute to making Artefact an essential business partner.

Consulting: You are adept at choosing and setting up the most suitable technical stack based on your client's needs. You have a critical mindset to understand and optimize the organisational functioning of large firms.

Your mindset

Curious , you are always on the lookout for the latest solutions to best meet client needs. You're actively involved in the entire value chain, whether it be front-end, back end, big data infrastructure, ML model…

Entrepreneurial spirit , you come up with solutions, new ideas not only within your team but also within the entire Artefact world

Benevolent , your team fulfillment is key for you, thanks to constructive feedback you guide,drive and make your collaborators grow

Advocate of knowledge sharing, you actively participate in circulating information within Artefact (seminars, trainings, certifications, online KM)

Profile:
Ideally you hold a masters in Software Engineering or possibly machine Learning, mathematics, or computer science

Minimum three years of experience developing and implementing data driven solutions within a consulting firm

You have the capacity to actively participate in all the project value chain ( building infrastructure and platforms, collecting data, machine learning application models, setting up API's REST, tests and continuous deployment)

You have in-depth knowledge of Python, you have a strong interest for DevOps, you're familiar with Cloud technologies such as GCP or Azure. You master data technologies like Spark or Beam, with previous experience of Docker (Kubernetes is a plus)

You're a ninja of the use and exploitation of data bus like Kafka or PubSub

You have practiced indexation system such as ElasticSearch and Vespa. Ideally, you have implementation experience of a LETOR

You have a proven capacity to vulgarize technical terms and solutions for those coming from the business field, you are a key player in a diverse team

You can foresee projects risks and mitigate them through your technological choices

You have a working command of business English

Why us ?

Cutting edge stack : Python,Kubernetes, Spinnaker, Kafka, Spark, Google Cloud Platform (BQ, Dataflow, Compute Engine, PubSub, AppEngine…) , Airflow, Docker

Wide variety of projects :
Datalake set up
Chatbot building
Industrialisation of machine learning algorithms
Define the data strategy
Young and challenging environment of skilled engineers , grow your skills thanks to our mentoring program

Internationally renowned : offices in Dubaï, London, Hong Kong, Sao Paulo

Come join us #FR !

Talents-fr@artefact.com"
Courbevoie (92),,,Data Scientist Manager,INTERSEC Group,- Courbevoie (92),"Intersec est un éditeur de logiciels “fast data”, définissant et fournissant à ses clients des plateformes innovantes leur permettant de valoriser leurs données. Nos solutions permettent d’acquérir, stocker et traiter de grands volumes de données provenant de sources hétérogènes, pour en déduire des enseignements et des actions en temps réel.

Notre domaine d’application principal est le monde des opérateurs de téléphonie mobile, que nous aidons dans la valorisation de leurs données de transaction et de géolocalisation. Nos cas d’usage, allant de l‘exploitation de données géolocalisées à l’optimisation de campagnes marketing, nécessitent une expertise algorithmique dans l’analyse de données, portée principalement par l’équipe Data science. Nous recherchons aujourd’hui pour cette équipe un manager inspirant, avec une forte expertise sur la dimension marketing.
Dans ce cadre, nous recherchons un lead data scientist, qui saura :
apporter son expertise dans la mise au point de solutions de machine learning dans le domaine du marketing ;
porter le sujet tant via des projets d’expérimentation avec des opérateurs partenaires que dans la définition de solutions industrialisées ;
faire monter en compétence d’autres membres de l’équipe sur ces applications ;
organiser et suivre la roadmap sur les autres thèmes d’étude, notamment sur les données de géolocalisation.

Plus concrètement, vos missions principales seront :
Contribuer à définir clairement les besoins et cas d’usage visés et à les prioriser, en concertation avec les équipes produit et les clients partenaires identifiés
Définir les approches algorithmiques à mettre en oeuvre pour répondre à ces besoins :
Mener des recherches bibliographiques pour identifier des techniques proches des concepts étudiés
Proposer et élaborer des solutions théoriques
Réaliser le développement de prototypes pour valider les solutions proposées
Synthétiser vos travaux pour en fournir des conclusions claires et exploitables
Participer à la définition des aspects fontionnels du produit mettant en oeuvre ces solutions, au-delà du “coeur algorithmique” mentionné au point précédent
Interagir directement avec les clients partenaires tout au long des projets d’expérimentation, et les accompagner dans l’utilisation des solutions élaborées une fois cellesci
déployées
Encadrer les travaux d’études des autres membres de l’équipe ; en outre, leur transmettre votre expertise marketing, pour leur permettre de pouvoir répondre efficacement aux mêmes types de besoin dans ces domaines
Assurer l’encadrement humain des membres de l’équipe


Requirements
De formation bac+5 école d’ingénieur ou équivalent, avec une spécialisation dans le domaine du traitement de données, vous avez une connaissance approfondie des mécanismes d’apprentissage automatique, que ce soit du point de vue théorique ou pratique.

Vous justifiez d’une solide expérience dans la mise en pratique de ces méthodologies, ainsi que dans la mise en production de systèmes les mettant en oeuvre, dans le domaine du marketing (idéalement, en justifiant d’une expérience dans le secteur des opérateurs de télécommunication).

Vous avez le goût du challenge et une appétence pour mettre en place des projets de bout en bout. Être référent d’un domaine et en avoir la responsabilité de l’avancement est une perspective qui vous motive.

Vous êtes capable d’échanger en direct avec les clients sur leurs besoins (notamment en anglais), ainsi qu’en interne avec les équipe de product management et de développement, pour garantir une intégration réussie des modèles dans les solutions industrialisées commercialisées par la société.

Vous avez une appétence pour le management de projets et d’équipe, idéalement avec une expérience réussie sur ce positionnement.

Vous aimez transmettre et savez faire monter en compétence d’autres data scientists sur vos domaines d’expertise.
Benefits
Si vous recherchez un environnement avec une forte culture tech : blog, hackathon, show & tell, bonnes pratiques/veille, tenue décontractée
Si vous recherchez une équipe ouverte à l'innovation et à la prise d'initiatives
Si vous appréciez les environnements multiculturels (+22 nationalités)
Des bureaux lumineux, avec une superbe vue à 360 degrés, magasins et nombreuses commodités à proximité
Esprit startup : billard, baby-foot, consoles, bornes d’arcades, ping-pong, piano
Télé-travail & RTT
Nombreux apéros et déjeuners d’équipes
Plusieurs surprises de notre groupe « Wellness » et Comité Social d’Entreprise
Restaurant d’entreprise, cafétaria, cuisine équipée, tisaneries, salle de sport
1% employeur, prise en charge à 100% du pass navigo, Mutuelle, prévoyance"
Paris 15e (75),CDI,,Ingénieur Data F/H,Health Data Hub,- Paris 15e (75),"En lien avec les producteurs de données, la direction des données a la charge de la collecte, de la mise en qualité et de la gestion du catalogue de données. Elle prépare les jeux de données nécessaires aux projets pilotes et apporte, le cas échéant, un soutien aux projets pilotes dans le traitement des données.

Au sein de la direction des données, le data engineer, intervient auprès des producteurs de données dans la consolidation et la mise en qualité du patrimoine de données nécessaires aux projets. Il conçoit et implémente les flux d’ingestion des données depuis les entrepôts de données opérés par les producteurs de données vers le Health Data Hub.

En particulier, il a aura la charge :
D’appuyer les producteurs de données dans la consolidation des données requises :

Identifier les données nécessaires et définir le circuit de circulation des données

Collecter et nettoyer les données sources

Standardiser les données

De mettre en place les flux d’ingestion depuis le site producteur vers la plateforme « Hub » :

Mettre en place les flux d’ingestion depuis les données sources

Mettre en place un pipeline d’analyse de risques

D’apporter une expertise en « data engineering » aux producteurs de données :

Apporter une expertise en ingestion de données auprès des producteurs de données afin d’améliorer les échanges et l’automatisation des services

Promouvoir l’utilisation de modèles et format d’échange ou de stockage des données de santé standards et interopérables

Profil recherché Compétences :
Expérience dans la conception d’architecture de flux de données (Data Science pipeline)

Connaissance en architecture et technologies de systèmes distribués / Cloud, utilisées notamment dans le cadre de projets en science des données :

Hadoop, hdfs, spark

Docker, Kubernetes

Bases de données managées (SQL et NoSQL)

Connaissance des cycles et outils de développement modernes:
Cycle de développement agile

Politiques de tests

Gestion de sources distribués (git)

Compétences managériales et relationnelles :
Capacité à produire du code propre et des architectures solides et performantes.

Exigence et rigueur

Excellent relationnel et un très bon sens de la communication
Entreprise LE HEALTH DATA HUB

A la remise du rapport Villani, le Président de la République a affirmé sa volonté de faire de la santé un des secteurs prioritaires pour le développement de l’intelligence artificielle en France. Deux actions majeures ont été annoncées : l’élargissement du système national de données de santé (SNDS) aux données médicales et la création d’un « Health Data Hub » pour faciliter l’accès aux données de santé pour des projets d’intérêt général innovants sous hautes conditions de sécurité et dans le respect des droits des citoyens.

Faisant suite à plus de 100 auditions de l’ensemble de l’écosystème, le rapport de préfiguration, remis à la Ministre le 12 octobre, s’était appuyé sur une analyse des freins existants et des attentes des parties prenantes pour proposer une vision cible et une feuille de route de mise en œuvre pour le « Health Data Hub » autour de quatre grandes missions :

Soutenir les producteurs dans la collecte et la consolidation du patrimoine national de données de santé ;

Favoriser un accès simplifié, effectif et accéléré aux données à travers un rôle de « guichet unique » pour les porteurs de projets ;

Mettre à disposition des porteurs de projets des capacités technologiques sécurisées et humaines à l’état de l’art pour permettre une réutilisation innovante et performante des données ;

Soutenir l’écosystème et assurer le lien avec les citoyens et la société civile.

18 mois plus tard, la feuille de route ambitieuse a été respectée. Le 24 juillet, la loi relative à l’organisation et la transformation du système de santé a été promulguée. Son article 41 définit la Plateforme des données de santé autrement appelée Health Data Hub. En pratique, celle-ci fut effectivement créée le 30 novembre 2019. D’ici quelques semaines, la plateforme technologique sera ouverte aux premiers projets pilotes dans la perspective d’une ouverture au plus grand nombre milieu 2020. Un premier catalogue de bases de données est en cours de définition qui permettra une mise à disposition facilitée des données jugées prioritaires aux chercheurs, associations de patients et citoyens, institutions, start-ups et plus généralement, aux différentes parties prenantes du secteur de la santé.

L’équipe du Health Data Hub compte aujourd’hui une vingtaine de personnes passionnées, aux compétences variées et rassemblées autour d’un projet qui fait sens. Face aux ambitions poursuivies, c’est autant d’experts scientifiques, médicaux, ingénieurs, chefs de projets qui sont en ce moment recherchés au sein des quatre directions : technique, données, guichet, fabrique.

Plus d’information sur le Health Data Hub et son équipe sur notre site."
Noisy-le-Grand (93),,,Ingénieur Big Data,Phoenix-ISI,- Noisy-le-Grand (93),"Entreprise
Spécialisée dans l’ingénierie informatique, Phoenix ISI est le leader en prévision du trafic autoroutier français. Fort de plus de 20 ans d’expérience et d’une grande expertise dans le traitement et la valorisation des données, Phoenix ISI accompagne les sociétés concessionnaires d’autoroutes (ASF, APRR, SANEF, ATMB, ESCOTA …) en développant des méthodes de simulation et de prévision pour les aider à anticiper et définir leurs stratégies, afin d’améliorer les performances de leurs processus opérationnels.
Dans le cadre de notre fort développement et de l’augmentation des projets internes et externes de notre société, nous recherchons des ingénieurs d’études en informatique.
A la pointe de l’innovation, nos technologies évoluent constamment. Nous proposons donc à nos ingénieurs les formations nécessaires leur permettant de se maintenir et/ou de devenir des experts reconnus dans leurs domaines.
Notre environnement méthodologique et technologique couvre des concepts dynamiques et actuels tels que le “Big data”, l’intelligence artificielle, le “machine learning”.
Mission
En tant que futur Ingénieur Big Data, vous rejoindrez une équipe de développement spécialisée dans la mise en œuvre de systèmes intelligents de transport. Le système en cours de développement est basé sur une architecture hybride Big Data / Fast Data. La chaîne Big Data repose principalement sur SPARK / HDFS. La chaîne Fast Data repose par contre sur Kafka / KafkaStream.
En tant qu’Ingénieur Big Data vous serez responsable de la création et de la maintenance de l’infrastructure analytique support des fonctions manipulant des données. En particulier, vous serez responsable du développement, de la construction, de la maintenance et du test des architectures, tels que les bases de données et les systèmes de traitement Big Data et Fast Data.
Dans ce cadre, vous serez également responsable de la création de processus de modélisation des jeux de données sur l’exploration, l’acquisition et la vérification de ces derniers.
Vous monterez donc en compétence sur les domaines suivants :
Programmation : Python, Scala et JAVA
Script : Bash, Pearl
Big Data / Fast Data : Hadoop (HDFS, Hive, Oozie), Spark, Kafka
Profil recherché
Récemment diplômé(e) d’une école d’Ingénieur spécialisée dans l’informatique, autonome, curieux(se), rigoureux(se), vous êtes passionnés par les technologies web et vous cherchez à mettre en pratique vos connaissances en développement et en gestion des données dans une entreprise à taille humaine, dynamique, qui saura vous accompagner et vous former tout au long de votre carrière dans un cadre de travail sain et serein."
Paris (75),CDI,,Data Engineer,ASTRAKHAN,- Paris (75),"Astrakhan agit auprès de grands comptes en France, et à l’international (Hong Kong), sur des problématiques fonctionnelles, techniques et managériales.

Nos missions nous permettent d’intervenir sur une gamme de prestations à forte valeur ajoutée, en adéquation avec les besoins des métiers, tous secteurs d’activité confondus.

Nous recrutons de nouveaux talents pour rejoindre notre équipe IT Consulting. Si vous souhaitez accompagner les transformations digitales de nos clients, dans un cabinet à échelle humaine, sur des projets de grande envergure, alors cette offre est faite pour vous.

Description du poste :

Nous sommes à la recherche d’un(e) Consultant(e) Data Engineer d’au moins 2 ans d’expérience, curieux(se) et soucieux(se) de se diversifier vers des rôles de Data Analyst ou Data Scientist, pour concevoir des pipelines de données sécurisés traitant des volumes importants de données.

Dans le cadre des différentes missions que nous menons, dans tous les secteurs d’activité, le(la) Consultant(e) Data Engineer veillera à créer de la valeur pour ses clients : identification et qualification des usages, design de solution, Architecture et gouvernance des données…

L’exigence dans le travail et le souci de la qualité des livrables seront particulièrement appréciés.

Vous intégrerez une équipe pluridisciplinaire, centrée tant sur la technologie que sur la capacité à innover et travailler en équipe.

Profil
Vous disposez d’une formation en École d’Ingénieur ou d’une formation de niveau bac+5 dans le domaine des technologies de l’information et vous justifiez idéalement d’une première expérience en Data Engineering ou Big Data.

Vous êtes un spécialiste des langages structurés (JavaScript ; Java ; Scala) ou des langages de données (Python, R). La connaissance d’un environnement de services Cloud (Amazon Web Services, Google Cloud Platform …) est fortement appréciée.
Vous maitrisez les principales technologies du Big Data (Big Query, ElasticSearch, Hadoop, Impala).
Vous souhaitez vous impliquer et prendre rapidement des responsabilités sur des missions à forte valeur ajoutée.

Le poste est à pourvoir immédiatement.

Maitrise de l’anglais souhaitable.
Région Paris - Région parisienne
Contrat CDI
Salaire Négociable selon profil
Statut Cadre du secteur privé
Niveau d'expérience 2 ans minimum"
Saint-Mandé (94),CDI,,Docteur R&D – Intelligence Artificielle / Natural Language Processing - PAC F/H,RD2 CONSEIL,- Saint-Mandé (94),"Notre client souhaite aujourd’hui renforcer son expertise R&D par le recrutement d’un Docteur (H/F) en Intelligence Artificielle / Natural Language Processing avec pour objectif d’améliorer la solution sur la rapidité et la précision de la détection des comportements anormaux.

Dans une équipe Data Science de 4/5 personnes et en lien direct avec le co-fondateur de la société, Docteur en Intelligence Artificielle, vous interviendrez principalement sur l’analyse des logs des systèmes informatiques et vos missions seront les suivantes :

Développement de nouveaux modèles de Machine Learning pour la prédiction, la classification et le clustering

Analyse de données volumineuses (Big Data) dans le cadre du développement de systèmes apprenants et prédictifs

Déploiement et tests des modèles Machine Learning à grande échelle

Coopération avec l’équipe développement pour intégrer les modules de machine learning dans le produit final
Profil recherché Nous cherchons un candidat disposant en particulier des compétences suivantes :

De formation initiale en Informatique, vous avez réalisé un Doctorat en Natural Language Processing ou Intelligence Artificielle

Vous maîtrisez également la programmation informatique permettant de concevoir, d’’implémenter les solutions sur des données volumineuses et les tester à grande échelle (en particulier Python)

Une expérience dans la construction de modèles Deep Learning (utilisant des réseaux de neurones profonds) est un plus. Vous devez être à l’aise avec d’autres techniques de ML plus traditionnelles

Maîtrise de l’anglais obligatoire

Notre client recherche surtout des collaborateurs engagés et dynamiques. Vous disposez des qualités suivantes :

Force de proposition et proactif

Esprit d’équipe

Pragmatique et orienté résultat

Si vous pensez être cette personne, que vous êtes titulaire d’un Doctorat et n’avez jamais été embauché en CDI après l’obtention de votre thèse (contrainte impérative pour respecter les critères du CIR), nous vous invitons à nous faire parvenir votre CV et lettre de motivation par mail sous la référence PAC
Entreprise RD2 Conseil est un cabinet de recrutement spécialisé sur la

recherche de compétences scientifiques

pour les besoins en R&D des PME innovantes et entreprises privées, souhaitant se doter de compétences pointues et de réelles ressources humaines en matière d’Innovation.

Créé en 2018, notre client a développé une solution automatisée, basée sur l’Intelligence Artificielle, de maintenance prédictive pour les infrastructures informatiques et travaille avec plusieurs entreprises du CAC 40.

L’outil est précurseur par sa capacité à gérer la complexité (à la fois par sa capacité à monitorer des architectures distribuées et gérer un volume significatif de données). Il permet à la fois de prédire les incidents IT et également d’accompagner les ingénieurs dans la résolution des problématiques (gain de 50% du temps d’intervention). La qualité de service et l’expérience utilisateurs et ainsi considérablement améliorée.

Forte d’une récente levée de fonds de plus de 2 millions d’euros, la start-up est en plein développement. Elle a également été nominée comme la start-up la plus innovante et a remporté le « Trophée Start-up Numérique » organisé par la région Île-de-France."
Paris (75),CDI,,Data Engineer (H/F),Cirruseo,- Paris (75),"Cirruseo part of Accenture data met en place pour ses clients des solutions hébergées sur le cloud dédiées à l’analyse des données internes et externes à l’entreprise.
Ces solutions couvrent l’ensemble du spectre du data management, de la simple modélisation type datawarehousing jusqu’aux prototypes les plus innovants, mêlant reconnaissance visuelle, exploration sémantique, méthodes statistiques avancées.
Le collaborateur aura l’occasion de participer au design et à l’élaboration de solutions, depuis le recueil des besoins jusqu’à la mise en production et au support en production.
Une participation aux activités d’avant-vente.
Au-delà de solides compétences techniques, ce poste requiert une culture scientifique large, une vraie curiosité pour l’ensemble des process opérationnels de l’entreprise (marketing, ventes, comptabilité, production…) et une capacité à traduire les besoins métier dans une architecture applicative performante et ergonomique.
Profil recherché
De formation ingénieur (informatique ou généraliste) ou Bac+4, Bac+5, vous remplissez plusieurs des critères suivants :
expérience en développement de solutions Big Data / Machine Learning
maîtrise de Python, ou d’un autre langage majeur (Java, C++/#…)
compétences SGBD et maîtrise SQL
compétences Hadoop / Spark
Un plus si connaissance des produits Google Cloud Platform (BigQuery, Cloud DataFlow, Google APIs ML…)
De plus, vous avez une bonne maîtrise de la langue anglaise.
Vous êtes intéressé par le Cloud Computing, passionné par Google et les technologies web. Vous êtes curieux, aimez apporter des solutions et vous approprier de nouvelles technologies. Vous êtes sociable, communiquant et aimez travailler en équipe.
Déroulement des entretiens
Cirruseo part of Accenture, c’est plus de 100 collaborateurs, tous plus passionnés les uns que les autres. Nous rejoindre c’est partager une belle aventure qui dure depuis 2011 dans un cadre jeune et dynamique. Vous intégrez une équipe passionnée et dynamique de développeurs à la pointe des technologies web et Google.
Ce poste vous apportera :
Le plaisir de travailler sur des technologies innovantes et en avance sur le marché
L’opportunité de participer à des projets d’envergure, porteurs d’enjeux stratégiques pour nos clients
La satisfaction de contribuer à l’adoption d’une informatique moderne : le Cloud Computing
L’opportunité d’interagir régulièrement avec Google et d’autres acteurs majeurs Cloud/Big Data
Merci de nous envoyer votre CV à recrutement@cirruseo.com ou de postuler directement sur notre site"
Paris (75),,,[Technologies] Ingénieur Big Data (H/F),Meritis Technologies,- Paris (75),"Vos points forts
# # # # #
Ce poste est-il fait pour vous ?
Vous êtes diplômé d’une école d’Ingénieur en Informatique
Vous avez déjà voyagé dans les pays suivants au cours des 3 dernières années : Python, Spark et Hadoop
Vous rêvez de découvrir de nouveaux horizons tels que Yarn, Zeppelin et Hive
Evidemment, grâce à ces nombreux voyages, vous parlez Anglais couramment
Contexte
Comme beaucoup d’entreprises, notre client, grand site de voyage en ligne, collecte et stocke des quantités massives de données, qu’elles proviennent de l’extérieur ou de l’intérieur de son système d’information. Dans le cadre de sa transformation DevOps, notre client développe des nouveaux services de supervision applicative et conçoit les outils de détection d’anomalies et d’alerting de demain.
Poste en détail
Vous serez amené(e) à travailler sur les sujets suivants :
L’exploitation de l’infra Big Data Hadoop, Yarn et Spark
L’architecture Big Data :
Définition des besoins techniques et des flux de données dans une architecture Big Data
Suivi de l’alimentation des données dans le système de stockage HDFS
Le développement :
Réalisation de POC d’utilisation de technologies Big Data
Analyse des logs en Spark
L’intégration de nouvelles technologies dans la stack Big Data :
Configuration des outils
Gestion de la configuration de l’infrastructure"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),"Apprentissage, Contrat pro",,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
Dirigée par le Chief Data Officer et rattachée directement au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques (DDSA) se compose de cinq services. Elle met en œuvre la stratégie définie par le Chief Data Officer afin que la Banque transforme ses données en un capital pleinement valorisé.
La DDSA a pour missions essentielles la gouvernance, le partage et la valorisation des données, le développement de projets d'intérêts communs, le développement d'une culture de la donnée et la contribution à la data réputation de la Banque.

Présentation du Service
Au sein de la Direction des Données et des Services Analytiques (DDSA), le Service des analyses quantitatives et méthodes avancées (QUANTIM) développe un savoir-faire en matière d'analyse quantitative des données en s’appuyant plus particulièrement sur les méthodes innovantes issues de la data science et offre son expertise dans le cadre de travaux menés en coopération avec les autres services de la Banque sur des problématiques métier très variées.
Le QUANTIM contribue également à la mise en œuvre de la plateforme analytique du Datalake de la Banque ainsi qu’à l’animation de communautés dédiées aux méthodes de traitement des données et à l’accompagnement de tous les utilisateurs de R.

Descriptif de mission
En tant qu’Alternant Data Scientist au sein du QUANTIM, vous serez intégré(e) à une équipe de 10 personnes.
Les missions qui vous seront confiées pourront notamment porter sur l’une ou l’autre des thématiques suivantes :
• À partir des bases de données disponibles à la Banque (sur le portail statistique public Webstat ou, en interne, le Datalake de la Banque), développer des outils permettant de recommander automatiquement des séries explicatives (à partir de différentes corrélations, corrélations glissantes, cohérences d'ondelettes, etc.) s'apparentant à l'ancien outil de Google appelé Google Correlate ;
• À partir des bases de référentiels disponibles à la Banque, mettre en place des outils de visualisation des groupes bancaires et financiers en s'appuyant sur les méthodes d’analyse des réseaux ;
• À partir des articles de presse quotidienne disponibles sur Internet, contribuer à l’analyse de l'information textuelle afin d’estimer le niveau d'incertitude économique en général et, à la discrétion des autorités de la Banque, liée à une problématique précise (coronavirus par exemple).

Profil recherché
Formation recherchée : Grande école ou Master 2 en data science ou en économétrie / statistiques avec une forte appétence pour la data science
Compétences : machine learning, text mining, webscraping, datavisualisation, graph mining, séries temporelles, programmation R/Python, connaissances en anglais (littérature académique)
Qualités : rigueur, réactivité, autonomie et curiosité ; esprit d’initiative, sens aigu de l’innovation
Une première expérience significative (stage de 6 mois, projet annuel en groupe ou mémoire ) dans la pratique de la data science constituera un atout.

La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes recrutées."
Stains (93),,,Chef de projet R&D Intelligence Artificielle (H/F),CRIGEN,- Stains (93),"Le CRIGEN est le centre corporate de R&D et d'expertise opérationnelle d’ENGIE dédié aux nouveaux gaz, aux nouveaux usages de l’énergie, au digital et technologies émergentes. Situé en région parisienne à Stains (93), il compte 200 collaborateurs. Il fournit des applications industrielles testées, éprouvées et commercialisables, ainsi que de nouvelles offres basées sur le développement et la mise en commun d'idées innovantes, de connaissances scientifiques et d'expertise technique. Sa capacité à innover constitue un avantage clé pour le Groupe ENGIE.
ENGIE a remporté en août 2019 un important projet européen sur l’interopérabilité des solutions informatiques basée sur les techniques de Knowledge Representation & Reasonning.
La digitalisation du secteur de l’énergie permet de meilleurs niveaux de performance opérationnelle notamment grâce à l’adoption de technologies disruptives. L’environnement Big Data des réseaux énergétiques intelligents fournit un écosystème idéal pour l’exploitation de la connaissance générée par les données. Le Projet vise à déployer de façon simple des traitements distribués et des technologies d’analyses de données pour des systèmes de management de l’énergie en temps-réel. Des connecteurs IDS garantiront la gouvernance de la data pour le partage de données entre les différentes parties prenantes et garantiront la coordination et la coopération sur toute la chaine de valeur. Le projet développera une architecture, de conformité COSMAG, pour construire et déployer des solutions évolutives et reproductibles de management de l’énergie. Ces solutions contribueront à augmenter la consommation d’énergie renouvelable, à développer le management de réseaux intelligents, à améliorer l’efficacité énergétique et à optimiser la gestion des actifs de l’énergie.
La nouvelle architecture et ses composants seront d’intérêt pour les différentes parties prenantes du secteur de l’énergie depuis le fournisseur d’électricité, en passant par le distributeur, l’agrégateur, l’ESCo, et jusqu’à l’utilisateur final. Le projet sera validé par 7 pilotes dans 4 pays différents qui fournissent des cas d’usage réels de Big Data dans le secteur de l’énergie. Son objectif est de construire une solution basée sur les standards européens pour manager les données et l’accès aux données des pilotes, les modèles, les interfaces, la gouvernance, et les enjeux de souveraineté. Il vise aussi à fournir un reporting des résultats au différents groupes de standardisation.
Le Lab Computer Science & Artificial Intelligence est spécialisé dans le développement « d’agents » intelligents et interopérables pour apporter de nouvelles solutions digitales aux BUs du Groupe. Ses domaines d’expertise sont le Machine Learning (notamment dans les domaines de la Computer Vision, le Natural Language Processing, la sémantique et les graphes de connaissance), les blockchains et les systèmes multi-agents. Il dispose de moyens de calcul puissants en calcul scientifique HPC et avec le système NVIDIA DGX pour les enjeux d’Intelligence Artificielle.
Ainsi, le Lab Computer Science & Artificial Intelligence du CRIGEN souhaite renforcer ses effectifs et recherche un(e) :
Chef de projet R&D Intelligence Artificielle (H/F)
Poste basé à Stains (93)
Rattaché(e) au Chef de Lab, dans le cadre de ce projet de recherche international et pluriannuel, vous :
- réalisez des travaux à caractère scientifique pointu,
- travaillez en mode collaboratif avec les partenaires du projet,
- maîtrisez les enjeux, risques et contraintes associées au fonctionnement et pilotage des projets européens,
- garantissez la réussite technique et la qualité de la production des livrables,
- conduisez les projets de recherche et développements collaboratifs associés et assurez la production et le suivi scientifiques,
- managez l’équipe projet,
- assurez la synergie et la mobilisation des compétences des différents acteurs internationaux et communiquez, diffusez et valorisez les résultats obtenus,
- réalisez des prestations de conseil de haut niveau et de soutien technique.
A moyen terme, vous pourrez évoluer vers des postes à responsabilités dans la gestion de projets et d’encadrement d’équipes.

Qualifications
De formation Bac +5 ingénieur ou filière universitaire ou doctorat, vous justifiez d’u ne expérience réussie d'au moins 5 ans dans le domaine de l’intelligence artificielle en R&D appliquée et de la sémantique, dont plus de 2 ans en montage et gestion de projets collaboratifs internationaux avec recherche de financements. Vous disposez de compétences en Data Sciences, Machine Learning, Text Mining, aide à la décision, Deep Learning, optimisation, programmation (R, Python, C/C++, JAVA, C#, SQL, PL/SQL, VB6), base de données (Oracle, SQL Server, Access, GraphDB, Neo4j), Big Data (Hadoop, Spark) et conception (Merise, UML).
Doté(e) de connaissances générales et d’un intérêt pour les énergies renouvelables, vous avez une bonne compréhension du contexte énergétique français et européen, des mécanismes de soutien financiers aux projets de R&D et du montage de projets industriels.
La maîtrise de l’anglais est nécessaire et des déplacements en France et à l'international sont à prévoir.
A l’écoute, vous vous adaptez aisément à différents interlocuteurs, faites preuve d’aisance relationnelle et d’une capacité à communiquer votre expertise. Doté(e) de recul et d’autonomie, vous appréciez le travail en équipe, êtes force d’analyse et de proposition. Rigoureux(se) et organisé(e), vous êtes à même d’anticiper, de planifier et d’être polyvalent(e).

Emploi
: R & D / Laboratoires
Lieu principal
: Europe-France-Île-de-France-Stains
Organisation
: Fonctions Opérationnelles
Horaire
: Temps plein
Nature de responsabilité
: Responsable d'équipe de première ligne / Cadre
Publication d'offre
: 26 déc. 2019, 18:05:57"
Paris (75),CDI,40 000 € - 50 000 € par an,DATA SCIENTIST - Jeune Docteur / PhD,Harnham,- Paris (75),"Data Scientist - Jeune Docteur / PhD
Paris, France
40-50K

Cette belle startup de 2 ans vient de lever plusieurs millions d'Euros pour continuer sa croissance. Elle a construit une plateforme SaaS qui accompagne les entreprises dans leurs projets IT grâce à de l'Intelligence Artificielle et du Machine Learning.
Ce poste offre la possibilité de travailler sur des sujets NLP et des sujets plus larges de Machine Learning, entouré d'une équipe Data Science en place.
LE POSTE:
Encadré par le CTO de la société, vous travaillerez avec une équipe de profils seniors et juniors basé sur Paris
Votre background académique et technique vous permettra d'apporter votre expertise du côté Data Science sur des sujets R&D Machine Learning (utilisation de Python à prévoir)
Vous travaillerez sur divers algo ML pour optimiser la plateforme sur des problématiques clés dans la roadmap data de la société

VOTRE PROFIL:
Un Doctorat en Computer Science ou Data Science/NLP ou domaine relié
Vous êtes en recherche de votre premier CDI (afin d'être éligible au CIR)
Expertise sur Python ou C++
Force de proposition et bon communicant

COMMENT POSTULER :
Si vous êtes intéressé(e), merci de faire part de votre CV via ce site / postuler."
Paris 14e (75),CDI,,Data Manager et biostatisticien(ne) recherche cliniqueH/F,GROUPE HOSPITALIER PARIS SAINT-JOSEPH,- Paris 14e (75),"Parce que vous placez le patient au ceur de votre engagement, votre expertise et votre enthousiasme nous intéressent,
Rejoignez le plus important groupe hospitalier privé à but non lucratif de France !

Le Groupe Hospitalier Paris Saint-Joseph est né le 01 janvier 2020, de la fusion de l'Hôpital Marie Lannelongue et de l'Hôpital Paris Saint-Joseph

De réputation nationale et internationale : une dynamique d'excellence toujours au service des patients, et un engagement fort dans l'innovation et la recherche pour rester à la pointe des avancées médicales

Nos domaines de spécialisation selon nos sites :

Hôpital Marie Lannelongue (Le Plessis-Robinson-92) : pathologies cardiovasculaires et pulmonaires complexes du nouveau-né à l'adulte

Hôpital Paris Saint-Joseph (Paris 14ème arrondissement) : 25 services de spécialités médicales, chirurgicales et obstétriques, organisées autour de centres pluridisciplinaires et d'instituts hautement spécialisés.


Le/la Data Manager et biostatisticien(ne) recherche clinique assure la création, le suivi, le contrôle, le traitement et l'analyse statistique des bases de données des projets de recherche clinique, en relation étroite avec toute l'équipe du Centre de recherche Clinique du Groupe hospitalier Paris Saint Joseph, l'investigateur le coordonnateur et le méthodologiste de l'étude ainsi que l'ingénieur statisticien du département de l'information médicale de l'hôpital.

Les missions seront les suivantes:

Participer à l'élaboration du plan d'analyse statistique des protocoles, en lien avec l'investigateur et le méthodologiste responsable
Elaborer des cahiers d'observation (CRF, eCRF) à partir d'un protocole d'essai clinique
Réaliser et mettre en production des bases de données cliniques,
Définir et programmer des contrôles de cohérences.
Valider des données (suivi des queries : envoi et traitement des retours, contrôle qualité).
Préparer des réunions de revue des données (production de listing et de rapports).
Gérer les comptes utilisateurs, la formation des utilisateurs.
Assurer la réconciliation de différentes bases de données (EIG, PV, codification, données externes ).
Gérer et traiter les données numériques pour l'analyse statistique.
Assurer l'analyse statistique des bases de données cliniques.
Rédiger des rapports d'analyse, validés en collaboration avec le référent statisticien et communiquer les résultats au promoteur et aux investigateurs jusqu'à la publication.

De Formation scientifique (de niveau bac + 2 à Bac +5) en gestion des données et une première expérience dans ce domaine est souhaitée.
Bonne connaissance de la recherche clinique et de la réglementation : Cnil, BPC, ICH, Loi Jardé.
Bonnes connaissances des outils de programmation, statistiques (R, python, SAS)et bureautique .

Rigueur scientifique, réactivité, adaptabilité, capacités d'analyse et de synthèse et esprit d'équipe sont des qualités qui vous permettront de réussir sur le poste

Temps plein, 35h du lundi au vendredi.


Ampli"
Paris 2e (75),"Temps plein, CDI",,Natural Language Processing Researcher,Lingua Custodia,- Paris 2e (75),"The company - Lingua Custodia
Founded in 2011, Lingua Custodia is the unique Fintech expert in Machine Learning applied to financial translations. We are developing smart translation engines specialised by document types or customised for a client. Our ambition is to help financial institutions to use their linguistic data more efficiently so that they can spend less time and money in translation and communicate rapidly and effectively with their clients whatever their native language may be. Our clients are mid to large financial institutions (AXA, HSBC, BNP-Paribas, …) mostly located in Europe and some in Asia. Lingua Custodia is a founding member of France Fintech, certified by Finance Innovation since 2014 and member of the Luxembourg House of Financial Technology (the LHoFT). The company is widely recognised for its innovation capability and has been regularly awarded. We are just about to close a fund raising operation in order to fuel our growth and international development. Opening a new office in Luxembourg is already scheduled in September 2019.
Lingua Custodia’s team is composed of a diversified mix of profiles, strongly skilled in their area of expertise, all committed to our entrepreneurial adventure. But what we value the most at Lingua Custodia are soft skills: Team spirit, trustfulness, open-minded thinking, enthusiasm, freedom to try new ideas or practices.
www.linguacustodia.finance
Responsibilities
The NLP researcher will be part of the R&D team. He/she will design and implement experiments in the field of Neural Machine Translation, which will be reported in scientific, technical publications and demonstrators at international conferences (WMT, EAMT, ACL, EMNLP). Research activities relate mainly to the following topics:
Automatic data extraction and cleaning methods
Bilingual Terminology induction from monolingual data
Terminology control in Neural Machine Translation to ensure the reliable translation of specific entities
Modeling of source sentence coverage during translation
Document-level Machine Translation
Machine Translation evaluation
Qualifications
PhD in Computer Science, Machine Learning, Natural Language Processing or any related fields.
Strong track record of successful implementations and publications in Natural Language Processing or Machine Learning.
Experience in Linux environment: Bash scripting.
Proficiency in Python
Proficiency in at least one neural framework: TensorFlow, Pytorch, MxNet, etc.
Benefits
Friendly startup environment in the center of Paris
Laptop
Possibility to work remotely
Good health insurance
Meal vouchers
Job Types: Full-time, Permanent"
Paris (75),"Temps plein, Stage",,JUNIOR SOCIAL DATA ANALYST - ITALIAN SPEAKER,Linkfluence,- Paris (75),"About
Linkfluence first started as a passion project between four students with an ambitious goal: to understand and “map” the social web. With backgrounds in engineering, artificial intelligence, and sociology, these founders soon realized the potential of this idea and launched a company in 2006 to fulfill this potential.
Today, Linkfluence is a leading social media intelligence company that turns social data into valuable insights for global brands. Our hybrid combination of AI and human expertise is what sets us apart from other social listening players in the industry.
We serve over 500 clients worldwide across all industries, from global brands like LVMH, Danone, Carrefour, AirFrance, Pernod Ricard, and agencies like Publicis and Havas.
Our team is young, diverse, and ambitious, and we’re growing rapidly. We have 220 people of over 20 different nationalities spread across our offices in Paris, London, San Francisco, New York, Düsseldorf, Shanghai, and Singapore. We are a multicultural organization, and are committed to a gender-balanced workforce.
If you’re passionate about staying on top of online trends, if your ambition is to help companies serve their customers, if you’re curious about what’s happening in the world and love to listen to others, and if you’re thrilled to be a part of shaping the future of social media intelligence, then we want to hear from you!
Job Description
Linkfluence is looking to hire a Social Media Analyst intern to join our Global Insights Department. After being trained in Linkfluence technologies and methodologies, you will assist in the production of social media monitoring and research reports for our clients.
Your missions will be to:
Analyze qualitative and quantitative data from different social media platforms via our software, Radarly.
You will work on diverse projects from different sectors: Corporate, Luxury, Beauty&Cosmetics, FMCG, Wines&Spirits, Automotive, Pharmaceutical, etc and your missions would include:
Detecting trends and influencers
Monitoring consumer conversations
Production of monitoring and ad-hoc social media research reports
Providing workable recommendations for clients to help them with their strategy and to understand their consumers
For this role you should be:
· Curious and analytical
· Excited to work with a variety of brands and sectors
· Capable of working under pressure in a team with a positive energy
Preferred Experience:
A first experience in a similar position in data analysis.
Masters or equivalent in Marketing & Communication, Commerce or Social Science
Good understanding of marketing strategies, market studies and social media
Fluent in Italian and English, a third language is a plus
Comfortable working with quantitative data. Advanced MS Office (Excel and PowerPoint)
What we offer:
Company with passionate and ambitious projects
Complete training and onboarding process
Opportunity to take initiatives
Flexible work space (standing desks and cozy rest areas)
Full of dynamic, multicultural and kind people : )
Flexible working hours and home office policy
Great office address with tons of good restaurants and bars
Lunch vouchers (Lunchr card)
Afterwork, Pizza&Learn
Why should you join the team and take on the mission?
As a social media intelligence company, social media and technology are our future. We’re committed to innovation and work hard to stay ahead of digital and social trends.
We’re passionate about giving a voice to consumers by helping brands to understand online conversations and exchanges, and by providing the human expertise necessary to respond to these exchanges. We believe helping businesses around the world to better understand each other can only lead to good outcomes.
As a growing company, we combine a startup mindset with the resources necessary to commit to exciting new initiatives. We have a proven track record of success and funding and work with global brands with significant influence and market presence.
At Linkfluence, everyone has an opportunity to make a difference. We believe in hiring motivated individuals with passion and talent, and we listen to our employees when making company-wide decisions.
Our Paris office is situated in the heart of Paris, 9th arrondissement (South Pigalle), which means we’re well-connected with 4 different metro lines and surrounded by fantastic restaurants and bars!
If you’ve read this far, you should probably apply!
*We’re already looking forward to knowing more about you! *
Job Types: Full-time, Internship"
Paris (75),,,Lead Data Analyst,Blade,- Paris (75),"COMPANY DESCRIPTION

Shadow is a high-end Windows 10 PC accessible from anywhere at anytime. Thanks to our apps (Windows, Mac, Linux, Android) and to the Shadow Ghost, the service is available on any kind of device (laptop, smartphone, tablet, Android TV…). This way, any connected device with a screen becomes a powerful gaming or working station offering a unique experience.
Shadow’s software is frequently updated and the hardware components are improved in our highly secured data centers. No need to change your computer every few years, Shadow is the end of obsolescence!

With more than €100m raised since inception, we truly believe that Shadow represents a whole new way of using computers. Much more than a PC, Shadow is THE answer to the increasing need of computing power, mobility and hardware replacement.
Help us make this incredible dream come true.

JOB DESCRIPTION
Sitting in our Paris office, you will report directly to the VP of Business intelligence and will interact with employees from our two offices, Paris and San Francisco. You will be primarily responsible for collecting, analyzing and summarizing data to answer departments needs and turn it into actionable insights. You will also work on data science projects to answer cross-functional challenges faced by the company. You will integrate a team of 3 to 4 full time employees and 1 to 2 interns.

Responsibilities
Take part in the definition and computation of company KPIs to drive growth, efficiency and profitability
Define, display and communicate a unique source of truth within the company through data visualization tools. You will be the key business partner in the following areas:
Sales & marketing
e-commerce
Product & Dev
Support
Business development
Be responsible for the overall consistency of operational data displayed, communicated and used within the company, across the different tools we use (e.g. Power BI, Metabase, Adobe, etc.)
Propose, design and develop advanced models / algorithms to drive smarter business decisions (e.g. prediction tools, clustering)
Participate in the definition of data architecture specs & processes. You will work hand in hand with data engineers to define the architecture and content of the company data warehouse, accessible to all departments.
Contribute to the data literacy of the company by training other departments on the data warehouse and make a better use of data.
Be the key data partner in the implementation of the Adobe suite (Analytics, Audience Manager, Campaign, Target). Contribute to the use of Adobe within the company and the maintenance of the tool. Leverage on Adobe data and infrastructure to propose and develop data science projects (e.g. churn reduction, segmentation, etc.).
Support the rest of the BI team when needed on infra, finance, management and investors topics
Make recommendations on the data tools and infrastructure which best suit our needs
Background & Skills
1-2 years of experience in data analysis and ideally data science
Fluent in French and English
Very good command of a data visualization tool like Power BI, Tableau, Looker (or any other tool)
Advanced level in SQL
Good knowledge of programming languages used in data analysis and data science (Python or R for instance). Experience in machine learning and ability to run a project from A to Z (data preprocessing, model selection and running, fine-tuning of parameters, supervision of deployment with data engineers)
Knowledge of web analytics tools (such as: Google Analytics, Adobe analytics) and tracking implementation on different platforms would be a plus
You are very analytical, pay attention to details and to data consistency across sources
You are not only a technical/analytical person, you also have strong business sense and have great interpersonal skills
Eager to learn and eager to share your knowledge and best practices with the rest of the company"
Paris (75),CDI,,CONSULTANT SENIOR DATA & ANALYTICS F/H,Ipsos,- Paris (75),"À propos
Ipsos est le leader en France des études de marché et des enquêtes d’opinion. Groupe français indépendant, fondé en 1975, Ipsos opère aujourd’hui dans 90 pays et donne aux entreprises et aux institutions pour lesquelles il travaille, les clés de compréhension de la société, des marchés, des citoyens et des consommateurs.
Une mission qui s’appuie sur la disruption numérique, l’extension des domaines d’observations et l’innovation continue pour améliorer la finesse des analyses.
Intégrer Ipsos aujourd’hui c’est :
Choisir un métier passionnant au cœur des enjeux d’actualités et des transformations de la société.
Bénéficier d’une multiplicité d'opportunités d’apprentissage dans des secteurs différents : le marketing, la publicité, les médias, la politique, le CRM, qui intègrent les dernières innovations digitales et technologiques.
Se voir confier des responsabilités immédiatement sur des études avec de véritables perspectives d’évolutions professionnelles.
Evoluer au sein d’un groupe international dans lequel les opportunités de mobilité sont une réalité.
Pour répondre aux nouveaux besoins de ses clients, Ipsos dispose de plus de 75 services différents regroupés dans 17 Lignes de Services.
Cette nouvelle organisation nous permet d’aiguiser nos expertises pour apporter à nos clients des réponses précises à leurs questions, en nous permettant d’être plus spécialisés, rapides et homogènes sur tous les marchés.
Descriptif du poste
Le département DMC (Data Management Center) d’IPSOS France recherche un(e) Consultant Data et Analytics expérimenté(e) capable de déployer l’offre data et de porter le discours d’hybridation auprès de nos clients/prospects.
Le DMC produit des analyses data basées sur des modèles supervisés/non-supervisés.
Nous travaillons principalement sur des données «individus/consommateurs/citoyens»
Nous hybridons diverses sources : enquêtes, comportements digitaux, base CRM, open data, géo data…
Nous déployons nos solutions au niveau international
Notre activité est en forte croissance
Missions
Sous la responsabilité du Chief Data Officer :
Vous imaginez et présentez des solutions « data centric » auprès de nos clients/prospects
Vous élaborez et/ou supervisez l’élaboration de modèles de comportements d’achat, des typologies hybrides, des analyses de drivers de KPI…
Vous insufflez une vision « client-centric » 360°
Vous mettez en place des formations internes et externes en data fusion/data science orientée solution « client »
Profil recherché
Data Scientist (H/F) avec une expérience minimum de 5 ans ; une expérience antérieure en Institut d’Etudes Marketing sera fortement appréciée
Vous avez une forte appétence commerciale, vous aimez communiquer (clients/prospects/interne) et êtes fortement impliqué au sein de communautés Data
Vous avez une expérience en hybridation des données (activation de cibles digitales par exemple)
Vous maitrisez Python, le Machine Learning & le Cloud Computing
Vous aimez travailler en équipe
Maîtrise de l’anglais
Informations complémentaires
Type de contrat : CDI
Date de début : 05 avril 2020
Lieu : Paris, France (75013)
Niveau d'études : Bac +5 / Master
Expérience : > 5 ans"
Montrouge (92),"Apprentissage, Contrat pro",,Inspecteur Data Analyst H/F,CA CIB FRANCE,- Montrouge (92),"Crédit Agricole CIB est la banque de financement de d'investissement du groupe Crédit Agricole, 12e groupe bancaire mondial par les fonds propres Tier1 (The Banker, juillet 2018). Près de 8300 collaborateurs répartis en Europe, Amériques, Asie-Pacifique, Moyen-Orient et Afrique du Nord, accompagnent les clients de la Banque dans la couverture de leurs besoins financiers à travers le monde. Crédit Agricole CIB propose à ses clients grandes entreprises et institutionnels une gamme de produits et services dans les métiers de la banque de marchés, de la banque d'investissement, des financements structurés, de la banque commerciale et du commerce international. Pionnier dans le domaine de la finance Climat, la Banque occupe aujourd'hui une position de leader sur ce segment avec une offre complète pour l'ensemble de ses clients.

Pour plus d'information : www.ca-cib.fr

Twitter: https://twitter.com/ca_cib
LinkedIn: https://www.linkedin.com/company/credit-agricole-cib/
Référence
2020-47695
Date de parution
05/05/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Inspection / Audit
Types de métier complémentaires
Types de métiers Crédit Agricole S.A. - Financement et Investissement
Types de métiers Crédit Agricole S.A. - Systèmes d'information / Maîtrise d'Ouvrage
Type de contrat
Alternance / Apprentissage
Durée (en mois)
12
Date prévue de prise de fonction
01/09/2020
Missions
Le département Inspection Générale a pour mission de mener sur place et sur pièces des missions d’audit sur l’ensemble des entités et activités du Groupe Crédit Agricole CIB, en France et à l’International.
L’Inspection Générale donne aux dirigeants de l’entreprise et à son Conseil d’Administration une opinion indépendante sur le fonctionnement du Groupe et son contrôle interne à partir de l’évaluation de la fiabilité des informations de toutes natures, de la maîtrise des risques, de la conformité des opérations et du respect des lois, règlementations et procédures.

Au cours de votre alternance, vous participerez, au sein des missions de l’Inspection Générale, à :
la réalisation des travaux de cadrage de la mission,
au recueil et contrôle qualité des données issues des systèmes d'information des unités auditées,
la conception des analyses,
l'interprétation des résultats,
la documentation des diagnostics et des tests.

Avec l’appui et l’assistance de l’ensemble de l’équipe d’Inspection Générale de CACIB et de la Ligne Métier Audit Inspection, vous contribuerez également à des projets transverses, liées aux nouvelles technologies et au digital ainsi qu’à des projets d’automatisation des travaux.

L’ensemble de ces activités sera réalisé dans le respect des normes professionnelles de l’audit interne, des règles de protection des données personnelles et des principes fixés par la Ligne-Métier Audit / Inspection et par la Charte d’audit interne.

Vous effectuerez votre alternance sur le campus de Montrouge, activement ouvert sur la ville et intégré dans un écosystème et une vie locale dynamique. Vous y découvrirez un environnement de travail moderne et agréable dans des bâtiments aux dernières normes HQE environnementales, de nombreux services (salle de sports, boulangerie, conciergerie, vélos électriques, take-away, etc.).

Intégrer CACIB, c'est aussi rejoindre une banque internationale qui s'engage depuis plusieurs années en faveur de l'insertion des jeunes, en proposant un accueil et un accompagnement de qualité pour chacun de ses alternants avec :
un tuteur/une tutrice formé(e) et volontaire,
une équipe dédiée à l'alternance qui organise un suivi des étudiants : journée d'accueil, accompagnement et suivi, etc.,
des opportunités post alternance en VIE, CDD et CDI.
Conformément à la politique de CACIB en faveur de l’insertion de personnes en situation de handicap, ce poste est ouvert à toutes et à tous.

Si cette annonce vous correspond, postulez pour rejoindre notre communauté d’alternants en 2020, vous devez probablement être notre prochain talent !

Merci d’indiquer en titre de votre CV votre rythme d’alternance.

Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 92 - Hauts-De-Seine
Ville
Montrouge
Critères candidat
Niveau d'études minimum
Bac + 4 / M1
Formation / Spécialisation
Formation : Université, Ecoles de commerce ou d'ingénieur/Informatique.

Spécialisation : Data Science.
Niveau d'expérience minimum
0 - 2 ans
Compétences recherchées
HARD SKILLS
Capacités d'analyse et de synthèse
Communication orale et écrite

SOFT SKILLS
Rigueur
Discrétion
Organisation et gestion des priorités
Travail en équipe
Faculté d'adaptation
Curiosité intellectuelle
Sens pédagogique
Outils informatiques
Maîtrise du traitement informatique des données à des fins d'analyse ou de statistiques : requêtes complexes SQL, analyses SAS/Python.

Connaissances appréciées en :
.DataViz, DataLineage (Power BI, MicroStrategy, Tableau, Abinitio, ELK, Collibra…),
.Programmation (Python, R, Cypher…),
.Big Data (Hadoop, Spark).

Maîtrise du Pack Office (Excel, PowerPoint, Word).
Langues
Français et Anglais courants"
Paris 10e (75),,,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong

Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris 11e (75),,,Data Analytics Teacher Assistant (freelance mission),Ironhack,- Paris 11e (75),"#About the gig

3 months Mission!

At Ironhack we are looking for a full time Teacher Assistant for our brand new Data Analytics Bootcamp, who is not only passionate about data, but also about sharing their knowledge with the next generation of data analysts.
The Teacher Assistant will maintain a close relationship with the students, helping them advance through our intense programs. The perfect TA must be a strong communicator and also very patient, since you’ll need to be able to explain abstract concepts to first-time data analysts.
The job can be combined with freelancing activities, so it should be a perfect fit for a seasoned freelancer who wants to spend 3 months in an amazing environment surrounded by passioned data students:
Teacher Assistant will be responsible for:
Helping the Data Analytics students of the course achieve their goals
Oversee and mentor their work on a daily basis
Taking part in technical interviews for admissions of candidates in the program
Help teachers with materials and exercises they have planned
Brief and pass knowledge every week from teacher to teacher
Overseeing the whole academic experience of an Ironhack bootcamp
Providing feedback of the course weekly to the team

The ideal candidate should:

Be passionate about education: although we don’t require previous formal teaching experience, we’re looking for people who enjoy teaching/mentoring
Be passionate about Data, with 6 months to 2 years of previous experiences in Data Analytics
Understand the importance of Data Visualization
Know at least 1 method of Regression analysis
Be able to draw the flow-chart according to the code and vice versa
Know of Git, MySQL, Python (Pandas, Seaborn libraries)
A great communicator: can you be engaging as a teacher?
** Fluent in both French and English**

This is a full time mission for 3 months, and takes place in Paris 11e"
Paris 9e (75),"Temps plein, CDI",,Biostatisticien / Data Scientist Clinic,Soladis,- Paris 9e (75),"SOLADIS est une société de conseil, prestation et formation spécialisé dans les métiers constituant la chaine de valeur de la donnée. Créée en 2000, l’entreprise basée en France (Lyon, Paris, Lille, Sophia-Antipolis), en Suisse (Bâle), et en Amérique du nord (New-York, Toronto) est aujourd’hui constituée d’une centaine de collaborateurs répondant aux projets diversifiés (R&D, manufacturing, marketing,…) d’une clientèle variée.
Nos équipes sont organisées en business units spécialisées, apportant chacune leur contribution aux savoir-faire de l’entreprise :
- SOLADIS STATISTICS : notre équipe spécialisée dans le développement de méthodologies expérimentales et à l’analyse de données au travers d’approches biostatistiques (laboratoire, préclinique, clinique) ou statistiques (projets industriels,…) ;
- SOLADIS CLINICAL STUDIES : notre département CRO qui conçoit et coordonne des études cliniques en Europe, et apporte son expertise médicale et scientifique au groupe ;
- SOLADIS OMICS : notre pôle spécifique à la conduite de projets sur les données –Omics, le séquençage et l’analyse des données générées n’a pas de secret pour nos bioinformaticiens et biostatisticiens ;
- SOLADIS DIGITAL : notre branche dédiée à l'exploitation des données de masse, multi-source, et utilisant des algorithmes avancés et des méthodes dites de data science : machine learning, IA,… ;
- SOLADIS CONNECT : notre support d’ingénierie spécialisée dans l’IoT, les capteurs et les biocapteurs pour offrir des solutions innovantes de collecte de données.
Le leitmotiv de SOLADIS est depuis 20 ans de favoriser le développement et l'évolution de ses collaborateurs.Si vous êtes dynamique, volontaire, doté d’un bon relationnel et que vous soyez junior ou confirmé, alors vous êtes un candidat qui NOUS correspond et vous aurez votre place au sein de nos équipes. Si vous recherchez une entreprise dynamique, favorisant le partage des compétences, reconnaissant les spécificités et les expertises de chacun, encourageant l'esprit d'équipe et le dialogue, SOLADIS est alors une entreprise qui VOUS correspond !
MISSIONS :
Dans le cadre de la croissance de ses équipes parisiennes dédiées aux sujets Cliniques et Digitaux, Soladis recherche un profil de biostatisticien ou data scientist F/H avec une expérience en clinique/CDISC et en programmation python/R-Shiny.
Intégré(e) à une équipe spécialisée dans le développement d’outils digitaux, vous participerez à la conception de solutions analytiques, de visualisation, et de pre-processing de données. Spécifiquement rattaché(e) aux problématiques cliniques, vous travaillerez en particulier sur des projets en lien avec le CDISC en Python / R-Shiny et pourrez intervenir sur des développements algorithmiques de modèles. Vous serez amené(e) à travailler dans un contexte international avec des équipes sur 3 continents et travaillerez en étroite collaboration avec des équipes cliniques.
PROFIL :
Vous justifiez d'un parcours type PhD / Master en Biostatistiques ou en Data Science et de 2 à 3 ans minimum d’expérience professionnelle.
Compétences techniques :
- Très bonne pratique de la programmation sous R et Python, de la gestion de bases de données, avec maîtrise de R-Shiny ;
- Bonne connaissance du CDISC : STDM et ADaM ;
- Connaissance de SAS ;
- Esprit d’initiative et autonomie ;
- Travail en équipe avec des facilités à transmettre ses connaissances à d’autres métiers.
Doté(e) d'un bon relationnel, vous avez des capacités reconnues de vulgarisation et de communication. Vous aimez le travail en équipe et avez une bonne capacité à interagir et transmettre vos connaissances à des interlocuteurs ayant des métiers très différents (biologistes, bio-informaticiens, statisticiens). Une qualité rédactionnelle est requise. Niveau courant d'anglais obligatoire pour la compréhension et la rédaction de la documentation.
Type d'emploi : Temps plein, CDI
Expérience:
biostatisticien / data scientist ou similaire: 2 ans (Requis)
Formation:
Bac +5 (Master / MBA) (Requis)
Langue:
anglais (Requis)"
Paris (75),,,Sales Data Insights Lead Analyst,Oath Inc,- Paris (75),"As Verizon’s media unit, our brands like Yahoo, TechCrunch and HuffPost help people stay informed and entertained, communicate and transact, while creating new ways for advertisers and partners to connect. With technologies like XR, AI, machine-learning, and 5G, we’re transforming media for tomorrow, too. We're creators and coders, dreamers and doers creating what's next in content, advertising and technology.
Verizon Media is seeking a Sales Data Insights Lead Analyst for EMEA based out of Paris. Within the INVENTORY & OPTIMIZATION EMEA team, you will work in collaboration with the experts France and EMEA, who will train you on our processes and tools so that you can support our publishing partners in the development of their sales regardless of the platform used: display, mobile, native and video.
You will be in charge of optimizing through your analyzes the sale of the advertising inventories of our publishing partners, made available on the OATH programmatic platforms.
Key responsibilities:
Monitor customer accounts on a daily basis and offer proactive optimizations to increase sales and customer satisfaction.
Work closely with our internal sales and account management teams to maximize the sale of inventories available on our platforms
Build and improve consolidated reporting of programmatic activity
Conduct performance analysis and projections by product
Perform advertising analysis for our clients publishers and clients agencies and advertisers media / trading desks
Intervene in support of the sales teams publishers for the response to the Tenders Platforms
Intervene in support of media sales teams to optimize the sale of publisher inventories
Key experience and skills:
You know how to combine commercial attitude, management and customer relations and analysis of encrypted data
You know how to manage priorities, according to the strategy defined by your management.
Your interest in data analysis and your mastery of the Google / Microsoft Office tools as EXCEL allows you to provide your customers with adequate analysis and advice.
Rigorous and organized, you know how to work autonomously and in a team, knowing how to manage the stress of short internal and external deadlines.
You have a good understanding of the functioning of an advertising network and the issues of the programmatic media.
You have a fluent level of English
You are graduated from a Business or Engineering School and specialized in Finance, Science, Business Analysis
3 + years of experience in functions or companies in the same sector of activity
******************
Analyste données des ventes:
Verizon Media est à la recherche d’un Analyste Données des Ventes basé à Paris. Au sein de l'équipe INVENTORY & OPTIMISATION EMEA, vous travaillerez en collaboration avec les experts France et EMEA, qui vous formeront sur nos process et outils afin que vous puissiez accompagner nos partenaires éditeurs dans le développement de leur CA, quelle que soit la plateforme utilisée, en display, mobile, native et vidéo.
Vous serez en charge d'optimiser par vos analyses la vente des inventaires publicitaires de nos partenaires éditeurs, mis à disposition sur les plateformes programmatiques OATH.
Responsabilités clés:
Assurer un suivi quotidien des comptes clients et proposer des optimisations proactives pour augmenter le CA et la satisfaction client.
Travailler en étroite collaboration avec nos équipes commerciales et account management internes afin de maximiser la vente des inventaires disponibles sur nos plateformes
Construire et améliorer des reportings consolidés de l’activité programmatique
Réaliser des analyses et projections de rendement par produit
Réaliser des analyses publicitaires pour nos clients éditeurs et clients agences et annonceurs media/trading desks
Intervenir en support des équipes de ventes éditeurs pour la réponse aux appels d'Offres Plateformes
Intervenir en support des équipes de vente media pour l'optimisation de la vente des inventaires éditeurs.
Expériences et compétences clés:
Vous savez combiner attitude commerciale, gestion et relation clients et analyse de données chiffrées
Vous savez gérer les priorités, en fonction de la stratégie définie par votre direction.
Votre intérêt pour l'analyse de données et votre maîtrise des outils Google / Microsoft Office dont EXCEL vous permettent d'offrir à vos clients des analyses et conseils adéquats.
Rigoureux(se) et organisé(e), vous savez travailler en autonomie et en équipe, sachant gérer le stress des courtes deadlines internes et externes.
Vous avez une bonne compréhension du fonctionnement d'une régie publicitaire et des enjeux du média programmatique.
Vous avez un niveau d’Anglais courant
Vous êtes diplômé d’une Ecole de Commerce ou d’Ingénieur et êtes spécialisé(e) en Finance, sciences, analyse business
Vous avez au moins 3 ans d’expérience dans des fonctions ou sociétés de même secteur d'activité
Verizon Media is proud to be an equal opportunity workplace. All qualified applicants will receive consideration for employment without regard to, and will not be discriminated against based on age, race, gender, color, religion, national origin, sexual orientation, gender identity, veteran status, disability or any other protected category. Verizon Media is dedicated to providing an accessible environment for all candidates during the application process and for employees during their employment. If you need accessibility assistance and/or a reasonable accommodation due to a disability, please email ApplicantAccommodation@verizonmedia.com or call 408-336-1409. Emails/calls received for non-disability related issues, such as following up on an application, will not receive a response.
Currently work for Verizon Media? Please apply on our internal career site."
Paris (75),CDI,45 000 € par an,Data Analyst Confirmé,montreal,- Paris (75),"Start-Up en pleine croissance
Poste de Data Analyst à forte autonomie
Relation business importante
Localisation : Paris
Contrat : CDI
Salaire : ~45 K€


Dans le cadre d'une création de poste vous rejoignez le Head of Data au sein d'une nouvelle Business Line de cette entreprise Ecommerce en pleine croissance
Quel est votre rôle?
Sous la responsabilité du Head of Data et en relation avec toutes les parties prenantes de l'entreprise, vous avez pour rôle de collecter, transformer et valoriser la donnée de l'entreprise.


A ce titre vos missions sont:
La réalisation des ateliers de recueil des besoins métiers
L'extraction & la manipulation des données (SQL) et leur analyse
Le travail sur la qualité des données
La production de nouveaux KPI et la création et automatisation des rapports (Tableau)
La réalisation d'études statistiques (Scoring, Segmentation...)
Mais aussi la participation aux évolutions des processus métiers et à l'amélioration du SI
Profil recherché:
Bac+5 en Ecole de Commerce ou d'Ingénieur en Data & Analytics
2 ans d'expérience en tant que Data Analyst
Maitrise de SQL (requêtage et modélisation) et Tableau
R et Python sont un plus
Business accumen et excellente communication
Esprit de vulgarisation et simplification
Bon niveau d'anglais


Pourquoi les rejoindre ?
Start-up en pleine croissance
Poste à forte autonomie
Relation business avec CEO, CRO...
La cerise sur le gateau ?
Ambiance dynamique
Activités Yoga, Sport etc
Montreal Associates is acting as an Employment Agency in relation to this vacancy.

JN -042020-52615_158745563394012"
Paris (75),CDI,,Data Consultant F/H,Sutter Mills Epsilon,- Paris (75),"Votre rôle
Opérant pour des comptes internationaux dans des secteurs très variés vous travaillerez sur des missions d’envergure pour des clients grands comptes. Vous deviendrez donc un ambassadeur Sutter Mills en termes d’implémentation de projets big data, gouvernance de données, BI et stockage de données et devrez :
Être en contact avec les parties prenantes clients afin de comprendre les besoins opérationnels, travailler en collaboration directe avec des équipes cross-fonctionnelles data & produits et aboutir sur la construction de solutions data efficientes
Implémenter des data warehouse & data lakes et s’assurer de la délivrabilité des projets
Faire le lien entre les équipes technique et business et savoir agir sur les deux tableaux
Exécuter des analyses des architectures de données et fournir des recommandations basées sur l’expertise acquise
Profil recherché
Votre profil
Diplômé(e) d’études supérieures e bac+5 (école d’ingénieurs, école spécialisée, école de commerce ou équivalent universitaire), vous avez au moins 5 ans d’expérience en Business Intelligence et/ou projets Big Data
ainsi qu’une expérience confirmée en conseil ou en gestion de projet.
Vous avez les compétences suivantes :
Connaissance des technologies Big Data (Hadoop, Hive, Spark, MPP databases, distributed RDBMS)
Connaissance avérée des outils et concepts ETL (Talend, Informatica, etc.)
Solides connaissances des standards de modélisation de données
Bonne pratique et méthodologie en termes de management de projets
Intérêt pour le cloud et les innovations appliquées au domaine de la data
Excellente communication orale et écrite en français et en anglais
Valeur ajoutée:
Expérience dans le développement informatique et automatisation
Connaissance d’au moins un langage de programmation (Python, Java, Scala, etc.)
GCP/AWS ou autres certifications cloud
Nous recherchons avant tout quelqu’un de passionné par la Data et le digital, qui fait preuve de curiosité intellectuelle et qui a le goût de l’innovation et de la collaboration.
Votre profil correspond et vous êtes en recherche d’un nouveau challenge excitant ? N’hésitez pas et venez à notre rencontre !
Déroulement des entretiens
Ce que nous vous offrons:
Monter en compétences sur des outils et des sujets innovants
Assister à des workshops et des formations sur nos expertises
Faire partie d’une équipe soudée pendant et après le travail avec des événements réguliers (séminaires, sports, afterworks etc)
Votre créativité récompensée et de nouvelles opportunités
Une proximité avec l’ensemble des équipes Sutter Mills pour être force de proposition
Comment recrutons-nous?
Avec un maximum de 3 entretiens, nous évaluons nos candidats en fonction des “3 Cs” de Sutter Mills:
Compétences > Savoir-faire et expérience
Consulting > Savoir-être et gestion des clients (internes ou externes)
Culture > Adhésion aux valeurs clefs de l’entreprise (Innovation, Cohésion, Autonomie, Responsabilité, Excellence)
Les “3 Cs” Sutter Mills sont au centre d’un projet d’entreprise favorisant la qualité et la cohésion d’équipe pour que chacun puisse réaliser son potentiel et s’épanouir."
Paris 2e (75),,,Director of Data Science & Product Analytics,Adikteev,- Paris 2e (75),"MISSION
The Adikteev team is seeking for its Paris office the Director of Data Science & Product Analytics to serve as the expert in machine learning who leads the execution of artificial intelligence projects of the company roadmap. The mission also involves growing over the years a first-class team of Data Scientists and Analysts to design predictive features for the platform and drive business decision-making with performance studies.
RESPONSIBILITIES
Sophisticate machine learning features embedded in our predictive segmentation and real-time bidding platform in order to reach automatically campaign goals (performance and scale)
Watch product performance key KPIs, push relevant algorithm updates to maintain them at a high level, and give internal presentations showing the impact of new machine learning features on those performance KPIs
Drive and deliver R&D initiatives planned in the company strategy and regularly report progress to company managers
Communicate internally on behalf of the data science team, train client-facing teams about performance automation features of the product and attend meetings with key clients (occasional travels to San Francisco required)
Hire, manage and coach members of the data science team

Specific skills
Organization and planning - plans, organizes, processes, schedules, budgets and follows through in an efficient manner. Focuses on key priorities
Intelligence - Learns quickly. Demonstrates ability to quickly and proficiently understand and absorb new information
Communication - Speaks and writes clearly and articulately without being overly verbose or talkative. Able to build relationships with stakeholders of all levels
Creativity - Generates new and innovative approaches to company challenges
Analytical skills - Able to query, structure and process qualitative or quantitative data and draw insightful conclusions from it
Technical knowledge - Deep knowledge of statistics / applied mathematics and machine learning
Ability to develop people - Coaches people in their current roles to improve performance, and prepares them for future roles
Fluent English - Spoken and written, French is a plus for the position

Cultural skills
High standards
Modesty
Proactivity
Teamwork
Enthusiasm
Honesty
Adaptability
Calm under pressure

Qualifications
Masters degree, PhD, or equivalent self-education, preferably in Mathematics or Machine Learning
8+ years of experience working in teams using data science to power a core company product or service
A proven track record of consistently meeting and exceeding your objectives (reference interviews with previous colleagues will be conducted)
Knowledge of adtech or martech is a plus"
Paris (75),"Temps plein, CDI",,Data Engineer,Quinten,- Paris (75),"L'entreprise
Quinten est une société de conseil spécialisée dans la valorisation stratégique des données.
Avec 10 ans d'expérience et plus de 400 projets réussis, dans des secteurs tels que la santé, l'assurance, la banque, l'industrie, la cosmétique et les médias, Quinten est la seule société à disposer d'un tel recul dans cette jeune discipline qu'est la Data Science.
Elle apporte ainsi à ses clients une maîtrise peu commune de la mobilisation des données au service de la prise de décision business dans toutes ses dimensions : identification des sujets à forte valeur, faisabilité, développement et intégration dans les processus métiers propres à l'entreprise.
Grâce à une capitalisation interne constante et une R&D à la pointe du marché, Quinten trouve les solutions qui font entrer la donnée dans l'amélioration de la performance qu'attendent ses clients.
Quinten est partenaire stratégique de la transformation numérique de plusieurs entreprises de premier plan.
Le poste
Rattaché(e) aux opérations, vous mettez en œuvre vos compétences en termes de manipulation de données Big Data nécessaires aux différentes missions client. Vous travaillez au sein des équipes de Data Scientist, aussi bien en réalisation qu’en tant que conseil sur les missions suivantes :
* Audit et cadrage de projets sous l’angle des data ;
* Réalisation/accompagnement de projets impliquant la mise en place de flux de transformation de données ;
* Participer à la structuration/l’automatisation de nos processus internes pour rendre les équipes de Data Scientist plus efficaces dans l’accompagnement client ;
* Former et évangéliser sur les différentes technologies que nous utilisons.
Le profil recherché
Issu(e) d’une école d’ingénieur, vous avez au moins 3 ans d'expérience dans le domaine de la data engineering et disposez des compétences suivantes :
* Maîtrise du framework Spark (pyspark, scala) ;
* Maîtrise des SGBDR, NoSQL ;
* Capacités de synthèse, de communication et de vulgarisation vous permettant d’argumenter les choix technologiques et d’en expliquer les risques et avantages ;
* Qualités d’organisation et de rigueur et le goût du travail en équipe ;
* Vous assurez une veille technologique
**Compétences additionnelles**
* Versioning de code (Git) ;
* Testing ;
* Systèmes distribués ;
* Système Hadoop, Map Reduce ;
* Bonne connaissance de la Data Science et du Machine Learning ;
* Vous êtes autonome et curieux
Si vous souhaitez relever le challenge et intégrer une structure dynamique avec un environnement de travail collaboratif et axé sur le développement de vos compétences, n'hésitez pas à postuler!
Avantages :
Participation au transport
RTT
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
data engineer ou similaire: 2 ans (Requis)
Langue:
Français (Requis)"
Issy-les-Moulineaux (92),,,Data Scientist (H/F),Withings,- Issy-les-Moulineaux (92),"Fondée en 2008 par Eric Carreel, Withings a su préserver son agilité et son esprit start-up.
En quête incessante d’innovation, nous travaillons chaque jour avec passion et innovation afin d’ouvrir de nouvelles voies dans le domaine des objets connectés en santé.
Nous croyons en un monde où nous pourrions prévenir plutôt que guérir et ainsi redonner aux individus le contrôle de leur santé.
Notre exigence d’excellence nous permet de développer des objets connectés et des applications qui permettent à tous de mesurer, de suivre ce qui est important pour leur santé et de prendre les bonnes décisions pour atteindre leurs objectifs :
Suivre son poids
Être plus actif
Mieux dormir
Surveiller sa tension artérielle
Surveiller son rythme cardiaque
Etc
Chaque jour, des milliers de produits beaux et au design non intrusifs sortent de nos usines grâce à la collaboration entre nos équipes pluridisciplinaires. Nos balances connectées, nos montres hybrides, nos tensiomètres et nos moniteurs de sommeil sont aujourd’hui utilisés par des millions d’utilisateurs à travers le monde.
Nos bureaux à Issy les Moulineaux, Boston et Hong Kong nous permettent d’avoir une vue d’ensemble du marché des objets connectés en santé et de rester parmi les leaders du secteur.
Notre objectif à moyen terme ? Agrandir notre tribu et travailler tous ensemble pour révolutionner la manière dont on prend soin de notre santé !
Vos missions
Intégré(e) au sein de l’équipe Data science, tu auras la responsabilité suivante:
Recherche algorithmique pour analyser les données pertinentes et partage avec l’équipe
Réalisation de prototypes par la mise en pratique des méthodes retenues
Implémentation de services sur la plateforme ou dans les produits Withings, en tenant compte des contraintes de ressources et de temps d’exécution
Proposition de fonctionnalités nouvelles pour les applications et produits Withings
Lien avec les équipes de Recherche Appliquée et de Développement Produit pour comprendre les données recueillies (notamment leur qualité, leur lien avec la physiologie et le fonctionnement interne du produit) et proposition d’améliorations
Requirements
De formation doctorale ou PHD, vous disposez de:
Solides connaissances théoriques en statistiques, machine learning, algorithmie
Fortes compétences informatiques : calcul scientifique, Python
Rigueur, autonomie, initiative, curiosité
Connaissances en traitement de signal, R, C/C++ appréciées
Anglais
Si tu te reconnais dans cette offre d’emploi, et que tu souhaites relever de nouveaux challenges, envoie-nous ton CV !
Benefits
Tu hésites? On te dit pourquoi il faut nous rejoindre :
Nos équipes sont jeunes, dynamiques et travaillent avec passion
Nous avons gardé notre esprit start-up et aimons célébrer ensemble chacune de nos réussites !
L’agilité et la réactivité sont nos maitres mots
Tu deviendras beta testeur et tu contribueras directement au développement et à l’amélioration continue de nos produits
Nous sommes des mordus de sport et t’accueillerons avec plaisir dans nos différentes teams
Nous sommes situés sur la ligne 12 (Porte de Versailles ou Corentin Celton), entourés de plusieurs restaurants (italien, libanais, asiatique, fast-food etc) mais aussi de parcs et de complexes sportifs
Travailler chez nous, c’est bien plus qu’un simple job, c’est devenir un Withinger à part entière (avec toute la bonne humeur et l’excellence que cela exige)"
Paris (75),,,[Finance] Data Engineer (H/F),Meritis Finance,- Paris (75),"Vos points forts
# # # # # # # #
Ce projet est-il fait pour vous ?
Vous êtes passionné de Big Data.
Votre maîtrise du Big Data et de la BI sont sans faille.
Vous avez déjà mené des projets utilisant des technologies similaires.
Contexte
Pour le compte d’un grand groupe bancaire, vous intégrerez un DataLab transverse à l’ensemble des filiales du groupe.
Dans un contexte d’innovation et de refonte architecturale, vous interviendrez sur 2 plans distincts : l’accompagnement des départements métiers impactés dans la conception et la construction d’un environnement analytique Big Data. Au terme de l’implémentation de fonctionnalités analytiques supplémentaires en Python et R, vous devrez superviser le développement, sous SPARK, de modélisations de données afin de permettre leur application à des volumes très importants.

Projet
Pour mener à bien ce projet, vous aurez pour responsabilités de :
Rédiger un document établissant le bilan des composants installés : versions, fonctionnalités, niveau de maturité, failles connus.
Élaborer un protocole de tests pour valider la configuration et la sécurisation de chaque composant. Ce protocole devra décrire les étapes et scripts à appliquer.
Réaliser un document décrivant les étapes d’installation et de configuration des outils analytiques complémentaires (Python ou Scala) sur une plateforme distribuée.
Effectuer une démonstration aux membres du Data Lab permettant de valider le bon fonctionnement des composants analytiques par un exemple d’application sur un jeu de données fourni par le DataLab.
Rédiger un document de spécifications des fonctions à développer sous Spark.
Documenter les codes sources correspondants aux développements effectués. Ces derniers devront assurer une compatibilité totale avec les environnements Big Data en place.
Des connaissances en Cloud et DevOps sont appréciables."
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),CDI,,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Data Scientist (H/F) pour renforcer ses équipes.
Dirigée par le Chief Data Officer et rattachée au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques met en œuvre la stratégie DATA avec comme principales préoccupations
D’améliorer la gouvernance des données ;
De contribuer à la data réputation de la Banque de France ;
De tirer le meilleur parti des masses et de la diversité des données disponibles au sein de la banque Centrale,
De développer des projets d’intérêt commun
De développer une culture de la donnée au sein des unités métier

Présentation du Service
Au sein de la DDSA, le SIAD (Service Industrialisation et Algorithmique des Données) a pour missions de construire et entretenir les socles techniques BIG DATA, de réaliser des prototypes de solutions basées sur les approches Data Science et IA et de mettre à disposition des solutions business intelligence pour les équipes métier.

Descriptif de mission
Le pôle « Data Science et IA » cherche à renforcer ses capacités en recrutant un(e) Data Scientist.
Les missions de ce pôle, partie intégrante du domaine « conseil et expertise », sont les suivantes :
Cartographier de façon continue, en relation avec les équipes d’innovation et les urbanistes, les processus métier pour lesquels une approche Data Science pourrait procurer un avantage compétitif ou préserver un territoire acquis
Épauler les métiers dans la définition et la stabilisation de leurs besoins
Mettre en place de façon continue les Proofs of Concept (POC) fonctionnels et techniques issus des analyses d’opportunité
Benchmarker de façon régulière les outils du Big Data
Préparer l’industrialisation des POC identifiés comme pertinents
Accompagner la montée en compétence des équipes métier et des équipes techniques sur le Big Data
Sous l’autorité du « Lead Data Scientist », vous serez en charge plus particulièrement :
De la prise en charge des besoins métier et de leur analyse ;
De l’identification des solutions potentielles et du choix de la solution la plus adéquate au regard des besoins et contraintes tant métier que techniques ;
De la conception et de la mise en œuvre de la solution (POC, prototype, MVP),
De l’accompagnement et du soutien aux équipes projets en charge de l’industrialisation des solutions.

Profil recherché
De formation supérieure en informatique ou métiers de la donnée (Ingénieur ou équivalent), vous avez minimum 2 ans d’expérience dans la mise en œuvre de solutions mobilisant des connaissances statistiques et/ou mathématiques avancées, y compris en contexte d’apprentissage/alternance dans des contextes de travail variés (recherche, entreprises commerciales, sphère publique ) constituera un avantage clé.
Vous disposez d’une forte appétence pour la concrétisation de solution dans un environnement Bigdata.Par ailleurs, vous avez la maîtrise :Des sous-jacents mathématiques aux approches Bigdata / Data Science (mathématiques et statistiques, Machine Learning, réseaux de neurones ) et des bibliothèques de Machine Learning (Scikit Learn, PyTorch, )
Du développement en Python
Seraient en outre appréciées, dans l’un ou plusieurs des domaines suivants :
Une très bonne connaissance en développement sur la stack Hadoop (Oozie, Sqoop, Hive, Hbase, ), sur les technologies Spark (MLlib, SQL, GraphX et Streaming), en langages PySpark, Java et R (SparkR).
Une très bonne maitrise des outils de Search (ElasticSearch) et de streaming (Kafka)
Une bonne connaissance des bases de données NoSQL telles que Mongodb et Neo4J
Une bonne capacité à intégrer des sources de données multiples, internes / externes, structurées / non structurées et des interconnexions entre les SGBD et Hadoop
Une bonne capacité à restituer les résultats visuellement à l’aide de Kibana ou PowerBI
Une facilité à développer dans un environnement innovant en méthodologie Devops et Scrum
Rigoureux et apte à anticiper, vous avez le sens du résultat au service du client et êtes doté d’excellentes capacités de communication pour faciliter le travail « en réseau » :
Force de proposition et aisance de communication pour démontrer la valeur ajoutée des solutions Big Data et Machine Learning.
Excellente méthodologie de travail et de gestion de projet, vous travaillerez en mode agile.
Très bon relationnel, capacité à s'adapter, esprit d’équipe, ouverture d’esprit et curiosité naturelle, vous suivez l’évolution des technologies et nouveautés relatives au Big Data, Datascience et IA
Une bonne pratique de l’anglais est nécessaire.
Ce poste, en contrat à durée indéterminée, est basé à Paris (1er), avec des déplacements ponctuels dans les sites banque de France à Paris et en régions.
La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes."
Neuilly-sur-Seine (92),"Temps plein, CDI",,Pre-Sales Solution Architect – Data Analytics and AI (M/F),Altran,- Neuilly-sur-Seine (92),"Our Data Analytics and AI global service line is opening a new position for a Pre-Sales Solution Architect to be based in Paris. This is a great opportunity to be part of an international team within the undisputed world leader in engineering and R&D services, at the forefront of technology.
Key Responsibilities
As a pre-sales Solution Architect, your key responsibilities will be :
Discover clients’ needs through consultative selling approach
o Collaborate with business and industry leads to understand client needs
o Actively participate in internal sales events and plug into industry watch updates from industry vertical leads
Generate leads in creative ways and showcase our content values
o Drive AI/ML technology adoption by consulting internal stakeholders and external partners
Qualify the deals to ensure go/no go decisions
o Work cross-functionally within highly distributed and multi-cultural environments
Engage customers and tailor solutioning to unique needs
o Identify new AI/ML technology niches of business interest
o Prepare customer facing content and provide active thought leadership
Define and design a workable, profitable and differentiating proposals
o Apply entire spectrum of AI/ML technologies to solve real world challenges our customers are facing
o Prepare technical proposals and lead/drive cross-team colobarative proposals
Guarantee content credibility in defense meetings and deal closing phase.
Role/Skills Requirements
The matching candidate should display the following set of skills and experiences:
· Extensive experience within management and IT consulting services, focused on Enterprise Solutions, BI, Big Data, Analytics and AI/ML Space.
· Strong track record of professional success, preferably in the Consulting Services arena.
· Subject matter expert to identify, develop, and implement Analytics and AI/ML techniques to improve engagement productivity, increase efficiencies, mitigate risks, resolve issues, and optimize cost savings and efficiencies for each client.
· Have the technical expertise to be recognized by Impetus customers, prospects and partners as an authority figure in Analytics and AI/ML.
· Knowledge of market insight and competitor intelligence.
· Experience with gap analysis and strategic roadmap/blueprint development.
· Relevant Industry experience in architecting Analytics and AI/ML solutions for large clients across the globe.
· In-depth experience in defining an architecture utilizing any of the leading COTS/OSS technologies and should carry extensive experience in area of Business Intelligence/ /Big Data/Analytics and AI/ML solution architectures.
· Experience on at least 2-3 end-to-end implementation projects as lead architect / solution architect
· B.S in Computer Sciences , M.S CS is preferred
· 3+ Years of Machine Learning development experience
· Exposure of Computer Vision, Natural Language Processing, general Machine Learning and Deep Learning technologies
· 5+ Years of general Software Development experience
· Knowledge of data processing, big data, and distributed computing
· Minimum one programming language knowledge with Python as preferred language
· Excellent English written and oral communications skill
Job Types: Full-time, Permanent"
Boulogne-Billancourt (92),"Temps plein, CDI",50 000 € par an,Data Engineer - Partenaire Gold Microsoft - à partir de juin 2020,Elitegroup Recruitment,- Boulogne-Billancourt (92),"Description de la société :
Partenaire Gold Microsoft, mon client est une société de conseil et intégrateur de solutions innovantes devenu un acteur incontournable de la transformation digitale. Fondé il y a 11 ans, l'équipe compte aujourd’hui un peu plus de 300 collaborateurs, basés dans 6 agences en France (Boulogne-Billancourt, Nantes, Bordeaux, Toulouse, Aix-en-Provence, Lyon).
Labellisé Great Place to Work, mon client est reconnu pour ses valeurs et son environnement de bien-être au travail.
Description du poste :
Vous intégrez directement la business unit Data & AI qui identifie, met en œuvre et accompagne la transformation des clients dans ces domaines.
- > Ce poste est à pourvoir à partir de juin au sein de l’agence de Boulogne-Billancourt (92).
En tant Data Engineer, vous participerez aux missions suivantes :
- Design et développement du traitement des données streaming avec Scala, Python, Java
- Développement des APIs pour alimenter des données dans le Data Lake (Kafka, Spark Streaming, Azure…)
- Monitoring de l’environnement Big Data et l’optimisation de performance
- Performance Review des plateformes Big Data
- Rédaction de spécifications techniques
Vous serez également amené à :
- Accompagner des développeurs juniors dans l’optimisation de leurs traitements / de leurs requêtes
- Participer aux avant-ventes (définition et validation de la solution, contribution à la rédaction d’AO, participation aux soutenances des propositions).
- Participer à la veille technologique.
Votre profil technique :
En tant que Partenaire Gold Microsoft, mon client recherche un expert sur les solutions décisionnelles Microsoft. Vous connaissez parfaitement la couverture fonctionnelle et technique des produits et êtes en mesure de proposer des bonnes pratiques d'implémentation (fonctionnelles, organisationnelles, architecturales, logiciels ...).
Vous maîtrisez les technologies suivantes :
Microsoft Power BI
Suite décisionnelle Microsoft SQL Server 2014 / 2016 / 2019 (Base de données, langage Transact SQL, ETL Integration Services, Cubes Analysis)
Les Techniques de Data Science (Machine Learning, Deep Learning, Knowledge Mining)
Services avec les langages MDX ou DAX et Reporting Services
Services cloud Azure Analytics (ex: Data Factory, SQL Datawarehouse, Data Lake, HD Insight, etc.)
Une connaissance sur une ou plusieurs des technologies suivantes serait un plus : Ecosystème Hadoop (Spark, Pig, Hive, …)
Votre profil :
Titulaire d’une formation supérieure en informatique, d’un diplôme d’ingénieur ou d’une formation équivalente, vous disposez d’une expérience significative d’au moins 6 ans dans le domaine.
Anglais courant.
Vous savez être autonome et travailler en équipe, vous êtes réactif.
Bon communicant, vous êtes doté d’une bonne capacité d’analyse et d’un esprit de synthèse.
Votre curiosité pour les métiers de la transformation digitale et pour le métier de nos clients sera clef dans le succès de votre mission.
Type d'emploi : Temps plein, CDI
Salaire : 50 000,00€ /an
Expérience:
data engineer : 6 ans (Souhaité)
Télétravail:
Temporairement en raison du COVID-19"
Paris (75),,,Consultant Data (h/f),ippon,- Paris (75),"Contexte du poste :
La donnée vous inspire ? Le Big Data est plus qu’un buzzword pour vous ? Si oui, les portes d’Ippon sont grandes ouvertes pour vous accueillir sur le tatami de l’innovation technique et des projets à haute valeur ajoutée.
. . .
Profil :
Vous savez concevoir, mettre en place et optimiser une architecture adaptée aux volumes et aux enjeux. Vous savez mettre en production un projet de Data Science. Vous êtes à l’aise pour échanger avec les différents profils Data (Architectes, Data Scientists, …). Vous êtes curieux et conservez un regard attentif mais mesuré sur les nouvelles technologies et savez détecter celles porteuses de potentiel.
. . .
Si vous rejoignez IPPON :
Votre bonne élocution vous permet de communiquer aussi bien avec les profils Techniques que les interlocuteurs Métier,
Vous développerez principalement des jobs d’intégration de données, de transformation (nettoyage, enrichissement) et les stocker au bon format dans un espace commun #datalake.
Vous pouvez être amené à travailler avec le data scientist de 2 manières :
En réalisant les pipelines qui alimenteront le datalake avec les données attendues par le data scientist
En industrialisant (gestion d’erreurs, gestion de logs, voire même réécriture) le code du data scientist
Vous êtes curieux et aimez partager votre veille technique avec la communauté worldwide #Data
. . .
Votre plus :
Compétences sur la supervision et connaissance des indicateurs clés des plateformes,
Bonne connaissance d’un ou plusieurs outils et langages de développement adaptés au traitement de la donnée : Spark, Hadoop, Hive, Kafka, ElasticSearch, Cassandra, Scala, Python,
Bases en mathématiques et statistiques pour communiquer avec Data Scientists,
Connaisannces d’ Amazon Cloud ou Google Cloud PLatform."
Paris 1er (75),CDI,,Data Engineer F/H,SCIENT,- Paris 1er (75),"— TES MISSIONS

Au sein d’une fintech en pleine croissance, située en plein cœur de Paris, avec des challenges très intéressants :

10 mises en production par jour.

Gestion de nombreuses nouvelles données qui génèrent des nouvelles DATA.

Framework

+ Hadoop

+ Spark

Système de gestion de base de données (SGBD)

+ NoSQL

Langage

+ Python

Cloud Computing

+ Microsoft Azure

En interne

+ Organiser et transmettre les best practices

+ Être un(e) acteur(trice) et un(e) émulateur(trice) au sein de l’équipe

+ Proposer et piloter les projets en mode intrapreneur

— LES PLUS DE LA MISSION

Equipe passionnée et dynamique de 300 collaborateurs talentueux . Tournois de consoles, blind test, bataille de nerfs sont au programme !

Possibilité de home office (1 jour par semaine). Localisation en plein centre de Paris, des animations mensuelles, des séminaires d’entreprise organisés dans des lieux paradisiaques (Ibiza, Sicile...)
Profil recherché — TES COMPÉTENCES

+ Minimum 2 ans d’expérience

+ Capacité à communiquer, team-spirit

+ Esprit d'analyse et de synthèse

+ Rigueur

+ Bac+5
Entreprise Chez Scient nous sommes des Project Makers.

Grâce à une

approche innovante

et

non-conventionnelle centrée sur les

usages

, les

méthodes agiles

et notre

expertise data

, nous transformons les challenges de nos clients en succès.

Notre team-spirit orienté sur le

développement personnel

de nos collaborateurs

et sur les

valeurs du sport

nous confère une place toute particulière dans notre écosystème.

Rejoindre notre aventure, c’est rejoindre une entreprise en forte croissance et pleine d’ambitions avec des projets passionnants dans un cadre idéal à Paris et à Aix-en-Provence."
Paris (75),,,Directeur / Directrice Data Science & Marketing Analytics M13h recrute !,M13h,- Paris (75),"À propos
M13h est une start-up en forte croissance, plongée au cœur d’un monde du marketing digital en pleine ébullition. Nous intervenons auprès de Directions Marketing et Digital de grands comptes sur des sujets innovants mêlant data, marketing et technologies.
Notre ADN est au croisement entre cabinet de conseil et agence web marketing. Travailler chez M13h, c’est :
Intégrer une équipe à taille humaine, ambitieuse et curieuse de tout,
Participer à l’aventure d’une startup en pleine croissance,
ravailler pour des clients prestigieux comme La Française des Jeux, Kenzo, OVH, Boardriders, Bayard, Groupama, Vente-Privée.com, Altice Média, …
Descriptif du poste
En relation directe avec les associés, vous prenez la Direction du pôle marketing sciences de M13h, englobant des projets de Data Engineering, Data Science & Data Visualisation pour des Directions Métier, Marketing ou Digital.
Vous assumez la responsabilité et assurez le développement du pôle :
Pilotage et réalisation des missions
Recrutement, management, gestion de charge de l’équipe
Création et développement d’offres commerciales, réponse à appel d’offre, propositions commerciales
Développement des compétences et des expertises du pôle
Profil recherché
Diplômé d’une grande école de commerce, d’ingénieurs ou équivalent, vous disposez d’un minimum de 7 années d’expériences dans le secteur de la data, du digital ou du marketing. Vous avez acquis une bonne compréhension des enjeux de gestion de la donnée et avez une bonne vision des tendances du marché.
Vous justifiez d’une solide expérience en matière de traitement de données :
Data engineering : construction d’infrastructures de données basées sur le cloud, flux de données entre différents outils de l’écosystème data-marketing, …
Data science : algorithmie, analyse descriptive et prédictive, machine learning, …
Data visualisation : construction de dashboards adaptés aux enjeux opérationnels et managériaux Vous avez une expertise forte sur les plateformes (Google Cloud & co), les langages (SQL, Python, etc.) et les librairies de traitements de données.
Rigoureux, vous savez adopter une approche structurée et une posture conseil : recueil de besoins, formalisation de livrables, gestion de projet, convergence entre solutions techniques et enjeux business, pédagogie et évangélisation auprès de populations non-expertes, …
Dans un contexte d’entreprise en croissance, vous avez pour ambition d’être un élément clé du cabinet et souhaitez assurer, en plus de votre rôle opérationnel, des fonctions de management et de développement commercial.
Informations complémentaires
Type de contrat : CDI
Lieu : Paris, France (75002)
Niveau d'études : Bac +5 / Master
Expérience : > 7 ans
Télétravail ponctuel autorisé"
Paris (75),Stage,,Data Scientist - Italian Speaking (End-of-studies Internship),Shift Technology,- Paris (75),"Shift Technology is reinventing insurance claims automation and fraud detection with AI. We help insurers fully automate more claims, deliver a great customer experience while protecting against risk, and accurately identify suspected claims fraud, making investigative teams more effective and reducing fraud losses.
Since our launch in 2014 in Paris, we've raised over $100M with Tier 1 investors, opened offices in Boston, Tokyo, Singapore, London, Madrid, Zurich, and Hong Kong, and currently work with more than 80 insurers globally. If you are excited about joining a fast-growing insurtech innovator with a passion for excellence and global culture, Shift is the place for you.

Are you looking for an internship where you can get strong programming skills and discover real-life problems? Come and join the French Insurtech leader to change the insurance world with A.I.!

This position is for you if you are looking for an end-of-studies internship to complete your degree, and are interested in a permanent position if you think Shift is the right place to start!

YOUR ROLE

As a member of the data science team, and working alongside our technical experts, your role will be key to roll-out our different solutions to the clients. Your day-to-day will include :

Set-up and deploy in production the data processing pipelines of our clients, including data reception in batches or in real-time, data cleaning, information extraction, calibration of fraud detection models, etc.

Work closely with our clients to understand their needs, their feedback to improve our solutions

R&D for product development and innovation (through machine learning, image analysis, NLP, trend analysis, chatbots…)

Work closely with the sales team for prospects demo (and yes, that includes traveling worldwide!)

WHAT WE ARE LOOKING FOR

You have a master's degree in mathematics and Statistics, (a knowledge in machine learning and/or Big Data is a plus)

You have experience in object-oriented programming

You combine strong analysis with synthesis abilities and are not afraid to deal with the details

You can write quality production code

You are comfortable dealing with clients

You are fluent in Italian, and ideally in another European language

PERKS AND BENEFITS

Nice office in central Paris

International environment (we have more than 35 nationalities represented at Shift!)

Lunch card and public transportation sponsorship

Healthy seasonal basket fruits and cereals

Welcome drinks / Team building events

Workshop and training

EEO Statement
At Shift we thrive to be a diverse and inclusive workforce. We hire and trust people without regard to race, color, religion, marital status, age, national or ethnic origin, physical or mental disability, medical condition, pregnancy, genetic information, gender identity or expression, sexual orientation, or other non-merit criteria.
Shift is proud to be an Equal Opportunity Employer."
Paris (75),"Temps plein, Freelance / Indépendant",,Architecte Azure Big Data / Freelance,Pixie Services France,- Paris (75),"J’ai actuellement une opportunité pour une mission d’architecte BIG DATA Datalake sur plateforme Azure

Mission jusqu’à fin d’année 2020:
Zoning datalake (expérience réel en mise en oeuvre de datalake)
Industrialisation de services (comment passer les projets à la MCO)
definir les usecases
Integration de données
Experience sur Azure Datalake
Capacité de communication/vulgariser les services auprès des clients internes et utilisateurs.
activation et mise sous controle Azure xxx, peuplement du DataLake
technos: SQL server, Python, MSBI , Azure Datalake"
Nanterre (92),,,Data Engineer – Confirmé (e),Spark Consulting,- Nanterre (92),"Data Engineer – Confirmé(e)
Nous recherchons un(e) Data Engineer confirmé(e) pour renforcer nos équipes et participer à différents projets innovants au sein de nos clients. Votre mission en tant que Data Engineer :
Conception et prise en charge de bout en bout des différentes chaines de traitements liées au cas d’usage métier (traitement batch, traitement temps réel)
Participation à la définition des différents sprints de réalisation
Développement des applications et des modules métier (implémentation de modèles mathématiques)
Développement et implémentation des algorithmes de Machine Learning
Réalisation de documents de spécification et de conception techniques
Participation au reporting régulier et aux réunions hebdomadaires associées

Cette description prend en compte les principales responsabilités. Elle n’est pas limitative.

Compétences requises
Bac+5 en école d’ingénieur ou équivalent
Minimum 3 ans d’expérience
Maîtrise des langages structurés (Python, Javascript, Scala, …)
Connaissances en solutions de bases de données (SQL, NoSQL…)
Maîtrise de divers systèmes d’exploitation (UNIX, Linux, Solaris..)
Maîtrise des technologies du Big Data permettant le traitement et la manipulation de données (Hadoop, Spark…)

Compétences « NICE TO HAVE » :
Force de proposition, rigueur, réactivité, esprit analytique et de synthèse.
Esprit d’équipe, excellent relationnel, sens de l’organisation et de la qualité."
Paris (75),CDI,,INGENIEUR DATA SCIENCES ET MODELISATION QUALITE DE L'AIR H/F,INERIS,- Paris (75),"L’unité de modélisation atmosphérique et cartographie environnementale (MOCA) développe et
utilise des outils de gestion de la qualité de l’air dans le cadre de ses activités de soutien aux
pouvoirs publics, de recherche et en appui à des demandes émanant de clients privés, que ce
soit en France, en Europe ou à l’international.
La modélisation de la qualité de l’air constitue une activité phare de l’unité que ce soit pour des
évaluation d’exposition (chronique ou accidentelle), des prévisions à court terme ou des
projections à long terme (prospectif ou rétrospectif) en aide à la décision. Les échelles spatiales
couvertes peuvent concerner un site industriel, une agglomération, un pays ou un continent (en
Europe ou au-delà).
L’expertise de l’Ineris dans ce domaine est largement reconnue à travers nombre de projets de
recherche et opérationnels en soutien aux décideurs (Ministère de la Transition Ecologique et
Solidaire, Commission Européenne, Agence Européenne de l’Environnement ou Nations Unies).
Au sein de l’équipe, vous serez amené(e) à participer à l’activité de modélisation de la qualité de
l’air à travers plusieurs axes de travail relatifs à l’utilisation de modèles de dispersion à petite
échelle et à l’échelle régionale reposant sur les outils développés par l’Institut ou des partenaires.
Un focus important sera consacré à la consolidation des outils de prétraitement (automatisation,
interfaçage, assurance qualité) et post-traitement (diagnostic, validation, visualisation,
valorisation). Ce travail nécessitera de croiser les résultats de modèles avec de vastes bases de
données par des approches innovantes de traitement big data et machine learning.
Ce poste implique des déplacements sur le territoire français et à l’international.

Profil

Diplômé(e) d’un Bac+5, vous justifiez d’une première expérience en modélisation de la physico-
chimie de l’atmosphère ou en data science dans le domaine des données environnementales.
Vous disposez d’une très bonne connaissance de la programmation scientifique (fortran, c++,
python, R, SIG) et d’aptitudes à l’utilisation et à la conception d’outils d’analyse numérique.
Par ailleurs, vous démontrez les compétences suivantes : 
Goût du travail en équipe et en mode projet ; 
Capacité à développer et entretenir une relation client, un réseau et des partenariats ; 
Très bonnes qualités d’expression orale (présentation de travaux en congrès, de
propositions commerciales) et écrite (rédaction de rapports techniques), tant en français
qu’en anglais.

Compléments d’informations

Pour postuler merci d’adresser votre CV et lettre de motivation à l’adresse suivante :
ineris-076560@cvmail.com

Ce poste est ouvert aux personnes en situation de handicap."
Courbevoie (92),,,Big Data and Analytics Specialist Solutions Architect France,AWS EMEA SARL (France Branch),- Courbevoie (92),"Implementation and tuning experience in the Big Data / Apache Hadoop ecosystem (including tools such as Hadoop Streaming, Spark, Pig and Hive), or in the Real-time ecosystem (with tools such as Amazon Kinesis, Apache Kafka, Flink, Storm)
Proven experience on database and analytics technologies in the industry (such as Data Warehousing, MPP, Relational, OLTP, OLAP, and NoSQL databases), on commercial or open source solutions (Microsoft SQL Server, Oracle Databases, IBM DB2, MySQL, PostgreSQL, MongoDB, Apache Cassandra, HBase, Snowflake, or Amazon Databases), and on different stages of the lifecycle (Schema Design, Query Tuning and Optimisation, Data Migration and Integration)
Ability to learn new concepts and technologies, and apply them to provide the best business outcomes for customers
Ability to formulate and communicate ideas clearly in a business environment, including presenting in front of varied internal and external audiences
Business fluent French is required for customer interactions, alongside business English for internal communication and collaboration with the worldwide teams

Amazon Web Services (AWS) is looking for Big Data and Analytics Solutions Architects for our EMEA customers. If you have experience in designing architecture of data and analytics platforms, leveraging tools such as Apache Hadoop, Spark, Elasticsearch, or real-time event processing platforms such as Apache Storm or Kafka, and are interested in helping customers embrace cloud technologies, come and talk to us. Specialist Solutions Architects work with AWS' partners and customers to accelerate their cloud transformation. They engage in a wide range of activities around their domain of expertise, providing technical advice to customers, helping the internal and external communities, presenting AWS publicly on their domain, and providing a preferred path between AWS service teams and customers.

This is an opportunity to join Amazon’s technical teams, working with our engineers on the new services that power the cloud ecosystem, while developing your skills and furthering your career within what we believe to be one of the most innovative and progressive technology companies. These engagements will focus on Real Time and Batch-based Big Data processing, Business Intelligence, and Machine Learning. This role will specifically focus on AWS Services for Analytics, and on helping our customers and partners build innovative Solutions and Businesses that focus on leveraging the value of data.

As a Big Data and Analytics Specialist Solutions Architect (SA), you will help customers select the technologies that will support their business requirements. Part of the Specialist Solutions Architecture team, you will work closely with the other Specialist SAs on Big Data, Databases, Analytics, Artificial Intelligence, or Security, as well as the Business Development teams, to enable large-scale customer use cases and drive the adoption of AWS for their data processing platforms. You will interact with other SAs, providing guidance on their customer engagements by developing white papers, blogs, reference implementations, and presentations to enable customers and 3rd parties to fully leverage the AWS platform. You will also create field enablement materials for the broader SA population, to help them understand how to integrate AWS solutions into customer architectures.

Candidates have a mix of communication and technical skills, and will have the ability to engage with customers at different levels in the organization, from executive to developer. Previous experience with AWS is desired but not required, provided you have experience building large scale solutions. You will get the opportunity to work directly with senior engineers at customers, partners and AWS service teams, influencing their roadmaps and driving innovation.

If you are someone who enjoys innovating, likes solving hard problems and working on the cutting edge of technology, we would love to have you on the team.
Amazon's Culture

Our positive and supportive culture encourages our people to do their best work every day. We have 14 leadership principles that help guide us in our every-day decision making process. We believe they are a clearer articulation of those things that have always been a part of what makes Amazon great – things that we must consciously hold on to in fulfilling our mission to be Earth’s Most Customer Centric Company. We are continuously looking for new ways to maintain a culture where our people excel and lead healthy and happy lives. Learn more about life at Amazon. It is always Day One.

How You’ll Grow

At Amazon, our professional development plan focuses on helping people at every level of their career to identify and use their strengths to do their best work every day. From entry-level employees to senior leaders, we believe there’s always room to learn and develop your career. We offer opportunities to help sharpen your skills in addition to hands-on experience in the global, fast-changing business world. From on-the-job learning experiences to formal development programs, our professionals have a variety of opportunities to continue to grow throughout their career.

Roles and responsibilities
Customers' trusted advisor: collaborate with AWS account, training and support teams to help partners and customers learn and use AWS services such as Amazon Elastic Map Reduce (EMR), Redshift, Kinesis, SageMaker, Glue, S3, DynamoDB, and the Relational Database Service (RDS)
Business partner: serve as a key member of the business development and account management team in helping to ensure customer success in building and migrating applications, software and services on the AWS platform.
Public engagement: provide thought leadership on Analytics solutions that benefit customers through the use of AWS Services. This takes the form of contribution to external publications such as the AWS Blogs, Whitepapers and Reference architectures, or public presentations at AWS Summits, AWS re:Invent, AWS User Groups or industry events
Community player: capture and share best-practices, participate, and contribute as a member of the worldwide AWS technical community of Solution Architects, Professional Services Consultants, Technical Account Managers, and AWS Trainers
Service team point of contact: act as a conduit between the AWS Service teams and the customers, providing detailed guidance for the broader field organization and the customers, and acting as an advocate for the customers towards the central teams

Amazon is an Equal Opportunity-Affirmative Action Employer – Minority / Female / Disability / Veteran / Gender Identity / Sexual Orientation.

Technical degree in computer science, math, or engineering such as a Master's degree
Hands on experience leading large-scale global data warehousing and analytics projects, such as projects in the software development or Internet industries
Scripting/Programming skills – Python, Java, Scala, Go
Deep understanding of the technical and use case differences between OLTP, OLAP, in-memory, columnar, MPP, NoSQL, big data batch and streaming data stores and their impact on application design and performance
Experience in designing, deploying or managing Data Lake platforms in complex environments
Understanding of security practices related to data ingestion, storage, analysis and visualization
Track record of implementing AWS services in a variety of business environments such as large enterprises and start-ups. AWS Certifications, e.g. AWS Solutions Architect Associate/Professional"
Saint-Ouen (93),,,e-POP - Industrial Data Analyst (M/F),ALSTOM,- Saint-Ouen (93),"Req ID:69067
We create smart innovations to meet the mobility challenges of today and tomorrow. We design and manufacture a complete range of transportation systems, from high-speed trains to electric buses and driverless trains, as well as infrastructure, signalling and digital mobility solutions. Joining us means joining a truly global community of more than 36 300 people dedicated to solving real-world mobility challenges and achieving international projects with sustainable local impact.

CONTEXT / INTRODUCTION
This job is part of the Industrial Operations Management System organization, within the “central – corporate” team located in Saint-Ouen Headquarters – France.
The Industrial Operations covers all the Alstom businesses: Rolling Stock & Components, Services, Signaling and Systems & Infrastructure, and the Supply Chain activities as well as the Industrial activities.
The Management System organization ensures end-to-end process consistency, competency development with coherent tools roadmap including Smart Operations.
Smart Operations is the Industry 4.0 program for Alstom and is encompassing an innovative and digital transformation program called e-POP (Process & Operations Performance). Its objective is to harness all system-generated data available to improve operational efficiency (with fact-based decision-making process). This Program focuses on usage transformation thanks to digital with the objective to simplify targeted end-users day-to day life and bring value through innovation

PURPOSE OF THE JOB
Directly reporting to the e-POP Program Manager, you will contribute to improve the operational efficiency of Alstom by delivering added-value BI tools helping site managers in their short and long-term decision-making process. Your appetite for Big Data, Analytics & Business Intelligence as well as your ability to strongly collaborate with Industrial Operations Business Process Owners and your capacity to convert business needs into specifications understandable by technical teams are key factors to success.

ROLE & RESPONSIBILITIES:
Collaborate closely with Business Process Owners to understand business requirements and translate them into functional specifications or user stories
Be an expert of Industrial Operations data management tools and constantly be a force of proposal and challenger to Business Process Owners (best practices, visualization design, axis of analysis, modeling, etc.)
Design and build new BI solutions for our department in an agile mode or, depending on the context, make them developed by Alstom IT staff
Write test plans and coordinate the testing process with users, system integrators, and internal IT staff. Participate in testing activities, as needed
Coordinate activities with project managers to ensure successful deployments
Complete projects quickly and in the most efficient way, maintaining timelines, sprints, budget, and risks for projects, but with a continuous focus on customer (end-user) satisfaction
Document Projects: record properly every step of BI solution implementation with the proper documentation (including technical documentation and training one)
Drive Proof of Concept (PoC) with industrial sites / headquarter teams to evaluate plausibility of potential solutions
REQUIRED SKILLS & EXPERIENCES
You have a degree in computer science (or related discipline) from an engineering school or university (French or European), with a minimum of 2 to 3 years-experience in business intelligence project management (internships included)
You have a strong expertise in Qlik Sense. An experience in BO / BW and SAP is an asset.
You are able to facilitate dialog among several parties while eliciting requirements
You have critical thinking and analytical skills, including the ability to comprehend and document complex business processes through visual process modeling and other means.
You have excellent communication, listening, presentation and writing skills (French & English)
You are able to develop strong relationships with both IT colleagues and business subject matter experts in an international environment
You have solid organizational skills including attention to detail and multi-tasking skills
You are able to prioritize and manage time effectively
You are able to work independently with minimal supervision and can provide clear and fact-based reporting to your direct management
To satisfy and create added value for your customers (end-users) is key for you

An agile, inclusive and responsible culture is the foundation of our company where diverse people are offered excellent opportunities to grow, learn and advance in their careers. We are committed to encouraging our employees to reach their full potential, while valuing and respecting them as individuals.

Job Type:Graduate Job

Job Segment: Database, ERP, SAP, Computer Science, Supply, Technology, Operations"
Suresnes (92),,,Data Engineer/Architect (H/F),Bel Group,- Suresnes (92),"Vous serez au coeur de notre projet de transformation pour conduire l’exploitation des données en levier de performance. C'est un axe stratégique pour Bel afin d’atteindre les objectifs fixés de doubler de taille et de devenir l’acteur le plus innovant sur ses marchés. Ainsi, nous avons récemment créé le Data Lab de Bel, une structure dédiée à la Data Science et au service des activités industrielles, marketing et R&D du Groupe. Pour renforcer cette structure, nous recrutons un(e) Data Engineer/Architect.
Une opportunité pour vous de rejoindre Bel de devenir un acteur(rice) majeur(e) de la transformation digitale d’un groupe industriel international et familial dans lequel sont vécues au quotidien les valeurs d’Engagement, de Bienveillance et d’Audace.
Ainsi, vous participerez à des projets pionniers de Data Science dans les usines et la R&D entre autres, projets dont l’objectif est d’optimiser les processus industriels et ainsi d’améliorer la productivité des installations et la qualité des produits fabriqués ou encore de réduire les durées de développement. Pour ce faire, vous travaillerez en équipe pluri disciplinaire au contact des équipes de production pour automatiser la collecte des données et préparer les données au travail d’exploration des data scientists. Vous serez en charge de développer, tester et maintenir une infrastructure de Data Science pour consolider l’ensemble des data sets disponibles, en lien direct avec la communauté industrielle et les experts scientifiques et techniques du Groupe.
Accompagné(e) par un expert en analytique et data science appliquée, vous :
- Recueillez les besoins métiers, identifiez les sources de données et reconstituez le lien entre les différentes
données,
- Proposez, créez et documentez des solutions pour l’organisation et le stockage des données,
- Concevez, manipulez et interrogez des bases de données
- Concevez des pipelines pour ingérer la donnée et développez des API pour mettre les données à la
disposition de la plateforme de Data Science.
- Mettez en production les développements des data scientists
- Créez l’interface d’utilisation adaptée à l’utilisation des données par les clients finaux (Industriels, marketing
et R&D notamment).
- Maintenez à jour un référentiel de méthodes, techniques et technologies qui deviendront les standards du
groupe.
- Opérerez une veille sur les solutions d’architecture Big Data.
PROFIL
Issu(e) d’une formation supérieure BAC +5 (Ecole d’ingénieur ou équivalent universitaire), vous maîtrisez la programmation (Python), gérez le contrôle de version (git) et avez une bonne compréhension d’une stack complète, des webservices (HTML, CSS, JS) aux bases de données (SQL, NoSQL). Enfin vous avez une connaissance en architecture Big Data (Temps réel/Batch), pipelines et ETL.
Vous avez envie de mettre vos compétences au service de problématiques concrètes en travaillant avec des équipes et profils variés. Vous vous distinguez par votre capacité à traiter de l’information pointue et nombreuse et par votre talent pour la restituer de manière synthétique et pertinente. Ainsi, vous savez rendre simple le complexe et challenger le statu quo tout en faisant preuve de tact et d’écoute et en étant force de proposition. Votre maîtrise de l’Anglais vous rend capable de contribuer lors des réunions et de construire des supports dans cette langue.
CONTACT
Si ce poste vous intéresse, nous vous invitons à cliquer dès à présent sur le bouton Postuler. L'équipe recrutement prendra alors très prochainement contact avec vous."
Neuilly-sur-Seine (92),,,Pre-Sales Solution Architect – Data Analytics and Artificial Intelligence (F/M),Altran,- Neuilly-sur-Seine (92),"Our Data Analytics and AI global service line is opening a new position for a Pre-Sales Solution Architect to be based in Paris. This is a great opportunity to be part of an international team within the undisputed world leader in engineering and R&D services, at the forefront of technology.
Vos responsabilités
Key Responsibilities

As a pre-sales Solution Architect, your key responsibilities will be :

Discover clients’ needs through consultative selling approach
Collaborate with business and industry leads to understand client needs
Actively participate in internal sales events and plug into industry watch updates from industry vertical leads
Generate leads in creative ways and showcase our content values
Drive AI/ML technology adoption by consulting internal stakeholders and external partners
Qualify the deals to ensure go/no go decisions
Work cross-functionally within highly distributed and multi-cultural environments

Engage customers and tailor solutioning to unique needs
Identify new AI/ML technology niches of business interest
Prepare customer facing content and provide active thought leadership

Define and design a workable, profitable and differentiating proposals
Apply entire spectrum of AI/ML technologies to solve real world challenges our customers are facing
Prepare technical proposals and lead/drive cross-team colobarative proposals
Guarantee content credibility in defense meetings and deal closing phase.

Votre profil

Role/Skills Requirements

The matching candidate should display the following set of skills and experiences:
Extensive experience within management and IT consulting services, focused on Enterprise Solutions, BI, Big Data, Analytics and AI/ML Space.
Strong track record of professional success, preferably in the Consulting Services arena.
Subject matter expert to identify, develop, and implement Analytics and AI/ML techniques to improve engagement productivity, increase efficiencies, mitigate risks, resolve issues, and optimize cost savings and efficiencies for each client.
Have the technical expertise to be recognized by Impetus customers, prospects and partners as an authority figure in Analytics and AI/ML.
Knowledge of market insight and competitor intelligence.
Experience with gap analysis and strategic roadmap/blueprint development.
Relevant Industry experience in architecting Analytics and AI/ML solutions for large clients across the globe.
In-depth experience in defining an architecture utilizing any of the leading COTS/OSS technologies and should carry extensive experience in area of Business Intelligence/ /Big Data/Analytics and AI/ML solution architectures.
Experience on at least 2-3 end-to-end implementation projects as lead architect / solution architect
B.S in Computer Sciences , M.S CS is preferred
3+ Years of Machine Learning development experience
Exposure of Computer Vision, Natural Language Processing, general Machine Learning and Deep Learning technologies
5+ Years of general Software Development experience
Knowledge of data processing, big data, and distributed computing
Minimum one programming language knowledge with Python as preferred language
Excellent English written and oral communications skill"
Paris 2e (75),,,Data Scientist Senior f/m,Rakuten France,- Paris 2e (75),"Rakuten is looking for a datascientist to join the Recommendations and Personalization team in Paris offices. You will join an international team providing recommendations for all Rakuten services, and working on cutting-edge technologies and algorithms in order to improve and personalize customers experience.

In this position, you will interact with engineers and datascientists to provide the highest service quality to all our clients.
You role will consist in analyzing data, understanding users behaviors, and bring and implement new ideas for recommendations and personalization algorithms. You will also implement those algorithms in our platform with the help of our engineers, and perform analyses to provide insights on our customers. Ideally, you will help driving our roadmap for cutting-edge recommendations in a multi-services, worldwide and omni-channel group as Rakuten Group.

Responsibilities :
Follow state-of-the-art research on recommendations, bring new ideas and implement them.
Support operations and understand specific clients needs to be considered in our algorithms.
Help driving new features requests on our platform.
Provide specific data analysis to better understand our clients needs, and refine our strategy.
Collaborate with international clients and communicate results and insights to them.

We are looking for a senior candidate (5-10years +) with Master/Phd in Computer Science or Statistics, with a good knowledge of recommendations state-of-the-art algorithms, an appetite for Big Data technologies and Data Sciences concepts, and awareness of large-scale production-related constraints and challenges. Being rigorous is very important, as well as being a team player, to be able to share and discuss ideas with our team of datascientists.

Requirements and Experience
Master/PhD degree in Computer Science or Statistics
Good knowledge of Python and/or Scala
Feel at home on Linux systems
Experience with production environment and constraints, and best coding practices
Ready to address the data preparation and cleaning challenges
Business-level communication skill in English

Desirable
Academic publications in RecSys field is a plus.
Strong interest for Big Data technologies such as Hadoop, Spark, Couchbase, Kafka, ... is a plus"
Paris (75),CDI,50 000 € - 65 000 € par an,Data Architect Confirmé (H/F) – CDI,Expertime,- Paris (75),"À propos
Rejoindre Expertime, c’est faire partie d’une équipe de passionnés parmi nos 160 collaborateurs présents à Paris, Lille, Lyon, Nantes et Hong-Kong.
C’est également accompagner nos clients de tout secteur dans leur transformation digitale, grâce à notre force de proposition et l’expertise de nos différentes entités :
Intelligent Cloud : expert sur l’innovation applicative et du conseil sur les solutions DevOps, Data & IA en environnement Azure et Office 365.
Expertime Open : Accompagne dans la conception et la production de solutions Web, E-commerce, Chatbot.
Expertime Consulting : Agence de Conseil en commerce digital et CRM.
DÉCOUVRIR EXPERTIME
Descriptif du poste
Au sein des équipes Intelligent Cloud, vous intervenez dans le cadre de projets et missions qui répondent aux enjeux clients d’exploitation des données.
Vous participez aux phases d’avant-vente, aux études d’architecture, et à la réalisation des solutions avec une responsabilité d’encadrement technique des projets (tant sur des forfaits que des missions clients).
Vos missions principales consistent à :
Analyser et qualifier les besoins et les problématiques « métier » de nos clients
Définir et mettre en œuvre des architectures Data adaptées aux contextes des projets
Accompagner les équipes Métiers dans leurs travaux d’identification et de documentation des données
Accompagner des Consultants et des Ingénieurs spécialistes de la data sur les projets et œuvrer à la qualité de leurs réalisations et des livrables
Collaborer sur tous les domaines d’activité data : BI et Analytics, Big Data, Data Science et IA
Collaborer en transverse avec les autres expertises (UX/UI, architectes logiciels et techniques, experts cloud et DevOps) afin de concevoir et délivrer les solutions les plus adaptées et performantes
Maîtriser les bonnes pratiques de mise en œuvre technique et veiller à leur application selon les méthodes en vigueur (DevOps, gestion agile…)
Travailler dans un contexte agile et porter des approches novatrices
En parallèle :
Vous développez votre expertise par la formation, la veille technologique, les certifications et la participation aux événements communautaires
Vous contribuez à la construction d’une base de connaissances de l’équipe Data : cas d’usage, outils, indicateurs de pilotage, processus d’apprentissage etc.
Vous participez au bon niveau de connaissance et d’expertise des équipes par votre engagement et votre travail de formation personnelle (participation à des workshops partenaires, suivi de learning sessions, passage de certifications etc)
Profil recherché
Diplômé d’une école d’ingénieur, vous possédez une expérience de 3 à 4 ans minimum sur un poste de Tech lead / Architecte.
Vos compétences techniques :
Indispensables : SQL Server, SSAS, SSRS, SSIS, T-SQL, DAX, MDX
Appréciées : Azure Datalake, Azure SQL Database, Azure Analysis Services, Azure HD Insight, Azure Stream Analytics, Power BI, Python, R, Machine Learning
Vos softskills :
Vous êtes proactif et passionné par le traitement des données, à l’écoute des évolutions technologiques
Vous maîtrisez les aspects techniques d’un projet
Vous avez l’esprit d’équipe et vous avez de l’appétence pour accompagner les équipes dans le développement de leurs compétences
Vous êtes orienté solutions et résultats
Vous aimez le travail en mode multi-projets
Vous avez le sens des priorités et la capacité à gérer les délais
Vous êtes ambitieux et souhaitez être certifié Microsoft
Vous possédez un anglais professionnel courant (écrit et oral)
Pourquoi nous rejoindre ?
Nous sommes une entreprise à taille humaine = missions confiées avec de réelles responsabilités et très diversifiées
La polyvalence est un élément clé de succès, votre poste n’est pas figé = développement constant de vos compétences Ambition et Innovation = pouvoir être force de propositions et faire preuve de créativité afin d’améliorer l’organisation et les process de l’équipe
Diversité des secteurs d’activité et des problématiques clients = vous ne vous ennuierez pas
Dans votre développement personnel vous serez accompagné : capacité d’analyse et de synthèse, aisance dans la prise de parole en public, adoption d’une vraie posture de conseil
Environnement de travail :
Ce poste à pourvoir en CDI, dès que possible.
Rémunération entre 50 et 62K€ + variable + avantages
Lieu géographique : Siège social à Viroflay (78) et/ou en IDF chez nos clients, possibilité de télétravail (home-office ou espace co-working dans le 8ème proche St Lazare)
Notre Siège est accessible en transport en commun (RER C, ligne L et N) à 10 minutes à pied de Viroflay Rive-Gauche ou Rive-Droite."
Paris 8e (75),CDI,,Data Functional Architect F/H,CAPFI VITA DATA,- Paris 8e (75),"Le rôle du

Data Functional Architect

couvrira les sujets suivants :
Contribution à la
Data Gouvernance

: mise en conformité GDPR, définition des processus,

éthique, évangélisation

Cartographie des données et des flux, Data Lineage, Dictionnaire de données
Etre force de proposition sur l’architecture des données
Etre force de proposition sur la
Data Quality

Etre l’interlocuteur privilégié des directions métiers et de l’IT
Animer des ateliers de travail sur différentes thématiques : idéation, analyse et sélection de
scénarios, formalisation de solutions

Transmettre sa passion et son savoir afin d’évangéliser la transformation Data
Etre en support aux équipes Data
Profil recherché Vous êtes Diplômé d’une école d’Ingénieur, d’un Master 2 en Statistique/Mathématique, ou en Informatique avec une spécialisation en Gouvernance des données, Big Data, Data Science, BI.

Vous avez une expérience de plus de 5 ans en Modélisation de données et / ou Data Quality.

Vous avez travaillé en architecture de données dans des environnements Big Data ou Business Intelligence.

Vous aimez le travail en équipe, apprendre et partager .
Entreprise Capfi VITADATA est la start-up du groupe Capfi spécialisée en Data Science et Big Data. Nous accompagnons nos clients grands comptes sur leurs projets Data afin de :

Transformer leurs données en intelligence métier

Construire une architecture Data Centric contrôlée et évolutive

Nous répondons aux enjeux analytiques et prédictifs des Directions Digital, Marketing, Risque, Actuariat et Innovation de nos clients des secteurs Banque/Assurance, Energie, Retail, Media, Transport,… Et apportons une expertise aux Directions des Systèmes d’Information sur leurs projets de développements en méthodologie Agile, avec une tendance forte à décliner la culture DevOps."
Levallois-Perret (92),,,Architecte Big Data,ETAONIS,- Levallois-Perret (92),"Formation : Ingénieur Spécialité : Big Data Rémunération : Package variable selon le candidat
Issu dans l'idéal d'une grande école d'ingénieurs, vous maîtrisez les principaux outils du Big Data avec en particulier R-Hadoop ou Python-Spark. Votre profil est plus proche de celui du « Computer Scientist » que du « Data Scientist ». Des connaissances en traitement d'images sont un plus."
Paris (75),,,Architecte Big Data,BLUESCALE,- Paris (75),"Vos domaines d interventions seront les suivants :
Analyse des besoins en relation avec les équipes métiers et participation à l avant-vente (POC, Maquettes, etc.)
Définition de stratégies architecturales de BDD Big data (modélisation, design et implémentation)
Proposition de scénarios, d'architectures et de plateformes en cohérence avec le besoin du client
Conception, développement d'architectures logicielles et techniques de plateformes Big Data
Identification, évaluation et recommandation auprès du client des outils et technologies adaptés à ses besoins
Création et optimisation des BDD Big Data
Optimisation technique et fonctionnelle des bases de données en termes de performance et de fiabilité
Maintenance et optimisation des systèmes mis en place
Conception et installation de mises à jour des logiciels de management de BDD Big Data
Installation et déploiement des clusters, des sauvegardes et des procédures de récupération des données
Rédaction de livrables et présentation des solutions proposées
Veille technologique continue
Profil :
Vous êtes Bac + 5 en informatique ou issu d une Ecole d'Ingénieur (Centrale, Mines, Telecom Paris, etc.) et êtes sensibilisé aux sujets analytiques (Data mining, Machine Learning, etc.).
Vous connaissez les outils informatiques liés au Big Data (Hadoop, Hive, Pig, Spark, etc.).
Vous possédez les qualités relationnelles et rédactionnelles d'un consultant. Rigoureux et précis, vous êtes à l'aise dans des démarches d'analyse de problématiques complexes.
Les missions proposées requièrent des compétences dans le domaine du traitement complexe de la donnée ainsi que de bonnes compétences informatiques, notamment en manipulation de bases de données. Vous êtes curieux et avez un goût pour l'innovation et les nouvelles technologies."
Paris 10e (75),,,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong

Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Suresnes (92),,,Expert Presales Data (Solution Engineer),Talend,- Suresnes (92),"WHO WE ARE:

Talend, a leader in data integration and data integrity, enables every company to find clarity amidst the chaos.

Talend Data Fabric brings together in a single platform all the necessary capabilities that ensure enterprise data is complete, clean, compliant, and readily available to everyone who needs it throughout the organization. It simplifies all aspects of working with data for analysis and use, driving critical business outcomes.

From Domino’s to L’Oréal, over 4,250 organizations across the globe rely on Talend to deliver exceptional customer experiences, make smarter decisions in the moment, drive innovation, and improve operations. Talend has been recognized as a leader in its field by leading analyst firms and industry publications including Forbes, InfoWorld and SD Times.

Talend is Nasdaq listed (TLND) and based in Redwood City, California.

We are hiring an Expert Pre-Sales Engineer (Solution Engineer) to continue to build a proactive, customer-facing organization that ensures customers are getting value from Talend’s products and solutions.

We are seeking an Expert Pre-Sales Engineer (Solution Engineer) to join the sales team and support the increasing demand from our direct sales teams. Our portfolio of products has expanded from purely Data Integration to include Data Quality (DQ), Master Data Management (MDM), Enterprise Service Bus (ESB), Big Data and Cloud.

The main responsibilities are to secure the “technical win” in growing our customer’s community and contribute to the enablement of our prospects during their selection process.
The Expert Pre-Sales Engineer (Solution Engineer) will have a focus on one of our Product practice such as Big Data or Enterprise Service Bus.
Key Job Functions Include:
Identifying business issues and relating them to Talend capabilities
Articulating Talend’s value proposition and differentiation at all levels within Enterprise Accounts
Engaging in and responding to RFI/RFP procurement processes
Qualifying opportunities
Building and delivering comprehensive customized demonstrations
Working within the sales team to own technical relationships with prospects from developer to CIO
Managing delivering Proof of Concepts (POC)
Demonstrating success at working both independently and as a valued team player
Excellent interpersonal and presentation skills
Managing a high number of concurrent active prospects
Ideally possessing 5+ years of pre-sales experience
Experience working complex multi-solution six figure deals
Key Skills:
Data Integration (ETL); experienced in Data Warehousing and Business Intelligence
Technical knowledge should include JAVA, SQL, XML, JSON, XSD, XSLT, and HTML
Big Data (Hadoop distributions and key technologies)
Data Quality (DQ)
Enterprise Service Bus (ESB)
Relational and NoSQL databases
Note that this is a hands-on role and requires the pre-sales engineer to install and configure the Talend software to meet the needs of the POC as defined and agreed with the customer.

AND NOW, A LITTLE ABOUT US:

Talend has received some pretty impressive accolades along the way:
""2018 Best Public Cloud Computing Companies To Work For"" by Glassdoor
Named a Leader for Data Integration Tools in the Gartner Magic Quadrant
Named a Leader in Big Data Fabric for the Forrester Wave
Ranked in the DBTA “100 Companies that Matter Most in Data”
Listed in the CRN Big Data 100 Companies

We are passionate about helping companies become more data driven; and, if we can be honest, we are all geeks at heart who pride ourselves on the vibrant company culture that we have built.

As a global employer, at Talend, we believe our success depends on diversity, inclusion and mutual respect among our team members. We seek to recruit, develop and retain the most talented people from a diverse candidate pool. We are committed to making all employment decisions on the basis of business need, merit, capability and equality of opportunity. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin."
Paris (75),,,Senior Data Privacy Counselor (F/M),AXA,- Paris (75),"The purpose is to ensure that the data privacy 1st line of Defense, in the hands of Chief Data Officers, is at the appropriate level as innovation and regulations evolve, with an operational focus on initiatives co-led by rev and AXA operating companies.

The main activities are to:
Manage data privacy implementation for joint rev & entity initiatives, in close collaboration with G.O. Compliance, rev and entity teams;
Follow-up and regularly communicate on evolution of regulation pertaining to data, specifically on geographies concerned by initiatives co-led by rev and AXA operating companies;
Drive continuous improvement for pro-actively balancing enforcement of these evolutions, implementation of innovation and AXA risk appetite.

Technical and professional skills:
At least a global 10 years’ experience in the implementation of data privacy regulation, notably GDPR, at a worldwide scale;
English - Fluent in speaking and writing.

Soft skills and competencies:

Able to interact with a vast variety of stakeholders: business, compliance, developers, data managers, project managers;
Strong problem-solving skills;
Result oriented;
Self-motivated, proactive, future looking, and able to work in a complex organization;
Leadership, influence and conflict resolution;
Team player in a multi-cultural work environment, able to see the big picture as well as deep dive into details when necessary."
Boulogne-Billancourt (92),,,Architecte Data-(H/F),Boursorama,- Boulogne-Billancourt (92),"Vos missions au quotidien
Boursorama recherche un Architecte Data (H/F).
Au sein d’une équipe d’experts de la data (Architecte Data et système, DataScientist, statisticien, data engineer, Key user métier, analyste et expert en reporting), vous êtes en charge de :
Participer à la mise en place de nouvelles briques technique,
Assurer la performance des plateformes,
Réaliser de la veille technologique,
Travailler dans une approche ops avec les équipes d’architecture système,
Industrialiser les tâches dans une optique d’intégration continue,
Garantir la qualité des livraisons,
Définir les best practice de développement.
Vous définissez les standards relatifs à la nature des données, leur collecte, leur qualité, leur traitement et leur mode de stockage pour en assurer une utilisation optimale en tenant compte des contraintes de sécurité et de gouvernance.
Vous avez une position de prescripteur au sein de la DSI, notamment au travers des comités d’architecture, en proposant et concevant une architecture de données ergonomique et évolutive.
Il peut être amené à échanger avec le top management et dispose d’excellentes capacités de synthèse et communication écrite et orale.
Vous intégrez l'Equipe Data pour :
Accompagner Boursorama dans sa croissance et la mise en œuvre de sa roadmap,
Rejoindre une équipe de 20 personnes dynamiques et passionnées par la data,
Porter l’approche Datadriven et piloter la transformation du SI data,
Collaborer sur tous les domaines d’activité data : BI et analytique, big data, Datascience et IA, master data management et qualité des données,
Travailler dans un contexte agile,
Porter des approches novatrices,
Intervenir sur des sujets et métiers transverses : Marketing, risque, finance / banque, bourse, média.
Vos missions principales sont les suivantes :
Architecture
Garant de l’architecture data de Boursorama,
Design de solutions Big Data et de Solutions analytique temps réel - Datalake,
Maîtrise des architectures distribuées,
Modélisation de données,
Maîtrise des approches devops et continious delivery (Jenkins, nexus …),
Maîtrise de docker,
Exploitation technique et pilotage de solution en condition de production,
Exploitation de référentiel et qualité de données.
Compétences techniques
Expert en développement sur au moins un des langages suivants : Scala - Java,
Expert sur la technologie Spark (batch et streaming),
Expert sur la technologie Kafka,
Maitrise de l’écosytème Hadoop (HDFS, Hive …),
Maitrise de la suite Elastic Search,
Maitrise en modélisation de base NO SQL (Type Cassandra),
Connaissances des bases de données graphes (Type Janus graph),
Industrialisation de projet à composante statistique (IA, Machine / Deep Learning),
Connaissances avancées sur au moins un portail analytique du marché (Type Tableau).
Gestion de projet
Maitrise de la gestion de projet agile,
Organisation de Comités (Projet, Pilotage…) et présentations,
Participe à la négociation avec les éventuels sous-traitants,
Assure la coordination de l’ensemble des acteurs et rend compte de l’avancement.
Et si c’était vous ?
Diplômé d’une école d’ingénieurs avec une expérience d’au moins 5 ans sur un poste de tech lead / architecte
Vous disposez d’excellentes capacités de synthèse et d’une bonne communication écrite et orale.
Vous êtes flexible, agile, orienté solutions et resultats et aimez travailler en équipe.
Proactif, passionné par le traitement de données et les nouveaux usages, à l’écoute des évolutions technologiques et des approches actuelles, venez rejoindre notre équipe dynamique et motivée !
Pourquoi nous choisir ?
Avec son double positionnement unique de banque-média, Boursorama est leader, en France, sur trois métiers : la banque en ligne, le courtage en ligne, et ’information économique et financière sur Internet avec le portail Boursorama.com.
Après avoir atteint, en 2019, son objectif de 2 millions de clients avec un an d’avance, Boursorama s’est lancé un nouveau challenge : dépasser les 3 millions à horizon 2021.
L’entreprise, filiale à 100 % de Société Générale, compte plus de 800 collaborateurs. En devenant l’un d’eux, vous prendrez part à une aventure professionnelle enrichissante, placée sous le signe de la croissance !
Vous rejoignez notre Direction des Systèmes d’Information, composée de talents IT passionnés par leur métier : ingénieurs, architectes ou encore chefs de projet.
Leur mission principale ? Développer des solutions innovantes qui optimisent chaque jour la relation de nos clients avec leur banque.
En bref, l’IT de Boursorama, ce sont des technos de pointe, des projets et de l’innovation.
Nous sommes un employeur garantissant l'égalité des chances et nous sommes fiers de faire de la diversité une force pour notre entreprise.
Le groupe s’engage à reconnaître et à promouvoir tous les talents, quels que soient leurs croyances, âge, handicap, parentalité, origine ethnique, nationalité, identité sexuelle ou de genre, orientation sexuelle, appartenance à une organisation politique, religieuse, syndicale ou à une minorité, ou toute autre caractéristique qui pourrait faire l’objet d’une discrimination.
Référence: 19000MZW
Entité: Boursorama
Date de début: Immédiat
Date de publication: 02/04/2020"
Paris 12e (75),,,Architecte Data - H/F,Keolis,- Paris 12e (75),"Systèmes d'Information

Avec plus de 15 milliards de requêtes par an, Kisio Digital, filiale numérique du Groupe Keolis, est un acteur majeur de la mobilité. Les trois grands domaines d’intervention de Kisio Digital portent sur la recherche d’itinéraire multimodal en temps-réel ; l’achat de titres de transport dématérialisés et le mobile-ticketing. Sa vision de la mobilité : permettre à chacun de se déplacer plus facilement, plus agréablement et avec le moins d’emprise possible sur la planète. C’est ce qu’on appelle la responsive locomotion ! Kisio Digital travaille continuellement à l’amélioration des algorithmes qui permettent de calculer les meilleures solutions d’itinéraire en tenant compte du contexte et des préférences du voyageur. Pour répondre à ces enjeux, Kisio Digital réalise des applications mobiles, des sites web et des SDK basés sur son API www.navitia.io . Cette plateforme propose des services numériques de mobilité dans le monde entier. Elle rassemble une communauté de 20 000 développeurs ! Kisio Digital va désormais lancer des services à l’étranger. Rejoignez-les !

Missions

L’idée est de piloter la mise à jour quotidienne de centaines de jeux de données de natures différentes (OpenStreetMap, GTFS de Paris, de New-York ou d’Accra, vélo en libre services, etc.) ; de les corriger, de les améliorer, de les standardiser ; puis de les mixer avec des centaines de flux temps réel par seconde pour finalement les intégrer dans nos systèmes afin de répondre aux 15 milliards de requêtes annuelles. Et surtout, ne jamais avoir pas peur ™.

Vous êtes membres d’une équipe ayant pour mission de piloter les évolutions du produit de collecte, mise en qualité et redistribution des données manipulées dans l’entreprise, accompagné par une équipe composée de développeurs et d’un architecte technique.

Vous avez en charge les missions suivantes :
Définir et estimer les évolutions requises par les projets de nos clients
Définir la roadmap produit court terme et accompagner la définition de la stratégie globale
Synthétiser les besoins des parties prenantes et en déduire des évolutions produit pertinentes
Concevoir et/ou faire évoluer les modèles métier de gestion de données
Suivre et accompagner les évolutions produit et la réalisation des projets
Faire de la veille sur les données de mobilité et les différents formats d’échange
Accompagner les différentes équipes de l’entreprise sur leurs besoins en données

Profil

Hardskills
Maîtrise d’au moins un langage de manipulation de données (python, R, SQL)
Utiliser Linux ne vous fait pas peur
Vous savez explorer la donnée et en tirer des conclusions
Maîtrise d'une base de données relationnelle (PostGreSQL, c’est bien.) mais aussi connaissance d'une base de données non relationnelle (MongoDB ou autre)

Softskills
Esprit de synthèse et rédaction de documentation. Parce qu’il en faut.
Anglais courant, et veille technique dans la langue de Shakespeare.
Et surtout, vous êtes autonome tout en appréciant le travail en équipe. Vous préférez convaincre qu’imposer."
Poissy (78),CDI,,Data engineer H/F,PSAPeugeotCitroen,- Poissy (78),"Au sein de la DSI, le Data engineer est en étroite relation avec les directions métiers, il définit, construit et industrialise des solutions mettant en œuvre une masse importante de données tout en garantissant la sécurité de celles-ci. Il met en place la collecte, le stockage et l'exploitation de ces données pour les besoins des datascientist ou des applications de reporting ou de BI demandées par les directions métiers de l'entreprise. C'est le premier acteur de la chaine de traitement de la data. Il travaille en collaboration avec les développeurs, les datascientists et les experts des différents métiers de l'entreprise.
Principales actions :
Il met en place des architectures BigData efficientes pour rendre exploitable la donnée et répondre aux besoins des différents projets
Il collabore avec les data scientist pour concevoir et industrialiser les modèles (mise à disposition de donnée, qualité, restitution des résultats)
Il met à disposition des data analyst des données prétraitées ou mises en forme
Il industrialise, automatise les flux d'alimentation de données
Il assure le niveau de performance du traitement des données en fonction des exigences métier (batch ou temps réel) et leur intégrité.
Il document les chaines de traitement (data lineage)
Il assure une veille technologique régulière sur les nouveautés des infrastructures Big Data
Il est force de proposition sur les solutions proposées
Profil
Bac +5 Ecole d'ingénieur, master en Informatique, 1 ou 2 ans d'expérience dans le Big data ou le traitement des données (ETL, BI, …)
Bonnes compétences en programmation python
Utilisation de notebooks (Jupyter)
Connaissance en SQL et NoSQL (Oracle, Hbase, Cassandra, MongoDB)
Sensibilité à l'approche DevOps
Maitrise de git et des concepts généraux du versionning (Git, Github)
Maitrise des architectures distribuées, et du fonctionnement de l'environnement BigData (Hadoop, Spark, Hive, Pig, Impala)
Connaissance de technologies temps réel (Spark Streaming, Kafka)
Utilisation des plateformes Unix, maitrise du shell
Capacité à communiquer avec les équipes métiers et à analyser les besoins
Anglais courant (le groupe est international)
Localisation du poste
Pays
Europe, France, Ile-de-France, Yvelines (78)
Ville
Poissy
Critères candidat
Niveau d'expérience min. requis
5 à 10 ans
Langues
Anglais (C1 - Courant (3,5 - 4,4 Bright))"
Chilly-Mazarin (91),,,Sr. Data Scientist - Medical Imaging and Deep Learning ( M/F),Sanofi,- Chilly-Mazarin (91),"About the Company :
Sanofi is a global life sciences company committed to improving access to healthcare and supporting the people we serve throughout the continuum of care. From prevention to treatment, Sanofi transforms scientific innovation into healthcare solutions, in human vaccines, rare diseases, multiple sclerosis, oncology, immunology, infectious diseases, diabetes and cardiovascular solutions and consumer healthcare. More than 110,000 people in over 100 countries at Sanofi are dedicated to make a difference on patients’ daily life, wherever they live and enable them to enjoy a healthier life.
As a company with a global vision of drug development and a highly-regarded corporate culture, Sanofi is recognized as one of the best pharmaceutical companies in the world and is pioneering the application of Artificial Intelligence (AI) in the R&D organization including drug discovery, chemical manufacturing and control, translational research, clinical development, and regulatory document management and submission. Details of the organization and the company’s mission and goals can be found on our website ( https://www.sanofi.fr/ ).
Job Overview:
Artificial Intelligence (AI) and Machine Learning (ML) algorithms can significantly speed up drug discovery and shorten the time-to-market for drug development thereby creating better medicines that save lives. AI and Deep Analytics (AIDA) is a critical group in Digital and Data Science (DDS) focused on applications of AI/ML and Deep Learning (DL) in biologics drug discovery; image processing and computer vision (CV) for digital pathology, natural language processing (NLP) for sequence analysis, language modeling, and deep understanding of documents; wearable devices for digital clinical trials; IoT for bioprocess manufacturing; and Bioinformatics.
Image Segmentation, Classification, and Processing has broad applications in the pharmaceutical industry, particularly, in Digital Pathology (DP) applied to medical images of cancer patients as well as patients suffering from neurodegenerative diseases. This involves modeling and characterization of properties of images of tumors that can be effectively used for both personalized treatment of cancer patients (Precision Oncology), or monitoring the progress of status of clinical trials. Manual processing of pathology images by a Subject Matter Expert (SME) takes a relatively long time (e.g. a few weeks per image). This significantly limits evaluation of large number of images during a late-stage clinical trial. To overcome this limitation, novel deep learning-based image processing algorithms need to be utilized to speed up the process greater than 10 fold and reduce both the cost and length of such clinical trials. At the level of an individual patient, the baseline diagnosis can be done significantly faster.
We are looking for a Senior Data Scientist with a strong background in histopathalogy, bioimaging, high-resolution microscopy, cell microscopy , image processing, and deep learning in our AI and Deep Analytics (AIDA) group at the Digital and Data Science (DDS) organization of Sanofi R&D. The candidate will directly report to the Global Head of AI and Deep Analytics at Sanofi R&D. The head of AIDA is an experienced Data Scientist with a PhD and Master’s degree from MIT in Electrical Engineering and Computer Science and over 25 years of experience in machine learning.
The responsibilities of the senior data scientist in AI and Deep Analytics will include:
Applying AI/ML for modeling and embedding of biological sequences and classification, clustering, visualization, and prediction of properties of large datasets of sequences.
Close interactions with data engineers, subject matter experts (SMEs), and business stakeholders
Update and report relevant results to interdisciplinary project teams and stakeholders
Maintain a keen awareness of developments in data and cloud infrastructures and state-of-the-art of AI/ML/DL algorithms and research results
Evaluate and coordination of both academic and startup collaborations
Qualifications & Requirements:
A PhD degree in Computer Science, Electrical Engineering, Applied Mathematics, or Physics with an emphasis on machine learning and deep learning
3+ years industry experience with a strong record of accomplishments and project experience in applications of AI/ML
Strong familiarity with Deep Learning, neural network architectures including CNNs, RNNs, Embeddings, Transfer Learning, Attention-based Networks, and Variational Autoencoders.
Familiarity with Data Visualization tools/libraries and dimensionality reduction algorithms
Proficient in Python, SQL, and NoSQL databases
Familiarity with deep learning libraries such as PyTorch, TensorFlow, Keras, OpenCV
The ability to work with APIs and multi-GPU machines on the cloud
A change agent with a combination of business, science & technology, and diplomatic skills
At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.
As part of its diversity commitment, Sanofi is welcoming and integrating people with disabilities."
Suresnes (92),,,Senior Data Ops Engineer,Talend,- Suresnes (92),"WHO WE ARE:

Talend, a leader in data integration and data integrity, enables every company to find clarity amidst the chaos.

Talend Data Fabric brings together in a single platform all the necessary capabilities that ensure enterprise data is complete, clean, compliant, and readily available to everyone who needs it throughout the organization. It simplifies all aspects of working with data for analysis and use, driving critical business outcomes.

From Domino’s to L’Oréal, over 4,250 organizations across the globe rely on Talend to deliver exceptional customer experiences, make smarter decisions in the moment, drive innovation, and improve operations. Talend has been recognized as a leader in its field by leading analyst firms and industry publications including Forbes, InfoWorld and SD Times.

Talend is Nasdaq listed (TLND) and based in Redwood City, California.

As part of its growth, Talend is hiring a Senior DataOps engineer for the R&D Lab team based in Suresnes, France. This new role in the Lab team will contribute to accelerating the industrialization of machine learning applications developed by the Lab team and the Applications teams. You will help the team by delivering the appropriate data, with the expected quality and with respect of the privacy and security constraints. You will establish governance discipline, such as data lineage tracking.
Responsibilities :
Maintain and automate data operations
Work with the Cloud Application teams, the SRE team to locate and identify the required data for the Lab machine learning engineers.
Work with the Data Lake team to design the Cloud data architecture
Develop tools, frameworks and methods to ensure high quality data pipelines
Work with SRE team to develop appropriate infrastructures for data lake and machine learning pipelines
Bring best practices of CI/CD into the Lab team
Promote the DataOps culture to the teams
Manage and deploy internal and external monitoring/alerting solutions
Apply Agile development principles to data pipelines
Skills and Experience
3 years experience as Data Ops or Data Engineer or DevOps (SRE)
Good knowledge of Cloud providers (Amazon AWS, Microsoft Azure, Google Cloud Platform)
Good knowledge of Python, Java, Shell script
Knowledge of Kubernetes
Knowledge of Spark clusters, execution of Spark jobs
Knowledge of Airflow, MLFlow, Kubeflow or another ML lifecycle pipeline framework
Knowledge of CI/CD tools (Jenkins...)
Knowledge of Terraform
Easy communication with various profiles (engineering managers, devops, developers, data scientists...) in the company
Background in Data science, Data mining, Multivariate statistics, Machine learning
Familiar with data analysis tools such as Tableau
Excellent problem solving and communication skills
Ability to communicate effectively and clearly in English, both verbally and in writing.
Experience in working within a distributed & international agile team environment.
Join a passionate team and work with the latest cloud native approaches and technologies (K8S, Docker, Kafka, Terraform, AWS, Azure to name a few)
A challenging but rewarding environment with international scope

AND NOW, A LITTLE ABOUT US:

Talend has received some pretty impressive accolades along the way:
""2018 Best Public Cloud Computing Companies To Work For"" by Glassdoor
Named a Leader for Data Integration Tools in the Gartner Magic Quadrant
Named a Leader in Big Data Fabric for the Forrester Wave
Ranked in the DBTA “100 Companies that Matter Most in Data”
Listed in the CRN Big Data 100 Companies

We are passionate about helping companies become more data driven; and, if we can be honest, we are all geeks at heart who pride ourselves on the vibrant company culture that we have built.

As a global employer, at Talend, we believe our success depends on diversity, inclusion and mutual respect among our team members. We seek to recruit, develop and retain the most talented people from a diverse candidate pool. We are committed to making all employment decisions on the basis of business need, merit, capability and equality of opportunity. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin."
Paris (75),,,Data Sciences Specialist (M/W),Danone,- Paris (75),"DANONE SA in Corporate is looking for a Data Sciences Specialist - L8 (M/W) in Paris.
Each time we eat and drink, we vote for the world we want to live in.

Danone’s mission is Bringing health through food to as many people as possible and we want to invite people to join the movement for a healthier world. We recognize the power people have to impact the world through their daily choices. Healthy food needs a healthy planet, and this is what our new signature One Planet One Health embodies.
THE CONTEXT
To support Danone’s top-level ambition to adopt a data-enabled organization, we are building a team in Paris to be the “Data analytics and AI center of Excellence”. Our ambition is to become the data science talent hub for all Danone in Europe. This team will be part of the new Chief Data Office at Danone promoting data as an asset and covering fields such as data science, data governance, data transformation and master Data Management.

Our target team is a picture of diversity and inclusiveness. In Data analytics and AI team, we are starting today with a team of 6 people coming from various backgrounds with 47 cumulated years of passion for data and we want to build an enthusiastic, highly-skilled and delivery-oriented team from a mix of junior, senior, team leader & expert profiles.

Your mission, as a Senior data scientist, will be to promote a new data mindset by delivering state of the art, pragmatic, and creative data science solutions to answer complex business problems. Our target is to work for all of Danone’s businesses and address topics such as demand/supply forecasting, commodity pricing, milk collection optimization, marketing optimization and environmental impact reduction.
Joining us will be an exciting adventure as we are starting today with a team of 6 people coming from pharma, FMCG, banking, consulting, airlines, automotive industry background with accumulated 47 years of data passion.
Finally, as the data office team is international, you will have the chance to be part of an international fellowship of data scientists.
ABOUT THE JOB

Oversee from a technical point of view the activities of the junior data scientists over a data domain
Provides advanced expertise on statistical and mathematical concepts for the broader Data Analytics and AI team and data sciences fellowship.
Collaborate with business partners & data project leaders to identify business needs and translate them into actionable measures.
Support the implementation of these solutions.
Implement ETL workflows, Data Mining/Wrangling to make data useable and understandable for other Data Scientists or business teams.
Apply state-of-the-art algorithms and predictive models (Machine Learning/Deep Learning) to answer business problems.
Share results with technical and business teams (Data Visualization).
Build & improve team’s knowledge, processes and best practices.

ABOUT THE CAREER PATHS

Trainings and certifications possibilities will be given as part of the onboarding and continuous development process
Career opportunities will be built internationally and across Worldwide Business Units (WBUs) and across fields.
ABOUT YOU

More than 6 years of experience in Data Science within a fast-paced and complex business setting, preferably working as a Senior Data Scientist.
A MSc, PhD or other Advanced Degree in a field linked to computer science, applied mathematics, statistics, machine learning, or closely related fields
Experience in Fast-Moving Consumer Goods (FMCG) industry is a plus
Ability to manage complexity and to work under pressure
Rigor, methodical and structured approach
Ability to work in an international environment
Good interpersonal skills and team spirit
Fluent English is a must

ABOUT YOUR SKILLS

We are looking for people having several technical skills among the followings:

Programming: Python, R, SQL, Git
Databases: Relational/Non-relational databases
Modeling : Advanced Statistical Analysis, regressions, Gradient Boosting, Random Forest, Neural Netwok
Viz’: Power BI and MicroStrategy
Infrastructure: Cloudera HDFS, AWS, Docker, CI/CD
Data Science tools/modules : Jupyter Notebook, Databrick, ML Flow

Experience in all or several parts of Advanced Analytics process will be challenged:
Explore the potential of a raw data set
Build relevant and performant models and analyses
Automate workflows
Scale, deploy and monitor industrialized projects
Consistency of approach for a data domain/portfolio of projects

Mandatory skills:
Substantial experience working on full-life cycle data science project
Knowledge of agile development methodologies and tools:
SCRUM methodology
Flexibility and iterative way of working
Experience with Jira/Trello/ Asana solutions
Ability to meet tight deadlines and work in an environment with multiple priorities.
Excellent written and verbal communications skill. In particular, a strong proven ability to communicate statistical and modeling results in a clear manner.
If we just described your profile, please click the “apply now” button and upload your CV!

DANONE AND ITS BRANDS

Mix 75g of Activia, 130g of a small Blédina pot, 50cl of an Evian bottle and add a drop of Fortimel ... you get 4 brands representing the 4 divisions of the Danone group: Fresh Dairy Products and Vegetables (Activia, Danette, Actimel, Alpro, etc.), Waters (Evian, Badoit, Volvic, Salvetat), Medical Nutrition (Fortimel, etc.), and Infant Nutrition (Blédina, Gallia).
All these brands are worn by 100,000 Danoners in the World. Don’t wait, vote for the world you want to live in and join the movement!

A LITTLE TASTE?

Need advice on applying?
Follow our Danoners and our brands on Instagram, Facebook, Linkedin, Twitter
An overview of the premises: our head office in Paris and the new headquarters of Blédina in Limonest
What our trainees / alternates think about us: Happy Trainees # 4
Learn more about our jobs on Jobteaser.

140845
#LI-FR"
Paris (75),,,Pre-Sales Engineer,MyDataModels,- Paris (75),"The company
MyDataModels is the only Small Data automated predictive modeling software vendor for domain experts. “Leading the Small Data predictive analytics revolution by providing an easy-to-use Predictive Modeling tool, it’s Our Mission. Giving every professional in every domain, access to Machine Learning/predictive models, it’s Our Vision.”
The Position
MyDataModels is currently growing and recruiting Pre-Sales Engineers.
You will join MyDataModels’ adventure as it is fast growing and will participate in a rewarding entrepreneurial adventure. We work with a lean, startup mindset and are all entrepreneurs at heart!
Objectives
Develop and support sales revenues ensuring both short and long-term objectives are met
Improve the market position and standing of MyDataModels in its given territory
Key Responsibilities
Support the Sales team to sell MyDataModels’ products: identify, define and develop new business opportunities in collaboration with Sales, Marketing and Business Development teams
Ownership of customers’ trials: technical and project follow-up
Technical account management: customer follow-up after product purchase in order to ensure customer satisfaction
Drive and motivate the “virtual team”, i.e. Product Management, Marketing, Support – to achieve goals.
Work with Support services to ensure co-ordination of activity and effective support to customers and field sales force
Ensure customer technical issues are resolved without delay
Maintain a thorough understanding of the marketplace and respond to competitive pressures and initiatives
Some occasional local travel may occur (10-15%)
Candidate
Education and Training
Engineering Degree with a Data Science major or Masters Degree in Data Science
French mother tongue and very good working knowledge of English
Experience
Proven pre-sales or consulting experience (3-5 years) and success records are essential
Must be able to demonstrate successful experience of supporting penetration of strategic accounts and developing a technical strategy for key account management in sectors relevant to the company’s products
Customer-oriented and results driven
Must have experience in successfully working in a “virtual team”, being part of a dispersed team, providing leadership, drive, motivation to the team
Should be accustomed to the pace and environment of a startup company
Technical skills
Data Mining & Machine Learning experience
Python, Jupyter, R (not mandatory)
Profile
Self-confident, ready to take on challenges
Must be a self-starter with a strong commitment to achieving results, with a highly professional approach to the job
Must be well organized in approach to work and disciplined in evaluating priorities, in a fast-changing environment
Should demonstrate a firm commitment to customer service and satisfaction with an appreciation of the importance of quality
Should be an innovative thinker and effective communicator capable of developing sales and technical initiatives
Work well independently but also a team player
Solutions orientated – proactive in dealing with topics
Job Type
Permanent,
Located in Paris, France
As part of the Sales team and reporting to the Sales Manager
Attractive package with fixed, variable and stock options"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),"Apprentissage, Contrat pro",,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
Dirigée par le Chief Data Officer et rattachée directement au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques (DDSA) se compose de cinq services. Elle met en œuvre la stratégie définie par le Chief Data Officer afin que la Banque transforme ses données en un capital pleinement valorisé.
La DDSA a pour missions essentielles la gouvernance, le partage et la valorisation des données, le développement de projets d'intérêts communs, le développement d'une culture de la donnée et la contribution à la data réputation de la Banque.

Présentation du Service
Au sein de la Direction des Données et des Services Analytiques (DDSA), le Service des analyses quantitatives et méthodes avancées (QUANTIM) développe un savoir-faire en matière d'analyse quantitative des données en s’appuyant plus particulièrement sur les méthodes innovantes issues de la data science et offre son expertise dans le cadre de travaux menés en coopération avec les autres services de la Banque sur des problématiques métier très variées.
Le QUANTIM contribue également à la mise en œuvre de la plateforme analytique du Datalake de la Banque ainsi qu’à l’animation de communautés dédiées aux méthodes de traitement des données et à l’accompagnement de tous les utilisateurs de R.

Descriptif de mission
En tant qu’Alternant Data Scientist au sein du QUANTIM, vous serez intégré(e) à une équipe de 10 personnes.
Les missions qui vous seront confiées pourront notamment porter sur l’une ou l’autre des thématiques suivantes :
• À partir des bases de données disponibles à la Banque (sur le portail statistique public Webstat ou, en interne, le Datalake de la Banque), développer des outils permettant de recommander automatiquement des séries explicatives (à partir de différentes corrélations, corrélations glissantes, cohérences d'ondelettes, etc.) s'apparentant à l'ancien outil de Google appelé Google Correlate ;
• À partir des bases de référentiels disponibles à la Banque, mettre en place des outils de visualisation des groupes bancaires et financiers en s'appuyant sur les méthodes d’analyse des réseaux ;
• À partir des articles de presse quotidienne disponibles sur Internet, contribuer à l’analyse de l'information textuelle afin d’estimer le niveau d'incertitude économique en général et, à la discrétion des autorités de la Banque, liée à une problématique précise (coronavirus par exemple).

Profil recherché
Formation recherchée : Grande école ou Master 2 en data science ou en économétrie / statistiques avec une forte appétence pour la data science
Compétences : machine learning, text mining, webscraping, datavisualisation, graph mining, séries temporelles, programmation R/Python, connaissances en anglais (littérature académique)
Qualités : rigueur, réactivité, autonomie et curiosité ; esprit d’initiative, sens aigu de l’innovation
Une première expérience significative (stage de 6 mois, projet annuel en groupe ou mémoire ) dans la pratique de la data science constituera un atout.

La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes recrutées."
Levallois-Perret (92),"Temps plein, CDI",,FULL REMOTE Senior Data Scientist H/F - CDI,Jellysmack,- Levallois-Perret (92),"Nous continuons de recruter et avons adapté notre processus de recrutement. Tous nos entretiens, ainsi que l’onboarding, se déroulent désormais en full remote.
Cette offre d'emploi est proposée en FULL REMOTE
Jellysmack est une entreprise spécialisée dans la création de contenus vidéos originaux sur les réseaux sociaux. Avec plus de 3 milliards de vues par mois, Jellysmack a connu une ascension fulgurante, ne cesse de grandir et ambitionne de devenir le leader mondial dans son domaine. La recette de ce succès repose sur la qualité de nos contenus, mais aussi sur la technologie opérant en arrière-plan. Jellysmack a développé une suite d'outils propriétaires, propulsés par l'IA, permettant à nos équipes de contenu de publier, s'inspirer, comprendre la trend, analyser les résultats, mais bien plus encore, des outils qui analysent le contenu en ligne, les réactions des gens devant ce contenu, et déterminent ce que sera la tendance demain.
Après plus de 2 ans de développement technique, Jellysmack propose une technologie unique articulée autour de 3 produits qui visent à optimiser la création et la distribution sociale de vidéos.
L'équipe Tech œuvre pour la mise en place d’outils utilisés en interne par les équipes contenu afin de déterminer les sujets qui buzzent, les aider dans la création de contenu, suivre les performances des vidéos internes etc... en injectant dans chacun de ces produits une dose conséquente d’algorithmie, de statistiques et de machine / deep learning.
En lien direct avec le Head Of Data (basé en Corse), vous serez amené à travailler sur différentes problématiques - prioritairement axées autour du NLP - et sur des projets de taille très différentes, impliquant d’importantes quantités de données (plusieurs centaines de millions de vidéos stockées en base à date avec leur métadata textuelles, plus de 21 milliards de commentaires...).
Au sein d’une équipe de sept data scientist, vous serez le référent de l’équipe sur ces sujets d’analyse et de compréhension du langage et vous aurez un rôle consultatif.
Missions principales
Passer d'une problématique métier à un algorithme de data science
Passer d'un POC à un algorithme en production
Vulgariser un algorithme à l'état de l'art et être référent de l'équipe Data Science
Etre autonome sur les outils comme Git, avoir déjà travaillé sous docker - idéalement sous AWS
Quelques exemples de sujets :
Analyse de sentiments sur les commentaires des vidéos
Extraction de topics à partir des titres, descriptions, commentaires des vidéos
Catégorisation de vidéos en thématique à partir de l’ensemble des éléments textuels dont nous disposons
Génération automatique de titre/tag de vidéos...
Création d’un algorithme d’identification des meilleurs créateurs sur une thématique donnée
Analyse de vidéos (contenu et metadata) pour mieux comprendre la rétention des utilisateurs
Optimisation de coût sur l’acquisition de fans
Génération automatique de montage de vidéos...
Profil recherché
Docteur en computer science ou diplômé d’une maîtrise en data science, vous disposez d’au moins 5 ans d’expériences,
Une autonomie sur le passage en production d’algorithmes sera indispensable,
Vous êtes pédagogue sur la transmission de votre savoir,
Vous avez un très bon niveau de SQL (MySQL et PostgreSQL).
Avantages :
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
full remote senior data scientist h/f - cdi ou similaire: 1 an (Souhaité)"
Paris 17e (75),,,Data Tracking Specialist (M/W),Manomano,- Paris 17e (75),"To consolidate its position as DIY and Gardening online leader, ManoMano has put technology at the heart of its strategy.
We are convinced it is by fluidly delivering qualitatives products that we will be able to offer our clients and merchants all the functionalities to revolutionise their online DIY experience.
As a fast growing company, we are always on the look for ingenious and passionate people.
As Data Tracking Specialist you will
Be responsible of data tracking governance with all feature teams
Be in close relation with Data Engineers in order to validate the data
Be part of the data governance team
Ensure good practices
Use SnowPlow and Tag management tools
Code with JavaScript
Be proactive
We do at ManoMano
Software craftsmanship: clean code, testing, peer programming, code review…
Devops: CI/CD, observability…
React, PHP/Symfony, Java SpringBoot, Gradle, Quarkus, Python, Go, NodeJS, MariaDB, MongoDB, ElasticSearch, Redis, RabbitMQ, Docker, Linux, AWS…
GSuite, Slack, Confluence, Draw.io, JIRA…
What we can offer you at ManoMano
Fast growing start-up environment
International & agile company
1 day per week work from home
Sponsorings to external conferences - organisation of internal and external Meetups
Crafternoons every Thursday afternoon (share your knowledges, learn from others)
Amazing work environment with younger and older cool colleagues :-) in Paris 17th
Attractive salary (package)
Preferred Experience
3 to 5 years of experinence
“a doer” - someone who know how to develop with JaVaScript
Innovative and creative
Excellente digital culture and Data Driven
Participate in data governance
Autonomous and adaptable (desire to work in a fast growing environment / Start-up)
Humble et curious with a big appetite to learn discover and experiment new things
Team spirit and great communication skills
You come to work with good intentions and good vibes
High level of English
Nice to have :
Python
Google Tag Manager
Additional Information
Contract Type: Full-Time
Start Date: 08 June 2020
Location: Paris, France (75017)
Education Level: Master's Degree
Experience: > 3 years
Occasional remote authorized"
Paris (75),CDI,,Data engineer,Margo Conseil,- Paris (75),"Vos principales responsabilités
Au sein de l’équipe de Data Engineer, vous êtes en charge de : • Développer de nouvelles API Rest en Python 3 • Récupérer des données externes • Exposer ces données à l’ensemble des équipes internes • Détecter de nouvelles sources de données en collaboration avec le business et les Data Scientists • Développer des outils pour monitorer la qualité des données • Réfléchir à la modélisation et au stockage des données • Développer avec des technologies Big Data (PostgreSQL, Elasticsearch, Kibana, Pandas, MongoDB) pour permettre le passage à la chaîne • Travailler avec les DevOp’s sur Docker • Faire de la veille technologique afin de participer aux choix techniques


Vos autres activités
En parallèle de ce poste, vous êtes amené(e) à participer à des conférences pour enrichir votre veille technique, à rédiger des articles et à animer des formations en relation avec votre domaine de compétences.


Et après ?
Ce poste est un tremplin pour une carrière en data science, en coordination de projet ou en management.


Votre profil
• Vous êtes Ingénieur Bac + 5 • Vous justifiez d’au moins 2 ans d’expérience en langage orienté objet • Vous avez déjà évolué dans un environnement Agile / Scrum • Vous faites preuve d’autonomie • Vous faites preuve de curiosité et êtes force de proposition afin de contribuer à un projet jeune et ambitieux


Ce que vous aimerez chez Margo
« We design career algorithms », notre promesse est porteuse des principales valeurs de notre groupe : l'esprit visionnaire et entrepreneurial de nos associés ainsi que notre politique RH, focalisée sur le développement de chacun. Nous favorisons l'évolution de nos collaborateurs, en encourageant la mobilité professionnelle et internationale pour la diversité des expériences et l'intérêt de la progression de carrière.


Engagée en faveur de l'égalité des chances, Margo vous informe que ce poste est ouvert aux candidatures de personnes en situation de handicap."
Paris (75),,,Data Scientist,Fifty-Five,- Paris (75),"Contexte
fifty-five accompagne les entreprises dans l’exploitation de leurs données au service d'un marketing et un achat-média plus performants. Partenaire des annonceurs de la collecte à l'activation des données, l'agence aide les organisations à devenir de véritables entités omnicanales maîtrisant l'efficacité de leur écosystème digital et ses synergies avec le monde physique. Pilier data stratégique de You & Mr Jones, premier groupe de BrandTech au monde, fifty-five propose des prestations associant conseil, services et technologie. L’agence compte aujourd'hui des bureaux à Paris, Londres, Hong Kong, New York et Shanghai. Le poste concerne le bureau de Paris.
Afin d'accompagner les annonceurs dans l'amélioration de la conversion sur leurs sites et applications et l'optimisation de leur stratégie média, fifty-five consolide diverses bases de données. En interaction avec les data engineers et consultants, les data scientists exploitent ces données brutes pour en tirer des informations utiles (insights) ou activer des stratégies d'optimisation data driven.
Le processus de recrutement contiendra plusieurs test techniques.

Vos missions
Vérification de la méthodologie et du bon déroulé du projet.
R&D, veille scientifique
Synchronisation avec les autres équipes (consultants, ingénieurs, experts marketing, clients)
Participation à la création de la solution
Participation à la construction de nouvelles offres innovantes Data Science
Mise en place et suivie de l’approche Data Science pour répondre à un problème client donné (forecast, scoring d’engagement / de churn, systèmes de recommandations, …)
Compétences et expérience


Diplômé d’une grande école majeure statistiques/économétrie/machine learning
Avoir participé à plusieurs projets Data Science de la prise du besoin à la création de la solution
Une très bonne connaissance de l’ensemble des techniques existantes en machine learning
Une forte appétence pour l’innovation et les nouvelles solutions
Une expérience quantitative en marketing digital est un plus
Appétence pour l’encadrement de profils plus juniors
Fortes compétences en :
Python, R, SQL, Bash, Bitbucket
Statistique descriptive et analyse de données (ACP, ACM, Classifications…)
Inférence statistique (régressions linéaires, logistiques, séries temporelles …)
Expérience avec les environnements cloud
Résolution de problèmes business marketing grâce à des modèles statistiques/machine learning
Capacité à spécifier et concevoir l'industrialisation des prototypes sur de gros volumes de données
Capacité à partager ses résultats de façon claire et accessible à une audience non technique
Qualités rédactionnelles et esprit de synthèse
Bon niveau écrit et oral en anglais et français"
Paris (75),,,Senior Data Engineer (M/F),Voodoo,- Paris (75),"Voodoo is a tech company focused on creating mobile apps for a wide audience.
Our goal is to entertain the world with snackable content and gaming apps!

Leader in the mobile gaming market, we are the n°1 company with the most monthly downloads worldwide on the App Store.

Based on our principles and values, you will have the chance to join a small, independent, and helpful team.
You will have full ownership of your role allowing you to be unique and continuously strive for excellence to deliver innovative and creative projects.

Role

Voodoo is looking for a talented data engineer eager to deal with great volumes of data and / or willing to build the data infrastructure of new social and media applications with huge scale potential!
You will be part of a small and high performing team working to solve complex problems using best-in-class technology(Spark, Python, Scala, Airflow). Sky is the limit and you will be always able to learn new technologies.
Challenges
Work on leveraging our data pipeline and create new ones, making sure the architecture will support the business requirements
Collaborate closely with Data Scientists to develop new ways to acquire data, build processes to create data set, setup machine learning infrastructure, etc.
Take ownership of projects from initial discussions to release, including feature estimation & scoping, architecture design, benchmark of new technologies, product feedback...
Make things in a very agile environment with a fast decision process, having the opportunity to collaborate directly with people working on mobile & back-end development, data science, mobile games, broad audience mobile apps, product & marketing
Must have
You have at least 4 years of experience as a Data Engineer or another similar role
You have a proven track record of building and optimizing data pipelines for massive amounts of data
You have a strong experience in scalability, reliability and security and also strong analytical skills, so you are able to work with unstructured datasets
You have a strong experience with Amazon Web Services
You are result-oriented and focus on the value created by your developments
You are curious about business needs and like to create innovative, agile solutions to help grow the business through data
You have excellent communication skills and can speak & write English
Working experience in a Gaming, Advertising or successful company
Familiarity with Voodoo's ecosystem: gaming, apps, advertising, analytics, etc, at all scales"
Paris (75),,,Senior Expert - McKinsey Analytics,McKinsey & Company,- Paris (75),"QUALIFICATIONS
Business fluent in French, both written and verbal
Advanced degree in a quantitative discipline (e.g., statistics, mathematics, econometrics, engineering or any related field)
5+ years of deep technical experience in predictive analytics, machine learning, optimization, statistical modelling, etc.
3+ years of experience in a client-facing consulting environment
5+ years of industry experience in a CDO function or similar
Fluent in a number of the following technologies: R, Python, Julia, SQL, GMPL, or related
Knowledge of typical frameworks e.g. TensorFlow
Expert knowledge of statistical approaches, incl. advanced machine learning techniques (e.g. Data Science, Support Vector Machines, Neural Nets, Deep Learning, Machine Learning) and/or optimization
Experience in leading teams and mentoring others Willingness to travel up to 80%
WHO YOU'LL WORK WITH
You will be based in Paris and will be part of McKinsey Analytics, serving clients from the region but also globally.
Given the unprecedented proliferation of data in the world today and our clients’ growing need to understand and capture value from it, McKinsey Analytics is rapidly expanding. Ongoing investments in our people and technology platform, combined with acquisitions of leading-edge firms like QuantumBlack and Risk Dynamics, have made us one of the largest and most esteemed advanced analytics consultancies today.
Combining state-of-the-art tools and techniques with McKinsey’s 85-plus years of experience, we enable our clients to improve their performance through data and become analytics-driven organizations.
WHAT YOU'LL DO
You will work through our clients’ entire data ecosystem to understand what’s available, what’s missing - and where to find and collect that information.
This includes applying data science methods to improve and optimize our clients’ performance needs, capture meaningful insights from data and turn them into competitive advantages.
In addition, you will drive the creation of statistical models to solve specific operational problems, which may include predicting equipment failure to do proactive maintenance for wind turbines, determining how to use machine learning to predict consumer behaviour, etc. In solving these problems, you will have access to proprietary feature engineering AI and teams of world-leading experts in your domain.
You will be in the room, often with the senior management, working side by side with talented data scientists from leading client organizations both on technical issues and on making the change happen.
Lastly, you will mentor and guide your team colleagues and you will provide information and knowledge with them."
Paris (75),CDI,60 000 € - 70 000 € par an,Data Engineer sénior – plateforme de recrutement,Konekt,- Paris (75),"Description de l'emploi
Depuis sa création en 2008, cette startup s'est donné pour mission de réinventer et faciliter l'insertion professionnelle des jeunes talents.
Pour cela, ils ont développé un concept sans équivalent dans l’univers du recrutement en rassemblant les étudiants et jeunes diplômés, les entreprises et les écoles / universités sur une même plateforme.
Ils comptent aujourd’hui plus de 300 clients, plus de 100 écoles et universités partenaires, 400 000 inscrits et plus de 750 000 visiteurs mensuels.
Fort d""une des levées de fond les plus importantes de l'année 2019, cette startup à pour ambition de devenir le leader du recrutement des étudiants et jeunes diplômés Bac+4/5 en Europe.

Job Description
En tant que Data Engineer expérimenté, vous rejoindrez l'équipe Data qui travaille sur une nouvelle stack technique déployée sur AWS autour de Kafka, Kubernetes, Apache Spark, Airflow, Redshift, S3.
Au sein d'une équipe pluridisciplinaire composée de Data Scientists, Data Analysts et Data Engineers, vous aurez un rôle clé en garantissant un accès continu à une donnée de qualité.
Missions
Participer à l'architecture et au développement de projets data (API, ETL, …):
pour le produit: mise en production d'algorithmes de data science, alimentation du module Statistiques, etc.
pour le business: ETL de business intelligence, alimentation de notre outil de dataviz (Tableau)
Participer à l'optimisation de la stack Data et à son exploitation dans la philosophie ""You build it, you ship it, you run it"".
Participer aux revues de code et apporter son support au reste de l'équipe
En coordination avec le Lead Data Engineer et les autres membres de l'équipe, être force de proposition et contribuer à notre amélioration continue : organisation, process, qualité et maintenabilité du code, refactoring
Qualifications
Au moins 2 ans d'expérience professionnelle en développement Python
Une bonne maîtrise des problématiques de data processing (ETL, data streaming, …)
Une connaissance approfondie du langage SQL
Familier des problématiques d'infrastructure avec les plateformes telles que Docker et Kubernetes
Solide culture de la qualité de développement et des bonnes pratiques
Les plus:
Une première expérience avec AWS
Une première expérience avec Spark
Une expérience des outils de déploiement comme Terraform
Quelques connaissances de base en machine learning, pour gérer l'interface avec les data scientists
Additional Information
Tes avantages:
Labels ""Happy at Work"" et ""Great Place to Work""
Bureaux neufs en plein centre de Paris
Possibilité de participer à des conférences (orateur et auditeur)
Accès à des plateformes e-learning et e-book
Douches pour les sportifs"
Paris (75),,,Senior Data Analyst (M/F),Voodoo,- Paris (75),"Voodoo is a tech company focused on creating mobile apps for a wide audience.
Our goal is to entertain the world with snackable content and gaming apps!

Leader in the mobile gaming market, we are the n°1 company with the most monthly downloads worldwide on the App Store.

Based on our principles and values, you will have the chance to join a small, independent, and helpful team.
You will have full ownership of your role allowing you to be unique and continuously strive for excellence to deliver innovative and creative projects.

Role

We are looking for a talented data analyst interested in continuously tracking growth and optimizing performance for a set of wide-audience mobile applications.
You will contribute to building a world-class data stack from the ground up, growing our BI team and spreading a strong data culture in the organisation.
To succeed in this role, you will need a good business sense and a strong analytical mindset in order to leverage data to drive decision-making and identify growth levers.
Challenges
Collect and exploit behavioral data to provide actionable insights to the Product Team and contribute to building the best possible user experience in our apps!
Support our Marketing efforts by measuring acquisition campaigns performances and identifying optimisation levers.
Set up and run app-specific A/B tests to drive KPI improvements and help decision making.
Play a key role in developing a vision for business analytics within the organisation, challenge our current processes and recommend improved KPIs.
Work closely with data engineers and data scientists in order to set up a top data team that can bring high added value to our products and businesses for the long term.
Must have
3 years of prior experience in data and analytics
Practice of data warehousing and business intelligence platforms
Experience and taste in using dataviz techniques and tools to build clear and actionable dashboards
Full proficiency in SQL, knowledge of Python or R is a plus
Expertise in statistical theory, methods and tools
Ability to change directions quickly based on business, project, and team needs
Ability to effectively communicate complex insights and structured hypotheses to business stakeholders
Prior data analysis experience in a startup with a large user base
Prior experience of data scaling in terms of raw data to be mined and business/product expectations
Technical background with programming experience, ability to interact with technical teams"
La Défense (92),,,Consultant Expérimenté - Senior Data Analyst - H/F,EY,- La Défense (92),"Au sein d' EY, le département Forensic& Integrity Services fournit des prestations en matière d’intégrité des affaires notamment :
Dispositifs de compliance (anti-corruption, anti-fraude, anti-blanchiment, anti-trust, sanctions/OFAC, ..)
Investigations financières et comptables,
Evaluation indépendantes de préjudice financier dans le cadre de litiges entre sociétés
Analyse de données (financières et non financières, tel qu’emails, etc)
Electronic discovery
Gestion du risque cyber

Cette annonce concerne en particulier notre activité d’IT Forensic qui couvre l’activité d’audit, de conformité réglementaire et de lutte contre la fraude.
Vos missions
Intégré(e) dans notre équipe IT Forensic, vous travaillerez sur des cas concrets d’analyse de données lors d’investigation de fraude ou de conformité légale (SAPIN2, GDPR, Secret des affaires etc…)
Vous analysez aussi des volumes de données importants en travaillant sur les opérations et les résultats financiers de nos clients (Groupe internationaux, CAC 40, …).
Vous apprenez à maîtriser les différentes technologies et architectures utilisées par nos clients (ERP, bases de données, etc..) et vous adaptez, si besoin est, les moyens d’analyse des données.
Vous investiguez sur des suspicions de fraudes en développant des outils agiles: collecte de données, traitement de données et data vizualisation.
Vous intervenez dans un contexte international lors de missions avec vos collègues d’autres pays et vous êtes parfois relation directe avec nos clients étrangers.

Votre profil
Vous êtes diplômé(e) d’une école d’ingénieur ou d’une université (type Master2..) avec une majeure en système d’information ou en datascience.
Vous avez au moins 3 ans d’expérience en cabinet d’audit et de conseil en système informatique ou dans des services fonctionnels de grands groupes.
Vous maîtrisez divers des langages de programmation par ex : SQL, JAVA, PYTHON, etc.
Vous avez déjà travaillé sur des architectures Big Data.
Vous avez des connaissances avancées en mathématiques/statistiques.
Vous avez une première expérience significative dans un milieu fortement réglementé : bancaire, assurance ou médical.
Vous êtes curieux, dynamique et vous souhaitez vous investir dans une offre de services en fort développement. Votre rigueur et votre autonomie vous permettent d’intervenir pour gérer des problématiques métiers et informatiques dans des situations variées dans différents secteurs d’activités et dans des situations complexes.
Vous êtes mobile en France comme à l’étranger.
EY rassemble aujourd’hui 284 000 associés et collaborateurs à travers le monde dans plus de 150 pays. Grâce à ce réseau, dont le niveau d’intégration et l’ampleur internationale sont gages d’une même excellence partout dans le monde, EY renforce sa position de leader mondial de l’Audit, du Conseil, des Transactions, de la Fiscalité et du Droit. Nous faisons grandir les talents afin, qu’ensemble, ils accompagnent les organisations vers une croissance pérenne. Et notre engagement envers nos équipes commence avec cette promesse : quel que soit votre parcours avec nous, l’expérience EY dure toute une vie.



Dans le cadre de sa politique Diversité, EY étudie, à compétences égales, toutes candidatures dont celles de personnes en situation de handicap."
Paris (75),,,Senior Data Engineer,Kpler,- Paris (75),"Kpler is the leading provider of data intelligence for the commodity markets. Our software aggregates data from hundreds of sources including radar and satellite imagery as well as logistics, governmental and shipping databases. By connecting the dots across fragmented information landscapes, we bring our clients - mostly commodities producers, oil and gas companies, trading houses, public utilities and shipping companies, financial institutions and hedge funds - unique, real-time understanding of supply and demand in the commodity markets.

The company has offices in 6 countries and 7 locations (Paris, London, Brussels, Dubai, Singapore Houston and New York). With individuals of various backgrounds, diverse skills and international experiences, being global & inclusive is in our DNA!

What you’ll do

We are looking for an experienced Data Engineer to join our software engineering team in Paris (20 engineers). We are several roles open and are therefore looking for various level of experience!

Some of the exciting projects you’ll get to work on include:
Building a completely new feature involving cloud infrastructure with a direct impact on our customer base
Building new features for our core platform including metrics & forecasting as well as scaling and stabilizing our data pipelines

As a Senior Data Engineer, you will:
Work across the stack to deliver new features from start-to-finish
Improve performance and overcome scalability limits
Own meaningful parts of our service, have an impact, grow with the company
Actively share knowledge and document insights to support continuous team improvement and collaboration
Act as a mentor for our junior engineers; On some projects, you may also need to act as the Tech lead

Our Tech stack includes:
VueJs, D3js, RESTfulAPI and more on the frontend
Python, Go, Scala, Postgresql, ElasticSearch and more on the backend

You may be a fit if...

You have at least 4 years of experience in a similar role including significant experience in Go, Scala, Python or equivalent language
You value code simplicity, performance and detailsYou are familiar with data structures and algorithmsYou have demonstrated that you can learn and adapt quickly
You want to work in a fast, high-growth startup environmentYou are fluent in English and have experience working in an international environment Bonus point
You have been acting as a Tech lead or have some management experience

Why you REALLY need to join us...

Interesting product & challenging technical problems to solve: our market is very specialized and quite complicated! This means we build real algos and there’s some serious software engineering at work here!
Our growth is exponential: we build new features and products everyday! We frequently tackle brand new business areas which means there’s always everything to build and always an interesting problem to sink your teeth into!
We are still small enough that you can get exposure to our entire tech architecture, be close to the business and the impact you are making and build your career trying out different things!
We are at the cross-road of software engineering, energy and finance: This creates an interesting mix. We value the flexibility, collaboration and employee-centric approach that the Tech culture bring but we also value the pragmatism, hard-working and intellectual excellence expectation that often runs in the Finance and Energy worlds.
You’ll get to work in a truly global work environment: With offices in 6 countries, we have more than 20 nationalities and speak more than 15 languages.
We offer competitive compensation & benefits and are looking for feedback and opportunity to improve them everyday!"
Paris (75),CDI,,Software Data Engineer,Toucan Toco,- Paris (75),"À propos
Leur mission : faire acte de pédagogie pour transformer des données brutes complexes en des Dataviz et des Histoires interactives. Ils créent une catégorie logicielle : le Data StoryTelling.
Leurs utilisateurs : Les métiers des directions Marketing, Production, Financières, Ressources Humaines ou Commerciales de grandes organisations.
De 4 associés à 80 collaborateurs en 5 ans, autofinancé jusqu'en 2019, ils ont pu grandir grâce à la confiance de plus de 100 clients grands comptes, pour plus de 300 projets, parmi lesquels Renault, Crédit Agricole, Elior, Icade, Nexity, EDF, GRDF, BNP Paribas, Heineken, Marques Avenue, Euler Hermes, BIC, SNCF...
Les Small Apps de Toucan sont mobiles, simples à utiliser, faciles à mettre en place, intégrées dans les SI existants et au service de l'excellence opérationnelle des métiers RH, Marketing, Financière, Commerciaux et Directions Générales.
Au programme :
Une culture forte et bienveillante
Valeurs définies ensemble dont ""each one teach one"". ils sont tous tour à tour apprenant et enseignant.
Un produit logiciel excitant à créer, installer, marketer ou vendre
Une organisation en très forte croissance, où tu grandis vite!
Descriptif du poste
Et si tu étais en charge du développement des connecteurs Data vers les bases de données et les services tiers?
En tant que solution de visualisation de données il est stratégique pour nous de proposer une connectivité riche, flexible et robuste vers un maximum de systèmes.
TES MISSIONS
Tu développes en Python de nouveaux data connecteurs vers des bases de données, des services tiers exposant une API, et des systèmes de fichiers distants
Sur ces nouveaux connecteurs tu rajoutes les couches d’abstraction nécessaires qui permettront de faire un usage simple et accessible des différents objets mis à disposition
Tu évolues dans une squad chargée de construire des nouveaux produits clef en main à partir de ces systèmes tiers
Tu construis et mets à disposition des exemples de connexion aux systèmes tiers pour alimenter les démos de nos équipes commerciales
Tu** équipes et supportes l’équipe commerciale pour ses RDV d’avant-vente **sur les sujets data et connectivité
Tu collabores avec nos équipes Marketing, Sales, Product pour construire et diffuser des ressources pédagogiques de grande qualité liées aux data connecteurs (articles, tutoriels,...) qui susciteront l’envie chez nos prospects de tester notre solution
BÉNÉFICES POUR TOI
Tu participes au lancement de nouveaux produits & construis des middleware clefs pour la scalabilité de Toucan
Tu es exposé à une grande variété de technologies installées chez nos clients
Tu arrives au bon moment pour prendre place dans une organisation en forte croissance
Tu bénéficies d’une grande autonomie, tes prises d’initiatives sont encouragées
Tu évolues dans un univers B2B et révolutionnes les usages de la donnée dans des secteurs variés (industrie, luxe, automobile, télécoms, banques, retail, etc...)
CADRE
Une ambiance Bienveillante, Saine et Simple
La collaboration entre équipes n'est pas une fausse promesse mais une réalité
Télétravail occasionnel possible
Package attractif Fixe & Variable Individuel et Collectif, mutuelle Béton
Cerise sur le gâteau: Spotify Premium, Prime Vélo et on te laisse le choix de ton matos pour travailler dans les meilleures conditions !
Profil recherché
CODE
Tu as de l'expérience sur des projets de traitement de données complexes
Tu parles couramment Python; la connaissance de Flask est un grand plus
Tu as une forte appétence pour la phase de fast prototyping.** Tu as toujours quelque chose à montrer!**
Tu as la capacité de desginer des abstractions dans la phase d'architecture & scalabilité
ATTITUDE
Créatif·ive, curieux·euse et autonome, tu as de l'ambition
Tu n'attends pas qu'on te donne la solution à tes problèmes, *tu la crées *!
Tu comprends l'intérêt de la documentation
Tu aimes réfléchir en équipe aux questions d'architecture d'un produit
Tu veux progresser au contact d'individus performants"
Paris 2e (75),,,Senior Data Analyst,Adikteev,- Paris 2e (75),"Adikteev is the leading app retargeting solution that helps performance-driven marketers target and engage their app audiences. Combining science and creativity, Adikteev delivers measurable results that increase user LTV and fuel business growth.
Founded in 2012, Adikteev has worked with leading app companies like eBay, Nexon and Yelp to retain their loyal users and boost incremental revenue. A leading advertising technology company, Adikteev has been recognized as #10 among Inc Magazine’s Top 5000 fastest growing companies and #2 in global retargeting, of the AppsFlyer Performance Index. Its team of 60 people is based in Paris, NYC and San Francisco
Adikteev cherche son prochain Senior Data Analyst pour rejoindre l’équipe BI
Missions:
Réalisation et partage d’analyses et de données exploitables aidant à la prise de décision de l’ensemble des équipes
Réalisations d’analyses transversales permettant d’améliorer notre proposition de valeur, business model et nos process internes
Conduite d’analyses de performance et recommandations aux Account managers sur la mise en place des campagnes
Monitoring opérationnel des campagnes et propositions de pistes d’amélioration
Création et amélioration d’outils de reporting par la réalisation et le monitoring de dashboard sur le logiciel Tableau (principalement) pour les équipes opérationnelles (Sales, Account Managers, …). Définir et le suivi opérationnel des KPI pour tous les départements de l’entreprise ainsi que des business reviews régulière avec ces derniers
Support technique des Account Managers et des équipes Sales par le partage de l’expertise BI avec les account managers afin de les aider à gagner en efficacité et performance (exemple : mise en place de nouvelles campagnes (suivi, créations, critères de ciblage etc.) Analyse de la disponibilité de l’offre (le volume et le prix du marché).

Profil :
Vous vous justifiez de 5 ans d’expérience dans le domaine de la data et dans l’industrie de la publicité digitale
Vous répondez d’un double diplôme d’une école de commerce ET d’une école d’ingénieur avec une spécialisation dans la Data Science ou Business Analyste
Vous avez de grandes compétences d’analyse et une bonne maîtrise de Python, R, SQL, Tableau, PHP et JavaScript
Vous savez travailler en équipe et vous êtes reconnu pour votre bonne communication
Vous parlez couramment l’anglais et le français (une troisième langue serait un plus)"
Paris 8e (75),CDI,,Data Analyst / Big Data H/F,BIA Consulting,- Paris 8e (75),"Mission
Dans le cadre de la refonte du SI des risques opérationnels, une solution de centralisation des données risques dans un data lake et de reporting est en cours de construction.
Afin de renforcer l’équipe en place, nous recherchons un consultant :
– Expert en data management, data analyst ou data scientist.

Profil recherché
Le consultant devra :
– Avoir une expérience significative sur un projet de transformation vers le Big data
– Maîtriser l’univers Hadoop (HDFS, HIVE, java spark…)
– Avoir des connaissances sur Kafka
– Maîtriser Dataiku, Python, R
– Avoir une expérience de 5 ans minimum
– Avoir un anglais courant

Rémunération
Selon profil

Ville (CP)
75008

Type de contrat
CDI"
Paris 2e (75),CDI,,Data Integration Engineer - Talend F/H,YSANCE,- Paris 2e (75),"Au sein de l’équipe Data Integration et sous la responsabilité d’un(e) Tech Lead, vous concevrez et déploierez une chaîne d’intégration de données complexe, tout en tenant compte des problématiques de performance et de gestion de la qualité des données.

En tant que

Data Engineer Integration - Talend

, vous participerez à un véritable projet d’intégration dans lesquels vous effectuerez les tâches suivantes :

✔️ Participer à la définition des besoins et des livrables,

✔️ Effectuer l'analyse fonctionnelle, élaborer ou valider les solutions techniques, concevoir les modèles de données, élaborer des jeux de test,

✔️ Implémenter les modèles de données et les flux d’intégration de données en respectant les spécifications, les bonnes pratiques, les exigences de performance et de gouvernance de la qualité des données,

✔️ Rendre compte de l'avancement des travaux et du respect des délais,

✔️ Etre support au déploiement et à l'exploitation.

➡️Environnement technique : Talend, ODI, MDM, Data Quality, ESB…
Profil recherché Diplômé(e) d'un Bac+5 en informatique décisionnelle, une expérience de 2 ans minimum sur un ETL/ELT.

Doté(e) d’un très bon relationnel, d’un goût prononcé pour la technique, vous faites preuve d’une capacité d’abstraction et de prise de recul.

Vos qualités rédactionnelles, votre orientation client et votre rigueur seront les clés de votre réussite sur ce poste.

Pro-actif(ve), apte à travailler en équipe, passionné(e) de nouvelles technologies, vous souhaitez contribuer à la réalisation de projets ambitieux ? N'hésitez pas à postuler!
Entreprise YSANCE est une société spécialisée dans le traitement de la Data.

Nous couvrons l'ensemble de la chaîne de valeur Data :
✔️ Intégration de données (Talend ETL, ESB, Data Quality)

✔️ Big Data (Cloudera, Hortonworks, Snowflake, Big Query)

✔️ Cloud (Amazon, Microsoft, Google)

✔️ Data Science, prédictif, prescriptif (R, Python, DataIku)

✔️ Analytics (QlikView, QlikSense, Tableau Software, Toucan Toco)

Nous avons également développé des offres autour du Référentiel Client Unique (RCU), du périmètre e-RFM et du Customer Analytics.

Dans le cadre de notre développement et de nos projets, nous recherchons de nouveaux talents passionnés comme nous par la Data.

✔️ Notre valeur ajoutée ?

Une forte expertise technique autour de la Data qui repose sur nos équipes et qui est renforcée par de nombreux partenariats avec les éditeurs dans le domaine du Big Data & Analytics.

✔️Pourquoi nous rejoindre ?

Une forte culture Data, des clients de renoms dans des secteurs variés, une approche orientée autour du besoin client afin de répondre au plus près de leurs enjeux.

Alors si intégrer une structure Data Driven à taille humaine répond à vos attentes professionnelles, c'est avec plaisir que nous échangerons avec nos consultants opérationnels.

A bientôt,"
Paris (75),CDI,40 000 € - 50 000 € par an,Data Analyst Junior ou Senior,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data analyst sql r tableau
Taille entreprise de 500 à 5 à 000
Teletravail ponctuel
Expérience 1 à 2 ans
Expérience 3 à 5 ans
Expérience 6 à 10 ans
Statut CDI
Min 45k€
Max 60k€
L’ENTREPRISE : UN SITE D’ANNONCES À FORT TRAFIC
Métier : un site d’annonces grand public
Plusieurs centaines de collaborateurs et un esprit entrepreneur / startup intact
Croissance à deux chiffres
Budget important (plusieurs millions €)
Paris intra-muros

Notre avis chez Data Recrutement : le type de poste sur lequel on peut se projeter, au cœur de chaque prise de décision, grâce à :
Une très forte culture de l’innovation
Une réelle expertise dans les équipes Data
D’importantes ambitions et les moyens qui vont avec
Ses valeurs, son agilité et l’ambiance de l’entreprise
LA MISSION : CONTRIBUER AU SUCCESS DE L’ENTREPRISE EN APPORTANT LES INSIGHTS BUSINESS NÉCESSAIRES
Au sein de l’équipe Data composée d’une dizaine de personnes, vous avez un rôle d’ambassadeur de l’approche data-driven au sein de l’entreprise.
Vous collaborez avec chaque métier (marketing, commercial, produit, …) et leur apportez l’expertise analytique nécessaire à une bonne prise de décision.
Identifier les tendances et évolutions via une analyse continue des métriques business
Proposer des KPI et des solutions de restitution visuelle intelligible pour les différentes équipes
Réaliser des analyses ad hoc sur la segmentation clients, la personnalisation, les opportunités de vente pour les équipes métiers
Coordonner les acteurs impliqués (internes ou externes)
Etre force de proposition pour améliorer la collecte des données, la pertinence des analyses et leur impact décisionnel, opérationnel

VOTRE PROFIL : DATA ANALYST EXPÉRIMENTÉ ORIENTÉ BUSINESS
PRÉREQUIS :
+2/3 ans d’expérience à un poste similaire avec une collaboration avec des entités business : services e-commerce, marketing, connaissance client, web et/ou commerciaux.
Bac+5 en Statistiques / Data / Marketing
Excellentes capacités analytiques (préparation des données / restitution des résultats)
Forte sensibilité business, vous gardez à l’esprit la finalité de votre travail : éclairer les décisions business
Autonomie dans l’accès et la manipulation des bases de données de type SQL
Capacité à communiquer les résultats d’une analyse de manière claire et efficace
Esprit d’équipe et capacité à diriger des équipes transverses

NICE TO HAVE :
Utilisation d’outils BI et de data visualisation (Tableau, Qlickview, …)
Programmation en R, Python
Techniques de modélisation et/ou de Machine Learning
Création / coordination d’enquêtes Marketing
Stack Technique :
SQL / HiveQL / SparkSQL / R / Python
Tableau Software / BusinessObjects

Rémunération en fonction du profil : 45/60 K€ en package (40/50 K€ fixe + 3/6K€ variable semestriel + intéressement + participation)
Sélectionné par Alison Chopard
Manager, Spécialiste Sales & Data
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris 17e (75),"Temps partiel, Stage",,Data Analyst (stage),Spark,- Paris 17e (75),"Tu souhaites rejoindre une entreprise ambitieuse et évoluer dans un environnement exigeant et agile ?

️Spark en quelques mots

Notre objectif est d'accompagner la croissance de ses clients par la gestion de leur acquisition digitale payante et organique.
L’expertise et le positionnement de Spark entre conseil, technologie et agence permet d'approcher de l'acquisition digitale de manière résolument technologique et méthodique, afin de garantir une qualité de service optimale et sans faille à nos clients
Fondée en 2019 par Baptiste Lefranc-Morin et Xavier Drieux, Spark compte désormais plusieurs dizaines d'entreprises parmi ses clients (startups, pme, grands groupes) dans diverses industries (retail & home, food, services financiers, immobilier...)
En août 2019, nous étions encore une armée de 3 personnes. Nous sommes maintenant 10, et recrutons pour atteindre 150% de croissance en 2020.

Travailler chez Spark
Nous constituons une équipe de hauts potentiels avec pour objectif de les accompagner dans leur développement personnel et professionnel. En mettant en place les pratiques du lean management, nous souhaitons créer un environnement de travail stimulante et efficace, permettant à chacun d'exprimer son potentiel en toute autonomie.

Tu rejoindras un cadre dans lequel la technologie, l'algorithmie, et l'analyse de données poussée occupent une place prépondérante, avec toujours pour objectif final de maximiser la satisfaction de nos clients.

Le job
En tant que Data Analyst, tu travailleras directement avec les fondateurs en soutien des Acquisition Managers dans la réalisation d'analyse et la création d'outils permettant d'identifier des axes d'amélioration des comptes sous gestion.

Les missions
Après un premier temps de formation sur les plateformes publicitaires, tu travailleras notamment sur les projets suivants :
Mise en place de reporting clients.
Identification, analyse et interprétation des indicateurs de performances sur des datasets multidimensionels.
Communication des résultats aux Acquisition Manager.
Analyses sémantiques.
Contribution de la diffusion d'une culture de l'analyse au sein de Spark.
Tu seras amené(e) à travailler avec les technologies et outils suivants :
PostgreSQL
Python
Metabase
Excel
VBA
Dataiku
Supermetrics
Tu disposeras d'un degré d'autonomie important te permettant de proposer et implémenter des solutions innovantes aux problèmes que tu rencontreras.

Profil
Tu présentes le profil idéal si :
Expérience
Tu as déjà 1 ou 2 expériences significatives en stage.
Tu es entrain de terminer tes études dans une top école d'ingénieur ou de commerce.
Tu as déjà une première expérience significative en tant que Data Analyst ou équivalent.
Soft skills
Tu aimes être autonome dans ton travail.
Tu es ouvert d'esprit et souhaites apprendre de nouvelles méthodes de travail.
Tu as une appétence pour le travail en équipe.
Tu sais synthétiser et vulgariser des problématiques complexes.
Tu es perfectionniste et as la volonté d'aller au delà de ce qui t'es demandé.

Hard skills
Tu disposes d'une forte capacité d'analyse.
Tu as déjà travaillé avec des bases de données.
Tu as des notions de programmation : Python, VBA, JavaScript.
Tu as des notions sur le fonctionnement des principaux leviers d'acquisition payante (Google, Facebook), à défaut, tu n'as pas peur d'apprendre.

Disponibilité
Dès que possible.

Processus de recrutement
Entretien téléphonique : 15 minutes.
Cas pratique : 60 minutes.
Entretien physique sur place : 45 minutes.
Offre.
Offre acceptée .

Avantages
Indemnité de stage compétitive selon profil.
Prime à la performance.
Embauche potentielle à la clé.
Cadre de travail dynamique chez Morning Coworking.
Accès gratuit à une salle de sport.
Café, thé et snacks à volonté.
Petits déjeuners offerts.
Tickets restaurants avec Lunchr.
Remboursement du titre de transport."
Montigny-le-Bretonneux (78),CDI,,Ingénieur Big Data H/F,Orano,- Montigny-le-Bretonneux (78),"Intitulé du poste

Ingénieur Big Data H/F
Type de contrat

CDI
Vos missions

Dans le cadre de la réalisation d'offres et de projets et avec l'aide de l'équipe projet vous aurez en charge de développer des modèles statistiques et numériques complexes pour modéliser :
des profils de risques / opportunités sur les projets,
des résultats attendus lors de phases de réalisation de projets
des modèles d’élaboration d’offres
Aussi, en étroite collaboration avec les équipes Projets et/ou Direction Financière et / ou expertise technique, vous :
développerez des modèles d’analyses statistiques aidant les opérationnels pour la prise de décision et la performance des projets
collecterez des données exploitables pour modéliser les profils de risques
optimiserez des modèles mathématiques et statistiques.

Qui êtes-vous ?

Vous disposez d’un BAC + 5 Ingénieur ou de formation universitaire à dominante statistique, modélisation, analyse de données, big data, data science.
Vous êtes jeune diplômé ou avez une première expérience.
Vous êtes orienté objectif en particulier en terme de coût, délai, qualité.
Vous avez des capacité de conceptualisation de processus complexes.
Vous faites preuve de rigueur et de méthode.
Vous disposez de bonnes aptitudes pour le travail en équipe.
Votre bon niveau d’anglais serait apprécié

Rythme de travail

Horaire de jour
Métier

Excellence Opérationnelle & Performance Localisation du poste à pourvoir
Localisation du poste

Europe, France, Ile-de-France, Yvelines (78)
Ville

Montigny-le-Bretonneux

Sites d'Orano

SQY Informations complémentaires
Poste soumis à enquête administrative

OUI
Exigences réglementaires

A définir
Poste autorisant le dépistage des stupéfiants dans le cadre de la prévention des addictions

Non Critères du poste demandé
Niveau d'études min. requis

Grande Ecole, Master 2, DESS, DEA
Déplacement

A définir
Organisation

OP"
Paris (75),,,Senior Analytics Engineer - Data Team (H/F),Dailymotion,- Paris (75),"Company Description
Dailymotion’s mission is to connect publishers and advertisers with engaged viewers who turn to Dailymotion for videos that matter. Through partnerships with leading publishers and creators, including CBS, CNN, Fox Sports, GQ, Mashable, Universal Music Group, VICE and others, Dailymotion commands 3 billion monthly page views across its mobile app, desktop and connected TV experiences. Dailymotion is owned by Vivendi, one of the largest mass-media corporations in the world, and has recently launched a proprietary ad platform to gain better control of its monetization value chain and deliver a premium advertising experience.
Dailymotion is a global champion of diversity and inclusion. We pride ourselves in being an equal opportunity employer that provides an environment of mutual respect.

Job Description
Dailymotion is seeking a Senior Analytics Engineer to join the Data engineering team.
The team is in charge of building the datasets and machine learning models that power our products as well as owning the Data Platform used to run them (Google Cloud Platform, Airflow with some custom components).
As an Analytics Engineer, you bring software engineering best practices to production and maintenance of analytics code and bring an engineering mindset to discussions on how data is modeled from its source to its use in the data warehouse as business data & reporting data.
You are analytic and bring structure in your work, you champion consistency and predictability and you are self-driven and motivated. You enjoy making a data lake clean and usable. You guide others in the understanding of the data. You are naturally able to collaborate with data engineers, data analysts, software engineers as well as product & business people. You are excited at the prospect of working on tables with billions of rows per day and a datalake containing over 100.000 tables. You are an expert at SQL and can use Python to automate your analytics work.
We have important plans for improving the maturity of our analytics practice in 2020 as we build new components in our Data Platform (data catalog, internal dataset status information, data lineage,…) to be able to constantly produce data better, faster and more efficiently.
Your tasks will be to:
Own data model for data we generate ourselves in our products that need to be in the data lake (tagging plan, logs…). Test the data produced in order to ensure it is of high quality
Be part of discussions with product managers and analysts in order to guide them in their understanding of the data in the data lake, shape the product solutions and to better grasp the context of requirements coming your way
Capture business requirements for analytics and translate complex ones into technical requirements. Collaborate with data engineers to design & implement end-to-end solutions
Use SQL queries to transform data in our data lake in order to move it from raw nuggets into reliable business entities and then into reporting aggregates. Identify dependencies for these transformations. Schedule these transformations on our platform. Investigate discrepancies in data.
Documents analytics datasets and any business logic
Lead some refactoring of our data warehouse where needed, in order to make data more consistent, better documented and the pipelines more resource-efficient

Qualifications
Excellent SQL knowledge with the ability to create efficient data models (applied to data warehousing in particular)
Good business modelling skills: going from a stakeholder’s expressed requirements to an actual data model
Software engineering experience with hands-on experience automating tasks with scripting (Python would be perfect)
Ability to work with multiple parts of the business (product, ads) and multiple stakeholders (engineers, analysts, product managers…)
Fluent in English (spoken, written)

Additional Information
Technologies
Python, Airflow, SQL, Google Cloud Platform (BigQuery, Cloud Storage), Git, JSON, Bash, Druid, Tableau
Location: Paris (France)
Start Date: depending on your availabilities
Contract Type: Full-time and Permanent contract
If you're interested to learn more about dailymotion you can check out:
1./ Our NYC Built-in page https://www.builtinnyc.com/company/dailymotion
2./ Global Hackathon Video https://www.dailymotion.com/video/x70val9,
3./ Info & Videos at our HQ https://www.welcometothejungle.co/companies/dailymotion/team"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community
Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris 9e (75),,,Software Engineer,Numberly,- Paris 9e (75),"Company Description
The story began in a kitchen in the year 2000, then it's the IPO followed by acquisitions, a double-digit growth and here we are!
We are pioneers of Data Marketing, recognised experts in digital CRM and Programmatic Marketing. We handle everything from data collection to activation on all digital platforms (mobile, desktop, tablets and connected objects).
As of today, we are a strong team of 500 employees. Based in San Francisco, New York, London, Dubai, Amsterdam, Tel Aviv. Our R&D focused teams are based in Paris.
Alongside Alternext (ALMIL.PA), Numberly devotes more than 10% of its turnover to R&D, particularly in the field of machine learning, and has won the ""Innovative Company"" qualification of BPI France.
Join our success story.

Job Description
Numberly helps customers collect, analyze and leverage their data across all marketing channels.
To do this, we are more than 100 engineers (a quarter of Numberly) divided into teams with a human dimension. We accompany each person to develop a positive influence and be autonomous.
Our sustained growth pushes us to constantly challenge our technical and organizational choices.
Due to our wide range of interconnected products, our technical issues are very varied and often complex.
Our daily missions are to process thousands of queries distributed around the world per second, operate multiple petabytes databases (Big Data™), automate our entire bare-metal infrastructure, and build tomorrow's digital marketing interfaces.

Qualifications
Strong IT culture and technical curiosity
Thorough knowledge in at least one back-end and/or front-end stack
Interest in databases, the world of open-source, and/or DevOps culture
Good communicator, able to popularize work, defend ideas and listen to others
Willingness to progress and to help others progress, technically (meetups, internal training) and humanly
Good experience using Python and/or Javascript is a plus
Daily use of Linux is very preferable but not required
Professional English (our teams are international)

Additional Information
Even with 500 people we like to spend time together!
Participate to “Happy Meetings’” where we share the Group’s news with everyone from around the world
Get to know your “Jedi Master”, your ‘go to guy’ when you arrive
Go to yoga classes, cross-training, barbecues, internal parties...
Find the most incredible fancy costume for the next party"
Paris 8e (75),Stage,,Stage de fin d'études Consultant(e) Data Engineer,Sia Partners,- Paris 8e (75),"Company Description
Sia Partners réinvente le métier du conseil et apporte un regard innovant et des résultats concrets à ses clients à l'ère du digital. Avec plus de 1 650 consultants dans 16 pays, nous allons générer un chiffre d'affaires annuel de plus de 270 millions d'euros pour l'exercice en cours. Notre présence globale et notre expertise dans plus de 30 secteurs et services nous permettent d’accompagner nos clients dans le monde entier. Nous accompagnons leurs initiatives en stratégie, projets de transformation, stratégie IT et digitale et data science. En tant que pionniers du Consulting 4.0, nous développons des consulting bots et intégrons dans nos solutions la disruption créée par l'intelligence artificielle.

Job Description
Pour accompagner son développement, Sia Partners recrute un Consultant Data Engineer en Stage.
Il aura pour vocation d’assister la business unit Data Science dans la mise en place de solutions performantes d’infrastructure et d'architecture, permettant à la fois le passage à l'échelle ainsi que la réalisation de missions et travaux orientés données (projets internes et externes). Les travaux couvriront les thèmes suivants :
Services Cloud : choix d'architecture, utilisation de services de stockage & calcul avec une préférence pour les services serverless
Docker & Kubernetes : containerisation & orchestration d'applications, gestion du cluster datascience de Sia Partners
Programmation : développement d'outils exécutés côté serveur (traitement de données en masse, serveur API HTTP REST, authentification, ...)
Pipeline CI/CD : gestion de l'intégration et du déploiement continu de nos bots et de nos plateformes internes, appui au déploiement de projets datascience chez nos clients
Système UNIX : administration et décommissionnement progressif de serveurs dédiés (migration vers le cluster Kubernetes)
Infrastructures & Services adaptés au Machine Learning : veille technologique et mise en place de solutions utiles aux datascientists dans l'apprentissage et la mise à disposition de leurs modèles ML.

Qualifications
Bientôt diplômé(e) d’une grande école d’ingénieur ou d’une grande école de commerce, vous justifiez idéalement d’une expérience professionnelle réussie.
Vous êtes doté(e) d’une capacité à travailler en équipe, d’une ouverture d’esprit, d’un sens de l’analyse et vous souhaitez rejoindre un environnement professionnel motivant où vous partagerez les valeurs que sont la culture du résultat, la qualité et la satisfaction client.
Français, anglais professionnel courant indispensable, une troisième langue est appréciée.

Additional Information
Stage de fin d'études dans une logique de pré-embauche
Locaux situés en plein coeur de Paris (Georges V)
Découvrez notre showroom de bots : https://datascience.sia-partners.com/fr et une vidéo sur nos ""AI services & solutions"" : https://www.youtube.com/watch?v=hbnEoa9zHQY"
Paris (75),,,Data Engineer - Core Team,Deezer,- Paris (75),"Company Description
We are music and tech fans hailing from all over the globe, working to make Deezer the most personal music streaming service. From data scientists to tech experts, artists & labels specialists to marketers, and even in-house music editors, our team is spreading the love for music to over 180 countries. Supporting local and international artists and bringing them closer to their fans is our mission - we believe music is about diversity, multiculturalism and togetherness. Ready to join the team? We're all ears.
Job Description
How about you?
We are looking for a Data Engineer to join our Core Data Team, which is responsible for the storage, processing, and exploration of all data collected at Deezer. We work on large scale distributed systems, processing terabytes of data each day, enabling data scientists and analysts to retrieve valuable information from historical and real-time data.

What you will do:
Build and scale components to internal key activities such as log ingestion pipeline, job scheduling and ETL design/optimization
Work on the migration of the whole Deezer Data Platform to cloud solutions
Setup the best development practices for other data developers at Deezer
Communicate the work of our team inside and outside Deezer
Qualifications
What we are looking for:
3+ years experience in software engineering and the Hadoop ecosystem or with Cloud Technologies
Strong engineering skills (code design and quality, tests, reviews, logging, monitoring, continuous integration)
Proficient in at least one programming language within Python, Scala and Java.
Must be proactive, self-directed and organised
Fluent in English and French
Additional Information
Life @ Deezer HQ:

> Start-up environment with an at home vibe and outdoor space
> Kitchen stocked with free drinks and snacks daily
> Friday drinks & seasonal parties
> Gym access, plus yoga, pilates and boxing classes
> English and French language courses
> Hackathons & meetups

We are an equal opportunity employer"
Paris (75),,,Software Engineer / Data Expert,Orchestra networks,- Paris (75),"Full-time position in Paris, France

Join the core product R&D team, and get involved in the next generation of multidomain data management software. Within the team, you will develop a highly scalable and reliable data management system, written in Java on the back-end, and offering a unique set of rich features.

Your Mission

Contribute to building a highly scalable and feature-rich data management system.
Specifically provide and share your expertise in data engineering; collaborate with other teams to explore, evaluate and find the best solutions.
Participate in the continuous improvement of tests ensuring a highly reliable and scalable software.
Work with the Support team and the Professional Services to help our customers manage their most important data, as well as solve their data-related issues, such as performance, transactions, data recovery, systems operation.

About you

Data expertise - You have a solid hands-on experience in data engineering, for instance in query language, query optimization, indexing, caching, data compression, transactions, data distribution, temporality, versioning, data modeling. You have acquired this knowledge either through NoSQL technologies (Hadoop, HBase, Spark, Lucene, Solr, Elacticsearch, ...), through distributed cache solutions (Redis, Ehcache, Infinispan,...), or classic RDBMS (PostgreSQL, Oracle, SQL Server).
OO skills - You are able to build and maintain effective and robust frameworks thanks to your experience in object-oriented design, coding and testing; you are fluent in at least one OO language (Java, C++, C#, etc).
Clarity - You love clear statements, good design and clean code.
Research - You like to brainstorm, elaborate, and reflect on challenging issues, in order to find and build the best solution in the world.
Education - Master’s degree, Engineering degree, PhD, higher education or experience in engineering, computer science or another technical field.

Why join us?

You will be part of a product-focused team, where expertise, curiosity, quality and technical ability matter most.
You will be joining a globally-recognized Data Management professional.
You will enjoy our brand new office space in the center of Paris, across the beautiful Square Louis XVI.

The Company

Orchestra Networks produces one software - EBX - that allows large companies to manage, govern and share their data assets.

At the crossroads of big data, rich data modeling and model-driven engineering, EBX offers a unique set of cutting-edge features: temporality, versioning, incremental data validation, data inheritance, hierarchical views, rich relationships, and many more.

The company is headquartered in Paris and has offices in the United States, the United Kingdom, Germany and Vietnam. Our software is distributed in 25 countries and used by some of the largest organizations in the world.

We have been ranked as a Leader by Gartner in its 2017 Magic Quadrant for Master Data Management Solutions.
How to apply?
Please send us your application by email at hr@orchestranetworks.com, referencing this job position: FR - Software Engineer / Data Expert. Attach to your email your resume and cover letter. We look forward to reviewing your application."
Paris 2e (75),,,ADIKTEEV - Senior Data Engineer,Adikteev,- Paris 2e (75),"Adikteev is the leading app retargeting solution that helps performance-driven marketers target and engage their app audiences. Combining science and creativity, Adikteev delivers measurable results that increase user LTV and fuel business growth.
Founded in 2012, Adikteev has worked with leading app companies like eBay, Nexon and Yelp to retain their loyal users and boost incremental revenue. A leading advertising technology company, Adikteev has been recognized as #10 among Inc Magazine’s Top 5000 fastest growing companies and #2 in global retargeting, of the AppsFlyer Performance Index. Its team of 60 people is based in Paris, NYC and San Francisco.

Adikteev is now looking for a talented Senior Data Engineer to join the engineering team in Paris. Your role as a key member of the team will be to work hand-in-hand with Data Science and Product teams to create scalable, reliable APIs, stream processes and algorithms to serve the business.
With TBs of data per day and over 1 million incoming requests per second, real time data is not an empty promise at Adikteev. To tackle this complexity, our advertising platform relies on state of the art stream processing technology for machine learning, analytics and elasticity. The backend team is a vector of both efficiency and innovation at the company, allowing the BI and Data Science team to get fast insights. We also eat our own dog food, have a craftsman mentality and like moving fast.

Examples of ongoing interest include unified log architecture, elastic stream processes, distributed tables, distributed machine learning.

We are building a state of the art platform and are looking for talented engineers willing to get out of their comfort zone to join us.

Check out our Technical Stack.
Your Responsibilities:
Implementing APIs, stream processing jobs, monitoring and maintaining them
Identifying bottlenecks, inefficiencies and implementing innovative solutions
Adding value and unlocking leverage by proposing powerful abstractions
Porting data science algorithms and learning in a scalable way with high throughput
Building maintainable, reliable distributed APIs to deliver product value
Working iteratively, delivering fast, failing fast and learning from your mistakes

Team Culture
Demonstrations and writing are mandatory, your work has more value if you share it
Pick the right tool for the right job
Free-day: Friday afternoons are off-sprint, dedicated to learning/innovating

What we offer
You will play a critical role in determining the company's success. We want someone who brings a strong opinion to the table and gets involved with product planning.
- Personal Autonomy / Consensus Driven Culture - We foster consensus-driven rather than top-down decision making when it comes to important business decisions. From what features to build next to what furniture to buy for the office, we believe it's the fairest way of making decisions.
MacBook and all the necessary tools you need, to get the best out of your working day
Working in a great atmosphere in Paris city center.
Wage depends on your experience and track record.

Your skills
Graduated with a CS degree
3+ years experience building, deploying distributed programs on cloud platforms
Worked with several programming languages in production including functional (e.g. Scala, Clj., Py.)
Ability to work in cross-functional teams
- Experience with low latency, high throughput, high scale distributed programs, stream processing - technologies (e.g. Kafka Streams, Flink), distributed databases (e.g. Cassandra)
Enjoys experimenting new, better solutions that increase efficiency
Ability to dig in open source code and fix bugs or enhance APIs to solve blockers
Experience with distributed persistent queues (e.g. Kafka)
Experience with cloud platforms (e.g. GCP or AWS)

Bonus
Advertising technology experience
Gaming skills
Is involved in relevant user groups
Foodie"
Paris (75),"Temps plein, Freelance / Indépendant",,Développeur Java Sénior / Data engineer H/F / Freelance,Uniware,- Paris (75),"Nous recherchons un Développeur JAVA sénior (7 ans d’expérience), souhaitant s’orienter vers le DATA ENGINEERING.

Rejoignez une équipe innovante dans le secteur de la grande distribution, travaillez sur une plateforme basée sur un socle Big Data et infra multi Cloud. Le but est de développer et pérenniser la solution de centralisation des données techniques du groupe.

Obligatoire:
Java Expert
Python Maîtrise
SQL Maîtrise
Maîtrise appréciée de:
Scala / Spark
Intelligence artificielle / Machine learning
ElasticSearch
Cloud (GCP/Azure)
Pour plus d’information merci de m’envoyer votre CV à l’adresse e-mail indiquée.
Je ne souhaite PAS être contactée par des entreprises de sous traitance."
Paris 9e (75),,,Data Ingénieur H/F,MFG Labs,- Paris 9e (75),"Si vous aimez les maths et souhaitez prendre part à la révolution sur-médiatisée du machine learning, cette opportunité est pour vous.
Ce que l’on vous propose :
Dans un contexte de partage, de challenge continu et de veille où vous pourrez monter en compétences et vous épanouir vous :
Ferez partie d’une équipe pluridisciplinaire avec des talents en UX/UI, Front-end, Data science, et DevOps.
Développerez des applications de production intégrant différents outils des Mathématiques Appliqués: Machine (Deep) Learning, Recherche Opérationnelle, Statistiques.
Développerez des pipelines de traitement de données avec l’équipe de Data Science pour : ingérer, transformer et délivrer des données et modèles à nos applications.
Déploierez des applications utilisant les derniers outils mis à disposition par les différents clouds publics.
Pour vous épanouir sur ce nouveau poste nous vous accompagnerons dans votre parcours d’intégration, de formation et dans le suivi de votre carrière..
Votre profil :
Vous vous épanouissez en faisant aussi progresser les autres. Vous avez le goût pour le travail bien fait et vous souhaitez vous investir dans des projets dont vous serez fier(e). Vous avez :
Une expérience significative en production avec du Python, Scala ou Java.
Une bonne compréhension des méthodes d’analyse et de conception d’applications orientées objet.
Des connaissances sur les bonnes pratiques d’ingénierie logicielle: versioning, programmation défensive, intégration continue et tests automatisés.
De bonnes connaissances dans le développement d’API REST.
Les plus :
Connaissances en programmation fonctionnelle.
Expérience dans le développement et la maintenance de process ETL notamment avec des outils comme Airflow et Luigi.
Expérience avec des outils big data comme Apache Hadoop, Apache Spark ou Apache Beam.
Experience avec les frameworks de machine learning comme Tensorflow ou PyTorch.
Connaissances sur Kubernetes.
Connaissances sur PostgreSQL.
Vous vous reconnaissez dans cette annonce ? N’hésitez pas à nous contacter et partager votre profil, nous sommes ouverts et serons ravis d’échanger avec vous.
Déroulé des entretiens :
Entretien téléphonique
Entretien RH puis technique dans nos locaux
Entretien avec votre futur manager"
Paris (75),,,Software Engineer,Artefact,- Paris (75),"Who are we ?

Artefact is a new generation of a data service provider, specialising in data consulting and data-driven digital marketing, dedicated to transforming data into business impact across the entire value chain of organisations. We are proud to say we're enjoying skyrocketing growth.

Our broad range of data-driven solutions in data consulting and digital marketing are designed to meet our clients' specific needs, always conceived with a business-centric approach and delivered with tangible results. Our data-driven services are built upon the deep AI expertise we've acquired with our 1000+ client base around the globe.

We have 1000 employees across 20 offices who are focused on accelerating digital transformation. Thanks to a unique mix of company assets: State of the art data technologies, lean AI agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client.

To support and develop its growth, Artefact is looking for the next talents of the data division to join the engineering team. Organized in feature team, you will work in project mode (ou pizza team) to advise your clients on their IA problematics, machine learning and Big Data. The projects you will work on can go from the migration of infrastructure to the Cloud (Deezer) to the construction of a predictive model of the water rises (Greenpeace).

Your responsibilities :
Innovate . You will work with your team which is made up of consultants, data scientists, creatives and engineers to identify your clients needs and define innovative solutions.

Build. You'll take ownership of the solution from start to end. You manage both conception and implementation, while also optimising the performance and scalability.

Train. You will work in a collaborative team which champions knowledge sharing. You will coach others, keep abreast of industry news/updates and get involved into training sessions with our business partners and suppliers, such as Google & Amazon.

Communication. You will regularly attend events and conferences to share your knowledge, learnings and success, with the capability of presenting and communicating

Your mindset

Curious, you are always seeking innovative solutions for your clients. You are involved in all the value chain which can be, front-end, back-end, big data infrastructure, ML model …
Sharing of knowledge is essential for you and you actively participate in the diffusion of information within Artefact (seminaries, formations, certifications)
Entrepreneurial, you bring solutions, new ideas, within your team at Artefact

Profile :
You act on all the value chain of projects (infrastructures and platforms creation, data collection, application of machine learning models, APIs REST creations, of front-ends, of tests, continuous deployments)
Your studies involved software engineering, and you have experience in DevOps
You have a good knowledge of python, you are really interested in the command line *nix, you are familiar or have already used cloud technologies such as GCP or AWS, you have already used big data technologies like Flink, Spark, or Beam and Docker (K8S is an asset)
You can popularize technical terms or solutions to more business oriented profiles, you can work in a team with very diversified profiles
You know how to prioritize your tasks, respect deadlines, prevent in case of problems
You have a good level of english

Why join us :
Innovative projects and technologies, exciting
Really competent team, co-progression guaranteed
Strong ambition for the data department, full of progression opportunities (technical, management)
Recent Stack : Python, Spark, React/Redux, Google Cloud Platform (BQ, Dataflow, Compute Engine…), Nifi, HDFS, Ansible, Docker, Redis, ...

Come join us #FR !

Talents-fr@artefact.com"
La Défense (92),CDI,,URBANISTE DES SI / ARCHITECTE D'ENTREPRISE DATA H/F,Groupama Supports et Services,- La Défense (92),"En tant qu'Urbaniste des SI chez Groupama Supports et Services, vous aurez en charge :
d'identifier et de partager les contraintes et exigences métiers et informatiques, présentes et futures qui portent sur le système d'information
de développer une vision sur le devenir du système d'information Groupama, de la partager et d'en assurer l'adoption par l'ensemble des fonctions (informatiques et métiers) concernées,
de définir et piloter les trajectoires d'évolution du SI en miroir de la stratégie Groupama
de définir les règles d'urbanisation et de veiller à leur application
d'évaluer la pertinence et la cohérence des projets par rapport à l'architecture cible et aux systèmes existants
de participer à l'amélioration ou à la création de nouvelles applications ou services et de s'assurer de l'alignement entre les besoins et les solutions proposées
de participer à la gouvernance du système d'information et assurer l'alignement des évolutions avec le schéma d'architecture cible
de rechercher des solutions innovantes pour la création de nouvelles solutions
d'animer les réflexions d'évolution des systèmes d'information avec les clients et les donneurs d'ordre

En tant qu'architecte DATA, vous aurez en charge, en coordination avec l'architecte technique sur ce domaine :
d'identifier les impacts des stratégies Métiers sur l'architecture donnée
de définir les standards relatifs à la collecte, le traitement et le stockage des données pour optimiser leur utilisation
de garantir la cohérence de l'architecture donnée
d'accompagner les projets dans la définition des besoins métier sur la description et l'usage des données (concepts métiers, exigences métier, usages de la donnée), en prenant en compte les contraintes de sécurité
d'assurer l'adéquation de la solution au cas d'usage de la donnée
d'assurer une veille sur les tendances IT et métier, de promouvoir les innovations technologiques permettant d'élargir les cas d'usage et le traitement de la donnée
Profil
Vous avez 10 ans d'expérience minimum et êtes titulaire d'un Bac +5, issu(e) d'une école d'Ingénieur (informatique, télécoms, généraliste).
Vous êtes Consultant(e) dans un Cabinet de conseil en SI ou bien Architecte dans une SSII ou dans une Grande Entreprise, et vous souhaitez dynamiser votre carrière et prendre des responsabilités opérationnelles.
Bonne connaissance des sujets de gouvernance et de qualité des données
Modélisation des organisations et des processus
Pratique de la mise en œuvre de référentiels méthodologiques
Connaissance des méthodologies de cartographie, de framework d'architecture,
Connaissances avancées autour des problématiques de référentiels, des outils de BI et de la gestion de la data de manière générale
Bonne connaissance des technologies Data (principales solutions Open Source Big Data, principales offres Cloud, solutions BI, etc.)
Maîtrise des concepts de gestion de la donnée et des problématiques de sécurité associées
Bonne compréhension des sujets de data science

Une connaissance des métiers de l'assurance, des architectures de type Datahub, micro service, API management ou événementiel et des techniques sur Python, Hadoop, Kafka ou Qlik sont un plus.

Sens de la confidentialité et éthique
Rigueur, capacité d'anticipation et sens de la méthode
Qualités relationnelles et diplomatie dans un écosystème riche et divers (la direction informatique, les directeurs métiers, la maîtrise d'ouvrage, la maîtrise d'œuvre et la sécurité (RSSI) ...) pour assurer l'adéquation entre les aspects purement systèmes d'information et les aspects métiers, organisationnels financiers et humains, etc.
Curiosité, ouverture d'esprit, adaptabilité et capacité à comprendre le métier, les enjeux et la problématique de nos clients et donneurs d'ordre
Engagement, conviction et force de proposition
Capacité à communiquer, tant oralement que par écrit, de manière structurée, compréhensible par différents types de publics, pédagogie, capacité à convaincre.
Appétit pour le travail en équipe, le fonctionnement collectif, en organisation matricielle
Bonne compréhension des tendances actuelles de l'informatique, tant sur les aspects techniques que sur l'évolution des usages liée à la transformation digitale.
Profil principal
Systèmes d'information - Architecture technique & fonctionnelle
Type de contrat
CDI
Statut conventionnel appliqué/ Classe
CCN Stés Assurance 27 mai 1992/Classe 6
Catégorie emploi
Cadre
Structure de l'organisation
DUTP
Localisation du poste
Localisation du poste à pourvoir
France
Ville
Paris La Défense ou Lyon (Ecully)
Géolocalisation par zone
Non
Critères candidat
Niveau d'études min. requis
Bac+5 et plus
Niveau d'expérience min. requis
+ de 10 ans"
Paris,45 000 € - 55 000 € par an,,Développeur sénior Python | Secteur de l’énergie / big data,In-Team,- Paris,"Vous recherchez un nouveau challenge Python avec de fortes problématiques data science ?
Alors, rejoignez cette société spécialiste de la gestion énergétique au sein de parcs immobiliers !
Existant depuis plus 3 ans, cette entreprise développe une solution Saas qui, à travers la collecte de grande quantité de données, propose des solutions innovantes et impactantes d’optimisation énergétique. Vous l’aurez compris, au cœur de ce projet : la data.
Leurs clients ? JCdecaux, Picard, les plus grands groupes bancaires… leur font déjà confiance
Venant de lever 2.5 millions d’euro, il recherche pour renforcer leur équipe technique de 5 personnes, un développeur Python sénior, afin de travailler sur le développement back-end de leur solution, mais également sur la manipulation de grandes quantités de données.
La stack technique ? Python (Flask) ; JS (VueJS) ; MongoDB ;
Vous êtes curieux d’en savoir plus ?

Votre mission :
Au sein de cette entreprise d’une trentaine de personnes, vos missions seront :
Développement en Python – Flask et JS – VueJS
Créer des architectures logicielles
Travailler avec les SGBD non relationnel
Travailler sur la manipulation de grandes quantités de data
Monter en compétence sur du management (sélection, formation et encadrement des profils juniors)
Veille technique
Votre profil :
Bac +5 école d’ingénieur
2-5 ans d’expérience en développement Python / JS
Vous êtes exigeant sur la qualité de votre code et l’architecture logiciel car c’est quelque chose que vous jugez important
Opportunité :
Travailler sur un poste hybride avec des problématiques de développement et de data science
Être en contact direct avec le top management de l’entreprise
S’épanouir au sein d’une structure pérenne avec un esprit startup, reconnue pour son innovation
Salaire et avantages :
45-55k€
Contrat en CDI
Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !
Si vous souhaitez avoir d’autres informations sur cette opportunité je vous invite à me contacter également."
La Défense (92),"Temps plein, Freelance / Indépendant",,Architecte DATA / cloud AZURE H/F / Freelance,INFOGENE,- La Défense (92),"Infogene c’est avant tout une ESN Engagée, Responsable et Conquérante
Engagée par son adhésion au Pacte mondiale de l’ONU ; certifié GOLD par Ecovadis pour son engagement RSE (Environnement, corruption, droit de l’homme et normes internationales du travail) ;
Responsable du bien être de ses collaborateurs ; labélisé Happy Index at Work (CE, intéressement, rencontres sportives )
Conquérante par sa croissance, 6 ans d’existence, 450 collaborateurs, 2 centres de services et une agence digitale, 37M de CA en 2018, 46 M de CA en 2019 (prévisionnel)
5 pôles d’expertise : Digital, infrastructure, SAP, BI/Big Data et MOA ingénierie.
Venez nous rejoindre www.infogene.fr

Nous recherchons pour l’un de nos clients un Architecte DATA / cloud AZURE H/F

Les KEY skills seraient autour de :
Briques d’Ingestion des données dans les clouds provider surtout sur Azure (Data Factory)
Indexation des données : Elastic search .
Connaissance sur les Clouds providers : Sur les éléments natifs managés

Intégration Hybride :
o Solution de Data Virtualization
o API Management
o Autres
Management des méta données (Data catalogue)

Stockage DataLake :
o Gouvernance Globale / par Data set
Connaissance autour du Machine Learning et IA/Data science
Systèmes d’archivages
Connaissance sur les réglementations Impactant le milieu de la Pharmacie : Normes de stockage (hds) .."
Paris (75),CDI,,Ingénieur développeur(euse) DATA/SPLUNK F/H,Orange,- Paris (75),"Intégré(e) au département Data, vous interviendrez en tant qu'ingénieur en développement DATA pour un poste en CDI
Missions :
Le département a pour objectif de délivrer des prestations de qualité en analyse statistiques, dataviz et machine learning, avec une forte compréhension des enjeux fonctionnels des clients dans le cadre de projets d'intelligence opérationnelle :
Etudier et analyser les données collectées afin de répondre aux demandes marketing et/ou équipes techniques.
Accompagner le client dans des ateliers projets fonctionnels et techniques
Concevoir et mettre en oeuvre des tableaux de bords et rapports statistiques en illustrant les résultats par de la DataViz
about you
De formation BAC+5 minimum, vous justifiez d'au moins une première expérience dans le domaine.
Compétences techniques et qualités requises:
Compétence en développements : Python ou Java et Javascript
Connaissance en requêtage SQL, noSQL
Bonne maîtrise écrite et orale de l'anglais
Bonnes compétences rédactionnelles.
Savoir analyser, modéliser et présenter les données
Des formations seront proposées pour monter en compétence sur la solution Splunk.
Intéressé(e) par la Dataviz, le développement ou la manipulation de données, curieux(se), dynamique et force de proposition, vous pourrez vous investir sur des activités au coeur des nouvelles technologies au sein de nos équipes projet BI et Big Data.
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Paris (75),Stage,,Stage Machine Learning,La Javaness,- Paris (75),"Tu te sens prêt à plonger au cœur de la révolution IA ?!
En 5 ans, La Javaness s’est imposée comme leader français de l’IA pour les entreprises (BtoB). Sans tambour ni trompettes (mais avec beaucoup de R&D !), nous avons concentré nos forces à déployer l'Intelligence Artificielle à grande échelle au sein d’organisations publiques et privées en France et en Europe.
Mais pas n’importe comment ! Nous croyons en une IA éthique, responsable, au service des salariés et des citoyens européens. Nous militons pour la souveraineté des données et l’indépendance des entreprises européennes.
Pragmatiques et rationnels, nous déployons quotidiennement nos solutions « prêt-IA-porter » à un niveau industriel. Nous faisons aussi de la haute couture en développant des solutions IA sur-mesure pour répondre aux défis de certains de nos clients. Notre R&D bout sans relâche pour inventer, tester et déployer l'IA de demain.
En d'autres termes, dans la boutique de La Javaness, tu trouveras : Conseil data & IA, accélération par le design, développement front & back de pointe, défis business dans un joyeux mix exigeant d'intelligences. Avec ce super cocktail d'expertises et de créativité, nous intervenons sur tous les secteurs d'activité pour cracker les problèmes de nos clients !
Nous sommes le partenaire Data et IA de référence pour l'AMF, LCL, la Banque de France ou encore Pôle Emploi. Nous accélérons également des projets d'innovation digitale pour la Société Générale, Facebook, Enedis, Saint Gobain, Louvre Hôtels Group...
Comment ça marche au quotidien ?
4 labs : Design, IT, Data, Delivery & Business, travaillent ensemble sur tous les projets afin de concevoir et déployer des solutions complètes et innovantes répondant aux besoins de nos clients.
Fort d’un collectif unique, la Javaness investit sans cesse dans des talents pointus, atypiques et complémentaires qui lui confèrent une force de frappe hors norme. Et parce qu'on est pas que des machines, la ""Fullstackerie"" s'exprime aussi joyeusement lors de nos fameux apéros au débotté et de notre séminaire annuel.
Si ça te semble une aventure à ta mesure, c’est par ici pour nous rejoindre !

Descriptif du poste
Intégré(e) à notre Lab Data composé d’une dizaine d’experts en Machine Learning, tes activités s’orienteront autour de plusieurs grands axes :
Réaliser des missions avec de réelles données clients, où tu pourras très vite gagner en responsabilité
Effectuer un travail de R&D autour de l’état de l’art technologique et scientifique des méthodes de machine learning, dans le but de perfectionner les outils utilisés en interne
Participer aux data meeting hebdomadaires, au cours desquels chacun partage ses dernières avancées et découvertes
Collaborer avec les autres métiers (IT, Design, Business…), pour imaginer des solutions complètes et innovantes répondant aux besoins clients
Travailler au plus près des clients, en les conseillant directement et en concevant le produit qui saura répondre à leurs attentes
Début du stage : à partir d'octobre 2019

Requirements

Venant des meilleures formations en Data Science, Computer Science ou Mathématiques, tu justifies d’une grande connaissance des algorithmes de Machine Learning. Tu dois également être curieux et effectuer une veille autour des dernières avancées technologiques sur le sujet. Projets personnels et participations à des compétitions Kaggle sauront attester de cet intérêt.
De solides connaissances en Python et une bonne maîtrise de ses librairies de Machine Learning (pandas, scikit-learn, etc.) sont obligatoires. La maîtrise d’un ou plusieurs frameworks de Deep Learning (Keras, Pytorch…) est un réel plus.

Compétences obligatoires:
Python (pandas, sklearn…)
Machine Learning / Deep Learning


Compétences appréciées:
Ecosystème Big Data (Hadoop, Spark)
Programmation logiciel et web
Scala, C++, Java, etc


Format: Stage de 4 à 6 mois de préférence en fin d’études
Benefits
Projet ambitieux
Equipe smart & fun
Technos et projets variés
Offre d'emploi à la clé
Paris centre / Silicon Sentier"
Boulogne-Billancourt (92),,,Data Scientist Expérimenté,Mirum South Europe,- Boulogne-Billancourt (92),"Notre équipe Data a un rôle essentiel pour accompagner nos clients sur des projets digitaux et data d’envergure.
Sous la responsabilité de la Directrice Data et en binôme avec une data scientist confirmée, vous travaillez sur des projets innovants allant de la modélisation au Big Data en passant par le text mining ou l’analyse de parcours client.

Vos missions quotidiennes sont les suivantes :
Soutien aux juniors dans l’application de leurs missions
Le suivi opérationnel des projets data :
Connaissance client et data science : préparation des données, constructions de scores et de segmentations, réalisation d’études et analyses des différents résultats.
Mesure de l’efficacité des différentes actions marketing et digitales mises en place.
Conseil et restitution des projets en direct aux clients : vous ne travaillez pas dans l’ombre chez nous mais vous êtes LE référent qui va aider nos clients à réaliser leurs projets data. Vous allez présenter vos idées vous-même chez le client et vous êtes celui/celle qui l’aidera dans le déploiement opérationnel.
Expérimentation de l’utilisation de nouvelles données (non structurées, sociales, log webs…).
Rédaction des premiers niveaux de recommandations opérationnelles suite aux différentes études effectuées.
Participation aux pitchs de l’agence : vous allez aider votre équipe à décrocher des budgets data innovants !
Requirements:
A l’aise avec les nouvelles technologies, vous justifiez d'une expérience d'au moins 5 ans sur des projets liés à l’exploitation de la donnée.
Vous maîtrisez les principales techniques datamining & machine learning.
Vous connaissez à minima un ou plusieurs outils/langages statistiques : SAS, SPSS, SAP Predictive analytics, R, Python.
Vous êtes curieux, proactif et apporteur de solutions face aux challenges qui se présentent à vous.
Force de proposition, vous faites évoluer vos clients en leur apportant votre expertise et votre connaissance des innovations data.
Vous recherchez une équipe à taille humaine et vous vous épanouissez dans une ambiance start-up.

Benefits:
Contrat : CDI
Démarrage : ASAP
Rémunération : selon profil
Avantages : mutuelle, carte restaurant, RTT..."
Paris (75),CDI,,Consultant(e) Data Marketing,SOCIO DATA MANAGEMENT,- Paris (75),"Contexte
Depuis plus de 40 ans, Socio Data Management est leader dans le traitement et l’analyse de données, ainsi que dans les solutions applicatives pour en optimiser l’exploitation et la restitution.
Nos consultants experts accompagnent nos clients durant toutes les étapes de leurs projets Data : depuis le recueil et l’intégration des données jusqu’à leur mise à disposition sur des plateformes en ligne, nous mettons notre savoir-faire au service de nos clients sur toute la chaîne de valeur de la Data.
Spécialistes des modélisations intelligentes, nous les aidons à exploiter efficacement leurs données pour prendre des décisions optimisées, tant sur le plan opérationnel que stratégique.
Missions
Afin de renforcer nos équipes, nous recherchons un(e) Consultant(e) Data Marketing, pour intervenir chez l’un de nos clients grands comptes et accompagner sa transformation customer-centric en mettant à profit les technologies marketing pour améliorer la connaissance client et l’expérience client.
Vos principales missions :
Data Activation : AB Tests, Personnalisation, Marketing Automation, Mobile Engagement, Scoring prospects et clients ;
Référentiel client et marketing (RCU, CDP, DMP) : AMOA, de l’expression du besoin à l’exploitation ;
CRM, Data Analysis et Marketing Automation : Analyse de parcours client, élaboration de stratégie relationnelle, analyses des campagnes d’acquisition et du mix-media, mise en œuvre de programmes de marketing automation ;
Webanalyse : Élaboration de dispositifs de pilotage de la performance digitale ;
Analytics et performance web : Optimisation de l’acquisition et de la conversion.
Profil recherché
Vous êtes diplômé(e) d’un Bac + 5, avec une majeure en Marketing Stratégique ou Digital et vous justifiez idéalement d’une première expérience dans le Marketing, la Segmentation client/marché ou le Datamining.
Vous maîtrisez les problématiques et une ou plusieurs solutions CRM (Dynamics, Salesforce, Oracle Siebel…). De solides connaissances en bases de données (SQL…) et en outils de segmentation (ex : R, Python, SAS…) sont indispensables.
Doté d’une grande qualité d’écoute et de synthèse, vous aimez travailler en équipe. Vous êtes curieux de nature et passionné(e) par la Data, avec le souhait de mettre vos compétences au service des clients.
Nous rejoindre
Rejoindre l’équipe Socio Data Management c’est :
Un engagement de proximité : entreprise à taille humaine, nous restons proches de nos collaborateurs afin de les accompagner de façon pertinente dans leurs carrières.
Une garantie de diversité : nous intervenons sur des projets divers, enrichissants, innovants et à forte valeur ajoutée pour nos clients dans différents secteurs d’activités.
Une promesse d’innovation : en tant qu’expert Data, nous faisons partie du Data Lab, un véritable pôle R&D qui a pour vocation de faire émerger des initiatives innovantes.
Un gage d’intégration : faisant partie intégrante d’un groupe, nos collaborateurs ont la possibilité de créer et de tisser du lien, tout en développant leurs connaissances sur des sujets transverses (cybersécurité, gestion des risques, IT…).
Bénéficier de nos avantages : accès à notre plateforme CE, attribution de chèques-cadeaux, tickets-restaurants, prime vacances…"
Paris 8e (75),"Temps plein, Freelance / Indépendant",,Data Engineer / Freelance,Lawrence Harvey,- Paris 8e (75),"Freelance / Mission / Data Engineer / Confirmé / Pyspark/ Python / SQL/ GCP/Région Parisienne/ IDF /Paris

Lawrence Harvey recherche pour le compte de son client un Data Engineer. Le rôle sera basé en région parisienne.

Freelance - Pas de sous-traitance, merci.
Démarrage : ASAP
Contrat : 6 mois
Localisation : Région Parisienne
TJM négociable selon expérience

Activités principales :
Au sein d’une équipe de data engineer, vous vous occuperez de la gestion du datalake et accompagnerez les data scientists dans la mise en production de leurs algorithmes. Le client se concentre actuellement sur un cluster Hadoop/MapR d’une trentaine de machines avec plus de 300To de données. La migration de l’actuelle infrastructure vers GCP a commencé depuis quelques mois. Vous renforcerez ainsi l’équipe sur ce projet.

Compétences Requises :
Forte expérience en modélisation mathématique, analyse statistique et/ou machine learning
2 ans expérience minimum sur Python (natif, PySpark)
2 ans minimum d’expériences sur PySpark, SQL et de manière plus générale en algorithmie.
Connaissances de GCP/ Azure ou AWS serait un plus
Si cette superbe opportunité vous intéresse, merci de postuler vite sur l’annonce ou de m’envoyer votre CV à (Olivia Rouhet) et je vous recontacterai le plus rapidement possible si votre profil matche avec la mission.

N’hésitez pas à partager avec votre réseau si vous connaissez des personnes qui pourraient être intéressées

Lawrence Harvey is acting as an Employment Business in regards to this position. Visit our website www.lawrenceharvey.com and follow us on Twitter for all live vacancies @lawharveyjobs"
Paris (75),"Temps plein, Freelance / Indépendant",,Devéloppeur BIG DATA / SCALA / Freelance,Templeton and Partners Limited,- Paris (75),"Templeton & Partners est à la recherche d’un Développeur Big Data / Scala pour notre client dans le secteur de la Finance sur Paris .

Notre client recherche un développeur Scala :
Intégrer un projet dont l’objectif est le développement
L’étude et la maintenance d’un Datalake
Développement de nouveaux flux d’intégration et la mise en place de nouveaux outils de reporting basés sur le datalake.
Ce nouveau Datalake mettra l’accent sur les performances et la flexibilité avec une meilleure capacité à intégrer les transactions provenant d’autres plateformes rapidement et efficacement.

Compétences techniques:
Anglais Courant
Maitrise de Scala avec Spark Streaming
Pratique des tests unitaires, intégration continue (jenkins/gitci), TDD & BDD
Méthodologies Agile (Scrum)
Java J2EE (version 8 si possible)
Des connaissance de PERL et/ou Python
Expérience autour d’Hadoop / HDFS, idéalement sur la plateforme MAPR
Connaissance de Base de Données relationnelles (SQL), modélisation & optimisation.

Outils : contrôle de version (git), tickets (JIRA), Wiki (Confluence), etc.
Durée de la mission : 6 mois renouvelable
Date de démarrage : ASAP
Lieu : Paris"
Villeneuve-Saint-Georges (94),CDI,,Ingénieur(e) développeur DATA F/H,Orange,- Villeneuve-Saint-Georges (94),"Vous êtes intéressé(e) par le développement autour de la BI, du Big Data et de la manipulation des données ? Vous avez envie d'approfondir vos connaissances dans ce domaine ?
Vous aimeriez intégrer une équipe jeune, dynamique, fun & passionnée ?
Que vous soyez débutant ou déjà expérimenté, ne cherchez plus et rejoignez notre équipe Lilloise !
Dans le cadre de nos projets, vous serez amenés à :
Etudier et analyser les données collectées afin de répondre aux demandes de nos clients (équipes métiers, techniques & marketing)
Accompagner nos clients dans des ateliers fonctionnels et techniques
Concevoir et mettre en oeuvre des tableaux de bords et rapports statistiques en illustrant les résultats par de la DataViz dans l'outil Splunk
De notre côté, nous vous apportons :
L'intégration dans notre équipe data de Lille actuellement en pleine croissance
La collaboration avec des experts du domaine
Des formations & certifications avec notre partenaire Splunk
Un plan de développement personnel
Un cadre de travail de qualité
En fonction de votre profil et de votre expérience, nous vous accompagnerons dans votre montée en compétences au travers de différentes formations et vous serez amenés à participer à des projets d'envergure pour nos clients grands-comptes.
about you
Vous :
Avez une première expérience dans la Data et/ou vous êtes très motivés à l'idée d'évoluer dans ce domaine
Avez une formation d'ingénieur ou équivalent
Disposez de compétences en développement Python ou Java et HTML/CSS/ Javascript
Avez des connaissances en requêtage SQL et noSQL
Maîtrisez l'anglais à l'écrit comme à l'oral
Avez de bonnes compétences rédactionnelles
Êtes autonome, curieux, dynamique et savez être force de proposition
Êtes capable, idéalement, d'analyser, de modéliser et de restituer des données
Selon votre expérience, des formations vous seront proposées pour monter en compétence sur la solution Splunk.
Entité
Orange Applications for Business - DATA
Partenaire de la transformation digitale des entreprises, Orange Applications for Business est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs, et l'intégration de systèmes.
Nos équipes accompagnent au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience client, de la Data/analytics et des objets connectés, et dans les secteurs notamment des Smart Cities et de l'e-santé.
En 2019, Orange est l'un des dix groupes au monde à obtenir la certification « Top Employer Global 2019 ».
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Paris (75),"Temps plein, Apprentissage, Contrat pro",,Alternance – Client Intelligence & Data - CHANEL EUROPE,Chanel,- Paris (75),"Alternance – Client Intelligence & Data - CHANEL EUROPE
L’apprenti Client Intelligence & Data a pour mission d’aider l’équipe à apporter un support Connaissance Client, à l’ensemble des équipes opérationnelles et marchés Chanel Europe 3 divisions.
Il/elle sera intégré(e) à l’équipe Digital Europe, dans un environnement innovant et challenging, au sein d’un leader du Luxe, intervenant sur les trois univers : Parfums & Beauté, Mode, Horlogerie & Joaillerie.
Il/elle travaillera sur l’accompagnement des équipes dans leurs problématiques et l’adoption des nouveaux usages data driven, la mise en place et le paramétrage d’outils de diffusion de reportings (dashboards dynamiques), sur l’assistance à fournir des données ad hoc (extracts, analyses SPSS et Adobe à la demande), et aidera à la vérification, à l’automatisation partielle et à la diffusion de rapports d’analyses aux marchés.
Missions :
Analyses clients & reportings : support de l’équipe sur les reportings existants, de la collecte des données à la diffusion aux équipes métiers
Ad hoc analysis : production d’analyses clients ad hoc sur des enjeux particuliers des membres de l’équipe Digital Europe et des équipes marchés - paramétrage de flux de données & exports depuis SPSS et Adobe, analyse des données et production de synthèses
Data visualization : collecte des besoins, définition des KPIs, paramétrage de dahsboards dynamiques (Power BI, Tableau, Google Data Studio, Domo, Reeport…), coordination avec les différents prestataires, vérification des données et diffusion des dashboards
Profil :
De formation Business/Data (école de commerce, d’ingénieur, parcours universitaire…), vous bénéficiez de premières expériences dans le domaine de la data pour des grandes entreprises (retail apprécié), où vous avez utilisé différents outils de requêtage et de reporting (interfaces web app, automatisation de rapports, accès à des bases de données SQL…). Vous maîtrisez le langage SQL, et autres outils de programmation (VBA, Python, SPSS…). Vous avez un intérêt pour l’univers du luxe, êtes autonome, analytique, rigoureux, et force de proposition pour apporter des solutions aux besoins métiers. Vous parlez anglais couramment."
Paris (75),CDI,,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Data Scientist (H/F) pour renforcer ses équipes.
Dirigée par le Chief Data Officer et rattachée au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques met en œuvre la stratégie DATA avec comme principales préoccupations
D’améliorer la gouvernance des données ;
De contribuer à la data réputation de la Banque de France ;
De tirer le meilleur parti des masses et de la diversité des données disponibles au sein de la banque Centrale,
De développer des projets d’intérêt commun
De développer une culture de la donnée au sein des unités métier

Présentation du Service
Au sein de la DDSA, le SIAD (Service Industrialisation et Algorithmique des Données) a pour missions de construire et entretenir les socles techniques BIG DATA, de réaliser des prototypes de solutions basées sur les approches Data Science et IA et de mettre à disposition des solutions business intelligence pour les équipes métier.

Descriptif de mission
Le pôle « Data Science et IA » cherche à renforcer ses capacités en recrutant un(e) Data Scientist.
Les missions de ce pôle, partie intégrante du domaine « conseil et expertise », sont les suivantes :
Cartographier de façon continue, en relation avec les équipes d’innovation et les urbanistes, les processus métier pour lesquels une approche Data Science pourrait procurer un avantage compétitif ou préserver un territoire acquis
Épauler les métiers dans la définition et la stabilisation de leurs besoins
Mettre en place de façon continue les Proofs of Concept (POC) fonctionnels et techniques issus des analyses d’opportunité
Benchmarker de façon régulière les outils du Big Data
Préparer l’industrialisation des POC identifiés comme pertinents
Accompagner la montée en compétence des équipes métier et des équipes techniques sur le Big Data
Sous l’autorité du « Lead Data Scientist », vous serez en charge plus particulièrement :
De la prise en charge des besoins métier et de leur analyse ;
De l’identification des solutions potentielles et du choix de la solution la plus adéquate au regard des besoins et contraintes tant métier que techniques ;
De la conception et de la mise en œuvre de la solution (POC, prototype, MVP),
De l’accompagnement et du soutien aux équipes projets en charge de l’industrialisation des solutions.

Profil recherché
De formation supérieure en informatique ou métiers de la donnée (Ingénieur ou équivalent), vous avez minimum 2 ans d’expérience dans la mise en œuvre de solutions mobilisant des connaissances statistiques et/ou mathématiques avancées, y compris en contexte d’apprentissage/alternance dans des contextes de travail variés (recherche, entreprises commerciales, sphère publique ) constituera un avantage clé.
Vous disposez d’une forte appétence pour la concrétisation de solution dans un environnement Bigdata.Par ailleurs, vous avez la maîtrise :Des sous-jacents mathématiques aux approches Bigdata / Data Science (mathématiques et statistiques, Machine Learning, réseaux de neurones ) et des bibliothèques de Machine Learning (Scikit Learn, PyTorch, )
Du développement en Python
Seraient en outre appréciées, dans l’un ou plusieurs des domaines suivants :
Une très bonne connaissance en développement sur la stack Hadoop (Oozie, Sqoop, Hive, Hbase, ), sur les technologies Spark (MLlib, SQL, GraphX et Streaming), en langages PySpark, Java et R (SparkR).
Une très bonne maitrise des outils de Search (ElasticSearch) et de streaming (Kafka)
Une bonne connaissance des bases de données NoSQL telles que Mongodb et Neo4J
Une bonne capacité à intégrer des sources de données multiples, internes / externes, structurées / non structurées et des interconnexions entre les SGBD et Hadoop
Une bonne capacité à restituer les résultats visuellement à l’aide de Kibana ou PowerBI
Une facilité à développer dans un environnement innovant en méthodologie Devops et Scrum
Rigoureux et apte à anticiper, vous avez le sens du résultat au service du client et êtes doté d’excellentes capacités de communication pour faciliter le travail « en réseau » :
Force de proposition et aisance de communication pour démontrer la valeur ajoutée des solutions Big Data et Machine Learning.
Excellente méthodologie de travail et de gestion de projet, vous travaillerez en mode agile.
Très bon relationnel, capacité à s'adapter, esprit d’équipe, ouverture d’esprit et curiosité naturelle, vous suivez l’évolution des technologies et nouveautés relatives au Big Data, Datascience et IA
Une bonne pratique de l’anglais est nécessaire.
Ce poste, en contrat à durée indéterminée, est basé à Paris (1er), avec des déplacements ponctuels dans les sites banque de France à Paris et en régions.
La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes."
Paris 10e (75),,,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community

Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Levallois-Perret (92),"Temps plein, CDI",,FULL REMOTE Senior Data Scientist H/F - CDI,Jellysmack,- Levallois-Perret (92),"Nous continuons de recruter et avons adapté notre processus de recrutement. Tous nos entretiens, ainsi que l’onboarding, se déroulent désormais en full remote.
Cette offre d'emploi est proposée en FULL REMOTE
Jellysmack est une entreprise spécialisée dans la création de contenus vidéos originaux sur les réseaux sociaux. Avec plus de 3 milliards de vues par mois, Jellysmack a connu une ascension fulgurante, ne cesse de grandir et ambitionne de devenir le leader mondial dans son domaine. La recette de ce succès repose sur la qualité de nos contenus, mais aussi sur la technologie opérant en arrière-plan. Jellysmack a développé une suite d'outils propriétaires, propulsés par l'IA, permettant à nos équipes de contenu de publier, s'inspirer, comprendre la trend, analyser les résultats, mais bien plus encore, des outils qui analysent le contenu en ligne, les réactions des gens devant ce contenu, et déterminent ce que sera la tendance demain.
Après plus de 2 ans de développement technique, Jellysmack propose une technologie unique articulée autour de 3 produits qui visent à optimiser la création et la distribution sociale de vidéos.
L'équipe Tech œuvre pour la mise en place d’outils utilisés en interne par les équipes contenu afin de déterminer les sujets qui buzzent, les aider dans la création de contenu, suivre les performances des vidéos internes etc... en injectant dans chacun de ces produits une dose conséquente d’algorithmie, de statistiques et de machine / deep learning.
En lien direct avec le Head Of Data (basé en Corse), vous serez amené à travailler sur différentes problématiques - prioritairement axées autour du NLP - et sur des projets de taille très différentes, impliquant d’importantes quantités de données (plusieurs centaines de millions de vidéos stockées en base à date avec leur métadata textuelles, plus de 21 milliards de commentaires...).
Au sein d’une équipe de sept data scientist, vous serez le référent de l’équipe sur ces sujets d’analyse et de compréhension du langage et vous aurez un rôle consultatif.
Missions principales
Passer d'une problématique métier à un algorithme de data science
Passer d'un POC à un algorithme en production
Vulgariser un algorithme à l'état de l'art et être référent de l'équipe Data Science
Etre autonome sur les outils comme Git, avoir déjà travaillé sous docker - idéalement sous AWS
Quelques exemples de sujets :
Analyse de sentiments sur les commentaires des vidéos
Extraction de topics à partir des titres, descriptions, commentaires des vidéos
Catégorisation de vidéos en thématique à partir de l’ensemble des éléments textuels dont nous disposons
Génération automatique de titre/tag de vidéos...
Création d’un algorithme d’identification des meilleurs créateurs sur une thématique donnée
Analyse de vidéos (contenu et metadata) pour mieux comprendre la rétention des utilisateurs
Optimisation de coût sur l’acquisition de fans
Génération automatique de montage de vidéos...
Profil recherché
Docteur en computer science ou diplômé d’une maîtrise en data science, vous disposez d’au moins 5 ans d’expériences,
Une autonomie sur le passage en production d’algorithmes sera indispensable,
Vous êtes pédagogue sur la transmission de votre savoir,
Vous avez un très bon niveau de SQL (MySQL et PostgreSQL).
Avantages :
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
full remote senior data scientist h/f - cdi ou similaire: 1 an (Souhaité)"
Courbevoie (92),,,Consultant - Cloud Infrastructure,AWS EMEA SARL (France Branch),- Courbevoie (92),"3+ years hands on experience in IT implementation or leading IT Projects in Architecture, Engineering, or Development
Designed virtual infrastructure using services (e.g. EC2, ECS, ELB, RDS, Route53 & S3 or comparable virtualization/ experience) preferably using Container
Successfully implemented Infrastructure automation through CI/CD, DevOps scripting (E.g. shell, Python, CloudFormation, Terraform, Docker).
Worked in a customer facing (external or internal), consulting role or project organization delivering IT solutions
Business fluent verbal and written communication skills in French and English

Amazon Web Services () Professional Services helps customers design and build innovative solutions, and, migrate existing solutions to our platform. We provide the “how” of the move to the .

Our customers are global enterprises and necessitate high standards and big ideas! We adopt modern architectures, consulting and project methodologies embracing a multi-disciplinary team setup. Large-scale transformation, mass migrations, complex application architectures, Artificial Intelligence, Data Science and Big Data are our trade.

The French Professional Services Team is looking for a Infrastructure who is interested in:
Designing enterprise scale, globally distributed, highly available solutions using our Compute, Container, Storage, Database and Network Services
Work hands-on with new Services, including AI/Machine Learning, Serverless/Lambda IoT and Security Services to build Products and Solutions with our Customers
Structure and Guide our Customers through their -Journey
Migrate Data Centers from on-premise into the cloud.
Engage as part of our global Professional Services Community to learn and share you expertise

We offer a versatile team, modern offices, an open feedback culture, and a high pace of innovation. Take the chance and join us to Work Hard. Have Fun. Make History.

AWS Certification in Solutions Architecture, DevOps, or other specialty
Experience implementing AWS services and solutions on Customer Projects
Knowledge and experience using Container technologies (e.g. Kubernetes, Docker)
Experience working within large-scale, global Architectures
Deep understanding in Networking, Storage or Compute
Business fluent verbal and written communication skills in French and English

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build.

By submitting your resume and application information, you authorize Amazon to transmit and store your information in the Amazon group of companies' world-wide recruitment database, and to circulate that information as necessary for the purpose of evaluating your qualifications for this or other job vacancies.

aws-proserv-ea"
Paris (75),"Apprentissage, Contrat pro",,Alternance - 1 à 3 ans - Data scientist innovation (H/F) - Charenton-Le-pont,Groupe BPCE,- Paris (75),"Description de l'entreprise
Because you deserve much morethan just a job.
Bienvenue chez Natixis, l’entreprise qui vous offre bien plus qu’un job.
Chez Natixis, nous concevons des solutions en gestion d’actifs et de fortune, financement, investissement, assurance et paiements.
Notre ambition : nous dépasser collectivement pour mieux accompagner nos clients et leur proposer les meilleures solutions pour leur développement.
Chez Natixis, nos talents sont notre principal atout.
Rejoignez-nous et vous aurez les clés pour faire bouger les choses et avoir un réel IMPACT.
Rejoignez-nous et vous découvrirez un monde D’OPPORTUNITÉS.
Rejoignez-nous et vous donnerez du sens à votre projet professionnel par votre ENGAGEMENTen faveur de la société comme de l’environnement.
Signataire de la Charte de la diversité, Natixis veille à promouvoir tous les talents et à accompagner le développement de chacun. Elle est certifiée Top Employer France 2020, pour la 4ème année consécutive, et HappyTrainees.
Digital & Technology est au cœur des enjeux stratégiques de Natixis pour développer de nouveaux services & usages clients et adapter son modèle aux nouvelles réglementations bancaires.
Digital & Technology est doté d’une forte culture clients et innovante grâce aux nouvelles méthodologies & technologies IT (Digital, Big Data, Blockchain, IT bimodal, Agilité, Expérience utilisateur, Collaboratif, Sécurité de l’Information, Robotique).
Digital & Technology s’adapte régulièrement pour apporter le maximum de valeur aux Métiers de Natixis. Ses collaborateurs et les challenges qu’ils relèvent sont sa meilleure vitrine.
Vous intégrez Digital & Technology de Natixis, implantée dans 12 pays et 4 continents (3 300 collaborateurs), à la croisée des enjeux stratégiques de développement de nouveaux services & usages clients et de la nécessaire adaptation de son modèle aux nouvelles réglementations bancaires.

Poste et missions
Vous rejoignez l’équipe Innovation LAB de Natixis, qui recherche un data scientist, pour une alternance de 1 à 3 ans à partir de septembre 2020.
L’équipe Innovation LAB travaille sur les applications et technologies liées au monde de l’innovation : réalité augmentée, réalité virtuelle, chatbot, authentification biométrique, traduction, voix, applications mobile & IoT…
Au sein de cette équipe, vous participerez à la conception et à la réalisation des POC (Proof of Concept) et des projets en mode agile pour les différents métiers de Natixis.
Vous analyserez l’état de l’art : BERT, ELMo, Open AI GPT, Question Answering,Approche Deep Learning vision, regex, calcul de distance, …
Vous mettrez en œuvre des Proof of Concepts IA.
Vous évaluerez la maturité de ces technologies pour un usage opérationnel en production de ces techniques.
Vous développez des compétences scientifiques, relationnelles et de gestion de projet de premier plan.

Profil et compétences requises
C’est avant tout votre personnalité et votre état d’esprit qui nous intéresse.
Etudiant de niveau supérieur, vous préparez un diplôme universitaire ou d’école d’ingénieur, avec une spécialisation en DataSciences.
Vous êtes reconnu pour vos compétences en :
Statistiques :Mesure, Probabilités, Processus Stochastiques, Séries Temporelles, Théorie des jeux, etc.
Machine Learning et Deep Learning :apprentissage supervisé, non supervisé, par renforcement, théorie et implémentations numériques des algorithmes de Machine et Deep Learning (régressions logistiques, arbres de décision, arbres de gradient boosté, réseaux convolutionnels, auto-encoders, etc.)
Vous maitrisez les langages Python, Spark, SQL, et des architectures Big Data (Hadoop et Cloud).
Vous avez une appétence pour les outils suivants :
numpy, scipy, pandas, scikit-learn, xgboost, dask, etc.
tensorflow, pytorch, keras, etc.
SQL & NoSQL.
Pyspark, elasticsearch, etc.
Curieux, créatif, vous aimez travailler en équipe sur des projets innovants.
Vous êtes proactif et aimez travailler dans un environnement exigeant et challengeant.
And last but not least, you are perfectly fluent in English.
Vous vous reconnaissez dans ce profil ?
Alors vous êtes fait pour ce job et nous avons besoin de VOUS !
Vous bénéficierez d’un accompagnement dédié pour vous donner toutes les chances de réussir cette nouvelle mission.

Job Reference: NI12931"
Paris (75),CDI,,Data Engineer - Python,Sept Lieues,- Paris (75),"PME en forte croissance, sur le secteur de l'immobilier.
LE POSTE / LES MISSIONS
En collaboration avec l'équipe scientifique vous contribuez à l'amélioration en continue de la partie modélisation sur le marché immobilier.
Grace à votre expertise R&D vous travaillerez sur la conception et industrialisation des différents modèles.
Vous utiliserez donc des technologies d'intelligence artificielle (TAL, Machine Learning, modélisation spatio-temporelle) en rapport avec des gros volumes de données.
PROFIL RECHERCHÉ
Une première expérience confirmée au sein d'une équipe Data.
Vous avez de bonnes connaissances en :
Python
Modélisation et traitement de volume importants de données
Rigoureux, curieux, autonome
Développeur python ayant une volonté de découvrir des problématiques de modèles et de grosses quantités de donnée"
Paris (75),CDI,,Architecte intégration DATA/SPLUNK F/H,Orange,- Paris (75),"Intégré(e) au département Data, vous interviendrez en tant qu'architecte intégration DATA pour un poste en CDI.
Missions :
Le département a pour objectif de délivrer des prestations de qualité en analyse statistiques, mise en oeuvre de dataviz et utilisation de machine learning, avec une forte compréhension des enjeux fonctionnels des clients dans le cadre de projets d'intelligence opérationnelle :
Etudier et analyser les données collectées afin de répondre aux demandes marketing et/ou équipes techniques.
Accompagner le client dans des ateliers projets fonctionnels et techniques
Concevoir et mettre en oeuvre les solutions d'alimentation et de manipulation de données
Se tenir au courant des évolutions du marché sur les technologies innovantes
Des formations seront proposées pour monter en compétence sur la solution Splunk.
about you
De formation BAC+5 en informatique, vous justifiez d'au moins 5 ans d'expériences dont un minimum de 5 ans dans le développement ou la manipulation de données.
Compétences techniques et qualités requises :
Connaissance des langages de développements : Python, Java et Javascript
Connaissance en requêtage SQL, noSQL
Bonne maitrise de l'environnement Linux
Bonne maîtrise écrite et orale de l'anglais
Bonnes compétences rédactionnelles.
Savoir analyser, modéliser et présenter les données
Passionné(e) par votre métier, curieux(se), dynamique et force de proposition, vous pourrez vous investir sur des activités au coeur des nouvelles technologies au sein de nos équipes projet d'intelligence opérationnel.
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Paris (75),CDI,60 000 € - 100 000 € par an,Senior Data Scientist NLP pour réinventer l’après cookie dans la adtech,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data scientist ml ia nlp dl
Taille entreprise de 1 à 10
Teletravail a 100
Lead manager responsable a court terme
Technologies Bert
Technologies Nlp
Technologies Tensorflow
Expérience 6 à 10 ans
Statut CDI
Min 60k€
Max 100k€

ENTREPRISE : LA STARTUP ADTECH DISRUPTIVE DANS LA PUBLICITÉ EN LIGNE

RGPD oblige, Cette AdTech prépare la solution de publicité en ligne de l’après cookie : l’intelligence artificielle (pretargeting sémantique) au service d’un ciblage qui ne traque pas les utilisateurs.
La première solution de ciblage publicitaire sans cookie
Use case disruptif sur le marché de la publicité en ligne
Background monstrueux du fondateur
Potentiel très important : le prochain Criteo
Ouverture de poste suite à levée de fond + 500K
Locaux au coeur de Paris
Stack technique du poste : Python, Tensorflow, NLP, Deep Learning & Transformers, …
Mon avis : un timing parfait pour un intrapreneur / data scientist qui souhaite un projet cadré mais où beaucoup reste à construire. Une adtech du bon côté de l’histoire.
VOTRE MISSION : DÉVELOPPER L’ALGORITHME
A partir d’une base/plateforme déjà existante, vous oeuvrez à l’optimisation de l’algorithme pour optimiser le ciblage des publicités en fonction du contexte (et non du cookie de l’utilisateur)
Optimiser un moteur NLP pour évaluer l'affinité d'une page web avec un produit ou une marque
Avoir la responsabilité de vos modèles, de l'expérimentation à la mise en production
Intervenir sur un grand volume de données (un panel de 2 millions de devices, 10 millions de pages analysées par jour)
Encadrer plusieurs juniors à horizon de 1 an
VOTRE PROFIL : DATA SCIENTIST SENIOR NLP
Diplômé d’une grande école d’ingénieur ou Phd : Polytechnique, CentraleSupelec, ENS…
3 à 10 ans d’expérience en Data Science
Expérience significative en NLP
Connaissance de l’inférence Bayésienne ou excellent niveau en mathématiques
Compréhension des enjeux business
Vous êtes autonome et force de proposition
Si précédente expérience dans l’Adtech, c’est en plus !
MODALITÉS :
Salaire : 60/100K€ selon profil
Paris Hyper centre
PROCESS DE RECRUTEMENT :
2 à 3 entretiens avec le fondateur (rencontre, cas pratique)
Rencontre avec les Business Angels (selon profil)

Sélectionné par Thomas Gourmelon
Spécialiste Python, Ruby, Go & Data Scientist
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),CDI,,Data Engineer & Cloud F/H,OCTO Technology,- Paris (75),"Convaincu que la Data et le Cloud peuvent répondre aux enjeux de nos clients autour de la transformation digitale & de la Data, OCTO souhaite développer cette expertise et les lier à nos activités autour de l'Analytics et l’Intelligence Artificielle.
Profil recherché
De formation supérieure, vous possédez une première expérience acquise au sein d’un cabinet de conseil ou société technologique.
Vous avez de solides compétences en développement logiciel (Python, Java …) et vous disposez de solides expériences dans la mise en place de pipeline de données
Vous avez une solide expérience en traitement de données SQL/NoSQL

Vous portez de l'intérêt et avez au moins une premère expériences sur l'un de ces sujets :
Expérience sur une plateforme Cloud (AWS, Google, Azure)
Langages: Shell, Java
DevOps : Jenkins, Gitlab, Maven, …
Méthodes agiles : Scrum, SAFe
Stockage / BDD : RDBMS (SQL), Redshift, NoSQL, Objets/blobs, Archivage
Big Data : Hadoop, HDFS, MapReduce, Spark, Kafka
Détails de l'offre
Type de poste : CDI
Lieux : Paris, Île-de-France (FR)
Descriptif du poste
Votre rôle consistera à accompagner nos clients dans la mise en oeuvre de solutions autour de la gestion et transformation de leur data.

Plus précisément, voici les missions sur lesquelles vous interviendrez :

Répondre aux enjeux de transformation de nos clients autour de la donnée
Aider les équipes Data et métier de nos clients dans la clarification et la formalisation de leur besoin
Concevoir et développer des solutions de Data pipeline pour nos clients
Participer au cadrage et à la mise en place de solutions Data dans le cloud
Optimiser les process et les pipelines d'alimentation de données
Maintenir les pratiques Devops “You build IT, You run IT”
Être constamment en veille et chercher des idées innovantes
Participer à l’industrialisation de projets Data science de nos clients sur des plateformes Cloud.


Mais ce que nous cherchons avant tout, ce sont des personnalités qui enrichiront OCTO. Nous les reconnaissons à leur volonté de participer à l’amélioration de la vie de l’entreprise, de construire la vision et les offres de demain, de partager leurs connaissances pour faciliter la montée en compétences réciproque. De rejoindre, enfin, une communauté qui n’a pas peur d’affirmer sa différence."
Paris (75),CDI,,Big Data Engineer - Scala | Python | Spark | Hadoop | Azure - H/F,Esens Consulting,- Paris (75),"DESCRIPTION DU POSTE
Faire évoluer la plateforme cloud de l’équipe DATA (essentiellement sur une base Microsoft Azure)
Assurer le paramétrage et l’administration de la plateforme
Définir les normes de développement et les procédures d’exploitation.
Superviser les alimentations de production grâce aux outils (AirFlow…)
Développer et suivre la mise en place des alimentations de données dans le but de la constitution du Datalake - Scala, Python, SQL.
Assurer la cohérence de la conception des bases de données du Datalake
Travailler avec les Data Scientist à l’optimisation des traitements statistiques et algorithmiques
Réaliser une veille technologique sur les composants Cloud.
CONNAISSANCE ET COMPETENCES REQUISES
Hadoop / Microsoft Azure / Spark / Python / SCALA / Langage SQL / SQL Server / Datawarehouse, HDFS, NoSQL,
Curiosité – Esprit de synthèse – Raisonnement structuré
PROFIL RECHERCHE
De formation supérieure bac+5 minimum en informatique et Big Data, vous avez une culture très orientée développement et innovation.
Vous disposez de minimum 2ans d'expérience dans la mise en place d’architecture Cloud et de projets Data.
La connaissance des technologies Hadoop / Microsoft Azure / Scala est un pré-requis.
SOCIÉTÉ
Vous avez poursuivi votre lecture jusqu’ici ? Nous sommes par conséquent à quelques jours de notre rencontre au sein de nos bureaux WeWork Colisée :
Ouverts H24
Rooftop en plein centre de Paris
Open Bar à Bière de 17h à 20h
Accès aux espaces WeWork dans plus de 180 villes WW
ESENS innove depuis 10 ans sur le marché des nouvelles technologies, aussi bien dans des contextes client, qu’en matière de R&D.
Rejoignez-nous !
PARTAGER CETTE OFFRE"
Paris (75),CDI,40 000 € - 45 000 € par an,Data Engineer pour une scale up,Data Recrutement,- Paris (75),"Soyez alerté de la prochaine offre similaire en cliquant ici.
Data Engineer pour une scale up
Offre publiée le 18-05-2020.
Paris
Fonction Data engineer hadoop spark
Technologies Etincelle
Technologies Git
Technologies Java
Technologies Python
Technologies Scala
Technologies Spark
Expérience 1 à 2 ans
Expérience 3 à 5 ans
Expérience 6 à 10 ans
Statut CDI
Min 40k€
Max 65k€

L’ENTREPRISE : UNE STARTUP SPÉCIALISÉE DANS LE MARKETING MOBILE
Cette startup propose une technologie intégrée à des milliers d’applications qui permet de créer des profils d’utilisateurs mobile extrêmement précis. (100% RGPD compliant).
Quelques chiffres :
Startup créée en 2014
Rentable dès sa première année
+400M d’utilisateurs actif sur Android
+20M€ de levée de fonds (3 levées)
14 bureaux
International : +300 clients
Stack technique du poste : Python, Java, Scala, Spark, Étincelle, Git, …

VOTRE MISSION : RENDRE LA DONNÉE SCALABLE
Développer des solutions performantes et massivement évolutives pour la génération de données synthétiques, simulées et semi-réalistes
Collaborer avec les Data Engineer, les Data Scientist et les développeurs androïdes afin de définir les spécifications fonctionnelles
Maintenir et tester les solutions développées sur des mobiles réels et sur des émulateurs
Identifier, concevoir et mettre en œuvre des améliorations du crawler
Rédiger une documentation détaillée et précise de votre travail
Revoir les peer des Data Engineer afin de s’assureur de leur qualité
Déployer les services dans un environnement de staging et de production
Programmer dans une ou plusieurs langues au sein d’un écosystème de données, par exemple Python, Java, Scala
Participer à la mise en place des méthodologies Agile/Scrum
Travailler dans un environnement startup en forte croissance
VOTRE PROFIL : DATA ENGINEER
Junior, confirmé ou sénior, idéalement diplômé d’une école d’ingénieur ou d’informatique, avec :
Expérience en développement logiciel (JAVA)
Expérience en scripting (shell ou python...)
Maitrise de Git
Compétences de base en SQL
Anglais obligatoire (écrit indispensable + bonne expression et compréhension orale)
LES + :
Expérience avec les technologies de Big Data : Étincelle, Python, Scala
Expérience avec AWS, Docker, NoSQL
Appétences pour le Machine Learning et la Data Science
MODALITÉS :
Poste Basé à Paris
Salaire selon profils :
Junior : 40/45K€
Confirmé : 45/55K€
Sénior : 55/65K€

Sélectionné par
CONNAÎTRE LE NOM DE L’ENTREPRISE"
La Défense (92),,,Expert Traitement du Signal et Statistiques à La Défense (IDF) H/F,Altran,- La Défense (92),"Le World Class Center (WCC) Analytics est un centre d’expertise comprenant des Solution Managers, Chefs de projets, Architectes et autres Experts qui accompagnent les clients industriels internationaux du Groupe Altran dans des projets liés au domaine de l’analytics et de la Data Science (machine learning/analyse et traitement de données, traitement du signal et statistique pour la conception, la fabrication et le monitoring).

Dans le cadre du développement de ses activités et pour renforcer ses équipes, le WCC recrute un(e) Expert en Traitement du Signal et Statistiques.
Vos responsabilités
Vous intervenez au sein des équipes de l’antenne Française (Back Office UK) et vous participez aux projets d’envergure internationale et multi-industries de nos clients (santé, automobile, Aéronautique, Energie, industrie 4.0…). Vous êtes en charge des activités suivantes:
Développement de méthodes traitement de signal pour monitoring
Delivery de projets / Réalisation de prototypes, projets industriels à l’échelle Temps réels, (Matlab, C)…
Développement d’outils statistiques pour le contrôle de fabrication, la fiabilité,…
Des revues de pair sur des méthodologies / algorithmes de monitoring
Du coaching de consultants ALTRAN en TdS ou en statistiques
Développement d’affaires en support des équipes commerciales
Contribution à des offres transverses expertises ex : Industrie 4.0 – Design & Innovation – Digital – Big Data
Votre profil
De formation BAC+5 (Ecole d’ingénieur ou Master) spécialisée en traitement du signal et/ou de l’image. Vous justifiez d’au moins 5 ans d’expérience sur des projets/activités en traitement du signal, idéalement dans le monde industriel et sur des systèmes de condition monitoring, de suivi de production…. Vous avez une réelle compréhension des techniques de la majeur partie des techniques en traitement du signal avancé et statistiques. Vous avez une bonne connaissance des langages et logiciels: R / Python / Matlab / SPS / SAS / Statistica. Vous êtes capable de:
proposer une démarche structurée efficace pour atteindre l’objectif, en participant à sa définition (vision d’architecte).
vous projeter / Identifier la valeur business potentielle / penser hors du cadre
Communiquer aisément avec les différents types d’interlocuteurs (experts techniques – décideurs – IT – chefs de projets)
Faire preuve de proactivité
Aussi, vous aimez évoluer dans un environnement international. De ce fait, vous parlez parfaitement anglais.
Ce poste est ouvert aux personnes en situation de handicap."
Paris (75),CDI,,Architecte Big data (H/F),Acensi,- Paris (75),"Description de l'offre
POSTE
Dans le cadre de son développement, ACENSI recherche plusieurs Architecte BIG DATA.
Vous êtes Architecte .Net, Java, Web ou Big Data et avez un goût prononcé pour de nouveaux challenges techniques.En dehors des compétences en architecture (Recommandations, Norme, proof of Concept, dimensionnement), vous aimez vulgariser vos connaissances pour un public technique et non technique.
Pour ce faire vous évoluerez sur des problématiques d’APisation et de Bi Data et devrez :
Accompagner les développeurs depuis l’architecture technique jusqu’au déploiement en production
Participer à l’implémentation de vos recommandations
Mettre en œuvre des outils de monitoring pour améliorer la production
Environnement technique :
Hadoop
Bases de données NoSQL
Machine Learning
Constitution de datalake
Spark
Python
Java
Distribution Big Data (pour le Big Data).
Architecture REST, SOA, Web Services
Middleware d’entreprise
Développement et debug avancé
Servicisation pour l’Apisation du SI.

PROFIL
De formation Bac+4/5, vous avez au moins 10 ans d’expériences et souhaitez relever de nouveaux challenges au sein d’une entreprise dynamique et reconnue.
Vous avez des compétences en Big Data, ou souhaitez-en acquérir."
Paris (75),"Apprentissage, Contrat pro",,Alternance - 1 à 3 ans - Concepteur développeur Big Data (H/F) - Paris,Groupe BPCE,- Paris (75),"Description de l'entreprise
Because you deserve much morethan just a job
Bienvenue chez Natixis, l’entreprise qui vous offre bien plus qu’un job.
Chez Natixis, nous concevons des solutions en gestion d’actifs et de fortune, financement, investissement, assurance et paiements.
Notre ambition : nous dépasser collectivement pour mieux accompagner nos clients et leur proposer les meilleures solutions pour leur développement.
Chez Natixis, nos talents sont notre principal atout.
Rejoignez-nous et vous aurez les clés pour faire bouger les choses et avoir un réel IMPACT.
Rejoignez-nous et vous découvrirez un monde D’OPPORTUNITÉS.
Rejoignez-nous et vous donnerez du sens à votre projet professionnel par votre ENGAGEMENTen faveur de la société comme de l’environnement.
Signataire de la Charte de la diversité, Natixis veille à promouvoir tous les talents et à accompagner le développement de chacun. Elle est certifiée Top Employer France 2020, pour la 4ème année consécutive, et HappyTrainees.
Digital & Technology est au cœur des enjeux stratégiques de Natixis pour développer de nouveaux services & usages clients et adapter son modèle aux nouvelles réglementations bancaires.
Digital & Technology est doté d’une forte culture clients et innovante grâce aux nouvelles méthodologies & technologies IT (Digital, Big Data, Blockchain, IT bimodal, Agilité, Expérience utilisateur, Collaboratif, Sécurité de l’Information, Robotique).
Digital & Technology s’adapte régulièrement pour apporter le maximum de valeur aux Métiers de Natixis. Ses collaborateurs et les challenges qu’ils relèvent sont sa meilleure vitrine.
Vous intégrez Digital & Technology de Natixis, implantée dans 12 pays et 4 continents (3 300 collaborateurs), à la croisée des enjeux stratégiques de développement de nouveaux services & usages clients et de la nécessaire adaptation de son modèle aux nouvelles réglementations bancaires.

Poste et missions
Vous rejoignez notre équipe IT Global Markets, qui recherche un Concepteur Développeur Big Data, pour une alternance de 1 à 3 ansà partir de septembre 2020.
Vous intégrerez une équipe agile de 4 personnes évoluant dans un environnement DevOps (TDD,Continuus Testing, Packaging & Continuus Delivery).
Vous participerez à l’élaboration d’une application de Business Activity Monitoring (BAM) visant à offrir aux différentes équipes IT et aux équipes métiers une vision globale de la chaîne.
Passionné(e) par les nouvelles technologies, vous participerez à l’implémentation de la BAM s’appuyant sur les services et composants de la plateforme Big Data (Kafka, ElasticSearch, Grafana, …).
Vous interviendrez sur :
le développement de nouvelles fonctionnalités (calcul de KPI via des analyses statistiques, implémentation de nouveaux dashboards, ...),
la revue de l'architecture de l'application (modèle de données, infra back end et front end, disaster recovery plan, ...),
l'optimisation (insertion des données et leur restituation),
le design de l'interface utilisateur (grafana & angular).

Profil et compétences requises
C’est avant tout votre personnalité et votre état d’esprit qui nous intéresse.
Vous préparez un diplôme universitaire ou d’école d’ingénieur de niveau bac +5 en informatique.
Vous êtes reconnu pour vos compétences en Python, base NoSQL comme ElasticSearch.
Vous avez développé des connaissances sur la méthode Agile.
Votre agilité et votre sens du service sont reconnus de tous.
Vous aimez travailler en équipe.
And last but not least, you are perfectly fluent in English.
Vous vous reconnaissez dans ce profil ?
Alors vous êtes fait pour ce job et nous avons besoin de VOUS !
Vous bénéficierez d’un accompagnement dédié pour vous donner toutes les chances de réussir cette nouvelle mission.

Job Reference: NI12922"
La Défense (92),CDI,,Architecte DATA Senior F/H,Orange,- La Défense (92),"Chez Orange aussi on fait de la DATA. La filiale OBS Digital & DATA met aujourd'hui la donnée au coeur de son approche client.
Nos clients prennent conscience de la valeur business de leurs données et sont de plus en plus sensibles à la question de leurs exploitations efficaces. Nous sommes là aujourd'hui pour les accompagner et les conseiller dans une meilleure connaissance et maîtrise de leurs données.
Nous recherchons aujourd'hui, un Architecte DATA expérimenté à même d'intervenir chez nos clients pour les accompagner dans la structuration de leurs SI autour de la donnée.
Vos principales missions seront les suivantes :
Animer des études de cadrage pour collecter le besoin métier et concevoir des architectures simples qui répondent au besoin du client.
Auditer des architectures existantes pour proposer une roadmap de recommandations. (Cartographie données et process SI)
Animation d'atelier clients (recueil du besoin, formation…)
Apporter son expertise sur des problématiques précises rencontrées chez les clients.
Déployer des infrastructures cloud pour le traitement des données
Rédiger les documentations techniques associées à vos activités.
Participer à l'animation du pôle d'architectes et veille techno
Rester informer et former sur les nouvelles solutions DATA
Maîtriser les notions de réglementation de la données (RGPD) et les impacts sur la gouvernance et la traçabilité des données (Data Lineage)
Gérer les communications associées internes et externes.
S'assurer de la satisfaction client.
Contribuer aux phases d'avant-vente et au développement business.
Participer à la conception, l'évolution et la présentation de nos offres DATA.
about you
Profil de formation bac+5, vous justifiez de plusieurs expériences significatives en qualité de d'Architecte DATA sur des projets intégrant des pratiques DevOps et AGILE.
Vos compétences :
Des langages objets ou scripts (Java, Javascript, Scala, Python…)
Divers systèmes d'exploitation : UNIX, Windows
Connaissances en solutions de bases de données (SQL, NoSQL…)
Expertise les outils ETL (TALEND, Informatica...)
Maîtrise des technologies du Big Data (Hadoop, Spark, Kafka…)
Connaissance des architectures Clouds (AWS, AZURE…)
Capacité d'analyse et de restitution
Pilotage d'équipe technique
Autonomie, rigueur, bienveillance, écoute et sens du service sont des qualités nécessaires pour ce poste.
La maîtrise de l'anglais (oral et écrit) est un plus.
Postes à pourvoir à PARIS.
Nous vous proposons d'intégrer des projets centrés sur les dernières technologies dans des équipes à taille humaine organisées à 60 % en mode forfait.
Vous recherchez un Groupe qui saura être à l'écoute de votre potentiel et qui vous permettra d'évoluer, alors rejoignez-nous !
Nous avons des projets pour vous.
Critères candidat :
Niveau d'études min. requis Bac+5
Niveau d'expérience min. requis supérieur à 5 ans
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Paris (75),"Apprentissage, Contrat pro",,E&C FR ALTERNANCE DATA INFORMATIQUE DECISIONNELLE H/F,Air Liquide,- Paris (75),"Présentation du Groupe
Air Liquide est un leader mondial des gaz, technologies et services pour l’industrie et la santé. Présent dans 80 pays avec environ 65 000 collaborateurs, le Groupe sert plus de 3,5 millions de clients et de patients. Oxygène, azote et hydrogène sont des petites molécules essentielles à la vie, la matière et l’énergie. Elles incarnent le territoire scientifique d’Air Liquide et sont au cœur du métier du Groupe depuis sa création en 1902.

Air Liquide a pour ambition d’être un leader de son industrie, d’être performant sur le long terme et de contribuer à un monde plus durable.

Air Liquide place la diversité au cœur de ses activités et s'engage notamment en favorisant l’égalité professionnelle et l’emploi des travailleurs en situation de handicap.

Descriptif de l'entité et de l'activité
Air Liquide Global E&C Solutions est un partenaire technologique de choix pour la conception, l’ingénierie et la construction d’unités de production de pointe dans le monde entier. Grâce à nos équipes et à leur capacité d’innovation constante, nous permettons à nos clients d’optimiser l’utilisation des ressources naturelles pour fournir une énergie propre et durable. Nos technologies exclusives et particulièrement innovantes nous permettent de contribuer à la transformation du secteur de l’énergie, à la préservation et à la protection de l’atmosphère de notre planète.
Forts de plusieurs dizaines d’années d’expertise opérationnelle au sein du leader mondial des gaz, technologies et services pour l’industrie et la santé, nous concevons pour nos clients des solutions originales, sûres, fiables et concurrentielles et proposons dans le monde entier les meilleures unités de production dans un marché en constante évolution.

Missions & Responsabilités
Au sein de la Direction des Systèmes d’Information vous serez basé (e) à Champigny, intégré au pôle Solutions et vous bénéficierez du support du centre d'expertise d'Air Liquide.
La mission, d’une durée de 3 ans comprend 3 aspects :
Autour de différents sujets attenant la gestion de la DSI, conduire des projets depuis leur phase de conception jusqu’à leur phase livraison. Promouvoir et faire vivre les solutions mises en place.
Participer au maintien et évolutions des applications de Business Intelligence à la fois sur la partie technique (ETL, Microsoft Power BI, outils tiers) et la partie contenus (rapports, tableaux de bords). Notre plateforme de reporting est en interaction directe avec les besoins utilisateurs, que ce soit dans les domaines finance, gestion, achats ou exécution de projet en Europe, Asie et Amérique. Proposer et développer de nouvelles solutions techniques autour de l'informatique décisionnelle (mobilité, etc.).
Développer des solutions permettant de mieux exploiter nos données d'entreprise, en s’appuyant sur la Data Science et le Machine learning, afin de répondre aux nouveaux défis Digitaux.
Gérer et supporter les outils open source de gestion interne de la DSI (Mantis, SVN,…).

Profil et compétences
Formation technique, type ""MIAGE"" ou école d'ingénieur informatique en apprentissage.
Connaissance des méthodes de modélisation de bases de données transactionnelles, décisionnelles et des méthodes de modélisations objets.
Connaissance de PHP, JSP, Java, Python, SQL, scripts,…
Connaissance d’outils de data analyse / visualisation serait un plus.
Maîtrise du français et de l’anglais indispensable.
Attrait pour l’informatique et la communication
Esprit curieux et méthodique.
Capacité à écouter et à s’intégrer dans un environnement multiculturel.

Informations complémentaires
Localisation géographique : France / Ile de France / 94-Champigny-sur-Marne
Responsable hiérarchique : Kim Line Say
Responsable RH : Maud de la Guérivière
Convention Collective Nationale : Industries chimiques
Catégorie professionnelle : Techniciens et Agents de Maîtrise

Job Reference: FR09600"
Paris (75),,,SENIOR SOFTWARE ENGINEER (DATA ENGINEER),"Cairn Biosciences, Inc",- Paris (75),"JOB DESCRIPTION
We are seeking an energetic, creative and entrepreneurial Software Engineer who will play a key role of Cairn’s Analytics Paris team as one of its foundational members. The ideal candidate will have hands-on experience in both back- and front-end software development and exposure to machine learning and deep learning methods. The candidate should lead by example and inspire others to relentlessly pursue bold, impactful goals to help unlock new biology and build Cairn Biosciences into a leading drug development company that transforms the lives of patients.
Key responsibilities:
Build infrastructure and software
Automate data flows and analyses to develop interactive systems that support and enable the scientific team to make decisions
Develop code for interactive data visualization applications and tools for data analysis
Participate actively in decisions about next implementations and the different technical choices associated
Promote software development best practices with colleagues
PREFERRED EXPERIENCE
Required skills:
Master in Computer Science or equivalent and 2+ years of experience
Experience in high-quality software development, including familiarity with at least one relevant programming language (Python, Java, Scala, C++)
Experience with database technologies (e.g. SQL, PostgreSQL or NoSQL as MongoDB) for creating data pipelines involving a wide range of data types
Familiarity with data architecture patterns (data warehouse, data lake, streaming, Lambda/Kappa architecture)
Experience with cloud computing (AWS, GCP or similar)
Exceptional communication, critical thinking and problem-solving skills that promote a goal-oriented work culture while fostering an environment of technical excellence, flexibility and productivity in a fast-paced startup environment with shifting priorities
Resourceful, can-do, solutions-oriented individual who is self-motivated to deliver on aggressive goals that support attainment of company technical and corporate milestones
Fluent in English
Current European work authorization
Desired skills:
Experience creating public or internal APIs or user interfaces
Familiarity with machine learning methods
RECRUITMENT PROCESS
Please submit your resume and a cover letter detailing your interest and experience to
careers@cairnbio.com
. Cairn Biosciences is an Equal Opportunity Employer offering a competitive salary and benefits package. Note to employment agencies: Please do not forward agency resumes; Cairn Biosciences will not be responsible for any fees related to resumes that are unsolicited.
ADDITIONAL INFORMATION
Contract Type: Full-Time
Location: Paris, France (75013 )
Education Level: Master's Degree
Experience: > 2 years
Occasional remote authorized"
Paris (75),,,Data Engineer,HYPERLEX,- Paris (75),"À propos
Hyperlex, c'est la start-up Legaltech qui réinvente la gestion et l'analyse de contrats grâce à l'Intelligence Artificielle et au Machine Learning !
Cette solution en ligne simplifie le travail des professions juridiques au quotidien tout en les aidant à accroître leurs performances.
Fondée en 2017 par 2 ingénieurs, Hyperlex a réalisé 2 levées de fonds depuis sa création, dont la dernière de 4 millions d'euros en juin 2019 auprès d'investisseurs de renom comme Elaia, Axeleo Capital, ISAI Venture et Kernel Investissements.
L'équipe est composée de 20 personnes parmi lesquels des experts en développement logiciel, sécurité informatique et intelligence artificielle, mais aussi des juristes, des commerciaux et autres talents passionnés par leur métier. Cette passion et cette recherche de l'excellence ont permis à Hyperlex de développer une technologie innovante récompensée à plusieurs reprises, notamment : le Prix EDF Pulse et le Trophée de la meilleure Legaltech Corporate aux Trophées du droit édition entreprise en 2018.
Hyperlex est toujours à l’affût de nouveaux talents : rejoignez-les et prenez part à un projet technologique qui souhaite révolutionner les pratiques du secteur juridique grâce à l'IA !
Descriptif du poste
Hyperlex recherche un Data Engineer (H/F) pour rejoindre son équipe Tech / Machine Learning à Paris.
Le poste
Industrialisation et optimisation des algorithmes de machine learning
Conception et implémentation de pipelines scalables de traitement de données
Centralisation et standardisation des données par la mise en place d'un Data Lake
Amélioration de notre pipeline de traitement de documents pour la rendre plus scalable
Identifier les besoins de l'équipe Data Science en terme de performance et de déploiement
Pourquoi postuler ?
Vous aurez un impact immédiat sur le produit en améliorant la qualité et la rapidité de nos approches
C'est le moment idéal pour rejoindre Hyperlex en terme de perspective de croissance
Nous avons une solide équipe de Machine Learning qui vous aidera à apprendre sur de nombreux sujets
Profil recherché
Votre profil :
Première expérience réussie à un poste similaire (stages inclus), issu d'une formation ingénieur avec un réel goût pour la technique et l'environnement startup
Maîtrise de Python
Solides connaissances en base de données (PostgreSQL)
Etre familier avec les bonnes pratiques de développement, intégration continue, déploiement continue (tests unitaires, docker, drone)
Les plus appreciés :
Une première expérience réussie (stage / césure / CDI) à un poste similaire
Une connaissance des algorithmes de machine learning et des librairies associées (scikit-learn, spaCy, Tensorflow, pyTorch, Keras, opencv)
Connaissances des infrastructures et des systèmes de stockage cloud (GCloud, AWS, OVH)
Etre familier avec un/des systèmes de gestion de base de donnés type Big data (Spark, mongodb, hadoop ...)
Process de recrutement
Vous nous envoyez votre CV ou lien linkedin ainsi que des exemples de réalisations ou de code (github, bitbucket) si vous en avez
Nous vous appelons pour faire connaissance
Nous nous rencontrons pour évaluer vos connaissances (Data + Engineering)
Vous rencontrez l'équipe
Et voilà
Informations complémentaires
Type de contrat : CDI
Date de début : 01 septembre 2020
Lieu : Paris, France (75009)
Niveau d'études : Bac +5 / Master
Expérience : > 1 an
Postuler
Voir toutes les autres offres de Hyperlex"
Paris (75),CDI,58 000 € - 70 000 € par an,Data engineer Python pour une marketplace à fort trafic,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data engineer hadoop spark
Taille entreprise de 201 à 500
Teletravail ponctuel
Technologies Ansible
Technologies Apache
Technologies Bigquery
Technologies Docker
Technologies Google cloud plateform
Technologies Jenkins
Technologies Kubernetes
Technologies Machine learning
Technologies Python
Technologies Terraform
Expérience 1 à 2 ans
Expérience 3 à 5 ans
Expérience 6 à 10 ans
Statut CDI
Min 58k€
Max 70k€
L’ENTREPRISE : UNE SCALE-UP EN HYPERCROISSANCE PROPOSANT UNE MARKETPLACE DANS LE DOMAINE DE L'IMMOBILIER
Leader sur son marché
+ 2 millions d'utilisateurs par mois
Créée en 2008
Rachat récent par un grand groupe
Ouverture prochaine à l'international
Top ambiance et cadre de travail : sports, team buildings, meetups, budget bonférences
Equipe : + 260 collaborateurs dont 20 personnes au sein de l'équipe data science
Stack technique de l’entreprise : Python, PostgreSQL, Google Cloud Platform : ML Engine, DataFlow, Airflow, Docker, Kubernetes, BigQuery, Jenkins, Docker, Ansible et Terraform

VOTRE MISSION : CONTRIBUER À L'AMÉLIORATION DES MOTEURS DE MODÉLISATION DU MARCHÉ DE L'IMMOBILIER
Au sein de l'équipe Data composée de 20 personnes, vous vous appuyez sur votre expertise R&D et en proche collaborarion avec les data scientist vous industrialisez les différents modèles qui font de l'entreprise une référence en la matière. Pour ce faire, vous :
Optimisez les modèles existants
Echangez continuellement avec l'équipe de data scientist
Réalisez des prototypes
Designez des architectures cloud, logicielles permettant de passer à l’échelle
Améliorez continuellement un système de production de données maintenable, scalable, robuste, sur lequel l'entreprise peut s’appuyer
VOTRE PROFIL : DATA ENGINEER
Vous avez plus de 2 ans d'expérience en tant que data engineer
Vous avez de bonnes compétences sur Python et son écosystème
Vous maîtriez le traitement de volumes importants de données
Vous êtes rigoureux, curieux, autonome, team-player, constructif dans vos discussions.
Si vous êtes aussi un développeur Python, avec une soif de découvrir des problématiques de modèles et de grosses volumétries de données, n'hésitez pas !
VOS +:
Vous avez un goût prononcé pour les stats et les maths
Vous disposez de compétences dataviz et/ou en cartographie
MODALITES :
Package : variable selon expérience
Junior 55 K€
Jusqu'à 70K€ pour un profil senior
Prise en charge mutuelle à 80%
1 jour de télétravail par semaine
Restaurant d'entreprise
Soirée d'équipe, tournois baby-foot, playstation
Enveloppe pour assister à des conférénces
Enveloppe pour customiser son lieu de travail (choix de chaise, machine...)
Salle de sport
RTT
baby-foot possible
Paris Intra-muros

Sélectionné par Renaud De Cock
Manager, Spécialiste Product & Design
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),45 000 € - 60 000 € par an,,Développeur Python/Angular | Solution Saas dans le big data,In-Team,- Paris (75),"Vous êtes développeur et souhaitez travailler sur poste bas niveau dans le secteur de la data?
Alors, rejoignez cette société développant une solution Saas Big Data à destination de grands groupes internationaux !
Existant depuis plus de 3 ans, cette entreprise de 30 personnes manage les big datas des plus grandes entités internationales. A travers leur solution Saas, elle leur fourni des solutions pertinentes afin d’en améliorer l’utilisation et leur propose surtout des synergies pour augmenter et optimiser la pertinence de chaque action.
Elle fait donc le lien entre ses différents clients autour de ces quantités astronomiques de données.
Vous l’aurez compris, au cœur de ce projet : la data sur tout son cycle de vie, de la collecte, à son utilisation finale.
Venant de lever plusieurs millions d’euros, il cherche aujourd’hui un développeur Python/Angular pour rejoindre leur équipe technique d’une dizaine de personnes.
Vous êtes curieux d’en savoir plus ?

Votre mission :
Dans un environnement startup’ innovant et dynamique vos missions seront :
Travailler sur des projets complexes de big data, et être moteur dans les choix techniques
Participer au développement d’un produit SaaS à forte valeur ajoutée en Python/Angular
Être force de proposition sur les solutions techniques à choisir dans l’équipe R&D
Etiliser les meilleures méthodes et outils de développement à l’heure actuelle : méthode agile (Scrum), intégration continue, pair programming…

Votre profil :
2/5 ans d’expérience en développement Python/Angular
Une première expérience dans du développement en temps réel à fort volume
Avoir une bonne connaissance en NoSQL (MongoDB, redis…)
Du répondant au babyfoot et à Mario kart sera un vrai plus !!!
Opportunité :
Travailler dans une entreprise manipulant d’immense quantité de data
Travailler dans des supers locaux en plein cœur de Paris
Rejoindre une équipe dynamique à l’esprit startup’
Salaire et avantages :
45-60k€
Contrat en CDI
Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !
Si vous souhaitez avoir d’autres informations sur cette opportunité je vous invite à me contacter également."
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community
Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris 9e (75),CDI,,Software Engineer - Performance,Criteo,- Paris 9e (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

Most of all, we are creators. From designing ground-breaking products to finding unique ways to solve technical challenges at an exceptional scale, our tech teams work with state of the art methodologies to shape the future of advertising.

The Software Engineering team builds the products that make Criteo tick: from developing industry leading machine learning techniques, to building high scale/low latency real-time applications (over 5M qps, handling over 300 Bn HTTP requests daily), to delivering first class client interfaces, both API and UI, with brilliant UX at their core, all using state of the art technology.
What you'll do
Offer a reactive, efficient, modular ecosystem to ease relationships between your team partners through a high value & high quality inventory and encourage new solution explorations.
Build services that impact all Criteo R&D and collaborate with many different engineering teams.
Make determining choices for the business in a short latency and in a constraint environment.
Develop open source projects. As we are working at the forefront of technology, we are dealing with problems that few companies have faced.

Who you are
MS or PhD in Computer Science or equivalent.
You like working with problems involving huge amounts of data (Hadoop stack). You have an experience on streaming.
You are proficient in, at least one programming language such as C#, Scala, Java, C++. You can adapt very quickly, choose and use the best tool for the job.
You love algorithms and new technology. You are also a great team worker and a great communicator in English, both written and spoken. You are strongly committed to quality designs, automated testing and documentation.

What we offer
Competitive compensation package
35+ annual holidays days
Health insurance
Discounted transport
Personalized relocation package if moving from abroad
Catered lunch
Private nursery
Maternity and paternity leave
Annual cross teams hackathon
2 conferences per year of your choice
Internal mobility programs
Tailored educational resources

Want to know more?
What does it feel like to be part of something big? Get a snapshot
Get the story directly from our R&D engineers, check our Medium R&D blog
Interested in discovering your Criteo community first? Let’s meet

#LI-LL1

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Paris (75),CDI,40 000 € - 45 000 € par an,Data Engineer / Data Lake pour une scale up,Data Recrutement,- Paris (75),"Soyez alerté de la prochaine offre similaire en cliquant ici.
Data Engineer / Data Lake pour une scale up
Offre publiée le 18-05-2020.
Paris
Fonction Data engineer hadoop spark
Technologies Python
Technologies Spark
Technologies Sql
Expérience 1 à 2 ans
Expérience 3 à 5 ans
Expérience 6 à 10 ans
Statut CDI
Min 40k€
Max 65k€
L’ENTREPRISE : UNE STARTUP SPÉCIALISÉE DANS LE MARKETING MOBILE
Cette startup propose une technologie intégrée à des milliers d’applications qui permet de créer des profils d’utilisateurs mobile extrêmement précis. (100% RGPD compliant).
Quelques chiffres :
Startup créée en 2014
Rentable dès sa première année
+400M d’utilisateurs actif sur Android
+20M€ de levée de fonds (3 levées)
14 bureaux
International : +300 clients
Stack Technique du poste : Java, Phyton, AWS, Airflow / AWS Data pipeline, SQL, NoSQL, AWS Redshift, Azure SQL Data Warehouse, OLTP, OLAP, Hive, Presto, Kafka
VOTRE MISSION : RENDRE LA DONNÉE ACCESSIBLE
Au sein d’une équipe composée d’un tech lead, d’un product owner et de deux data engineer, vous oeuvrez à :
Développer des ETL en utilisant Airflow ou AWS Data pipeline pour traiter les GB/TB de données avec Spark
Participer à l‘architecture du Data Lake (~1 pétaoctets) sur AWS
Développer un API REST pour rendre les données accessibles aux autres membres de la société : Data Scientist, ….
Participer à la mise en place des méthodologies Agile/Scrum
Travailler dans un environnement startup en forte croissance
VOTRE PROFIL : DATA ENGINEER / DATA LAKE
Junior, confirmé ou sénior, idéalement diplômé d’une école d’ingénieur ou d’informatique, avec :
Expérience en tant que développeur (Backend Developer, Data Engineer ou Software developer)
Plus d’un an d’expérience avec au moins une plate-forme Cloud (AWS, GCP, Azure)
Bonnes compétences en SQL
Bonnes compétences en résolution de problèmes et en algorithmique
Anglais obligatoire (écrit indispensable + bonne expression et compréhension orale)
LES + :
Expérience avec Python
Expérience avec Spark
Expérience avec un entrepôt de données (AWS Redshift, Azure SQL Data Warehouse, ….)
Bonne compréhension des données en général, des systèmes OLTP et OLAP, des technologies SQL et NoSQL
Expérience avec diverses solutions Big Data telles que Hive, Presto, Kafka
Expérience avec Github, Jira, Confluence, Asana
MODALITÉS :
Poste Basé à Paris
Salaire selon profil :
Junior : 40/45K€
Confirmé : 45/55K€
Sénior : 55/65K€

Sélectionné par
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),40 000 € - 60 000 € par an,,Data engineer – Optimisation énergétique & Industrie,In-Team,- Paris (75),"Vous êtes Data engineer et recherchez un nouveau challenge dans le secteur de l’énergie ?
Alors rejoignez cette société qui développe une solution Saas à destination des grands groupes industriels.
Leur cœur de métier ? En appliquant les outils d’intelligence artificiel, de data science et de machine learning au concept d’ontologie, ils fournissent à leurs clients des solutions sur mesure d’optimisation énergétique.
Ayant levé 4 millions d’euros en 2017, ils poursuivent leur internationalisation et cherche à renforcer leur équipe data avec un nouveau data engineer.
Au programme : Java/Scala, Nifi, Kafka, Spark, Storm
VOTRE ROLE
Au sein de l’équipe data votre rôle sera de :
Travailler sur l’ingestion des données en temps réel (Nifi, Kafka)
Travailler sur leurs persistances (HDFS, InfluxDB, PostgreSQL)
Travailler sur leurs traitements en streaming ou batch avec des frameworks de calcul (Flink, Spark, Storm)
Faire de la R&D
VOTRE PROFIL
Bac +5
Une 1ère expérience de data engineer sur des problématiques de temps réel
Une connaissance et/ou une appétence pour le secteur de l’énergie est un vrai plus
OPPORTUNITE
Utiliser vos compétences au sein d’un projet dynamique et innovant
Rejoindre un startup’ en plein essor et en pleine internationalisation
Rejoindre une structure ayant une culture de la formation et de la montée en compétences
Avoir des perspectives d’évolutions en interne
LE SALAIRE ?
40-60k€ selon profil
Si vous aimez :
Le challenge technique et les projets d’envergure
Travailler dans un environnement technologique stimulant
Mettre vos idées en avant et les mettre en application de A à Z
Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !

Tel :
Afficher le nº de téléphone
__
6 Cité de l’Ameublement
75011 Paris
www.inteam.fr"
Paris 15e (75),CDI,,Architecte data H/F,Credit Agricole Assurances,- Paris 15e (75),"Crédit Agricole Assurances, premier assureur en France, rassemble les filiales assurances du Crédit Agricole. Le groupe propose une gamme de produits et services en épargne, retraite, santé, prévoyance et assurance des biens. Ils sont distribués par les banques du groupe Crédit Agricole en France et dans 9 pays dans le monde, par des conseillers en gestion patrimoniale et des agents généraux. Les compagnies de Crédit Agricole Assurances s'adressent aux particuliers, professionnels, agriculteurs et entreprises. A fin 2018, Crédit Agricole Assurances compte 4 600 collaborateurs et son chiffre d'affaires s'élève à 33,5 milliards d'euros (normes IFRS).
Référence
2019-41378
Date de parution
03/05/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Systèmes d'information / Maîtrise d'Ouvrage
Type de contrat
CDI
Poste avec management
Non
Cadre / Non Cadre
Cadre
Missions
Au sein de la Direction Transformation et Innovation IT, Vous serez rattaché(e) au Responsable Architecture. L'équipe Architecture a pour mission de concevoir la cible du SI, le cadre de référence associé et de vérifier sa bonne application au sein des projets.
Vous serez chargé(e) de définir l'architecture et la stratégie de données de l'Entreprise et de contribuer à la roadmap de mise en œuvre
Pour cela, vous allez contribuer et accompagner la transformation IT & SI

A ce titre, vos principales missions seront de :
En collaboration avec son responsable,
Définir l'architecture et la stratégie de données de l'Entreprise : nouvelles architectures Data Centric, API Management, Master Data Management, Omnicanal, Big Data, Data Analytics
Contribuer à la mise à jour du cadre de référence de l'architecture : cartographier et maintenir la documentation sur les données (Flux de données, API, dictionnaire de données, etc.), définir les principes d'architectures, élaborer les buildings blocks sur la donnée...
Contribuer à l’élaboration de trajectoires de la transformation des BU CAA en plaçant la donnée au cœur de ces transformations
Contribuer à la mise en place et animer la gouvernance des données avec la DSI et les directions métiers
Etre l'interlocuteur privilégié des équipes de réalisation des projets Data
Développer les sujets autour du Big Data
Effectuer de la veille technique et métier sur la data et l’architecture
Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 75 - Paris
Ville
36/44 Boulevard de Vaugirard,75015 PARIS
Critères candidat
Niveau d'études minimum
Bac + 5 / M2 et plus
Formation / Spécialisation
N/A
Niveau d'expérience minimum
11 ans et plus
Expérience
Une expérience de 10 années dans le domaine de l'architecture et 5 ans dans le domaine de l'assurance est indispensable.
Compétences recherchées
Bonne connaissance des technologies Data (principales solutions Open Source Big Data, principales offres Cloud, solutions de référence MDM, etc.)
Maîtrise des concepts de gestion de la donnée et des problématiques de sécurité associées
Une très bonne compréhension des sujets de data science
Bonne maîtrise des techniques de traitements et d'analyse (Big Data, Machine Learning, Intelligence Artificielle)
Bonne connaissance fonctionnelle sur les métiers de la banque et de l'assurance
Bonne connaissance dans les méthodes agiles et design thinking
Capacité d'abstraction, de communication et de synthèse sur des sujets complexes techniques
Autonomie et capacité d'adaptation aux changements d'organisation
Outils informatiques
Programmation Java JEE, Python, Angular HTML5
Docker Kubernetes et principes devops
Hadoop, kafka et suite big data
Architecture micro service, API management et event processing

Connaissance des processus de vente des produits assurances Epargne Retraite, Prévoyance et Assurance des emprunteurs."
Paris (75),,,Data Scientist Confirmé,Sept Lieues,- Paris (75),"Entreprise à taille humaine qui a développé une plateforme à l'aide de la collecte de données par différents capteurs.
Sous la responsabilité du Lead Data Science, vous rejoindrez l'équipe Data Science composée de 2 autres personnes en mode SCRUM. Vous travaillerez également en collaboration avec l'équipe Data Engineer.
LE POSTE / LES MISSIONS



Vos missions seront les suivantes :
Etat de l'Art
Amélioration de la plateforme en continue
Recueillir les données, les traiter et les analyser
Redaction Dashboard
Implémenter des solutions algorithmiques
Force de proposition

Vous travaillerez sur des données hétérogènes.
PROFIL RECHERCHÉ
Issu(e) d'une école d'ingénieur ou équivalent, vous justifiez d'une expérience de minimum 3 ans sur un poste similaire.
Vous disposez de connaissances en mathématiques, algèbre linéaire, probabilités et statistiques.
Vous maîtrisez Python, Java et Scala."
La Défense (92),,,Senior Analytics Architect for Industrie à La Défense (IDF) H/F,Altran,- La Défense (92),"Le World Class Center (WCC) Analytics est un centre d’expertise comprenant des Solution Managers, Chefs de projets, Architectes et autres Experts qui accompagnent les clients industriels internationaux du Groupe Altran dans des projets liés au domaine de l’analytics et de la Data Science (machine learning/analyse et traitement de données, traitement du signal et statistique pour la conception, la fabrication et le monitoring).

Dans le cadre du développement de ses activités et pour renforcer ses équipes, le WCC recrute un(e) Senior Analytics Architect.
Vos responsabilités
Vous intervenez au sein des équipes de l’antenne Française (Back Office UK) et vous participez aux projets d’envergure internationale et multi-industries de nos clients (santé, automobile, Aéronautique, Energie, industrie 4.0…). Vous êtes en charge des activités suivantes:
Conseil stratégique à nos clients (grands groupes à PME) dans le volet Analytics de leur transformation digitale (Rôle d’Analytics Partner)
Revues de pair de travaux analytics
Coaching des consultants ALTRAN en Analytics
Développement d’affaires en support des équipes commerciales
Contribution à des offres transverses expertises ex : Industrie 4.0 – Design & Innovation – Digital – Big Data
Participation à des Hackathon / Animation de workshops
Delivery des projets / Réalisation de prototypes R / Python / Matlab …
Votre profil
De formation BAC+5 (Ecole d’ingénieur ou Master) spécialisée en data sciences/analytics/statistique, vous justifiez d’au moins 5 ans d’expérience sur des projets/activités Analytics dans le monde industriel.

Vous avez une réelle compréhension des techniques de la majeur partie des techniques Analytics en Machine Learning et en statistiques. Vous êtes capable de:
proposer une démarche structurée efficace pour atteindre l’objectif, en participant à sa définition (vision d’architecte).
vous projeter / Identifier la valeur business potentielle / penser hors du cadre
Communiquer aisément avec les différents types d’interlocuteurs (experts techniques – décideurs – IT – chefs de projets)
Faire preuve de proactivité

Aussi, vous aimez évoluer dans un environnement international. De ce fait, vous parlez parfaitement anglais.
Ce poste est ouvert aux personnes en situation de handicap."
Paris 11e (75),CDI,35 000 € - 45 000 € par an,Ingénieur Python et Big Data & Développeur Back-end [CDI],Onogone,- Paris 11e (75),"Détails de l'annonce
ONOGONE est une équipe de développeurs et data-scientists spécialisée dans la recherche informatique appliquée et l'innovation. Nous développons des applications ambitieuses dans les domaines du web, de la Data Engineering, de la Data Science et de l'Intelligence Artificielle pour des clients prestigieux et intenationaux.

Êtes-vous indépendant(e) et passionné(e) par le codage du web, la modélisation, l'apprentissage automatique et surtout le traitement du langage naturel ? Rejoignez notre équipe pour développer des moteurs de recherche, des applications de suivi de l'information et de data-visualisation capables de produire des aperçus ou des prédictions en temps réel à partir de volumes de données gigantesques.

Nous recrutons trois développeurs back-end python et javascript disponibles dès que possible pour rejoindre notre start-up dans un incubateur numérique et culturel au centre de la ville de Paris.


Missions :
Vous participerez à des projets ambitieux de programmation et Data Science pour nos clients.
Vous apprendrez comment être un développeur à 360°, et éventuellement devenir un CTO entièrement capable.
Vous participerez au développement des technologies internes d'IA et d'NLP.
Compétences requises (2 ou plus) :
Algo : Python (tornado, flask), Javascript (NodeJS)
Data : MongoDB, ArangoDB, PostGreSQL, ElasticSearch, RabbitMQ
Linux, Docker
Compétences Appréciées :
Algo : Go, Java, Spark, Redis, Django
Front : AngularJS, ReactJS, D3JS
Data-Science: Machine Learning algorithms, connaissance des principaux réseaux de neurones, connaissance des paquets Python et des APIs
Profil recherché
Ingénieur informaticien, diplômé d'une école d'ingénieur ou/et avec un Master 2 en informatique.
Passionné, indépendant ; avec une première expérience professionnelle en Python / JS ou une expérience personnelle sur un projet achevé.
Désireux de maîtriser des environnements Web complets et curieux du domaine de la Data Science et des algorithmes de machine learning."
Paris (75),CDI,,Data Engineer - Commerce,Sept Lieues,- Paris (75),"Entreprise d'une quinzaine de personnes, qui utilise les outils de data / big data pour analyser le comportement des utilisateurs, lorsqu'ils font leurs courses, et leur proposer des promotions adaptées.
LE POSTE / LES MISSIONS
Vous rejoindrez l'équipe Data, composée de 6 personnes (Chief Data Officer, Data Scientists et BI) pour participer au projet d'automatisation et de personnalisation de la solution développée par l'entreprise.

Vous serez en charge de la partie Data Engineering.

Vos principales missions seront les suivantes:
Aider à mettre en production les modèles de machine learning développés par les Data Scientists
Faire tourner le code
Etre capable de découper les algorithmes (développés par les Data Scientits) et de les reconfigurer pour qu'ils soient bien écrits

Vous serez également en charge de la partie Devops / Data : être capable d'avoir un serveur qui tourne sous Amazon & savoir modifier / réparer l'architecture

Vous travaillerez en méthodologie agile et aurez la possibilité d'échanger avec toutes les personnes de l'entreprise (tech / sales / marketing).
PROFIL RECHERCHÉ
Formation d'Ingénieur Bac+5
Expérience sur des problématiques de data engineering
Maitrise d'un langage de programmation (Python, Node.JS, C++, etc.)
Expérience avec Spark
Bonnes connaissances algorithmiques / mathématiques

Vos plus: envie d'apprendre, curieux"
Paris 10e (75),,,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Company Description
Adevinta is a world leading online classifieds business that reaches more than 200 million people each month through our household name brands across 22 countries. Our brands include Leboncoin.fr, OLX, Vibbo.com, fotocasa, infojobs and Shpock to name a few.
Our brands are supported by tech hubs in Paris and Barcelona. Their goal is to develop common global product & innovation platforms which all of our brands can leverage; creating data and identity based ecosystems; empowering local entrepreneurs, delighting users, driving Adevinta's future growth and helping us achieve our mission of creating perfect matches on the world's most trusted marketplaces.
Image recognition is essential to many of the services we offer, for instance to understand what sellers are posting to our marketplaces and help buyers find specific items they are interested in. The image recognition team in Adevinta works with solving problems like these and many more.

Job Description
Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community

Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.

Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),CDI,,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Data Scientist (H/F) pour renforcer ses équipes.
Dirigée par le Chief Data Officer et rattachée au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques met en œuvre la stratégie DATA avec comme principales préoccupations
D’améliorer la gouvernance des données ;
De contribuer à la data réputation de la Banque de France ;
De tirer le meilleur parti des masses et de la diversité des données disponibles au sein de la banque Centrale,
De développer des projets d’intérêt commun
De développer une culture de la donnée au sein des unités métier

Présentation du Service
Au sein de la DDSA, le SIAD (Service Industrialisation et Algorithmique des Données) a pour missions de construire et entretenir les socles techniques BIG DATA, de réaliser des prototypes de solutions basées sur les approches Data Science et IA et de mettre à disposition des solutions business intelligence pour les équipes métier.

Descriptif de mission
Le pôle « Data Science et IA » cherche à renforcer ses capacités en recrutant un(e) Data Scientist.
Les missions de ce pôle, partie intégrante du domaine « conseil et expertise », sont les suivantes :
Cartographier de façon continue, en relation avec les équipes d’innovation et les urbanistes, les processus métier pour lesquels une approche Data Science pourrait procurer un avantage compétitif ou préserver un territoire acquis
Épauler les métiers dans la définition et la stabilisation de leurs besoins
Mettre en place de façon continue les Proofs of Concept (POC) fonctionnels et techniques issus des analyses d’opportunité
Benchmarker de façon régulière les outils du Big Data
Préparer l’industrialisation des POC identifiés comme pertinents
Accompagner la montée en compétence des équipes métier et des équipes techniques sur le Big Data
Sous l’autorité du « Lead Data Scientist », vous serez en charge plus particulièrement :
De la prise en charge des besoins métier et de leur analyse ;
De l’identification des solutions potentielles et du choix de la solution la plus adéquate au regard des besoins et contraintes tant métier que techniques ;
De la conception et de la mise en œuvre de la solution (POC, prototype, MVP),
De l’accompagnement et du soutien aux équipes projets en charge de l’industrialisation des solutions.

Profil recherché
De formation supérieure en informatique ou métiers de la donnée (Ingénieur ou équivalent), vous avez minimum 2 ans d’expérience dans la mise en œuvre de solutions mobilisant des connaissances statistiques et/ou mathématiques avancées, y compris en contexte d’apprentissage/alternance dans des contextes de travail variés (recherche, entreprises commerciales, sphère publique ) constituera un avantage clé.
Vous disposez d’une forte appétence pour la concrétisation de solution dans un environnement Bigdata.Par ailleurs, vous avez la maîtrise :Des sous-jacents mathématiques aux approches Bigdata / Data Science (mathématiques et statistiques, Machine Learning, réseaux de neurones ) et des bibliothèques de Machine Learning (Scikit Learn, PyTorch, )
Du développement en Python
Seraient en outre appréciées, dans l’un ou plusieurs des domaines suivants :
Une très bonne connaissance en développement sur la stack Hadoop (Oozie, Sqoop, Hive, Hbase, ), sur les technologies Spark (MLlib, SQL, GraphX et Streaming), en langages PySpark, Java et R (SparkR).
Une très bonne maitrise des outils de Search (ElasticSearch) et de streaming (Kafka)
Une bonne connaissance des bases de données NoSQL telles que Mongodb et Neo4J
Une bonne capacité à intégrer des sources de données multiples, internes / externes, structurées / non structurées et des interconnexions entre les SGBD et Hadoop
Une bonne capacité à restituer les résultats visuellement à l’aide de Kibana ou PowerBI
Une facilité à développer dans un environnement innovant en méthodologie Devops et Scrum
Rigoureux et apte à anticiper, vous avez le sens du résultat au service du client et êtes doté d’excellentes capacités de communication pour faciliter le travail « en réseau » :
Force de proposition et aisance de communication pour démontrer la valeur ajoutée des solutions Big Data et Machine Learning.
Excellente méthodologie de travail et de gestion de projet, vous travaillerez en mode agile.
Très bon relationnel, capacité à s'adapter, esprit d’équipe, ouverture d’esprit et curiosité naturelle, vous suivez l’évolution des technologies et nouveautés relatives au Big Data, Datascience et IA
Une bonne pratique de l’anglais est nécessaire.
Ce poste, en contrat à durée indéterminée, est basé à Paris (1er), avec des déplacements ponctuels dans les sites banque de France à Paris et en régions.
La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes."
Châtillon (92),52 000 € - 58 000 € par an,,Décisionnel MOE / Développeur Data Confirmé,PAC.JOBS,- Châtillon (92),"ENTREPRISE
PAC, cabinet spécialisé dans le recrutement et la délégation de compétences dans le domaine de l'informatique et du digital, recherche pour son client , un Décisionnel MOE / Développeur Data Confirmé à Châtillon (92) .
POSTE
Votre rôle sur le projet sera de :
Guider les analystes système, les ingénieurs, les programmeurs et autres sur les limites et les capacités du projet, les exigences de performance et les interfaces.
Analyser les défis d'intégration des systèmes liés aux données et proposer des solutions appropriées.
Examiner la nouvelle conception de l'application et recommander des corrections si nécessaire.

Vos missions seront réparties autour de 3 principaux axes :

Axe 1 : Les Normes
Analyse des besoins et production des spécifications.
Documentation des solutions (par exemple, modèles de données, configurations et installation).
Suivez les meilleures pratiques et les normes de sécurité pour toutes les données, y compris les données personnelles identifiables.
Assurez-vous que les solutions adhèrent et se conforment aux exigences de l'entreprise, aux normes d'intégrité des données et au cycle de vie du développement logiciel (SDLC).

Axe 2 : Spécifique au projet
Créer un flux de données Datasource / datawarehouse / datamart à partir de plusieurs sources (RH, informatique, ventes, finance)
Assurer la qualité et la cohérence des données grâce aux règles métier et au RDM d'entreprise
Développer les meilleures pratiques pour les conventions de dénomination standard et les pratiques de codage afin d'assurer la cohérence des modèles de données.
Recommander des opportunités de réutilisation des modèles de données dans de nouveaux environnements.
Développer des modèles de données selon les normes de l'entreprise.

Axe 3 : Qualité des données
Développer des rapports et des mesures standard sur la qualité des données
Valider les objets de données métiers pour leur précision et leur exhaustivité.

Environnement technique Datalake: Cloudera (bientôt remplacé par Azure Datalake)
Environnement de requête: Hue
Langues de requête: Hive / Impala
Intégration: Attunity (Qlik)
Suite bureautique
PROFIL
De formation supérieure en informatique, vous justifiez d'une expérience significative réussie sur ce type de poste ainsi que de 5 ans et plus d'une expérience pratique relationnelle, dimensionnelle et / ou analytique.
Une expérience en assurance / assistance serait appréciée

Compétences requises
Outils d'analyse et de modélisation des données : Power Designer, ERWin, ER / Studio)
SQL (expert)
VBA (avancé)
Plateformes RDBMS : SQL Server, Oracle, Netezza, Teradata, DB2 / UDB
Connaissance de PowerBI (DAX) et Visual Studio un atout
Expérience dans un environnement Dev / Ops avec intégration et déploiement continus via Visual Studio Team System
Maîtrise des solutions Microsoft Azure PaaS et SaaS, y compris Azure Functions, Logic Apps, .NET, JavaScript, Python, etc.
Maîtrise Microsoft Azure App Service Fabric, App Service Environment, technologies de la plateforme de gestion des API Microsoft Azure
Connaissance d'Azure SQL et d'autres offres Azure centrées sur les données et l'analyse
Connaissance Microsoft Visual Studio Team System, Azure Service Bus et Azure Notifications Hub
Bonne connaissance de la gestion des métadonnées, de la modélisation des données et du contrôle de version
Expérience avec l'entrepôt de données, le lac de données et les plateformes de Big Data d'entreprise dans des contextes multi-centres de données.
Capacité en modélisation de données, idéalement à partir de diverses méthodologies (3NF, modélisation dimensionnelle, coffre-fort de données...). pour des solutions efficaces
Solides compétences en gestion des parties prenantes et en établissement de relations auprès d'un large éventail de parties prenantes dans un environnement international, multiculturel et complexe
Capacité à communiquer clairement des idées techniques complexes, quelle que soit la capacité technique du public

CONTACT
Perrine Liénard
Afficher le nº de téléphone
perrine.lienard@pac.jobs

Salaire / rémunération : 415-425€/jour ou 52-58k€/an
Lieu : Châtillon (92)
Durée : CDIC ou Indépendant pour mission renouvelable
Référence : 6119"
Cachan (94),,,INGÉNIEUR DATASCIENCE (H/F),AViSTO,- Cachan (94),"Pour un de nos clients du secteur immobilier, AVISTO recrute un ingénieur Data Science, Machine Learning. Vous devrez mettre votre savoir-faire en data science (modèles de données, programmation, statistiques, machine learning, analyse et visualisation de données structurées et non structurées, etc.) à la disposition des métiers du groupe.

Dans ce cadre, vos missions seront les suivantes :
Construire les modèles de prédictions sur des problèmes d’exploitation de la donnée
Créer de la valeur à partir des jeux de données existants
Conseiller les clients sur leurs enjeux data, et y répondre notamment grâce à la plateforme
Mener des études R&D, utiliser les derniers outils de Data Science / Big data

Profil recherché

Ce qui est très important pour candidater à ce poste :
Être ingénieur BAC+5 en Computer Science ou Statistiques
Idéalement une expérience de 3 ans dans la Data
Expérience en modélisation mathématique ou en Machine Learning
Expérience en Python ou en R
Connaissances en SQL
Anglais courant (écrit et oral)

Être dynamique, motivé, créatif, rigoureux, doté d'un excellent relationnel et d'un très bon niveau technique.
Si vous souhaitez travailler dans un environnement convivial au sein d’une équipe technique passionnée. Vous pensez que ce poste est fait pour vous ? Envoyez-moi vite un mail à nouedy-bah-leclert@avisto.com

A propos de AViSTO
Rejoindre AViSTO, c’est intégrer une communauté de spécialistes en informatique passionnés par leur métier et par les nouvelles technologies. Les projets menés y sont ambitieux, dans des environnements où la haute technicité et l’innovation s’expriment pleinement.
Vous aimez les défis techniques ? Vous cherchez de vraies opportunités de carrière ? Alors rencontrons-nous !"
Saint-Ouen (93),,,DATA ARCHITECT,ALSTOM,- Saint-Ouen (93),"Req ID: 54315

We create smart innovations to meet the mobility challenges of now and the future. We design and manufacture a complete range of transportation systems, from high-speed trains to electric buses, autonomous subways, signalling and digital mobility solutions. Joining us means joining a truly global community of 36 300 people dedicated to solving real-world mobility challenges and achieving international projects with sustainable local impact.
What are my responsibilities?
As Data Architect, you lead the industrialization and the deployment of our PHM applications worldwide. You partner with our data capture experts, fellow data scientists and IT guys to create a cohesive working environment driven by curiosity and innovation.
Your responsibilities include:
Contributing to the design and development of the architecture of the data platform which hosts our PHM applications.
Adapting the dataflow management and data storage strategy to our range of solutions and customers, partnering with PHM data scientists, PHM engineers and our customer’s IT department and our Alstom IS&T.
Ensuring the maintainability, upgradeability and scalability of our solutions through careful planning of feature deployment at the platform level, in agreement with the product roadmap defined by the Solution Director.
Supporting the team in planning a development roadmap.
Contributing hands-on to the actual implementation of the platform functionalities.

What do I need to qualify for this job?
In addition to being a technical expert, your analytical and creative mind makes you a problem solver, driven by the curiosity and excitement to be building the mobility of the future. You also demonstrate the ability to work in an international and multidisciplinary team.

Minimum qualifications
5 to 15 years of experience with a software vendor, IT service provider or digital player.
Proven experience in designing and developing production-grade data applications, including data model design
Fluent in English.
Extensive knowledge of data processing and storage, in Java or/and Python, PostgresSQL
Extensive knowledge of Kubernetes and Linux environment.
Engineering degree in computer science, software engineering or equivalent combination of training.

Preferred qualifications
Additional language (French is a plus).
Extensive knowledge of Apache Nifi (a plus), OpenFaaS and ElasticSearch.
Experience of Cloud providers like Microsoft Azure or AWS, including security and VPN
Experience of Machine Learing in Python or R.
We believe that a diverse and inclusive workforce is a lever to running a sustainable and successful business. We are dedicated to creating an inclusive environment where all our employees are encouraged to reach their full potential, and individual differences are valued and respected.

Job Segment: Database, Computer Science, Developer, Java, Cloud, Technology"
Paris (75),CDI,,Agile Data Architect,Sfeir,- Paris (75),"Be part of the most innovative European Dev community

Envision - Make Real - Learn & Share

#PlatformData #MachineLearning #Insight #DataViz #Training

Notre vision de l’Architecte Data:
Tu interviens sur des missions d’expertises dans des contextes variés.
Tu es capable d'expliquer des choix d'architecture.

Tu es capable d'appréhender ces contextes client et de construire une plateforme pour valoriser leurs données.
Tu es à l’aise sur l’un des langage suivant (Python, Java, Go) et tu as utilisé des frameworks de calculs distribués (Spark, Beam,…).

Tu sais choisir la bonne solution de stockage en fonction des besoins (SQL, NoSQL, Search engine,...).
Tu sais partager auprès des clients et des Sfeirien.ne.s.
Tu connais les principes du développement Cloud et des chaînes CI/CD.
Tu sais former les équipes aux bonnes pratiques.
Tu incarnes l’expertise de SFEIR auprès des clients et tu peux leur fournir conseil et accompagnement.
Tu participes aux RAO, cadrage, spécifications, et es capable de rédiger des documents d’architecture technique et livrables pour les clients.
Tu as des connaissances en machine learning.

Tu rejoins un pôle d’experts dédiés aux projets Data parmi les plus pointus du marché.
Les sujets sur lesquels tu pourras évoluer et progresser :
Rejoindre des projets Data parmi les plus pointus du marché.
Open Source (Spark/Elasticsearch/Cassandra/Mongo/Kafka/Airflow and Co)
Les stacks data dans le Cloud (Google, AWS, Azure)
Statistical programming (Python/TensorFlow)
Machine Learning (NLP, Computer Vision, forecasting, predictive analytics)

Avec les autres Sfeirien.ne.s, tu pourras participer à nos soirées Cloud Nights, Quarters Back, ou à nos formations SFEIR School GCP, Go, Python, K8s.
Tu retrouveras aussi nos Sfeirien.ne.s aux conférences Google Cloud Summit et Google Next.
Notre process de recrutement: les PlayOffs, 3 tests d’évaluation technique en peer-programming (Algorithme, Langage, IaC).
Angelo, SFERIEN depuis 3 ans - Developpeur Agile Web: « Lorsque j’ai passé les PlayOffs, c’était une expérience très enrichissante. J’ai rencontré des évaluateurs brillants, bienveillants, où j’ai appris des choses, en mode coaching ».

En quoi SFEIR est différent ?
Nicolas, SFEIRIEN depuis 8 ans - Software Architect & Team Leader
“C'est un état d'esprit. L'humain avant tout. La fierté d'être développeur. Le salaire au dessus du marché aussi. Les consultants sont pris en considération. Nous appartenons à une famille. Tout le monde est facile à vivre et toujours prêt à aider. Chez SFEIR, nous donnons à chacun la possibilité de se développer. Il y a souvent un fossé entre ce qu'une entreprise communique & la réalité quotidienne. Pas chez SFEIR.”

5 raisons qui te feront aimer SFEIR

Apprends des meilleurs
Tu travailles avec les meilleurs développeurs de ton domaine qui ont développé des solutions techniques les plus innovantes.

Avoir de l'impact
Nous envisageons l'avenir en travaillant avec les plus grands. Google, Linux Foundations, Apigee, Louis Vuitton, Teads, Decathlon, Webedia nous font confiance pour livrer leurs projets internationaux.

Partages et transmets
Chez SFEIR, l'action de chacun compte. Vous pouvez donc avoir un impact direct sur la gouvernance de l'entreprise à travers différents rôles: évaluateur, conférencier, formateur, ambassadeur.

Booste ta carrière
Nous travaillons sur plus de 100 projets simultanés, autant de chances de trouver un environnement propice à ton épanouissement.

Diversité
Il y a 26 nationalités différentes parmi les Sfeiriens, avec une tranche d'âge de 20 à 63 ans, et un âge moyen de 31 ans, dont 25% de femmes développeuses.

“De quoi es-tu le plus fier, depuis que tu es chez Sfeir?”
“De ma progression”
Angelo, SFEIRIEN depuis 6 ans - Tech Lead Full Stack"
Paris (75),"Intérim, Stage",,SOFTWARE ENGINEER INTERN FOR ~6 MONTHS STARTING AUGUST 2020,Scortex,- Paris (75),"JOB DESCRIPTION
Working as a software engineer in a cross-domain machine learning and engineering team, you will help design and build the machine learning platform that supports both the research and the delivery machine learning teams in their endeavor to ship ever better machine learning models at increasing paces. This platform will slowly open to less and less technical users to allow them to interact with the machine learning process which is at the core of the Scortex Quality Inspection Solution.
You will:
handle complex and high throughput data flows
help design and implement the software library built to support and automate machine learning tasks
work on the deployment, logging and monitoring of machine learning models in production
build, improve and maintain the tooling made available to the users of the platform (command-line tools, web tools, …)
design, populate and maintain MongoDB / PostgreSQL databases
build and maintain APIs to integrate the machine learning business logic to the Scortex software ecosystem
help integrate existing external tools
PREFERRED EXPERIENCE
Hands-on experience with Python 3
Software engineering/architecture experience
Database management and usage experience
Strong organizational, problem-solving and communication skills
Strong algorithm complexity knowledge
Parallel system and algorithm experience
Interest for Machine Learning
Experience in building a multi-user, multi-developer library
Pragmatism when considering a new tool or software design
Fullstack skills would be a plus
Knowledge of the data engineering ecosystem is a plus
You’re passionate and always up to date with new tools and practices, and are willing to improve the whole ecosystem you’re evolving in.
ADDITIONAL INFORMATION
Contract Type: Internship
Start Date: 16 August 2020
Location: Paris, France (75013)
Education Level: Master's Degree"
Paris (75),,,Data Architect F/H,Saagie,- Paris (75),"Data Architect F/H
Paris
CDI
Postuler
Retour
Data Architect F/H
Saagie recrute !
À propos
Saagie (which means Heron in Japanese) is a french startup of 75 people with offices in Paris, Normandy (Rouen) & New York City.
Saagie provides a ready to go DataOps Orchestrator.
Saagie is leading the way in big data analytics by providing DataOps Orchestration that accelerates and operationalizes analytic projects. Their mission is to unify people, process and technology enabling organizations to deliver projects from raw data to production in weeks. Saagie delivers unmatched time-to-value, is “open by design” with isolated containers, strong network engineering as well as transparent security and governance bringing trust, privacy, audit and traceability to analytic projects. Saagie includes best-in-class integration with open source and commercial technologies to support today’s Big Data/AI and analytic use cases enabling global companies to realize value from their data intensive initiatives. Ultimately, Saagie provides a Plug and Play Orchestrator for DataOps that accelerates the distribution of Artificial Intelligence (AI) and Big Data to give companies a competitive advantage across industries.
Descriptif du poste
Nous recherchons un(e) data architect (5 ans d'expérience minimum dans le big data) pour rejoindre notre équipe service.
Vos missions seront :
Définir l'architecture technique et participer au choix des technologies sur les projets Data de nos clients
Accompagner, conseiller nos clients et partenaires dans l’intégration de leurs projets Data dans leur SI
Etre force de proposition et pousser les bonnes pratiques d'architecture et de gouvernance des données chez nos clients
Préparer et donner des formations sur les technologies Big Data.
Accompagner la force commerciale et vulgariser les technologies de Saagie auprès de nos clients.
Participer au cadrage des projets, à l’élaboration de propositions d’accompagnement, et au delivery des projets portés par l'équipe Service Saagie
Vous rejoindrez une équipe pluridisciplinaire composée de développeurs expérimentés, de data scientists et de data engineers.
Le télétravail occasionnel tout à fait possible !
Vous vous reconnaissez ? Parlons-en !
Profil recherché
Une expérience sur un/des projets Big Data d'envergure (clusters conséquents, architecture temps réél critique...)
Une bonne culture des technologies de l'écosystème Big Data
Une bonne expérience dans l'organisation des projets data
Etre déjà intervenu sur des projets de Data Science impliquant de travailler avec des Data Scientists sur leurs algorithmes
Langages : Scala et/ou Python
Une expérience sur de la récupération/traitement de données en temps réel (Kafka, Spark Streaming, Flink ...) serait un plus
La connaissance d'un outil d'orchestration (Mesos, Kubernetes) est fortement souhaitée
Curieux(se)
Autonome
Avec le sens du service (accompagnement, support, formation client)
A l'aise en anglais (à l'écrit et à l'oral)
Process de recrutement
Premier call puis entretien avec notre Talent Acquisition Manager.
Entretien avec un-e manager de notre team Service.
Entretien technique sur les différentes technologies Big Data.
Une immersion au sein de l'équipe pourra également vous être proposée (1/2 à 1 journée).
Informations complémentaires
Type de contrat : CDI
Lieu : Paris, France (75008)
Niveau d'études : Bac +5 / Master
Expérience : > 5 ans
Postuler"
Paris (75),,,Data Scientist,Akur8,- Paris (75),"Akur8 develops a SaaS platform which helps insurance companies in their pricing strategy to ensure that their prices as are competitive as they can be. To do so, we rely on cutting-edge AI modelling and heavy cloud-computing, leveraging the most recent technology.
You may know pretty well how to build complex models using state of the art machine learning techniques. However, when it comes to describe a complex phenomenon with a simple and interpretable model, you may have no other ideas than to ‘hack’ a Gradient Boosting or a Multi Layered Perceptron. With researchers from ENS-INRIA we built the fundamentals of an optimization technique that is interpretable by design. We bring non-linear penalized regressions to the next level using state of the art optimization advances: if you're curious about the subject, you can take a look at our collaboration paper with a Google AI researcher.
As a data scientist, you will contribute to the design of machine-learning models to enhance risk modelling, demand modelling (probability of potential clients to buy our products or renew their contracts) and price optimization (determine best price to sell the insurance product).
Practically you will begin by... :
Reading, understanding and explaining to the team strengths and weaknesses of research papers in ML, algorithmic and optimization
Implement pragmatic solutions and test their robustness on our data
Optimize your code using Cython, to achieve the same performance of open-source packages such as Numpy or Scikit-learn.
... and integrate your findings in production:
Implement reliable tests, use continuous integration and exploit at best AWS Cloud capabilities with our back-end engineers.
Your work will:
Rely on a strong understanding of the machine learning methods and optimization techniques used (R&D papers)
Take into account the business objectives of the models created (in particular: robustness, interpretability and implementation cost).
Design, build, integrate and maintain efficient, reusable and reliable code.
Requirements
High proficiency in mathematics (in particular statistics), algorithmic (optimization), and programming.
Knowledge in machine learning, signal processing, speech recognition or image processing.
Interest in R&D topics
Strong problem solving skills: high level of rigor, integrity, curiosity and self-motivation.
Communication and presentation skills.
Excited about code craftsmanship, to build robust code with the best practices.
Comfortable with Python (NumPy, Pandas, ...) and knowledge of an object-oriented language (Java, C#...)
Bonus:
Experience with Scikit-Learn API and its coding standards.
Experience with Docker, Terraform is a plus.
Benefits
You'll join a motivate team, willing to share their knowledge and passion for advanced computer science and software development."
Paris (75),,,Data Scientist Senior,IPANEMA CONSULTING,- Paris (75),"Contexte
Dans le cadre de son développement d’activité, IPANEMA CONSULTING recherche data scientist.
La mission sera en étroite collaboration avec les fondateurs du projet et le CTO.
Mindset ipanema
Notre Vision est que la Révolution Numérique est une opportunité à saisir pour chaque entreprise, que les entreprises ont le droit à développer une vision augmentée d’elles même, Nous croyons aux démarches de conduite du changement pour faire évoluer les organisations dans une culture « Data Centric »
A l’ère du Digital, notre vision est que les entreprises ont plus que besoin de se ré-inventer grâce à des solutions non fantasmées, alignées et coordonnées avec précision.
Intégrer une communauté de « Data Refiners » et de mettre la puissance de l’intelligence artificielle au cœur de la transformation des entreprises et des administrations.
Notre mission
IPANEMA CONSULTING est un cabinet d’accompagnement à la transformation Numérique qui fédère des talents autour de la stratégie, du change management et de la data.
En plaçant la technologie et l’humain au cœur de la transition, nos équipes proposent des solutions pour les challenges des entreprises de demain.
La force de notre écosystème
Nous avons développé un écosystème fort pour accompagner nos clients dans leurs enjeux d’innovation et pour leur adresser des solutions les plus complètes possibles.
(M&A spécialisé en Tech, lab de starts up, accélérateur de starts up, expertises stratégie, expertise Océan Bleu, expertise Design thinking, expertise Data et blokchain).
Talent recherche :
Issu d’un cursus statistiques, mathématique ou ingénieur école top 5, justification de 2 ans d’expérience dans l’intelligence artificielle (Chatbots, RPA, NLG, etc.) ou la Data Science,
Compétences en : Les langages statistiques (Python, R, etc.), le datamining, la connaissance des algorithmes de machine de learning et de deep learning, les langages NLG
Maitrise de l’écosystème Hadoop, Spark, Kafka ainsi que son intégration dans une architecture d’entreprise, connaissances en bases de données SQL et NoSQL, et ETL
Bon relationnel équipe et client
Sens de l’écoute, force de propositions et envie de partager tes connaissances et savoir-faire et d’apprendre de tes pairs.
Missions :
Bien plus qu’un emploi, une véritable aventure humaine au sein d’un marché prometteur
Faire des recommandations business qui vont servir à la prise de décision et influencer la stratégie proposée aux clients
Utiliser les technologies Big data et les méthodes d’analyses afin d’accompagner nos clients de l’idée à l’action en déployant leurs dispositifs de pilotage et d’aide à la décision.
Construire des algorithmes pour améliorer les résultats de recherches et de Ciblage
Construire des modèles prédictifs
Développer des métriques pertinentes d’aide à la décision.
Début
Dès que possible
NB : Pour intégrer ses nouveaux collaborateurs, IPANEMA CONSULTING a conçu un programme spécifique d’intégration.
Rémunération
En fonction de l’expérience."
Levallois-Perret (92),"Temps plein, CDI",,FULL REMOTE Senior Data Scientist H/F - CDI,Jellysmack,- Levallois-Perret (92),"Nous continuons de recruter et avons adapté notre processus de recrutement. Tous nos entretiens, ainsi que l’onboarding, se déroulent désormais en full remote.
Cette offre d'emploi est proposée en FULL REMOTE
Jellysmack est une entreprise spécialisée dans la création de contenus vidéos originaux sur les réseaux sociaux. Avec plus de 3 milliards de vues par mois, Jellysmack a connu une ascension fulgurante, ne cesse de grandir et ambitionne de devenir le leader mondial dans son domaine. La recette de ce succès repose sur la qualité de nos contenus, mais aussi sur la technologie opérant en arrière-plan. Jellysmack a développé une suite d'outils propriétaires, propulsés par l'IA, permettant à nos équipes de contenu de publier, s'inspirer, comprendre la trend, analyser les résultats, mais bien plus encore, des outils qui analysent le contenu en ligne, les réactions des gens devant ce contenu, et déterminent ce que sera la tendance demain.
Après plus de 2 ans de développement technique, Jellysmack propose une technologie unique articulée autour de 3 produits qui visent à optimiser la création et la distribution sociale de vidéos.
L'équipe Tech œuvre pour la mise en place d’outils utilisés en interne par les équipes contenu afin de déterminer les sujets qui buzzent, les aider dans la création de contenu, suivre les performances des vidéos internes etc... en injectant dans chacun de ces produits une dose conséquente d’algorithmie, de statistiques et de machine / deep learning.
En lien direct avec le Head Of Data (basé en Corse), vous serez amené à travailler sur différentes problématiques - prioritairement axées autour du NLP - et sur des projets de taille très différentes, impliquant d’importantes quantités de données (plusieurs centaines de millions de vidéos stockées en base à date avec leur métadata textuelles, plus de 21 milliards de commentaires...).
Au sein d’une équipe de sept data scientist, vous serez le référent de l’équipe sur ces sujets d’analyse et de compréhension du langage et vous aurez un rôle consultatif.
Missions principales
Passer d'une problématique métier à un algorithme de data science
Passer d'un POC à un algorithme en production
Vulgariser un algorithme à l'état de l'art et être référent de l'équipe Data Science
Etre autonome sur les outils comme Git, avoir déjà travaillé sous docker - idéalement sous AWS
Quelques exemples de sujets :
Analyse de sentiments sur les commentaires des vidéos
Extraction de topics à partir des titres, descriptions, commentaires des vidéos
Catégorisation de vidéos en thématique à partir de l’ensemble des éléments textuels dont nous disposons
Génération automatique de titre/tag de vidéos...
Création d’un algorithme d’identification des meilleurs créateurs sur une thématique donnée
Analyse de vidéos (contenu et metadata) pour mieux comprendre la rétention des utilisateurs
Optimisation de coût sur l’acquisition de fans
Génération automatique de montage de vidéos...
Profil recherché
Docteur en computer science ou diplômé d’une maîtrise en data science, vous disposez d’au moins 5 ans d’expériences,
Une autonomie sur le passage en production d’algorithmes sera indispensable,
Vous êtes pédagogue sur la transmission de votre savoir,
Vous avez un très bon niveau de SQL (MySQL et PostgreSQL).
Avantages :
Participation au transport
Titre-restaurant / Panier
Type d'emploi : Temps plein, CDI
Expérience:
full remote senior data scientist h/f - cdi ou similaire: 1 an (Souhaité)"
Paris (75),Stage,,"Research Intern, 2020",Google,- Paris (75),"Applications are currently closed for this role. Applications for 2021 internship opportunities will open in the fall 2020.
To start the application process, you will need an updated CV or resume and a current unofficial or official transcript in English. Click on the “Apply” button on this page and provide the required materials in the appropriate sections (PDFs preferred):

1. In the “Resume Section:” attach an updated CV or resume

2. In the “Education Section:” attach a current or recent unofficial or official transcript in English.

Under “Degree Status,” select “Now attending” to upload a transcript.

Note: By applying to this position your application is automatically submitted to the following locations: Paris, France; Amsterdam, Netherlands; Grenoble, France
Minimum qualifications:
Currently enrolled in a Master’s or PhD degree in Computer Science or a related technical field.
Experience (classroom/work) in Natural Language Understanding, Neural Networks, Computer Vision, Machine Learning, Deep Learning, Algorithmic Foundations of Optimization, Data Science, Data Mining and/or Machine Intelligence/Artificial Intelligence.
Experience with one or more general purpose programming languages: Java, C++ or Python.
Experience with research communities and/or efforts, including having published papers (being listed as author) at conferences (e.g. NIPS, ICML, ACL, CVPR, etc).

Preferred qualifications:
Available to work full-time for a minimum of 13 weeks.
Returning to your degree after completing the internship.
Relevant work experience, including internships, full time industry experience or as a researcher in a lab.
Ability to design and execute on research agendas.
About the job

At Google, research-focused engineering interns are embedded throughout the company, contributing to the setup of large-scale tests and deploying promising ideas quickly and broadly. Ideas may come from internal projects as well as from collaborations with research programs at partner universities and technical institutes all over the world.

As a Research Intern, you'll work on creating experiments and prototyping implementations to designing new architectures. You will work on real-world problems including artificial intelligence, data mining, natural language processing, hardware and software performance analysis, improving compilers for mobile platforms, as well as core search and much more.
Research happens at Google everyday, on many different embedded teams throughout the company. Our research reaches the user through both services and products such as Search, Maps, Google Assistant, Google Translate, Google Cloud and our computing, storage, and networking infrastructure. To achieve this, we’re working on a wide variety of projects that utilize the latest state-of-the-art technologies that push the boundaries of what is possible.
Responsibilities
Participate in cutting edge research to develop solutions for real-world, large-scale problems.
At Google, we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Paris (75),,,CAT Reinsurance Data Base Engineering - (F/H),GIE AXA,- Paris (75),"Environment:

The AXA Group
AXA Group Risk Management Property & Casualty (GRM P&C) deals with the most sophisticated P&C challenges of a leading international insurance company, among which the management of natural catastrophe risk (CAT). Natural variability of climate and seismic activities have demonstrated their devastating potential, climate change bringing additional uncertainty for the future.
AXA’s rapid expansion – both in terms of geographical footprint and P&C insurance offer – widely exposes AXA to natural perils, being in charge of the financial protection of its clients and helping them live a better life.
In this context, AXA must maintain state-of-the-art CAT risk management techniques through permanent innovations.

The Departments
The internship will be based at the AXA Group Risk Management (GRM) department.
AXA GRM brings together high level and multidisciplinary staff with engineers, actuaries and financials split between Paris, Zürich and Madrid. Its main missions are focused on analysing, modeling and aggregating the Group’s risks (economic capital); implementing the process enabling to limit the undertaken risks (risk appetite, assets accumulation, longevity, natural catastrophe...) and optimizing the Group protections (reinsurance, securitization, hedging, etc.).
Within the P&C department, the intern position belongs to the GRM P&C CAT & Reinsurance Risk team (15 FTEs) which is organized in three excellence centers (CAT DATA R&D, R&D Modeling and Reinsurance). The intern will join this dynamic team dedicated to the monitoring and the modeling of Natural Hazard risks borne by the company.

As part of AXA’s Internal Model under the Solvency II framework, the GRM P&C CAT/RI teams are primarily in charge of delivering the annual CAT modeling process, mainly consisting of:
Collecting CAT exposure data (geographical, physical and financial information) on a per-entity (AXA France, AXA Mexico, AXA Philippines…) and per-location basis (houses, factories, vehicles etc);
Assessing the risk on a per-entity per-peril basis (cyclones, earthquakes, floods, hailstorms...)
Estimating the efficiency of the Group Reinsurance covers
The CAT modelling process has strong strategic and operational impacts since it feeds the Economic Capital, Economic Combined Ratio and CAT budget calculations which drives the earnings and the solvency position of AXA Group and determines adequate levels of reinsurance needs, which may boost or hinder profitability.

The CAT Reinsurance Data Base Engineer will play a strong role in the standardization of the reinsurance treaties and the implementation of key metrics to support the risk mitigation assessment and boost the understanding of the reinsurance performance.
Role and Responsibilities:
The reinsurance framework operated in AXA Group regroups diverse structures with complex mechanisms which must be accurately implemented in the reinsurance model to enable the risk assessment.

The accuracy of the CAT risk results is strongly impacted by the integration of the reinsurance treaties and mechanisms as an input data. The objective of the internship is to understand, reference, standardize and implement a reinsurance treaty database within the modeling framework to improve and eases the reinsurance modeling process:
Read, understand and reference the reinsurance treaties based on historical AXA books of reinsurance
Build a structured database to standardize the reinsurance treaty information and characteristics
Implement innovative tools for the reinsurance treaty standardization (ex: text mining …) and the import automation process within the reinsurance modeling
Identify key metric improvements to evaluate treaties efficiency on AXA risks
According to the advancement of the project, it will be also possible to work on the operational production of the CAT risk analysis which is performed on a yearly basis to compute the reinsurance capacity and efficiency. Beyond the possibility to acquire knowledge on how CAT risk is assessed and modelled within a leading insurance company, the intern will have the opportunity to be immersed within R&D activities and to work within an environment of technical excellence
Qualifications
Profile Requirements:
The candidate, , will have a specialization in actuarial, computer science, mathematics or equivalent (engineering schools…) with strong analytical skills and the ability to evolve in a technical environment:
Bachelor or Master’s degree
Interest for Reinsurance
Robust programming skills (R / Python / SQL …)
Knowledge in C# and/or Remetrica is a plus
French and Business English (spoken and written).
Team work
Autonomy
Creativity

About AXA
Would you like to wake up every day driven and inspired by our noble mission and to work together as one global team to empower people to live a better life? Here at AXA we strive to lead the transformation of our industry. We are looking for talented individuals who come from varied backgrounds, think differently and want to be part of this exciting transformation by challenging the status quo so we can push AXA - a leading global brand and one of the most innovative companies in our industry - onto even greater things.
In a fast-evolving world and with a presence in 64 countries, our 165,000 employees and exclusive distributors anticipate change to offer services and solutions tailored to the current and future needs of our 107 million customers.
The headquarters of the AXA Group, based in Paris 8th, brings together the Group's corporate activities. It coordinates the various entities with the Group's strategy, and is responsible for managing international projects. The headquarters has approximately 800 employees and is distinguished by its strong international culture (39 nationalities).
What We Offer
We provide you regular career opportunities in international teams. If you want to join us, don’t hesitate to apply !
Information provided by applicants will be processed in strict confidentiality and may be used exclusively for recruitment processes."
Paris (75),,,Senior Data Analyst,Artefact,- Paris (75),"Who we are

Artefact is a new generation of a data service provider, specialising in data consulting and data-driven information system, dedicated to transforming data into business impact across the entire value chain of organisations. We are proud to say we're enjoying skyrocketing growth.

Our broad range of data-driven solutions in data consulting and information system are designed to meet our clients' specific needs, always conceived with a business-centric approach and delivered with tangible results. Our data-driven services are built upon the deep AI expertise we've acquired with our 1000+ client base around the globe.

We have 1000 employees across 20 offices who are focused on accelerating digital transformation. Thanks to a unique mix of company assets: State of the art data technologies, lean AI agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client.

To support and develop its growth, Artefact is looking for the next talents of the data divizion to join the engineering team. Organized in feature team, you will work in project mode (ou pizza team) to advise your clients on their IA problematics, machine learning and Big Data. The projects you will work on can go from the migration of infrastructure to the Cloud (Deezer) to the construction of a predictive model of the water rises (Greenpeace).

What you will be doing: Key responsibilities

As a Data Analyst, your role will encompass:
Conducting projects to accompany the transformation of your clients' businesses through the effective collection, processing, and visualisation of data

Extracting valuable insights from our clients' marketing-related data sources.

Designing dashboards for marketing decision-making while taking into account the business needs

Accompanying our clients in the conception and implementation of data architectures and data pipelines, from collection to monitoring.

Actively contributing to the expertise level and competencies of the Data & Analytics team

Closely collaborate with the other divisions (Media & Activation, Creation, Consulting, Data Science and Data Engineer) to provide comprehensive services to your clients

Being a great tech role model

Demonstrating the skill and credibility required to ensure the success of our clients' initiatives

Researching and developing new technical approaches to address problems efficiently

Staying up-to-date on developments within the industry, sharing best practices and actively contributing to Artefact's institutional knowledge

Embodying Artefact's values and inspiring others to do the same

Qualifications: Education & experience required

Academic level of education (Bachelor or Master)

A minimum of 3 years of work experience as a data specialist

Verifiable knowledge and experience of web analytics platforms like Google Analytics, Adobe Analytics, WebTrekk etc.

Verifiable knowledge and experience of tag management systems like Google Tag Manager, Tag Commander, Tealium IQ Tag Management, Relay42 etc.

Verifiable knowledge and experience of website optimization tools like Optimizely, Google Optimize, Convert, AB Tasty etc.

Knowledge of Data Management Platforms like BlueKai, Krux, Ysance, Weborama, Relay42, Adobe Audience Manager, Tealium Audience Streams etc.

Knowledge of computer and web-related technologies:
Network techniques/protocols

JavaScript, CSS and HTML (optionally AJAX, JSON, Angular)

Database techniques (REST API's, SQL, No-SQL)

Cloud technology (Google Cloud Platform, Amazon Web Services, Microsoft Azure)

Optionally, knowledge of data processing and data modeling algorithms and techniques

What we are looking for

A Doer: you get things done and inspire your team to do the same

An Analyst: you LOVE data and think every company should take their decisions based on facts

A Pragmatist: you have a no-nonsense mindset that seeks for practical and realistic solutions

A Mentor: your clients and colleagues naturally seek you out for advice

An Adventurer: you're an entrepreneur constantly looking for business opportunities

Why you should join us

Artefact is the place to be: come and build the future of marketing

Progress: every day offers new challenges and new opportunities to learn

Culture: join the best team you could ever imagine

Entrepreneurship: you will be joining a team of driven entrepreneurs. We won't give up until we make a huge dent in this industry!

Come join us!"
Paris (75),,,Développeur - pôle Market Data (H/F),Natixis,- Paris (75),"Nous souhaitons renforcer le pôle « Market Data », qui comporte environ 20 personnes, dont deux tiers de développeurs basés à Paris et Porto et un tiers de business analysts, placées sous la responsabilité du responsable de pôle.
La principale application du pôle vise à alimenter en données de marchés (risk factors) les systèmes FO de booking et les systèmes des risques, pour les calculs quotidiens de risques et de valorisation de fin de journée.
Elle gère les workflows de collecte, contrôle et mise à disposition des market data de la totalité des classes d’actifs traités sur les marchés par la BFI de Natixis.
Ce référentiel transverse est donc une pièce importante et critique du SI Marchés et alimente également de nombreux autres clients de Natixis et du groupe BPCE.
Les challenges sont très nombreux, avec notamment des évolutions majeures à réaliser pour répondre aux nouvelles exigences règlementaires (FRTB, TRIM, IMM, RIM) et aux besoins accrus de maîtrise de la qualité des process métiers et des données utilisées (BCBS 239).
L’application connaît un développement important qui nécessite le renfort des capacités internes.
Son architecture technique est en cours de transformation, avec une place importante donnée aux technologies de type Hadoop (stockage de gros volumes, machine learning, etc.).
Les process SI sont gérés en mode agile.
Votre rôle dans l’équipe :
Projets et évolutions fonctionnelles :
Design des solutions, en interaction avec la MOA et le responsable d’équipe
Développement et tests
Documentation de maintenance et d’exploitation ; formation du support
Préparation des releases
Support :
Participer (rotations) aux astreintes et aux permanences de support
Prise en charge des actions correctives

De formation supérieure d’ingénieur en informatique ou équivalent. Vous avez des connaissances techniques autour du Big Data (Hadoop, Spark, Scala) et des Data Sciences (Machine Learning, Python).
Vous avez également des connaissances sur les opérations de marchés en vision FO ou Risques, acquises à travers une expérience professionnelle significative en CIB.
Vous maîtrisez le développement .Net C#,SQL et les Outillages complémentaires supportant les best practices agiles.
Vous possédez le goût du travail en équipe dans un environnement exigeant, avec de nombreuses interactions.
Vous savez communiquer de manière claire et concise.
Vous êtes dynamique, réactif et orienté client.
Vous êtes également organisé, rigoureux et force de proposition.
Votre niveau d'anglais est courant.
Site géographique: 30 Avenue Pierre Mendès-France - 75013 PARIS

Informations complémentaires sur le poste :
Convention collective applicable: Convention Collective de la Banque.
Responsable de recrutement: Marie Laure BERTIN."
Paris 2e (75),CDI,,Data Engineer F/H,YSANCE,- Paris 2e (75),"Afin d’agrandir notre équipe de Data Engineer, nous recherchons des

Data Engineer

, pour qui les traitements de la donnée n’ont plus de secret et leurs optimisations un vilain défaut.

Le/La Data Engineer sera amené(e) à intervenir directement chez nos clients ou à intégrer une équipe projet.

En tant que Data Engineer chez Ysance, vous serez amené(e) à :

✔️ Accompagner des équipes métiers dans leurs travaux d’identification et expression des besoins sur la data,

✔️ Concevoir des solutions nécessitant l’utilisation de technologies Big Data pour répondre à des cas d’usages métiers,

✔️ Développer et tester des flux d’ingestion de données de Data Lake et de traitement des données,

✔️ Contribuer à la mise à disposition des données au travers d’outils d’exploitation simples et rapides pour les clients,

✔️ Industrialiser et optimiser au quotidien des pipelines Data.

➕ En bonus :
✔️ Devenir un de nos futurs référents technique,

✔️ Participer aux recrutements de nouveaux collaborateurs,

✔️ Participer activement à la veille technologique,

✔️Animer des sessions de formations techniques en interne mais aussi en externe.

➡️ Environnement technique : Kafka, Hadoop, SQL, Hive, Spark, Python, NoSQL, Docker, Terraform, Ansible
Profil recherché Vous êtes titulaire d’un Bac +5 en informatique, avec une première expérience de 3 ans minimum sur des missions ou projets Data,

Vous possédez des compétences avancées autour des langages suivants : SQL et Python ou Scala,

Vous maîtrisez les bases de données relationnelles et NoSQL,

Vous possédez une bonne compréhension de l’ensemble des stacks Data : des pipelines ETL (Talend) aux outils analytics,

Vous avez une bonne maîtrise de l’optimisation des déploiements (Docker),

Vous détenez des connaissances autour des processus d’industrialisation (Terraform ou Ansible) et des outils d’orchestration.
Entreprise YSANCE est une société spécialisée dans le traitement de la Data.

Nous couvrons l'ensemble de la chaîne de valeur Data :
✔️ Intégration de données (Talend ETL, ESB, Data Quality)

✔️ Big Data (Cloudera, Hortonworks, Snowflake, Big Query)

✔️ Cloud (Amazon, Microsoft, Google)

✔️ Data Science, prédictif, prescriptif (R, Python, DataIku)

✔️ Analytics (QlikView, QlikSense, Tableau Software, Toucan Toco)

Nous avons également développé des offres autour du Référentiel Client Unique (RCU), du périmètre e-RFM et du Customer Analytics.

Dans le cadre de notre développement et de nos projets, nous recherchons de nouveaux talents passionnés comme nous par la Data.

✔️ Notre valeur ajoutée ?

Une forte expertise technique autour de la Data qui repose sur nos équipes et qui est renforcée par de nombreux partenariats avec les éditeurs dans le domaine du Big Data & Analytics.

✔️Pourquoi nous rejoindre ?

Une forte culture Data, des clients de renoms dans des secteurs variés, une approche orientée autour du besoin client afin de répondre au plus près de leurs enjeux.

Alors si intégrer une structure Data Driven à taille humaine répond à vos attentes professionnelles, c'est avec plaisir que nous échangerons avec nos consultants opérationnels.

A bientôt,"
Paris 3e (75),CDI,,Data Engineer / Ingénieur Big Data F/H,Soyhuce,- Paris 3e (75),"Vous souhaitez mettre en oeuvre vos talents au sein d’une jeune entreprise innovante, où bonne ambiance et défis techniques rythment notre quotidien ?

Dans le cadre du développement de ses activités de R&D et de ses missions de conseil, SoyHuCe est à la recherche d'un(e) Data Engineer pour consolider son équipe infrastructure et développement Big Data.

Descriptif du poste

Mission 1 : Conseil

Vous aurez pour rôle d’accompagner nos clients dans la conduite et la mise en oeuvre de leurs projets Big Data (traitements de données, déploiement d'infrastructure, data management, etc.).

Vous mobiliserez vos compétences en :
Data Analysis

Data Engineering

Data Visualisation

Gestion de projets Data

Déploiement d’architecture cloud

Opérant pour de clients grands comptes, dans des secteurs très variés, vous devrez :

Accompagner nos clients dans la mise en place de leur stratégie data et définir leurs roadmaps ;

Définir et concevoir l’architecture data ;

Définir et délivrer des solutions de data security, reporting et management ;

Mission 2 : R&D

En tant que Data Engineer chez SoyHuCe, vous évoluerez au sein d’une équipe d’une vingtaine de développeurs, ingénieurs en science des données, algorithmiciens, intégrateurs et graphistes.

Votre rôle sera de :
Accompagner nos clients sur la prise en main de notre plateforme Big Data;

Comprendre les besoins métiers de nos clients;

Concevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateforme;

Concevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big Data;

Contribuer au développement de notre offre Big Data;

Participer à la veille technologique.

Vous travaillerez conjointement avec les Data Scientists et le Data Architect déjà en poste et vous serez impliqué(e) dans la prise de décisions liée à notre solution Big Data et à son évolution. Vous participerez également à la construction d’un pôle Data au sein de l’entreprise.

Notre stack (en constante évolution):
Stockage de données: PostgreSQL, Cassandra, Kafka, ElasticSearch, MongoDB, Minio, Redis;

Cloud: AWS, GCP, Azure, OVH;

Orchestrateurs: Kubernetes;

Technologies Big Data : Spark; Cassandra, HDFS, Kafka, Knox, Jupyter ou Zepplin ;

Bases de données : PostgreSQL, MySQL, Oracle ;

Machine learning: Spark, Tensorflow, PyTorch, MXNet, Scikit-Learn;

Langages: Scala, Python, Golang, Shell ;

Outils : Kibana, Dataiku, Power BI.
Profil recherché Profil recherché

Diplômé(e) d’études supérieures dans le système d’information, computer sciences, big data (école d’ingénieurs, école spécialisée, école de commerce ou équivalent universitaire), vous avez 2 ans d’expérience minimum en BI et/ou Data engineering, ainsi qu’une expérience confirmée en conseil ou en gestion de projet.

Côté technique, vous possédez de solides bases en traitement de données avec Spark, Spark Streaming et Kafka dans un environnement Cloud ainsi qu’en base de données NoSQL.

Vous avez une expérience concrète sur la mise en place de pipelines complets de valorisation de données massives, de la collecte à la mise à disposition d’applications en passant par le traitement.

Vous êtes rigoureux(euse), ouvert(e), très curieux(euse) et adorez explorer et éprouver des nouvelles technologies.

Vous êtes passionné(e) par votre métier, aimez le faire partager, même à des personnes qui ne le connaissent pas.

Les avantages

Entreprise jeune en plein développement ;

Missions à forte valeur ajoutée (uses cases stratégiques, complexité des sujets) et variées ;

Environnement de start up innovant ;

Tickets restaurants Lunchr (valeur quotidienne unitaire 9,2 €) ;

Travail en lien avec de nombreux métiers coeurs du numérique : UX Designer, développeurs Front/back/fullstack, DevOps, Data Ingénieurs, Data Scientists ;

Une localisation idéale à Paris, au coeur du Marais.

Contrat

Le poste à pourvoir est un CDI, disponible immédiatement. Rémunération selon expérience.
Entreprise SOYHUCE

et un Studio R&D en algorithmie et data science, SoyHuCe accompagne les entreprises, et les collectivités dans leurs réflexions et projets numériques et métiers.

Les solutions que conçoit et développe SoyHuCe sont centrées sur les utilisateurs, mettant l'humain au coeur des organisations."
Paris (75),CDI,40 000 € - 50 000 € par an,Data Miner,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data scientist ml ia nlp dl
Taille entreprise de 51 à 200
Technologies Python
Technologies Tableau
Expérience Jeune à dipl me
Expérience 1 à 2 ans
Expérience 3 à 5 ans
Statut CDI
Min 40k€
Max 50k€
L’ENTREPRISE : UNE STARTUP SAAS DE DATA ANALYSE DE LA GREENTECH
L’entreprise a pour projet d’accélérer la transition écologique. Pour ce faire elle développe une solution SaaS de Data Analytics visant à améliorer l’efficacité énergétique.
Date de création : 2014
Croissance : double son CA tous les 12 mois
Levée de fonds série A de 2,5M€ et série B de 8M€
Plus de 120 clients
Effectif total : 75 personnes
Effectif technique : Plus de la moitié
MISSIONS : SOURCER DE NOUVELLES DONNÉES EN OPEN-DATA
En collaboration directe avec les data scientist et au sein de l’équipe R&D vous aurez à :
Identifier des données en open-data
Nettoyer et intégrer les données en vue de leur exploitation
Analyser les données pour répondre aux différents cas d’usage croisés chez les clients
Restituer ces analyses (dataviz, tableau…)
Communiquer avec les autres équipes
PROFIL RECHERCHÉ : DATA MINER AVEC UNE FORMATION EN DATA SCIENCE
Idéalement issu(e) d’une formation en data science
Vous êtes junior ou confirmé(e) l’entreprise à besoin de vous
Vous avez déjà travaillé sur du data mining à partir de source de données publiques
Python est votre langage de prédilection
Vous avez une expérience en data visualisation
Le fait d’être responsable d’une ouverture sur de nouveaux horizons pour l’entreprise vous attire
Le domaine de la transition écologique vous intéresse
POURQUOI LES REJOINDRE ?
Vous investir dans l’accélération de la transition écologique
Rejoindre une startup à un moment clé de sa croissance
Relever des responsabilités techniques à la hauteur de votre talent
Contribuer à un écosystème dynamique où les initiatives de chacun ont leur place
MODALITÉS :
Locaux : 10e arrondissement
Salaire : 40/50k€ selon profil et expériences
POUR EN SAVOIR PLUS : THOMAS.GOURMELON@DATARECRUTEMENT.FR
Merci d’envoyer au plus vite votre CV / votre profil LinkedIn par e-mail avec comme objet « Data Miner Greentech» à Thomas Gourmelon (thomas.gourmelon@datarecrutement.fr), responsable du Pôle Javascript & Mobile au sein de Data Recrutement.
Sélectionné par Thomas Gourmelon
Spécialiste Python, Ruby, Go & Data Scientist
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),CDI,,PRODUCT OWNER DATA (H/F),Epsilon France,- Paris (75),"EPSILON accompagne la transformation business des entreprises grâce à la data. Nous sommes le plus grand acteur datamarketing en France, avec 750 talents Adtech et Martech qui aident les entreprises à stimuler leur croissance et améliorer leur efficacité opérationnelle grâce et autour de la data.
Vous intégrez notre centre de compétences Data, rattaché au pôle Conseil Data et Implémentation Analytics Platform (cadrage fonctionnel et technique, définition de use-cases, stratégie des moyens, accompagnement du changement, mise en œuvre, maintenance et commercialisation de solutions).
QUE FAIT UN PRODUCT OWNER DATA
En charge des différentes phases du projet : pré-études, POC, Industrialisation et Run :
Il travaille main dans la main avec les différents PO des autres feature teams, les équipes data (IT, Analystes, Data Scientists,…) mais aussi les équipes Marketing et Commerciales pour définir les besoins data de l’entreprise (analyses, alimentation d’outils de CRM , création de reporting ou dataviz),
Décline les besoins en une roadmap qu’il incarne,
Priorise les évolutions du datalake au sein d’un backlog qu’il fait vivre avec l’équipe et communique sur l’avancement des réalisations data de l’équipe,
Il participe à la définition et la mise en place des best practices pour assurer la cohérence, la qualité et la conformité des datasets (harmonisation des modèles de données, KPIs, conformité GDPR,…).
Ses Missions et Livrables attendus :
Animation de story mappings et d’ateliers métiers
Recueil et formalisation des besoins métiers (proactivité dans l’identification de nouveaux usages)
Définition de roadmap partagée avec l’équipe (vision produit)
Rédaction complète des User Stories, en étroite collaboration avec les métiers et l’équipe Big Data
Priorisation et planification des User Stories (en coordination avec les métiers et les projets) / Tenue du Backlog
Garant de la qualité et de la conformité des livraisons de l’équipe Big Data avec le besoin métier initial
Etablit le Profiling des données
Définit la modélisation de la donnée en collaboration avec l’équipe et les autres PO Data
Reporting d’avancement des développements et remontée des risques
Co-animation des instances de pilotage avec le chef de projet MOE
Production de la documentation nécessaire à la bonne communication autour des usages délivrés (spécifications, fiches usages, présentation des résultats, flash info)
Interlocuteur privilégié des différents acteurs Métiers et IT
Participation au maintien du dictionnaire de données, en lien avec les data owners et le DPO
Mise en place du cahier de recette fonctionnelle en collaboration avec les différents métiers
Définition des contrats d’usage, qui encadrent l’accès des utilisateurs au Datalake.
VOUS MARQUEZ DES POINTS SI
Issu(e) de l’intégration BI/BIG Data ou des métiers de la Data Science, vous avez développé des compétences en gestion de projet et en méthode Agile (Scrum, SAFE).
Votre parcours vous a permis d’acquérir de solides connaissances sur la gestion des datas au service des usages métier. Idéalement, vous avez déjà travaillé sur des problématiques de qualité de la donnée (dictionnaires, monitoring, lignage de données, ...), et savez manipuler les données pour des analyses de premier niveau (SQL, Python, ).
Vous êtes sensible aux nouvelles tendances liées à la collecte, à la réconciliation, au stockage et à l’exploitation des données digitales (Big Data, DMP,…). Vous disposez notamment de connaissances sur les environnements Big Data.
Vous êtes un bon communiquant, à l’aise avec des interlocuteurs métiers et IT.
Pour accompagner notre activité en pleine croissance, nous recherchons des personnes passionnées, curieuses, créatives et innovantes.
La maitrise de l’anglais est indispensable pour intervenir auprès de nos clients internationaux."
Saint-Ouen (93),CDI,,Développeur big data H/F,GFI,- Saint-Ouen (93),"Qui sommes-nous ? Une entreprise agile, internationale et en pleine croissance vers les nouvelles technologies !

Développeur big data - H/F
Rejoignez notre Practice Smart Data et accompagner nos Experts Data (Big Data/ BI/ Data Management) en mission auprès de nos grands comptes sur des sujets stratégiques et aux enjeux forts !
Nous recrutons un Data Engineer H/F.
Vos missions sont les suivantes :
Etre fidèle aux best-practices DevOps
Travailler sur la mise en place d’infrastructures Big Data
Réaliser les flux de données
Valider leur fonctionnement en sécurité et performance
Assurer la pérennité de leurs évolutions

Nos ambitions ?
Encore plus de croissance !
Un plan de carrière personnalisé et adapté à vos souhaits d’évolution
Des formations ciblées
Des partenariats technologiques prestigieux
Une mobilité nationale et internationale
Des missions digitales via notre centre d’innovation

Pourquoi nous rejoindre ?
Acteur européen de référence des services numériques et éditeur de logiciels, GFI c’est 19 000 collaborateurs présents dans 20 pays et 40 villes en France.
En s’appuyant sur son expertise dans 5 branches (Consulting, Applications Services, Enterprise Solutions, Infrastructure Services et Software), le Groupe met au service de ses clients une combinaison unique de proximité, de solutions de qualité industrielle et d’innovation.
Notre division « Banque Finance et Assurance – IDF » compte près de 4700 collaborateurs, capitalise plus de 47 ans d'expérience et intervient auprès de clients grands comptes au sein des marchés bancaires et de l'assurance.

Une devise ? Vos idées, nos challenges !

#RejoignezUneEquipeQuiGagne #gfi #gfiinformatique #happygfi #happybfa #teamgfi #innovation #digital #developpeur #développeuse #java #angular #conception #banque #assurance

Plus d’infos : https://gfi.world/fr-fr/groupe

Profil
Qui êtes-vous ?
Ingénieur ou universitaire Bac +5 et spécialisé en Big Data, vous justifiez d’une première expérience significative et réussie (minimum 2 ans) dans un environnement Big Data.

Qu’attendons-nous ?

Environnement technique maitrisé :
Hadoop, Spark, Hive, Impala, ETL (Talend, Informatica, …), Java, Scala, Python, SQL, les bases de données SQL (oracle, …) et NoSQL (Cassandra, …).
Des notions de Machine Learning et d’IA sont recommandées pour bien appréhender les besoins de nos Data Scientists.
Vous maitrisez l’anglais.
Vous êtes curieux(se), passionné(e), technophile, créatif(ve) et adepte de l’agilité en équipe.

Entité de rattachement
Notre division BFA AS IDF (Banque Finance Assurance Applications Services IDF) capitalise sur plus de 50 ans d'expérience dans l'accompagnement de grands comptes, au sein des marchés bancaires et de l'assurance, dans la modernisation de leurs patrimoines applicatifs et de leurs méthodes de travail, par une approche mêlant Agilité et DevOps afin de digitaliser les systèmes d'information pour leurs métiers et leurs clients. Les activités BFA pèsent pour environ 30% du CA global du Groupe. Fort de nos 1000 collaborateurs, notre entité a atteint 100 M€ de CA en 2019. Nos consultants interviennent sur les métiers d'architecture, de MOA, de MOE, de testing, de développement, d'intégration et de maintenance des SI. Nous vous proposons des projets à fort enjeux dans un contexte de transformation profonde du SI, une gestion des carrières motivante, l'opportunité d'exprimer pleinement vos compétences et des parcours de formation enrichissants. Une devise ? Vos idées, nos challenges !
Postuler"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),CDI,,Développeur - pôle Market Data (H/F),Natixis,- Paris (75),"Présentation de l'entreprise
Bienvenue chez Natixis, l’entreprise qui vous offre bien plus qu’un job !
https://www.youtube.com/watch?v=DdaoWX466VY&list=PLCffxNP5tKRS4JIutLJW04CvFxAAJrT95&index=11
Chez Natixis, nous concevons des solutions en gestion d’actifs et de fortune, financement, investissement, assurance et paiements.
Notre ambition : nous dépasser collectivement pour mieux accompagner nos clients et leur proposer les meilleures solutions pour leur développement.
Chez Natixis, nos talents sont notre principal atout.
Rejoignez-nous et vous aurez les clés pour faire bouger les choses et avoir un réel IMPACT.
Rejoignez-nous et vous découvrirez un monde d’OPPORTUNITÉS.
Rejoignez-nous et vous donnerez du sens à votre poste par votre ENGAGEMENT en faveur de la société comme de l’environnement.
Signataire de la Charte de la diversité, Natixis veille à promouvoir tous les talents et à accompagner le développement de chacun de ses 16 000 collaborateurs présents dans 38 pays. Pour la 3e année consécutive, elle est certifiée Top Employer France 2019.
La DSI de Natixis est au cœur des enjeux stratégiques pour développer de nouveaux services & usages clients et adapter son modèle aux nouvelles réglementations bancaires. DSI internationale, implantée dans 12 pays (en Europe, en Amérique, en Asie et au Moyen-Orient), elle est dotée d’une forte culture clients et innovante grâce aux nouvelles méthodologies & technologies IT (Digital, Big Data, Blockchain, IT bi-modal, Agilité, Expérience utilisateur, Collaboratif, Sécurité de l’Information, Robotique). Elle s’adapte régulièrement pour apporter le maximum de valeur aux Métiers de Natixis. Ses collaborateurs et les challenges qu’ils relèvent en sont sa meilleure vitrine.
Le département IT Directions Fonctionnelles (DFO) accompagne le développement des fonctions supports centrales de Natixis (Finance & Risques, Gestion Financière, Secrétariat Général, Ressources Humaines). A la croisée des productions réglementaires et prudentielles, les DSI DFO déploient des solutions mondiales qui servent les besoins de pilotage opérationnel, à l’échelle des entités et de Natixis.
Le département DSI RPA implémente les outils nécessaires au suivi des Risques, PnL & ALM.
Mission
Nous souhaitons renforcer le pôle Market Data , qui comporte environ 20 personnes, dont deux tiers de développeurs basés à Paris et Porto et un tiers de business analysts, placées sous la responsabilité du responsable de pôle.
La principale application du pôle vise à alimenter en données de marchés (risk factors) les systèmes FO de booking et les systèmes des risques, pour les calculs quotidiens de risques et de valorisation de fin de journée.
Elle gère les workflows de collecte, contrôle et mise à disposition des market data de la totalité des classes d’actifs traités sur les marchés par la BFI de Natixis.
Ce référentiel transverse est donc une pièce importante et critique du SI Marchés et alimente également de nombreux autres clients de Natixis et du groupe BPCE.
Les challenges sont très nombreux, avec notamment des évolutions majeures à réaliser pour répondre aux nouvelles exigences règlementaires (FRTB, TRIM, IMM, RIM) et aux besoins accrus de maîtrise de la qualité des process métiers et des données utilisées (BCBS 239).
L’application connaît un développement important qui nécessite le renfort des capacités internes.
Son architecture technique est en cours de transformation, avec une place importante donnée aux technologies de type Hadoop (stockage de gros volumes, machine learning, etc.).
Les process SI sont gérés en mode agile.
Votre rôle dans l’équipe :
Projets et évolutions fonctionnelles :
Design des solutions, en interaction avec la MOA et le responsable d’équipe
Développement et tests
Documentation de maintenance et d’exploitation ; formation du support
Préparation des releases
Support :
Participer (rotations) aux astreintes et aux permanences de support
Prise en charge des actions correctives
Profil recherché
De formation supérieure d’ingénieur en informatique ou équivalent. Vous avez des connaissances techniques autour du Big Data (Hadoop, Spark, Scala) et des Data Sciences (Machine Learning, Python).
Vous avez également des connaissances sur les opérations de marchés en vision FO ou Risques, acquises à travers une expérience professionnelle significative en CIB.
Vous maîtrisez le développement .Net C#,SQL et les Outillages complémentaires supportant les best practices agiles.
Vous possédez le goût du travail en équipe dans un environnement exigeant, avec de nombreuses interactions.
Vous savez communiquer de manière claire et concise.
Vous êtes dynamique, réactif et orienté client.
Vous êtes également organisé, rigoureux et force de proposition.
Votre niveau d'anglais est courant.
Site géographique: 30 Avenue Pierre Mendès-France - 75013 PARIS

Informations complémentaires sur le poste :
Convention collective applicable: Convention Collective de la Banque.
Responsable de recrutement: Marie Laure BERTIN."
Orsay (91),,,Data Engineering,PARIS-SACLAY CENTER FOR DATA SCIENCE,- Orsay (91),"The Paris-Saclay CDS 2 has opened a data engineering position to reinforce the data science ecosystem and to build and support a data science platform. The data engineer will work on (in order of priority):
Software engineering. The objective to enable researchers to do better science thanks to better software tools. It means bringing state of the art data science research software into high quality toolboxes (as scikit-learn). Getting involved with open source development. Assisting data scientists (students, postdoctoral fellows, permanent researchers) to develop their software engineering skills and to get them involved with open source development.
Platform support. The CDS has developed tools to foster data-driven collaborative work between scientists and engineers across disciplines. The RAMP platform is web based service developed with this objective. The candidate should be able to contribute to its development and maintenance (technologies are Python, flask, django, docker, scikit-learn, HTML, Javascript, cloud tech such as Amazon Web Services).
Training. Accompany domain scientists in their data analysis efforts. Accompany data scientists in their methodological research. Designing training sprints and practical material for the courses (cf. based on software carpentry)
Team
The data engineer will work with scikit-learn core developers such as Gaël Varoquaux, Olivier Grisel, Loic Estève, Alexandre Gramfort and others. Possible collaboration with data and domain science researchers such as Balazs Kegl, Isabelle Guyon, Sarah Cohen-Boulakia, Karine Zeitouni, David Rousseau, and others.
Qualifications
M.S. / Ph.D. in Computer Science, Statistical Machine Learning
Good understanding of the data science workflow. Experience with data challenges is a plus.
Strong programming experience with one or more data science languages (Python, R, Matlab)
Experience with open source development .
The applicant should send a CV, a statement of purpose, and up to three letters of recommendations to cdsupsay@gmail.com.
Position is open now and will be open until it is filled.
Description:
Duration: 18 months
Gross salary per month in €: 1930 – 2370"
Paris (75),,,"Senior Research Engineer, Machine Learning",SoundHound Inc.,- Paris (75),"At SoundHound Inc., we believe every brand should have a voice. As the leading innovator of conversational technologies, we're trusted by top brands around the globe. Houndify, our independent Voice AI platform, with 70,000+ users, allows brands to create custom voice assistants that deliver results with unprecedented speed and accuracy.

Our mission is to enable humans to interact with the things around them in the same way we interact with each other: by speaking naturally. We're making that a reality through our SoundHound music discovery app and Hound voice assistant and through our strategic partnerships with brands like Mercedes-Benz, Hyundai, Deutsche Telekom, and Pandora. Today, our customized voice AI solutions allow people to talk to phones, cars, smart speakers, mobile apps, coffee machines, and every other part of the emerging 'voice-first' world.

Our diverse team of engineers, UX/UI designers, writers, data scientists and linguists are all passionate about creating a world with more conversations. With more than 14 years of expertise in voice technology, we have hundreds of millions of end users, and a worldwide team in six countries building solutions for a voice-first world.

About the Role:
Fantastic opportunity to join the group that is advancing SoundHound's core technologies
Lead high-impact machine learning projects that contribute to a comprehensive AI platform with the potential to reach 2 billion end users
Focus on production driven research that requires ground-breaking innovation
Stay up to date with the state-of-the-art in ML techniques

Requirements:
Track record of leading high-impact machine learning projects
Experience with Deep Learning / Neural Network frameworks such as Tensorflow, Torch, PyTorch, and MxNet
Strong programming skills on Linux using Python or C++
Solid knowledge of algorithms and probability / statistics
MS / PhD in Computer Science, Electrical Engineering, Statistics or equivalent
5+ years of industry experience

Nice-to-haves:
Research work / publications in Machine Learning and Language Technologies
Experience handling large data corpora"
Paris (75),,,Senior Machine Learning Research Engineer,SoundHound Inc.,- Paris (75),"At SoundHound Inc., we believe every brand should have a voice. As the leading innovator of conversational technologies, we're trusted by top brands around the globe. Houndify, our independent Voice AI platform, with 70,000+ users, allows brands to create custom voice assistants that deliver results with unprecedented speed and accuracy.

Our mission is to enable humans to interact with the things around them in the same way we interact with each other: by speaking naturally. We're making that a reality through our SoundHound music discovery app and Hound voice assistant and through our strategic partnerships with brands like Mercedes-Benz, Hyundai, Deutsche Telekom, and Pandora. Today, our customized voice AI solutions allow people to talk to phones, cars, smart speakers, mobile apps, coffee machines, and every other part of the emerging 'voice-first' world.

Our diverse team of engineers, UX/UI designers, writers, data scientists and linguists are all passionate about creating a world with more conversations. With more than 14 years of expertise in voice technology, we have hundreds of millions of end users, and a worldwide team in six countries building solutions for a voice-first world.

About the Role:
This is a fantastic opportunity to join the core group working on Speech Recognition at SoundHound

Work on building large scale Statistical Language Models, a critical system in Speech Recognition

Run experiments and tune parameters to improve Statistical Language Models

Build prototypes to explore novel methods/algorithms to improve the Statistical Language Models

Identify new techniques to explore, prototype them, and then implement winning ideas in production

Requirements:
Proficient in one of Java or C++ or Python

Excellent algorithms skills and ability to write efficient code

Good understanding of Machine Learning algorithms

Strong problem solving and communication skills

BS/MS in Computer Science or equivalent

5+ years of relevant industry experience

Nice-to-haves:
Experience building production systems based on Machine Learning lifecycle

Experience with application of Deep Neural Network methods to Natural Language Processing problems

Familiarity with Statistical Language Modeling

Familiarity with MapReduce/Spark and other relevant infrastructure

Experience working with Speech Recognition technology"
Paris (75),,,Consultant – Global Market Division – Paris ou Londres (H/F),Harwell Management,- Paris (75),"Harwell Management is a premium European management consultancy group exclusively dedicated to the financial industry, with offices in 4 countries (UK, France, Belgium, Switzerland) and 200+ employees. Our company has been selected by The Financial Times as one of 1000 Europe’s fastest growing companies in 2018. Our clients are international leading banks. Fast growing, we offer many varied opportunities and a unique career boost.
This present job offer is about Consultant to join our Quant Management practice.
As a Consultant, you have access to a range of assignment: Quantitative Research, Risk Management, Bank Strategy review, Organisation and Models design, high level Project & Change Management.

Your Role:
Your role will be to work with the Quantitative Management team to perform assignments, within our clients organisation, precisely their Front Office, Research or Risk division.
We offer varied opportunities and assignment themes, from analyst to senior positions, as follows:
Quantitative Research & Support for Trading
Data Science
Risk Model & Risk Management
Strategic project management
Quant Assignments, example of Assignment & related Roles
Front Office Research for Trading:
You will perform fundamental/quantitative research and implement these ideas into the investment strategies and to help maintain/develop the quantitative processes.
You will research and evaluate new ideas, incorporating these ideas into a quantitative-based portfolio, and programming algorithms.
You will be asked to improve upon existing quantitative processes as well as to perform special projects and research.
Risk Model Project:
Lead model validation projects
Understand business processes and portfolios associated with model use, and the nature of model use within those processes
Asses the methodologies and processes used by modeling teams to develop and manage their models, and identifying potential risk and the associated materiality of the risk
Benchmark model methodologies and performance by specifying and managing the development of alternative models
Provide constructive and actionable solutions to model issues identified
Data Science Projects:
Generate investment-related ideas through sourcing and researching large novel datasets such as transactional data, client data, financial data set,
Create models using Machine Learning, Big Data and Statistical Models for Front Office or Risk Management use.
Developing rules for the extraction of data and the creation of machine-driven content using various proprietary and third-party scripting and natural language processing languages.
Implement data science models to generate investment signals for Equities Fundamental and Quantitative Investment Teams.
Enhance key business processes through researching and implementing data science models.
Research quantitative topics for The Quantitative research Group
Manage the data acquisition process
Strategy related assignments (Senior role):
Using strategy formation approaches to facilitate the definition of business strategies through working with relevant stakeholders.
Research initiated to address gaps in knowledge relating to a specific business issue
Change Management related assignments (Senior Role):
Creation of the business case for initiatives being considered, with the aim of concluding on the potential value add / cost-benefit analysis of embarking on that initiative. (Encompasses financial analysis, definition of business drivers, assessment of risks etc. To be used by the appropriate governance forum to decide whether to progress with an initiative / decide between options)
Advisory to the Steering Committee for projects / programmes of work with the aim of ensuring successful delivery and maintenance of strategic programme objectives
Other Internal projects:
Facilitation of workshops for different teams / business groups within Harwell Management
Participation to Knowledge Management, internal projects and RFPs.
The role will involve:
Working in a team,
Delivery of consulting assignments, under the supervision of a more senior member of the team
Profile:
Recognized expertise in the financial sector and knowledge of the banking sector:
A PhD, or Masters with equivalent work experience:
A PhD, or Masters with equivalent work experience:
Understanding of banking and best practice, gained through experience of working in, or interacting closely with, a consultancy environment:
Experience of using, developing and adapting Quantitative models, techniques and languages:
Experience developing models in the appropriate language (SAS and C# for Credit or Counterparty Models, Python, R, Matlab for Market models, Python, Stata, Latex, Gretel for Data Science Models, C++, SQL for general quant subject matters):
For Data Science, solid background in machine learning, statistical analytical techniques, quantitative science research or experimental physical science:
For Trading, experience in building libraries or algorithm:
For Risk Management, experience in reviewing models, for Credit, Counterparty or Market perspective:
Job’s context:
Paris, London or Geneva based opportunity:
Europe mobility possible if applicant wants to:
Various career programmes offered:
Entrepreneurial mindset, fast promotion, unlimited ascension based on merit:"
Paris (75),"CDD, CDI",,Data Product Manager - Marketplace Team,Heetch,- Paris (75),"ℹ️This job can be based in Paris, Brussels or Lyon.

Marketplace team @Heetch

Our team focuses on balancing the demand (passenger requests) and offer (driver availabilities) to generate growth while maintaining a highly reliable service.

It requires a lot of data work, in order to formulate hypotheses and create models which will fit the different cities we operate in. In other words, we try to build scalable and smart things to make mobility easier, for both drivers and passengers.

The 3 main topics of our team: pricing, matching, routing.

Of course, you won’t do that alone, as our fast-growing team is composed of several engineers, data scientists and another PM.
Our team's goal is to make everything we can, so anyone can Heetch anytime.

Does it sound like you?

You're obsessed by the value you create for users, and not only with tiny little details.
You are interested in Data Science, algorithms and mathematics.
You want to impact users and don't just want to write specs.
You care about reliability. Our users too
You like to try out many things and,...
You are ok to drop some of them. And retry…
You look for space to push ideas, bootstrapping is one of your hobbies.
You are ok to work with a remote team.
You love to communicate your ideas to others.
You speak French, so you can speak with most of our drivers.

What will you do?

Find the right problems to solve and communicate about them
Organise the brainstorming to find solutions with the team and relevant stakeholders
Collaborate with stakeholders to provide them with relevant market insights
Collaborate with stakeholders to get valuable insights
Contribute to timely delivery
Monitor key KPIs to evaluate priorities and ensure the team has a positive impact

What will be your main challenges?

Contribute to improving our marketplace and company vision
Help to scale and grow in emerging countries
Educate people on our challenges, and results, so they continue to love us
Maintain a high level of happiness in the team
Heetch embraces diversity and equal opportunity for everyone We provide a safe and inclusive work environment. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills.
For non-European citizens, a valid working visa for France is required to be eligible for the role.

Heetch SAS is collecting your personal data (identity, contact details, academic background, professional experience and optionally a covering letter) for the processing of your application to our job offer, based on your consent.
Your personal data will only be accessible to our hiring team, our co-founders, and the manager of the position you are applying to. In addition, data are stored by our processor in order to use its applications tracking system. Your data may be stored outside of the EU/EEA but are protected by appropriated safeguards.
Your data are stored for a maximum duration of two years. If we do not reply to your application, you allow us to store your data during this term in order to potentially contact you for another position within our company or affiliates and subsidiaries.
You have a right to access to your data, to rectify them, under some conditions to erase them, and to limit the processing. Also, you have a right of portability on your data. In addition, you may revoke your consent and we shall stop processing your data. Eventually, you have a right to define directives about the fate of your data if your death should occur.
For more information about your rights, please see our privacy policy."
Paris 1er (75),CDI,,Data Analyst H/F (CDI),Forum Emploi-Formation-Alternance: Talents Handicap,- Paris 1er (75),"Rejoindre La Banque Postale, c'est intégrer une banque citoyenne, dynamique et innovante, qui poursuit un développement accéléré sur les marchés de la banque de détail, de l'assurance et de la gestion d'actifs.Banque de service public, La Banque Postale accompagne ses clients dans une relation bancaire durable : 10,7 millions de clients particuliers et 400 000 clients entreprises, professionnels, acteurs de l'économie sociale et du secteur public local lui font confiance.Attentive à ses collaborateurs, elle leur propose des parcours diversifiés et investit dans leur formation tout au long de leurs parcours professionnel.L'Inspection GénéraleDirectement rattachée au Directoire, l'Inspection Générale (IG) assure le contrôle périodique des activités du Groupe La Banque Postale. Par ses missions d'audit réalisées en toute indépendance sur l'ensemble des domaines de la banque, elle veille à la pertinence des dispositifs de maîtrise des risques, à la conformité aux différentes normes en vigueur, ainsi qu'à l'efficacité opérationnelle du Groupe.Au sein de la Direction Qualité et Ressources de l'Inspection Générale, l'équipe Solutions et Datamining : Répond aux besoins en exploration de données des différentes missions : expertises sur les outils et données des SI de la banque et de ses filialesTraite des données complexesGère les besoins informatiques en interface avec la DSIDans ce contexte, le dataminer apporte son expertise aux équipes de mission afin de les éclairer sur les SI et les données des domaines audités.Dans le cadre des missions d'Inspection ou pour le compte de l'Inspection Générale, le dataminer est amené à : Préparer et constituer les échantillons de données.Rédiger le rapport relatif aux extractions et traitements de données réalisés.Contribuer à la cohérence globale des données et à la gestion de leur connaissance ainsi qu'à la connaissance des outils SI.Contribuer de manière continue à l'acculturation des équipes d'inspection à la connaissance de l'informatique décisionnelle de la Banque.Assister le responsable du pôle dans le cadre des contrôles et reporting internes à l'Inspection Générale.Former les équipes d'inspection aux outils spécifiques.En fonction des missions, le dataminer pourra être, partiellement ou totalement, intégré à l'équipe l'inspection et participer aux réunions et travaux. Notamment, il réalise lui-même les traitements de données les plus complexes pour le compte de la mission. De formation supérieure (Bac+3 option datamining ou Bac +5 option informatique/ analyses statistiques), vous maitrisez les langages SAS, SQL, Python et R ainsi que les outils de bureautiques (fonctions avancées d'Excel).La connaissance des systèmes d'informations bancaires ainsi qu'une expérience confirmée en matière d'administration des données bancaires seraient un plus.Vous êtes autonome, rigoureux.se et avez une excellente capacité d'analyse ?

N'hésitez pas à postuler.Rejoignez la Banque Postale, Banque et Citoyenne !"
Paris (75),CDD,,"Engineering Manager, Data Engineering (M/F)",Dailymotion,- Paris (75),"Company Description
Dailymotion’s mission is to connect publishers and advertisers with engaged viewers who turn to Dailymotion for videos that matter. Through partnerships with leading publishers and creators, including CBS, CNN, Fox Sports, GQ, Mashable, Universal Music Group, VICE and others, Dailymotion commands 3 billion monthly page views across its mobile app, desktop and connected TV experiences. Dailymotion is owned by Vivendi, one of the largest mass-media corporations in the world, and has recently launched a proprietary ad platform to gain better control of its monetization value chain and deliver a premium advertising experience.
Dailymotion is a global champion of diversity and inclusion. We pride ourselves in being an equal opportunity employer that provides an environment of mutual respect.

Job Description
Dailymotion is seeking its new Engineering Manager for the Data Engineering team.
You will join the fast-growing Data Engineering & Machine Learning craft, a craft made up of multiple teams of engineers and machine learning experts that collaborate daily to create and run Data products in Dailymotion. Your impact will be broad and across all of Dailymotion’s business. Some examples of products we build and maintain are highly scalable client-facing analytics, event processing at tens of thousands of messages per second, a cutting-edge sequence-to-sequence recommender, text & video-based automatic classification of our content, synchronizing data across databases & systems, spam & fraud detection, etc.
The Data Engineering team collects vast amounts of data into our datalake, builds datasets used throughout the company, brings to production the machine learning models that power our data products and distributes our data and models through APIs, database tables, files, etc. Finally, the team is responsible for the underlying data platform (Google Cloud Platform, Airflow with custom components, Dataflow & Flink, Druid, etc…) used to deliver all the use-cases.
Our mission is to build systems that work at scale, stay on top of multiple technologies & business requirements and keep everything up and running in production in our cloud environment…
What you will do
Grow and lead a team of data engineers through hiring, feedback and hands-on career development. Encourage and value a healthy, collaborative engineering culture focused on delivering business value
Manage direct reports’ workload & project assignements and participate in company-wide staffing ceremonies. Support agile software development practices and help develop and evangelize great engineering and organizational practices.
Partner closely with other engineering managers and product managers to better grasp the context of requirements coming your way, shape the solutions and translate product requirements into actionable projects. In particular, you will constantly interact with the engineering managers from your sister teams (analytics engineering & machine learning engineering) in order to best realize our use-cases and maximize our efficiency
Support timely delivery of projects by reviewing, directing & guiding the work of all engineers either directly or through your senior engineers.
Manage team productivity by driving the technical vision of the data platform that all our use-cases depend on.
Manage the on-duty process for engineers. Track costs and budget for cloud resources

Qualifications
You are currently a technical manager who can understand the technical details of a project; you have already transitioned to a lead position, preferably for a data engineering team.
You have a background in engineering of complex systems and are comfortable delivering projects even when requirements are under-specified: you are a systems thinker that can see how the pieces fit together to make the puzzle.
You have had experience going through the full software cycle of requirements, design, coding/testing, rollout/deploy best practices. Experience with the software cycle applied to Machine Learning is a plus.
You can train and grow your team members: you can challenge technical designs and project milestones, encourage experimentation and uphold quality expectations.
You are able to build & present a strong vision/roadmap for your team.
You have had at least 5 years' experience with server-side languages (Java or Python), preferably on data platforms (streaming, batch, API, pipelines, etc..). You have spent at least two years as a senior engineering other employee

Additional Information
Technologies used by the team
Google Cloud Platform (BigQuery, Cloud Storage, Beam/Dataflow, Compute Engine, etc), Kubernetes, Tensorflow, Python, Airflow, SQL, Git, JSON, Bash, Docker, Druid, Tableau…
Location: Paris
Start Date: ASAP
Contract Type: Permanent
Feel free to explore Dailymotion culture a little further, please check out:

1./ Vistit the Paris HQ - Welcome to the Jungle page: https://www.welcometothejungle.co/companies/dailymotion/team
2./ Our BuiltIn page: https://www.builtinnyc.com/company/dailymotion

3./ Our Recent Global Hackathon in November 2018: https://www.dailymotion.com/video/x70val9

4./ Your medium page : https://medium.com/dailymotion"
Boulogne-Billancourt (92),,,# CONSULTANT MOBILITY BIG DATA (H/ F),1001talents,- Boulogne-Billancourt (92),"Le poste

A new organization of innovative IT services has been created recently.
We have the expertise to advise, integrate and accelerate the business of our customers resulting from their digital transformation.
The main tasks concern:
Consulting and Transformation to a hybrid IT (eligibility, business case, evaluation of projects to be carried out and support of the customer in his digitization process)
IT infrastructure modernization and migration projects (implementation of cloud and hybrid hardware and software infrastructures, consolidation and rationalization of infrastructures and data centers, environment virtualization, workload migrations)
Datacenter tools: supervision, security, automation, performance, ...
The design, implementation and operational maintenance of Hadoop-based Big Data solutions,

Le profil

Bac +5 in science, in computer science, applied mathematics, statistics or similar field of study
5 to 10 years experience in projects and / or infrastructure solutions
Experience Service with multiple participations in major projects
Desired Pre-Sales Experience (Project Sizing, Response Building, Attendance Support)
Knowledge of Big Data Hadoop (Hortonwork, Cloudera and / or MAPR)
Knowledge in linear algebra and statistics
Knowledge of Machine Learning, Deep Learning and Reinforcement Learning algorithms
Knowledge of Machine Learning and Deep Learning application development frameworks (Tensorflow, NumPy, Keras ...)
Mastery of Python, Java, Scala, R programming
Databases (PostgreSQL, MySQL)
Mastering cloud technologies and hybrid infrastructures, application container management tools (Docker, Kubernetes ...)
Autonomy, rigor, ability to communicate clearly and concisely, initiative, sense of the client.
Enjoy networking and an international team
Oral and written English required"
Paris (75),,,Data Manager Programmeur,Excelya,- Paris (75),"Présentation
“De toute façon, dans l’industrie pharmaceutique, les entreprises de prestation se valent toutes” Si vous pensez ça, nous vous invitons à découvrir Excelya de toute urgence !
Parce qu’Excelya est nouvelle sur le marché et cherche à construire un partenariat de qualité avec ses employés. Vous avez le sentiment d’avoir un lien de plus en plus distendu avec votre hiérarchie ? Tentez l’expérience d’un véritable attachement à votre entreprise. Vous avez des compétences ou des centres d’intérêt extra-professionnels originaux ? Excelya vous aidera à les promouvoir.
2. Mission
Dans le cadre d’une première mission, vous êtes responsable de la bonne conduite d’essais cliniques en Oncologie sur les phases I,II, et III au sein d’un grand laboratoire international.
Votre mission sera donc la suivante :
Definition et supervision de la programmation des rapports et documents standards pour le nettoyage de la revision de données
Définition et supervision de la programmation de la liste des écarts types
Publication de listes opérationnelles / tableaux de bord ad hoc spécifiques pour la surveillance des activités
Gestion de la cartographie des données externes selon les spécifications des norms internes
Gestion d’un outil de calcul des “anomalies potentiellement cliniquement significatives” (PCSA) pour différents types d’études.
3. Profil
Data Manager Programmeur
Maîtrise de la méthodologie de reporting de PCSA (potentially clinically significant abnormalities) dans les études cliniques (INDISPENSABLE pour cette mission)
Connaissances de Python, et SAS
Background de Data Management en études cliniques dans des Big Pharma.Anglais courant
Connaissances en biostat seraient un plus."
Paris (75),,,Data Manager Programmeur,Excelya,- Paris (75),"Présentation
“De toute façon, dans l’industrie pharmaceutique, les entreprises de prestation se valent toutes” Si vous pensez ça, nous vous invitons à découvrir Excelya de toute urgence !
Parce qu’Excelya est nouvelle sur le marché et cherche à construire un partenariat de qualité avec ses employés. Vous avez le sentiment d’avoir un lien de plus en plus distendu avec votre hiérarchie ? Tentez l’expérience d’un véritable attachement à votre entreprise. Vous avez des compétences ou des centres d’intérêt extra-professionnels originaux ? Excelya vous aidera à les promouvoir.
2. Mission
Dans le cadre d’une première mission, vous êtes responsable de la bonne conduite d’essais cliniques en Oncologie sur les phases I,II, et III au sein d’un grand laboratoire international.
Votre mission sera donc la suivante :
Definition et supervision de la programmation des rapports et documents standards pour le nettoyage de la revision de données
Définition et supervision de la programmation de la liste des écarts types
Publication de listes opérationnelles / tableaux de bord ad hoc spécifiques pour la surveillance des activités
Gestion de la cartographie des données externes selon les spécifications des norms internes
Gestion d’un outil de calcul des “anomalies potentiellement cliniquement significatives” (PCSA) pour différents types d’études.
3. Profil
Data Manager Programmeur
Maîtrise de la méthodologie de reporting de PCSA (potentially clinically significant abnormalities) dans les études cliniques (INDISPENSABLE pour cette mission)
Connaissances de Python, et SAS
Background de Data Management en études cliniques dans des Big Pharma.Anglais courant
Connaissances en biostat seraient un plus."
Paris (75),"Temps plein, CDD",,Research Engineer on Optimization for Parallel Computing,USA Recruitment,- Paris (75),"Research Engineer on Optimization for Parallel Computing – Initial 12 month contract – Optimization Algorithms / Parallel Computing / Deep Learning

A multinational technology company based in Paris is looking for a Research Engineer on Optimization for Parallel Computing on an initial 12-month basis.

Requirements for the Research Engineer:
MSc or PhD in Computer Science or Applied Mathematics
Ability to conduct research and develop algorithms for deep learning training
Good knowledge of optimization algorithms (linear programming, combinatorial and convex optimization) and related tools (CPLEX, Coin-OR, Matlab)
Basic knowledge of parallel computing (dataflow, data-parallelism)
Knowledge of deep learning computing (neural network training and inference)
Experience with programming languages (C, C++, Java, Python, etc.)

If this sounds like the role for you, please attach a copy of your CV with your application for review. You must be an EU citizen or have the right to work in France to apply.

Keywords:
Deep Learning / Optimization / Parallel Computing / Algorithms / Linear Programming / MatLab / Dataflow /Neural Network / C / C++ / Java / Python

#AI & Machine Learning

By applying to this role you understand that we may collect your personal data and store and process it on our systems. For more information please see our Privacy Notice https://eu-recruit.com/about-us/privacy-notice/"
Saint-Ouen (93),,,BIG DATA PLATFORM OWNER F/M,Danone,- Saint-Ouen (93),"DANONE SA in WBS IS/IT is looking for a BIG DATA PLATFORM OWNER F/M in Saint Ouen.
Each time we eat and drink, we vote for the world we want to live in.

Danone’s mission is Bringing health through food to as many people as possible and we want to invite people to join the movement for a healthier world. We recognize the power people have to impact the world through their daily choices. Healthy food needs a healthy planet, and this is what our new signature One Planet One Health embodies.

Danette, Evian, Activia, Volvic, Blédina, sound familiar to you? Do you know that behind these brands there is always Information Technology pushing them forward?
At Danone, we use advanced and innovative IT solutions which are implemented in all Danone units around the world to contribute to our mission: bringing health through food to as many people as possible. Don’t wait, click and discover the Danone IS/IT universe and join the movement: your IT skills could be a real asset for the alimentation revolution!
(https://youtu.be/MqjF1HxsTyw)

CONTEXT

Information Management context (Big Data, BI strategy, Analytics...) is moving fast and Danone needs to adapt its Data Management strategy in order to become a Data enabled Company. Danone IS/IT is moving from a full local strategy to a hybrid strategy mixing corporate core layers and localized applications with the objective to optimize the costs and time to market of its solutions with the most effective data supply chain.


The Big Data Platform Owner will be part of Data Platforms process within the Data to Insights (D2I) domain. D2I belongs to Business Transformation within the central IS function

D2I provides services and operates systems used by all Danone entities:
Global context, multi-divisions, multi-geographies, multi-domains
Opportunity to join a key stream of the strategic Data-centric journey
D2I is a growing domain leading and enabling major business transformations and new usages such as Big Data and Advanced Analytics
Involvement in current major programs: One Data, Impulse, S/4 HANA

ABOUT THE JOB

Your main responsibilities will be:

Platform Owner:
Responsible for data pipeline of the big data platform(s)
Drive the roadmap of platform and manage communication of evolutions
Contribute to processes definition about how platform is consumed
Enable best of breed solutions to ensure proper access for his consumers according to service level defined
Ensure release management for its scope is ensured versus global release management process
Accountable for smooth running (with Delivery Factory responsible for it)
Responsible to assess functionally needs & solutions powered by Data Platforms

Project Manager:

Globally manage and contribute to project in terms of deliverables, budget, planning & organization
Accountable for project delivery
SPOC to ensure project delivery and animation when project is lead out of D2I
Scope owner: responsible of project delivery on specific areas when requires specific activity


IS/IT Solution designer
Define high level design for solution
Contribute to evolution of best of breed design rules
Challenge and control developments done by the team
Challenge and control developments done on other layers affecting Data Platforms activities

The position is based in Saint-Ouen until September 2020, then in Rueil-Malmaison

ABOUT YOU

Technical and personal skills needed:
Engineer with a specialization in Information Management, Data management, BI or Big Data.
At least 6 years’ experience in project management, working with data analysis (BI solutions will be additional benefit)
Core mandatory technical skills required are Database (data modeling, SQL) and Dataflow management
Analytical skills, ability to analyze problems and to define solutions
Experiences or education in Big Data solutions will make a true differentiator
Analytical skills, ability to analyze problems and to define solutions
Ability to work in an international environment
Good interpersonal skills, team spirit
Leadership in cross-teams situations with no hierarchical link
Ability to manage complexity and to work under pressure
Rigor, methodical and structured approach
Fluent English is a must, French would be a plus

If we just described your profile, please click the “apply now” button and upload your CV!

DANONE AND ITS BRANDS
Mix 75g of Activia, 130g of a small Blédina pot, 50cl of an Evian bottle and add a drop of Fortimel ... you get 4 brands representing the 4 divisions of the Danone group: Fresh Dairy Products and Vegetables (Activia, Danette, Actimel, Alpro, etc.), Waters (Evian, Badoit, Volvic, Salvetat), Medical Nutrition (Fortimel, etc.), and Infant Nutrition (Blédina, Gallia).
All these brands are worn by 100,000 Danoners in the World. Don’t wait, vote for the world you want to live in and join the movement!

A LITTLE TASTE?
Need advice on applying?
Follow our Danoners and our brands on Instagram, Facebook, Linkedin, Twitter
An overview of the premises: our head office in Paris and the new headquarters of Blédina in Limonest
What our trainees / alternates think about us: Happy Trainees # 4
Learn more about our jobs on Jobteaser."
Paris (75),CDI,,Graphène Advisory - Big Data Project Manager,Beijaflore,- Paris (75),"Fondé en 2000, Beijaflore est un cabinet de conseil opérationnel en stratégie digitale présent à l’international avec des bureaux à Paris, Bruxelles, Rio de Janeiro, Sao Paulo et New York. Il regroupe plus de 1250 collaborateurs animés par une mission commune : accompagner de manière opérationnelle les entreprises dans la mise en œuvre de leur stratégie digitale.
Avec son entité Graphène Advisory, Beijaflore accompagne les entreprises dans la valorisation de leurs données par des projets Intelligence Artificielle. En proposant des solutions complètes, partant de l’identification des use cases au développement de la solution et son déploiement, Graphène Advisory amène les entreprises à créer leurs business de demain. Ces solutions sont basées sur du Machine Learning et l’IA articulés sur des architectures flexibles, modulaires et scalables appelées architectures Big Data.
Vous souhaitez rejoindre une équipe multidisciplinaire et complémentaire qui accompagne ses clients dans la réalisation de projets autour de l’IA et du Machine Learning ?
En tant que Big Data Project Manager, vous serez en charge du pilotage de projets Data Science, de mise en place d’outils de gestion de projets Data. Vous aurez pour objectif de manager les équipes data afin d’assurer le succès du déploiement des technologie big data et du développement des solutions analytiques.
Vous également un rôle de conseil et de suivi des projets, ainsi que la restitution des résultats et des livrables selon le projet.
Vos enjeux : piloter et suivre le développement des projets data ainsi que les équipes en charge de la mise en œuvre. Mettre en place les outils de suivi de projets pour la performance opérationnelle.
Vous serez plus particulièrement chargé de :
L’analyse du brief et de la validation de la faisabilité des projets en fonction des éléments fournis par le client, du budget et des délais.
La rédaction des différents livrables (Technique, process ou méthodologie …)
La résolution de problématiques créatives ou techniques en collaboration avec les équipes dédiées
Le pilotage du planning, des équipes et des budgets avec une exigence particulière sur le contrôle de la qualité des éléments produits
La construction d’une relation de confiance avec vos contacts clients.
Diplômé(e) Bac+5 d’une Grande Ecole d’ingénieur, de commerce ou d’une Université en management de projets avec une spécialisation en Data science option technologies big data. Vous justifiez d’une première expérience en tant que chef de projet big data ou chef de projet digitalisation (minimum 2 ans).
A cette occasion vous avez développé de la polyvalence et de bonnes connaissances sur les sujets suivants :
Techniques (HTML/CSS, PHP…)
Des outils de suivi de projets (Trello)
Méthodes de gestion de projets (Agile, …)
Management des équipes
Doté d’une bonne expression orale et écrite, vous avez développé une réelle capacité de vulgarisation des sujets techniquement complexes et vous souhaitez évoluer au sein d’un environnement innovant et dynamique ?
Rejoignez-nous !"
Saint-Ouen (93),,,BIG DATA PLATFORM OWNER F/M,Danone,- Saint-Ouen (93),"DANONE SA in WBS IS/IT is looking for a BIG DATA PLATFORM OWNER F/M in Saint Ouen.
Each time we eat and drink, we vote for the world we want to live in.

Danone’s mission is Bringing health through food to as many people as possible and we want to invite people to join the movement for a healthier world. We recognize the power people have to impact the world through their daily choices. Healthy food needs a healthy planet, and this is what our new signature One Planet One Health embodies.

Danette, Evian, Activia, Volvic, Blédina, sound familiar to you? Do you know that behind these brands there is always Information Technology pushing them forward?
At Danone, we use advanced and innovative IT solutions which are implemented in all Danone units around the world to contribute to our mission: bringing health through food to as many people as possible. Don’t wait, click and discover the Danone IS/IT universe and join the movement: your IT skills could be a real asset for the alimentation revolution!
(https://youtu.be/MqjF1HxsTyw)

CONTEXT

Information Management context (Big Data, BI strategy, Analytics...) is moving fast and Danone needs to adapt its Data Management strategy in order to become a Data enabled Company. Danone IS/IT is moving from a full local strategy to a hybrid strategy mixing corporate core layers and localized applications with the objective to optimize the costs and time to market of its solutions with the most effective data supply chain.


The Big Data Platform Owner will be part of Data Platforms process within the Data to Insights (D2I) domain. D2I belongs to Business Transformation within the central IS function

D2I provides services and operates systems used by all Danone entities:
Global context, multi-divisions, multi-geographies, multi-domains
Opportunity to join a key stream of the strategic Data-centric journey
D2I is a growing domain leading and enabling major business transformations and new usages such as Big Data and Advanced Analytics
Involvement in current major programs: One Data, Impulse, S/4 HANA

ABOUT THE JOB

Your main responsibilities will be:

Platform Owner:
Responsible for data pipeline of the big data platform(s)
Drive the roadmap of platform and manage communication of evolutions
Contribute to processes definition about how platform is consumed
Enable best of breed solutions to ensure proper access for his consumers according to service level defined
Ensure release management for its scope is ensured versus global release management process
Accountable for smooth running (with Delivery Factory responsible for it)
Responsible to assess functionally needs & solutions powered by Data Platforms

Project Manager:

Globally manage and contribute to project in terms of deliverables, budget, planning & organization
Accountable for project delivery
SPOC to ensure project delivery and animation when project is lead out of D2I
Scope owner: responsible of project delivery on specific areas when requires specific activity


IS/IT Solution designer
Define high level design for solution
Contribute to evolution of best of breed design rules
Challenge and control developments done by the team
Challenge and control developments done on other layers affecting Data Platforms activities

The position is based in Saint-Ouen until September 2020, then in Rueil-Malmaison

ABOUT YOU

Technical and personal skills needed:
Engineer with a specialization in Information Management, Data management, BI or Big Data.
At least 6 years’ experience in project management, working with data analysis (BI solutions will be additional benefit)
Core mandatory technical skills required are Database (data modeling, SQL) and Dataflow management
Analytical skills, ability to analyze problems and to define solutions
Experiences or education in Big Data solutions will make a true differentiator
Analytical skills, ability to analyze problems and to define solutions
Ability to work in an international environment
Good interpersonal skills, team spirit
Leadership in cross-teams situations with no hierarchical link
Ability to manage complexity and to work under pressure
Rigor, methodical and structured approach
Fluent English is a must, French would be a plus

If we just described your profile, please click the “apply now” button and upload your CV!

DANONE AND ITS BRANDS
Mix 75g of Activia, 130g of a small Blédina pot, 50cl of an Evian bottle and add a drop of Fortimel ... you get 4 brands representing the 4 divisions of the Danone group: Fresh Dairy Products and Vegetables (Activia, Danette, Actimel, Alpro, etc.), Waters (Evian, Badoit, Volvic, Salvetat), Medical Nutrition (Fortimel, etc.), and Infant Nutrition (Blédina, Gallia).
All these brands are worn by 100,000 Danoners in the World. Don’t wait, vote for the world you want to live in and join the movement!

A LITTLE TASTE?
Need advice on applying?
Follow our Danoners and our brands on Instagram, Facebook, Linkedin, Twitter
An overview of the premises: our head office in Paris and the new headquarters of Blédina in Limonest
What our trainees / alternates think about us: Happy Trainees # 4
Learn more about our jobs on Jobteaser."
Paris (75),CDI,75 000 € - 100 000 € par an,Senior Data & Analytics Manager,Data Recrutement,- Paris (75),"Soyez alerté de la prochaine offre similaire en cliquant ici.
Senior Data & Analytics Manager | 75-100 k€
Offre publiée le 18-05-2020.
Paris
Fonction Head of data management
Fonction Data scientist ml ia nlp dl
Fonction Data analyst sql r tableau
Fonction Web data analyst analytics tag
Fonction Data manager sql python
Teletravail ponctuel
Lead manager responsable
1
Technologies Aws
Technologies Google analytics
Technologies Google cloud plateform
Technologies Python
Technologies R
Technologies Sql
Technologies Tableau
Expérience 6 à 10 ans
Expérience Plus de 10 ans
Statut CDI
Max 100k€
LA STARTUP : UN ACTEUR PROPOSANT UNE APPLICATION DANS LA CYBERSÉCURITÉ QUI CARTONNE AU NIVEAU MONDIAL
Effectif : 140 personnes
10+ millions d’utilisateurs (dont 50% aux US)
50+Gb de données traitées par jour
100+M€ de levée de fonds
Clients : 50 000 entreprises utilisent la solution
Les + de cette entreprise ?
Une startup pure Tech, qui ambitionne d’être l’acteur n°1 mondial sur un sujet qui touche beaucoup d’entre nous.

TA MISSION : MANAGER L’ÉQUIPE DATA À PARIS
Sous la responsabilité du Head of Data à New York, tes missions seront :
Management :
Accompagner ton équipe pour couvrir tout le cycle de la donnée (de la collecte aux recommandations business)
Etre le point de contact principal au sein de l’équipe Data
Analyses :
Faire des analyses complexes et créer des tableaux de bord décisionnels
Construire de nouveaux modèles : segmentation client, prédictions de comportements, …
Accompagner les différente équipes métiers (Produit, marketing, …) et leur proposer des recommandations
Les + de ce poste ?
Tu vas être amené à rapidement développer ton équipe (10aine de recrutements prévus à court terme)

TON PROFIL : LEAD DATA ANALYST / MANAGER DATA OU ANALYTICS
Tu as un Bac+5 de type grande école d’ingénieur
Tu as 5+ ans d’expérience en SQL et les bases de données relationnelles (MySQL, BigQuery, Redshift, …)
Tu maitrises les outils de DataViz
Tu as 2+ années d’expérience en langage script (Python, JavaScript, Ruby, …)
Tu as 3+ années d’expérience en management d’équipe
Tes + à toi ?
Tu as de l’expérience sur des outils tels que R, SAS, …
MODALITÉS
Salaire entre : 75 à 100 k€
Avantages : stock options / RTT / mutuelle / tickets restaurants / CE
Locaux situés en plein coeur de Paris
Déplacements 3-4 fois / an à NY

Sélectionné par Alison Chopard
Manager, Spécialiste Sales & Data
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),CDI,,Senior Consultant en organisation – Data Science (H/F),Exakis,- Paris (75),"La Data chez Magellan Consulting, très vite le cabinet a pris la mesure du « phénomène Data » avec la création d’une practice dédiée regroupant les activités régaliennes historiques (Gestion des données de référence, Gouvernance de la donnée, « Data management/architecture », Business Intelligence), mais surtout l’ensemble des pratiques innovantes et digitales : Data Science (Analytique, Machine Learning, Big-Data…), APIs, Blockchain, Open-Data et Data-Driven Company. Toujours avec un positionnement orienté Conseil (stratégique ou métier) et/ou Architecture.
Vous rejoindrez une équipe de consultants expérimentés reconnue pour son savoir-faire et vous accompagnerez nos clients dans leur transformation.
Ville : Paris
Type de contrat : CDI
Expérience : Minimum 3 ans
Poste et Missions
Animer des ateliers avec des intervenants des différents métiers, faire converger les besoins et produire les livrables associés,
Apporter à votre client votre expertise des processus métier,
Etre reconnu par votre client et développer une relation de confiance avec vos interlocuteurs internes et externes,
Participer à l’amélioration de l’offre,
Définir et cadrer les problématiques, surtout sur la réalisation des projets de Data Science : aussi bien sous un angle Métier que technique,
Accompagner nos clients dans la formalisation de leurs problématiques Data, la réalisation de modèles et l’industrialisation,
Participer à la vie interne du cabinet : formation, recrutement, évaluation des consultants, team building, capitalisation des connaissances acquises.
Profil
De formation Bac+5, diplômé d’une école d’ingénieur, de commerce ou d’un Master spécialisé universitaire, vous justifiez d’au moins 3 ans d’expérience réussie en conseil en management.
Vous connaissez les concepts (Big-Data, NoSQL, Machine Learning, Data-Viz…), et en partie :
Des algorithmes (supervisés, non supervisés, Random Forest, SVM, réseaux de neurones, etc.),
Des langages (R, python, scikit-learn, tensorFlow, MapReduce, D3.js,…),
Et des outils (Hadoop, Spark, Hive, HBase, Cassandra, ElasticSearch…).
Vous avez développé des compétences métiers grâce à des missions de conseil en organisation. Vous êtes capable d’analyser les problèmes et les enjeux de nos clients, et êtes capable d’apporter des solutions pertinentes. Vous êtes force de proposition tout en reportant à un Manager.
Doté d’un excellent relationnel, de très bonnes qualités rédactionnelles et des qualités de synthèse. Vous maîtrisez aujourd’hui d’ailleurs les fondamentaux du Consultant : interviews, animation de réunions, conduite de projet, analyse, business-case, rédaction de supports à forte valeur ajoutée, et faites preuve de créativité.
Vous êtes fortement demandeur d’autonomie et de responsabilités. Votre esprit d’entrepreneur, votre approche innovante et votre appétence pour le travail en équipe vous permettront de contribuer au développement de notre cabinet en proposant des solutions sur mesure que ce soit à nos clients ou au sein de nos groupes de travail internes (innovation, formation, bien-être au travail, développement des offres).
Anglais courant impératif.
Vous êtes dynamique, rigoureux, curieux et faites preuve d’un esprit d’initiative, venez rejoindre nos équipes et rejoignez-nous pour accompagner notre croissance !"
Paris (75),,,Data Engineer – Paris (FR) - Consulting,Digital Source,- Paris (75),"Are you a Data Engineer looking to join a consulting agency specialized in Data Science?
Our client is looking for a new collaborator to join their teams in Paris.
Let’s see the details together.
Company Overview
Our client is a fast-growing consulting agency based in Paris and Casablanca. They help companies to value their data and propose solutions adapted to their needs to improve their performance.
They are active in different industries, but their focus is on banking, insurance, and health.
They have a team of 20 data scientists, and they are searching for their first Data Engineer.
Your missions
As a Data Engineer, you’ll work in collaboration with the Data Scientist teams, you’ll have to:
Report to the operation director
Realization/support of projects involving the implementation of data transformation flows
Participate in structuring/automating intern processes to make data scientist teams more effective in customer support
Advise on the tech to put in place for the different business clients
Profile
You are graduated from an Engineering school, and you have at least 3 to 5 years of experience as a Data Engineer.
Soft Skills
You are very organized
You are a good team-player
You have good communication skills (both on a professional and interpersonal level)
You are autonomous and curious
Hard Skills
You have practical knowledge in the Spark framework (pyspark, scala)
You are a master at SGBDR and NoSQL
Bonus
Code versioning (Git)
Testing
Distributed systems
Hadoop systems, Map Reduce
Great knowledge in Data Science and Machine Learning
Their offer
Competitive salary
Variables
Incentive bonus
Restaurant tickets
Transport pass
Can you see yourself in this role? Send us your CV, and we will get back to you ASAP


8216"
La Défense (92),,,Professor and Researcher in Financial Engineering,Leonard de Vinci,- La Défense (92),"ESILV, Ecole Supérieure d’Ingénieurs Léonard de Vinci, is a generalist engineering school centered on numerical digital technologies. With a five-year teaching curriculum, ESILV prepares engineers ready to take professional positions and management responsibilities. ESILV’s pedagogical project is articulated around digital sciences and technologies with four main specializations: Informatics, Big Data & Connected objects, Numerical Mechanics and Modelisation, Financial Engineering, New Energies. ESILV benefits also from a high level of interdisciplinarity as 20% of its courses are shared with a business school (EMLV) and a school of digital technologies (IIM). ESILV can therefore offer a 5 year course in Engineering Management that produces 2500 double diplomas. With the EESPIG label, ESILV is a member of CGE, of UGEI, of CDEFI, of Campus France, of Talents du Numérique and of LearningLab Network.
Web site: https://www.esilv.fr/
Reporting directly to the Director of the Finance Department, the candidate will be a member of the De Vinci Research Center (DVRC) of the Pôle Léonard de Vinci and will also report to the manager of the Finance Group. The candidate will teach in the Major Financial Engineering. The candidate must demonstrate skills as a teacher/researcher in particular through publications in major peer-reviewed journals in probability/statistics, mathematical finance, or operational research.
The missions and responsabilities of the position will be as following:
Teaching
Ensure teaching courses
Supervise students’ projects and stages
Supervise the academic progress of students
Advise students
Research
Initiate and/or continue research collaborations with members of DVRC or with researchers outside DVRC
Publish articles in major international peer-reviewed journals in the sectors mentioned above
Present research results within DVRC and outside DVRC in seminars, colloquia, conferences, congresses
Participate to research projects financed by third parties
Participate to the activities of DVRC (seminars, meetings)

External relationships and cooperation with support services
Take an active participation in ESILV’s promotional activities with young people and their families (JPO, fairs, forums, conferences, presse…)
Be jury for students admissions
Participate to the development of collaborations (teaching and/or research)
Courses are given to students of the third year and in the majeure Financial Engineering (4th and 5th years), on the following subjects:
Probability, Stochastic Calculus, Statistics
Market finance, Actuarial sciences
VBA, C++, Python, R.
All courses of the 4th year are given in English.
Lines of research pertain to the following themes of the laboratory: financial mathematics in discrete and continuous time, data science applied to finance, risk management.
Candidates should hold a PhD from a leading institution and have an established record of excellence in teaching and research within the advertised discipline. They also should hold the following knowledges:
Theoretical knowledge
Mathematics, Finance
VBA, C++, Python or R
Graduate level teaching
Economic framework and profession
Operational knowledge
Pedagogical methods
Fluent English (courses of the 4th year are given in English)
Office automation tools
Communication and project management
Behavioral knowledge
Reactivity
Interpersonal skills
Oral skills
Availability
Autonomy
Please provide your CV with the names and contact information of three referees, a cover letter describing your research activities and pipeline, any professional experience, two research papers and recent teaching evaluations."
Paris (75),,,"Manager, Consumer Analytics",PayPal,- Paris (75),"Job Responsibilities
Own the consumer funnel (activation, engagement, etc.); investigate and explain drivers of change
Develop a deep understanding of PayPal’s overall business (e.g., products, geographies, business model, value prop)
Identify key business levers, establish cause & effect, perform analyses, and communicate key findings to various stakeholders to facilitate data-driven decision making
Discover new opportunities to grow and optimize the business through analytics, financial modeling, and business case development
Build exec-facing dashboards and reports to track the progress of the business and its highest-priority initiatives
Roll up your sleeves and work with large quantities of data using SQL and Excel, statistical programming languages like R or Python, and reporting tools such as Tableau and Qlikview
Understand what matters most and prioritize ruthlessly
Be comfortable with ambiguity and frequent context-switching in a fast-paced environment
Demonstrate exceptional communication skills, both written and verbal – whether in PowerPoint or an elevator pitch, you need to translate complex concepts into layman’s terms and influence both peers and senior leadership
Basic Qualifications:
Data-driven mindset with degree in a quantitative discipline such as Computer Science, Statistics, Engineering, Mathematics, or Economics or equivalent
Several years of work experience in similar roles, including experience with high volume data environments in financial services, credit, insurance, banking, or internet services
Fluent in SQL, Excel, and visualization tools such as Tableau or Qlikview; familiarity with a statistical programming language (e.g., R, Python) preferred
Ability to work proactively and independently in a fast-paced environment and juggle competing priorities
Exceptional written and verbal communication skills to influence cross-functional teams
Fluent English required, French preferred
Job_Description_Summary: PayPal’s Global Consumer Analytics team provides the connecting fiber between Marketing, Product, and Finance. You will develop an extensive knowledge of PayPal’s overall business and will work with large quantities of data to develop deep insights that shape the thinking of senior leaders and our cross-functional partners. You will become an expert in the consumer funnel, understanding and explaining the drivers of acquisition, engagement, and churn across markets, segments, and product experiences. Your quantitative insights combined with influential presentation and storytelling will facilitate data-driven decision making across the organization.
Who we are: Fueled by a fundamental belief that having access to financial services creates opportunity, PayPal (NASDAQ: PYPL) is committed to democratizing financial services and empowering people and businesses to join and thrive in the global economy. Our open digital payments platform gives PayPal’s 286 million active account holders the confidence to connect and transact in new and powerful ways, whether they are online, on a mobile device, in an app, or in person. Through a combination of technological innovation and strategic partnerships, PayPal creates better ways to manage and move money, and offers choice and flexibility when sending payments, paying or getting paid. Available in more than 200 markets around the world, the PayPal platform, including Braintree, Venmo and Xoom enables consumers and merchants to receive money in more than 100 currencies, withdraw funds in 56 currencies and hold balances in their PayPal accounts in 25 currencies.
We're a purpose-driven company whose beliefs are the foundation for how we conduct business every day. We hold ourselves to our One Team Behaviors which demand that we hold the highest ethical standards, to empower an open and diverse workplace, and strive to treat everyone who is touched by our business with dignity and respect. Our employees challenge the status quo, ask questions, and find solutions. We want to break down barriers to financial empowerment. Join us as we change the way the world defines financial freedom.
PayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities."
Paris (75),,,Financial Risk Manager,Qonto,- Paris (75),"Our mission is to create the most amazing banking experience for SMEs through technology, elegant design, and an outstanding sense of customer care. At Qonto, we believe that great services come from great thinkers, that’s why we strive to provide an environment that will allow you to feel comfortable and help you excel in your work (read more about our method).

Alexandre and Steve launched Qonto in July 2017, and the team reached great achievements since then:
Market leader for online SME banking in Europe
75,000 SME clients
Outstanding customer satisfaction (App Store | Google Play | TrustPilot)
Recognized as one of the best startups to work at (Wired | LinkedIn)
€136 million raised
International investors with a solid fintech experience
And 200+ happy Qontoers helping us building the bank of our dreams (just that!)

Our values:
Ambition | We tackle big challenges no matter what
Teamwork | We create magic by collaborating at the same speed
Mastery | We pursue excellence through continuous learning and by facing challenges humbly every day
Integrity | We are transparent and trustworthy with our clients and each other

As a Financial Risk Manager, you will contribute to the structure and processes of the risk team and the set-up of the risk management system, within a scale-up context and for the launch of credit activities.

In this newly created function, you will be a key member of the growing Risk function and be the right arm of the Head of Risk, Maxime Laot.
️Your responsibilities
Secure our new credit activities: You will ensure that we build a state-of-the-art credit scoring engine and you will monitor its performance over time. You will manage the credit portfolio, perform stress tests, suggest risk steering actions and produce all necessary information for risk reporting and accounting (inc. IFRS9). You will participate in the credit decision and provide your opinion on the largest credit files.
Strengthen the resilience of our operations: You will ensure that our operational risk management framework tackles the challenges brought up by our rapid scale-up, our constant product innovation and changes in our regulatory status. You will lead risk-reduction projects, framing and steering the work of colleagues across Qonto.
Contribute to efficient asset-liability management: You will forecast our balance sheet evolution and structure over time. You will estimate our regulatory and economic capital consumption. You will use these insights to control our capital planning and asset-liability steering decisions, to make sure we always remain within the boundaries of our risk appetite.
Implement a risk monitoring and reporting framework: You will identify the data we need to meet our internal and external (i.e. prudential and financial) reporting requirements. You will set up the organization for meeting these requirements in time with the highest level of accuracy. You will set up and follow key risk indicators, and suggest risk-steering actions whenever needed.
About You
Experience: You have 4+ years of experience in a risk management position within a bank or a Fintech supervised by a European regulator (n.b. consulting for a bank and/or Fintech also qualifies).
Mastery: You are a master in credit risk modelling (i.e. credit scoring, economic capital allocation) and in data science (i.e. SQL, Python).
Banking regulations and accounting knowledge: You have a good knowledge of banking regulations (i.e. CRR, CRDIV, French Arrêté du 3 novembre 2014, Basel II, III and IV) and of accounting standards (i.e. IFRS9).
Team player: You have strong project management, communication, and organizational skills.
Languages: You are native or fluent in English, French is a plus.
Education: You have a Master’s degree, with a specialization or specific training in banking risk control or global risk management (e.g. FRM).
Perks
You got it: helping you succeed is our #1 priority. We have put together several perks to make your life easier and more will unlock as Qonto grows further

Team
3,200 sqm fully-renovated building near Opera with WeWork services
Monthly team events, and yearly offsite (Barcelona, Sicily… what’s next?)
Free coffee, snacks in the kitchen and a budget allocated to managers for small team events
The latest in Apple’s equipment

Qonto’s benefits
1 day of remote work per week
5 to 10 days off in addition to the legal 25 days
A Qonto Card that you can use as for lunch
Access to thousands of gyms and activities for 10-30€ a month, through our partnership with Gymlib
Relocation package and visa sponsorship for international talents (we have 25+ nationalities based in Paris!)
How we have adapted our hiring process to the current context
Is Qonto still recruiting? What are we planning for the next few months?
There are so many questions you may be asking yourself. The current public health crisis may have you doubting whether you should even be applying right now.
We strive to be the bank all businesses love. To continue to reach this goal, we need to hire talent more than ever.
That’s why we guarantee a fully remote recruitment process for all candidates!
We are lucky to have digital tools to help us continue to live and work as best we can despite everything going on.

Here is what you can expect from our adapted recruitment process:
A 60 min video-call with one of our talent acquisition managers to better understand your career plan and answer any of your questions
A 60 min video-call with your future manager to create a strong alignment on what they will expect from you and tell you more on their way of operating
A fully remote exercise to evaluate your abilities and give you a taste of what you could work on at Qonto
Video-calls with future team members to help you envision yourself at the company
A final video-call with one of our C-level/Founders

Offers usually follow within 48 hours :)"
Paris (75),,,Covid-19 : Postdoctoral position in mathematical modelling of SARS-CoV-2 serological data,Institut Pasteur,- Paris (75),"The Malaria: Parasites and Hosts Unit at Institut Pasteur utilises tools from molecular biology, serology and statistical and mathematical modelling to investigate the epidemiology of malaria and other infectious diseases. Building on our Unit’s long-standing expertise in serological surveillance, our inter-disciplinary team have developed a highly sensitive and highly specific serological assay to detect previous infection with SARS-CoV-2. This approach utilises multiplex serological assays, and has two notable advantages:
By measuring antibodies to multiple SARS-CoV-2 antigens, we can obtain higher sensitivity and specificity than single antigen diagnostic tests.
This technology will allow integrated serological surveillance of SARS-CoV-2 with other pathogens such as malaria and neglected tropical diseases.
Poste et missions
We are seeking a candidate for a post-doctoral position with expertise in statistics, data analytics, or mathematical modelling of infectious diseases to work on the following projects:
Develop algorithms for classifying previous SARS-CoV-2 infection given measurements of multiple antibody responses.
Analyse data from serological surveys in France, Senegal, Côte d’Ivoire, and Cameroon.
Develop mathematical models of antibody kinetics to assess the duration of immunity and how the sensitivity of diagnostics tests will change over time.
The successful candidate will be given a one-year contract for this project focused on SARS-CoV-2 serological surveillance. Importantly, there is a pathway to develop your interests beyond coronavirus. At the end of the first year, should both parties agree, there will be another position on a European Research Council project: “Algorithms and multiplex assays for integrated serological surveillance of malaria and neglected tropical diseases”. This second project will build on the advances currently being made in the laboratory to develop serological surveillance strategies for other infectious diseases such as trachoma, schistosomiasis, Zika, and dengue.
Mobilité géographique :
Pas de déplacement
Profil
Research experience of working with mathematical and/or statistical models.
A strong interest in infectious disease epidemiology.
Programming experience in C, C++ or Java.
Knowledge of a statistical programming language (preferably R).
Ability to collate and analyse data, interpret and present results to a high standard using a range of specialised research techniques.
Excellent verbal and written communication skills. The working language of the laboratory is English.
Experience in communicating research findings to a non-specialist audience.
PhD in one of the following areas: infectious disease epidemiology, statistics, population biology, mathematics, physics, computer science or a similarly quantitative discipline."
Paris (75),CDI,44 000 € - 57 000 € par an,Consultant data science on site pour un jeune cabinet de conseil prometteur,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data engineer hadoop spark
Fonction Data scientist ml ia nlp dl
Technologies Bigquery
Technologies Data studio
Technologies Google analytics
Technologies Google cloud plateform
Technologies Machine learning
Technologies Nlp
Technologies Python
Technologies Qlikview
Expérience Jeune à dipl me
Expérience 1 à 2 ans
Expérience 3 à 5 ans
Statut CDI
Min 44k€
Max 57k€
LA STARTUP : UN ACTEUR DU CONSEIL SPÉCIALISÉ DANS LE MARKETING DIGITAL ET LA DATA
Une top équipe : grandes écoles et anciens de cabinets de conseil
Une clientèle diversifiée auprès de différents acteurs : La Française des Jeux, Groupe Bayard, Kenzo, OVH,
Boardriders, Vente-Privée.com, …
Des locaux au coeur de Paris
Un cabinet en pleine croissance, intégré à un grand groupe en 2018 (agence digitale présente dans 15 pays)
Une dimension entrepreneuriale forte (culture, autonomie sur les missions, valeurs, petit effectif)
Un projet early stage où avoir de l’impact (10 à 30 personnes)
Créé en 2015
Environnement technique : NLP, Machine Learning, BigQuery, Google Cloud Platform, QlikView, Tableau, Data Studio, SQL, Python

VOTRE MISSION : CONSULTANT DATA SCIENCE ON SITE
Au sein du pôle Marketing Science, vous intervenez sur des problématiques d'analyses marketing et notamment de segmentation, d'analyse de performances de campagnes, d'analyse du parcours client, de scorings, d'attribution, prédiction, de flux de données et automation, de visualisation, … Pour ce faire, vous :
Utilisez des techiques avancées de modélisations de données et d'analyses statistiques
Restituez les données sous forme de Data Visualisation
Participez au développment des méthodologies d'analyse du cabinet et à son positionnement technologique avant gardiste
A noter : des déplacements ponctuels chez le client peuvent être demandés.

VOTRE PROFIL :
Vous êtes diplômé d'une grande école de commerce, d'ingénieurs ou équivalent
Diposez au moins d'une première expérience (stages compris)et jusqu'à 3 ans expérience sur un ou plusieurs des sujets suivants :
Data engineering : constructions d'infrastrures de données basées sur le cloud, flux de données entre différents outils
Data science : algorithmie, machine learing, analyse descriptive et prédictive
DataViz : dashboard adaptés aux enjeux opérationnels et managériaux
Vous maîtrisez Google Cloud Platform et des langages SQL et Python
Vous êtes autonome et êtes force de proposition
Vous avez la volonté d’apprendre et de monter en compétences

VOS PLUS
Vous avez une première expertise conseil
Vous avez des connaissances sur les briques techniques de Google Cloud Platform
Vous maîtrisez un ou plusieurs outils de dataViz

MODALITÉS :
Package 44 à 57K€ (variable selon profil – dont 2k€ de variable)
RTT : 10 jours
Jours de congés offerts ponctuellement
Petit déjeuners tous les lundis et panier de fruits
Carte Lunchr
Mutuelle

Sélectionné par Alison Chopard
Manager, Spécialiste Sales & Data
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),,,Lead IA Data Scientist - Paris (FR) - Insurance,Digital Source,- Paris (75),"Are you passionate about Machine Learning and Deep Learning?
Do you want to start a new managerial position in Paris as Lead IA Data Scientist?
Search no more, we have the opportunity you are looking for: Lead AI Data Scientist in Paris. Let’s discuss the details:
Who is our client?
Our client is an innovative start-up specialized in the assurance industry. Innovative because their ambition is to make the habitation assurance world easy, transparent and efficient for everybody!
Their game-changer strategy already paid for them because, since 2015, their profits have doubled.
Your tasks
As a Lead AI Data Scientist, we want you to:
Lead a team of 4 Data Scientists
Design, test and put in application new Machine Learning algorithms
Improve the systems of the company
Your profile
You have at least a Master Degree in Engineering or an equivalence.
Hard Skills
You have strong knowledge in Python
You have great practical uses of AWS
You have knowledge in Machine Learning and Deep Learning (with Tensor Flow)
You have experience in Computer Vision

Soft Skills
Data, Big Data is one of your passion
You are dynamic and proefficient
You speak and write a professional and fluent Egnlish
Bonus point if you write and speak a great French
Double bonus point if you know what NILM / NIALM means
What they offer
A nice workplace where there is an informal environment
Many team activities
Stock Options
Are you interested?
Apply now and show us why you are the Lead AI Data Scientist we are looking for!

7661"
Paris (75),Stage,,Site Reliability Engineering Internship/Data Processing and Governance,Criteo,- Paris (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

What is it like to work in our R&D

Most of all, we are creators. From designing ground-breaking products to finding unique ways to tackle technical challenges at an extraordinary scale, our tech teams work with state of the art methodologies to shape the future of advertising.
The Site Reliability teams keep one of the largest computing platforms in the AdTech world functioning like clockwork. They are processing, storing and monitoring through large scale data compute & storage services (Hadoop, SQL & NoSQL), streaming (Kafka), platform as a service (Chef, Mesos), identity management (Kerberos) and analytics (Hive, Druid, Vertica).
What You’ll Do
You will be part of the team working on data governance and processing and you will get the full picture of data transformation: who owns it, data growth, etc. That comes together with a full exposition to our tech stack, as the data goes through many different systems: Kafka, jobs based on Hive, Spark and Presto, many different SQL and NoSQL databases for online and offline purposes.
With the guidance and support of your mentor, you will learn how to drive your project, design and ensure best practices are applied.
You will participate in all knowledge sharing sessions/ workshops.
You will gain a better understanding of how to work on real world data and mission-critical constraints.
You are encouraged to actively voice your ideas whilst learning how to build and ship quality code into production.
You will participate in architecture discussions, influence the roadmap, and take ownership.
You will work with and learn from talented engineers, with a diverse set of backgrounds.

During your internships (6 months – end of studies) and according to your choice, skills and interest, you can tackle one of the following subjects:
Streaming data catalog: You will help to deal with more than millions of messages per second, flowing from several Kafka clusters, all around the world, into one of the biggest Hadoop clusters in Europe.
Understand the data and their dependencies in Criteo based on actual usage and develop some use cases with: Scala/React/Typescript/SQL/Hadoop.
Develop tools and analyses to understand and monitor the quality of our data with Scala/React/Typescript/SQL/Hadoop.

Who You Are
You are in your final year of study in Systems/Software Engineering or related field.
You have already built projects in Python, C# or Java, and you have some practical experience writing Map/Reduce, Spark or Hive.
You are curious about new technologies.
You have a strong sense of ownership and a dislike for passing the buck.
You are a problem solver, a fixer, and a creative technologist. We believe coding is a talent and a passion, not just a skill.
You are a strong communicator and a team player who can work efficiently with others.
You are fluent in English.

Want to Know More?

What does it feel like to be part of something big? Get a snapshot
Get the story directly from our R&D engineers, check our Medium R&D blog
Interested in discovering your Criteo community first? Let’s meet
Check out our NEW career website. Take a look

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Paris (75),"Temps plein, CDI",,Site Reliability Engineering Internship/Data Processing and Governance,Criteo,- Paris (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

What is it like to work in our R&D

Most of all, we are creators. From designing ground-breaking products to finding unique ways to tackle technical challenges at an extraordinary scale, our tech teams work with state of the art methodologies to shape the future of advertising.
The Site Reliability teams keep one of the largest computing platforms in the AdTech world functioning like clockwork. They are processing, storing and monitoring through large scale data compute & storage services (Hadoop, SQL & NoSQL), streaming (Kafka), platform as a service (Chef, Mesos), identity management (Kerberos) and analytics (Hive, Druid, Vertica).
What You’ll Do
You will be part of the team working on data governance and processing and you will get the full picture of data transformation: who owns it, data growth, etc. That comes together with a full exposition to our tech stack, as the data goes through many different systems: Kafka, jobs based on Hive, Spark and Presto, many different SQL and NoSQL databases for online and offline purposes.
With the guidance and support of your mentor, you will learn how to drive your project, design and ensure best practices are applied.
You will participate in all knowledge sharing sessions/ workshops.
You will gain a better understanding of how to work on real world data and mission-critical constraints.
You are encouraged to actively voice your ideas whilst learning how to build and ship quality code into production.
You will participate in architecture discussions, influence the roadmap, and take ownership.
You will work with and learn from talented engineers, with a diverse set of backgrounds.

During your internships (6 months – end of studies) and according to your choice, skills and interest, you can tackle one of the following subjects:
Streaming data catalog: You will help to deal with more than millions of messages per second, flowing from several Kafka clusters, all around the world, into one of the biggest Hadoop clusters in Europe.
Understand the data and their dependencies in Criteo based on actual usage and develop some use cases with: Scala/React/Typescript/SQL/Hadoop.
Develop tools and analyses to understand and monitor the quality of our data with Scala/React/Typescript/SQL/Hadoop.

Who You Are
You are in your final year of study in Systems/Software Engineering or related field.
You have already built projects in Python, C# or Java, and you have some practical experience writing Map/Reduce, Spark or Hive.
You are curious about new technologies.
You have a strong sense of ownership and a dislike for passing the buck.
You are a problem solver, a fixer, and a creative technologist. We believe coding is a talent and a passion, not just a skill.
You are a strong communicator and a team player who can work efficiently with others.
You are fluent in English.

Want to Know More?

What does it feel like to be part of something big? Get a snapshot
Get the story directly from our R&D engineers, check our Medium R&D blog
Interested in discovering your Criteo community first? Let’s meet
Check out our NEW career website. Take a look

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
,,,Site Reliability Engineering Internship/Data Processing and Governance,Criteo,- Paris (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

What is it like to work in our R&D

Most of all, we are creators. From designing ground-breaking products to finding unique ways to tackle technical challenges at an extraordinary scale, our tech teams work with state of the art methodologies to shape the future of advertising.
The Site Reliability teams keep one of the largest computing platforms in the AdTech world functioning like clockwork. They are processing, storing and monitoring through large scale data compute & storage services (Hadoop, SQL & NoSQL), streaming (Kafka), platform as a service (Chef, Mesos), identity management (Kerberos) and analytics (Hive, Druid, Vertica).
What You’ll Do
You will be part of the team working on data governance and processing and you will get the full picture of data transformation: who owns it, data growth, etc. That comes together with a full exposition to our tech stack, as the data goes through many different systems: Kafka, jobs based on Hive, Spark and Presto, many different SQL and NoSQL databases for online and offline purposes.
With the guidance and support of your mentor, you will learn how to drive your project, design and ensure best practices are applied.
You will participate in all knowledge sharing sessions/ workshops.
You will gain a better understanding of how to work on real world data and mission-critical constraints.
You are encouraged to actively voice your ideas whilst learning how to build and ship quality code into production.
You will participate in architecture discussions, influence the roadmap, and take ownership.
You will work with and learn from talented engineers, with a diverse set of backgrounds.

During your internships (6 months – end of studies) and according to your choice, skills and interest, you can tackle one of the following subjects:
Streaming data catalog: You will help to deal with more than millions of messages per second, flowing from several Kafka clusters, all around the world, into one of the biggest Hadoop clusters in Europe.
Understand the data and their dependencies in Criteo based on actual usage and develop some use cases with: Scala/React/Typescript/SQL/Hadoop.
Develop tools and analyses to understand and monitor the quality of our data with Scala/React/Typescript/SQL/Hadoop.

Who You Are
You are in your final year of study in Systems/Software Engineering or related field.
You have already built projects in Python, C# or Java, and you have some practical experience writing Map/Reduce, Spark or Hive.
You are curious about new technologies.
You have a strong sense of ownership and a dislike for passing the buck.
You are a problem solver, a fixer, and a creative technologist. We believe coding is a talent and a passion, not just a skill.
You are a strong communicator and a team player who can work efficiently with others.
You are fluent in English.

Want to Know More?

What does it feel like to be part of something big? Get a snapshot
Get the story directly from our R&D engineers, check our Medium R&D blog
Interested in discovering your Criteo community first? Let’s meet
Check out our NEW career website. Take a look

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Saint-Maurice (94),,,Data Engineer Apprentice,Veolia,- Saint-Maurice (94),"The Data Engineer Apprentice, part of the Data Lake team, will work closely with other members of the Data Integration, DevOps & Digital teams, as well as with other IT teams (Data Analytics, Cloud, Operations, Performance, Security, and Business teams) to:
Builds scalable pipelines
Transforms and loads data into structures complete with metadata that can be readily consumed by Data Scientists
Automates and operates Data Storage, Data Pipeline, Data Catalog and the Data Access central services
Follow iterative and quick-delivery methodologies, such as Agile and Lean startup
Participate in technology watch team effort




Contributions
Design and implement solutions on Corporate Data Lake
Manage projects with a DevOps methodology
Key face-offs
VWT Corp IT teams
VWT Business teams including Data Scientists
Subcontractors
KPIs
Respect of VWT Corp IT technological choices
Projects delivery (scope, timeline, quality)
Quality of technical solutions (compliance, performance, added-value, innovation level)
#weareresourcers
Profil recherché - Compétences requises
Qualifications / Requirements
Amazon Web Services Cloud
Development (Python, NodeJS, ..)
Cloud serverless architectures and Containers
Security (AWS IAM, cloud encryption, ...)
Big data (Hadoop, Spark, MapReduce)
Relational and NoSQL Databases
Delivery pipeline tools: Git, Github, Terraform, Jenkins, Travis CI
Knowledge of popular tools (Jira, Smartsheets, Trello, Slack, …)
Agile, DevOps, Continuous Integration, Continuous Development, Lean Startup concepts
Fluent English is mandatory
Innovative state of mind

Desired Characteristics

Technology minded
Strong oral and written communication skills
Strong relationship building and interpersonal skills, in a multicultural environment
Able to anticipate, identify, and resolve technical issues
Able to quickly skill up on any technology topic
Strong ability to report status and situations
Emploi
Administrateur Systèmes / Réseau / Telecom / Data
Localisation
France-Val-de-Marne-ST MAURICE
Poste publié depuis le
15 avr. 2020, 10:29:08
Type de contrat
Contrat d'alternance -
Temps de travail
Temps plein
Statut
Non cadre"
Chilly-Mazarin (91),,,Post Doctorant Digital Data Sciences,Sanofi,- Chilly-Mazarin (91),"Au sein du groupe Clinical Trial Simulation de la plateforme Digital and Data Sciences le collaborateur sera en charge de développer des méthodes innovantes d'analyse et d'identification de relation causale entre l'exposition au traitement et la réponse clinique en cas de profil pharmaco-cinétique complexe (""Target Mediated Drug Disposition"").
Cette mission s'inscrit dans un contexte de travail au sein d'un environnement international et justifie le fait du descriptif suivant en anglais:
PostDoc Project Title:
Confounding and causal inference in exposure-response and PKPD modeling: comparison of Artificial Intelligence approach (deep causal networks) with other causal modeling methodologies. Application to immuno-oncology compounds.
Project Description
In the context of exposure response (or PKPD) analysis, confounding refers to the situation where the exposure and response are correlated, in the presence or absence of exposure effects, via factors (the confounding factors). In the context of immuno-oncology, such a situation is rather frequent: target mediated drug disposition (TMDD) naturally induces complex causal relationships between exposure and response. The consequence of this confounding effect is a bias in the true effect of exposure on the response. The aim of this work is to compare the new Deep Instrumental Variables Networks approaches with more traditional causal modeling approaches: instrumental variables, propensity scores, directional acyclic graphs. Our hypothesis is that the application of causal inference methodologies, in particular of Deep Instrumental Variables Networks methodology will enable to obtain unbiased estimates of causal relationship between exposure and response in particular in the context of immuno-oncology.
The assessment of the properties of the various methods, and their benchmark, will be first based on simulated data. Those data will be simulated using target mediated drug disposition PK models.
The method will be then applied to the estimation of Exposure-Response models for selected compounds in development.
Skills Required
1. Expertise in statistics in general and knowledge in machine/deep learning and PKPD modeling.
2. Computing skills: R, Monolix, Python, SAS (ideally)
3. Good communication skills
Expected Qualification / Experience
PhD in Statistics with experience in machine learning methods and PKPD modeling.
At Sanofi diversity and inclusion is foundational to how we operate and embedded in our Core Values. We recognize to truly tap into the richness diversity brings we must lead with inclusion and have a workplace where those differences can thrive and be leveraged to empower the lives of our colleagues, patients and customers. We respect and celebrate the diversity of our people, their backgrounds and experiences and provide equal opportunity for all.
As part of its diversity commitment, Sanofi is welcoming and integrating people with disabilities."
,,,,,,
Paris (75),,,Senior Data Scientist (Paris and Berlin),PriceHubble,- Paris (75),"PriceHubble is a PropTech company, set to radically improve the understanding and transparency of real estate markets based on data-driven insights. We aggregate and analyse a wide variety of data, run big data analytics and use state-of-the-art machine learning to generate stable and reliable valuations and predictive analytics for the real estate market. We are headquartered in Zürich, with offices in Paris, Berlin and Tokyo. We work on international markets. We are backed by world-class investors. We have a startup environment, low bureaucracy and international team and business.
Data is at the core of PriceHubble. We process a wide variety of data from multiple sources. As a data scientist, your mission will be to develop cutting edge valuation and forecasting systems for the real estate market. You will manipulate a wide range and variety of data, build new datasets, and identify patterns that eventually impact prices in the real estate market. You will then use specific machine learning approaches to design the best valuation and forecasting solutions. As a significant part of your daily work, you will take part to the productionalization of the models developed by the data science team and contribute to our international expansion. You will work closely with the business team to integrate client feedback into our solutions.
Your role
As a Senior data scientist, your mission will be to develop cutting edge valuation and forecasting systems for the real estate market. You will manipulate a wide range and variety of data, build new datasets, and identify patterns that eventually impact prices in the real estate market. You will then use specific machine learning approaches to design the best valuation and forecasting solutions. As a significant part of your daily work, you will take part to the productionalization of the models developed by the team and contribute to our international expansion. You will work closely with the business team to integrate client feedback into our solutions.

RESPONSIBILITIES
Identify, analyse, and interpret trends or patterns in a variety of internal and external sources. Handle potentially incomplete datasets.
Create, implement, test and optimize scalable models and algorithms.
Extend existing internal ML libraries and frameworks.
Productionalize models.
Identify modeling issues, design new features, and continuously provide ideas to improve our models.
Requirements
MSc with at least 3 years of experience in a similar position or PhD in Computer Science or Applied Mathematics.
Strong experience in machine learning model development and productionalization.
In-depth understanding of basic data structures and algorithms.
Strong analytical skills with the ability to collect, organise, and analyse significant amounts of data with attention to detail and accuracy.
Strong programming experience with Python and ability to write high-quality production code.
Knowledge of our tech stack (or similar technologies) is an advantage: pandas, luigi, PySpark, tensorflow, postgreSQL, kubernetes
Comfortable working in English; you have a great read, good spoken command of it.
Benefits
Flexible work hours
Casual dress code
Free snacks, fruits, coffee, beers, sodas
Ping-pong tournaments
Thursday drinks
✈️Relocation package
L&D program
Well-located offices
Competitive salary"
Paris (75),CDI,,Senior Data Scientist,Client Server,- Paris (75),"Senior Data Scientist / Machine Learning Engineer (MSc / PhD Mathematics Python). Would you like to progress your career at a global technology company?

As a Senior Data Scientist you will contribute to the core product, a cutting edge valuation and forecasting system for the real estate market; you will manipulate a wide range and variety of data, build new datasets and identify patterns that eventually impact prices in the real estate market. You will then use specific Machine Learning approaches to design the best valuation and forecasting solutions and be heavily involved in productionalisation of the models developed by the team. You will partner with the business team to integrate client feedback into solutions and continually seek improvement, extending existing internal libraries and frameworks as well as designing new features.

You'll join an upbeat team based in Central Paris with casual dress code, free fruit and a friendly team atmosphere.

Driven by technology the company is able to conduct a remote interview and onboarding process during the current social distancing measures.

Requirements:
Outstanding record of academic achievement; MSc or PhD preferred in Computer Science or Applied Mathematics (will consider other scientific / numerate disciplines)
Strong commercial experience as a Data Scientist with experience of Machine Learning model development and productisation
Strong Python coding abilities
Good understanding of basic Data Structures and algorithms
Other technologies in the stack include Pandas, Luigi, PySpark, Tensorflow, PostgreSQL, Kubernetes; experience with any of these is beneficial
Strong English language skills required

As a Senior Data Scientist you will earn a competitive salary (to €80k, depending on skillset and depth of knowledge) plus bonus and benefits.

Apply now or call to find out more about this Senior Data Scientist opportunity."
Paris (75),CDI,60 000 € - 88 000 € par an,Manager Data pour un cabinet de conseil disruptif qui double ses effectifs,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data scientist ml ia nlp dl
Fonction Data analyst sql r tableau
Fonction Data manager sql python
Taille entreprise de 51 à 200
Lead manager responsable
Expérience 6 à 10 ans
Expérience Plus de 10 ans
Statut CDI
Min 72k€
Max 130k€
L'ENTREPRISE : UN CABINET DE CONSEIL DISRUPTIF QUI DOUBLE SES EFFECTIFS
Un acteur du conseil en organisation & management :
Créée en 2014
100 + consultants
Multi secteurs : public, distribution, banque, télécom, cosmétique, …
Basé au coeur de Paris
Le cabinet doit faire face à une importante croissance et souhaite doubler ses équipes
VOTRE MISSION : MANAGEMENT ET DÉVELOPPEMENT DE LA BU DATA
Au sein de l’équipe Data Driven Business d'une vingtaine de personnes et rattaché au directeur, vous avez pour mission d’aider les clients à tirer profit des technologies les plus innovantes pour valoriser leurs données.
Pour cela, dans le cadre de votre participation aux missions de conseil en phase d’avant-projet ou projet, vous :
Cadrez les besoins avec les clients
Menez des études d’opportunités, de faisabilité
Aidez au choix de solutions la plus adapté aux besoins clients
Mise en place de datalake
Mettez en place des solutions propres à la data science (machine learning, deep learning, Data Visualisation, Data Story telling, Big Data, Intelligence Artificielle)
Organisez et optimisez le fonctionnement du Data Lab
Pilotez le projet, que ce soit d’un point de vue fonctionnel ou technique
Gérez la relation avec les partenaires technologiques (éditeurs, startups…)
Encadrez et faites évoluer votre équipe de quelques data scientist
Êtes garant d’un résultat commercial
VOTRE PROFIL : MANAGER DATA DRIVEN BUSINESS
Vous êtes diplômé d’une grande école d’ingénieur / master Big Data
Vous avez plus de 7 ans d’expérience réussie dans le conseil ou métiers du service
Vous avez une expérience confirmée avec les projets big data et/ou data science
Vous disposez d’excellentes aptitudes de business développement confirmées par des résultats concrets, et êtes actuellement un leader d’équipe reconnu
Vous êtes passionné de technologie et vous démontrez une réelle curiosité pour les nouveaux usages et nouvelles solutions
Vous restez à l’écoute des dernières tendances
Vous êtes autonome
Vous connaissez les méthodes agiles
Vous avez la fibre entrepreneuriale
Vous possédez un excellent relationnel et le goût du travail en équipe
MODALITÉS :
Package selon profil :
+ 7 d’expérience : 60K€ à 88 K€ fixe + 12 K€ de variable non capé
+ 10 ans d’expérience : 88K€ à 110K€ fixe + 20 K€ de variable non capé
Paris intra-muros
PROCESS
Une rencontre / entretien téléphonique avec le DRH
Un entretien avec le directeur data
Une rencontre avec les associés avec présentation d’une étude de cas
Sélectionné par Alison Chopard
Manager, Spécialiste Sales & Data
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),,,Lead Data Scientist – Paris (FR) - Consulting,Digital Source,- Paris (75),"Are you a Lead Data Scientist looking to join a consulting agency specialized in Data Science?
Our client is looking for a new collaborator to join their teams in Paris. Let’s see the details together.
Company Overview
Our client is a fast-growing consulting agency in Data Science. Today, they have offices in Paris, and Casablanca. The data science team has a great expertise in the banking, insurance, and health sectors. Today, they are a team of 20 data scientists, and they are searching for a new lead data scientist.
Your missions
As a Lead Data Scientist, you’ll work with a major actor in the Health sector. You’ll have to:
Report with the operations director
Collaborate and communicate with the clients
Supervise and check projects
Advise on the tech to put in place for the client
On the other side, you’ll participate in technological watches to anticipate technical and commercial opportunities.
Profile
You are graduated from an engineering school, or you have a Master/Ph.D. in applied mathematics, statistics or a related field.
Soft Skills
You can work in an Agile, and flexible environment.
You have managerial skills
Hard Skills
You have practical knowledge in Python and/or R
You have technical skills in statistics and Machine Learning, and you can adapt an algorithm to a precise problematic
You know about Machine Learning for Data Science in libraries
You know continuous integration (Git, unit tests)
You have synthetic capacities and communication that permit to argument tech choices
You have practical knowledge in Deep Learning (Keras, Tensorflow) and Machine Learning libraries (scikit learn)
Bonus
You know NLP
Their offer
Competitive salary
Variables
Incentive bonus
Restaurant tickets
Transport pass
Can you see yourself in this role? Send us your CV, and we will get back to you ASAP

8217"
Paris (75),,,Medior/Senior Data Engineer,ORTEC,- Paris (75),"ORTEC France is looking to hire a Medior/Senior Data Engineer.
As Medior/Senior Data Engineer you are a key player in the development of innovative big data platforms for advanced analytics and data processing. You bring your knowledge on Hadoop, Spark and Hive, but you also get ample opportunity to discover more.
Together with your colleagues you develop and apply best practices for ETL processes, managing data, maintenance, reporting and security. You improve data foundational procedures, guidelines and (security) standards and are responsible for the maintenance, improvement, cleaning, and manipulation of data in the business’ operational and analytics databases, by working closely together with our customers like La Poste, Carrefour, Lactalis, Danone, etc. You act as the mediator between software engineers and the data analytics teams & data scientists to make sure newly developed models are integrated in the landscape of the customer’s IT department.
In short: a great combination creating solutions for today and experimenting for tomorrow, together with a small, dedicated and young team.
Who you are
An ambitious professional with a Bachelor or master’s degree in information technology or equal.
You bring experience with large scale data warehousing (SQL, key-value, and columnar stores;
You have proficiency in data processing (e.g. Spark/Databricks/serverless functions); message brokers (e.g. Kafka) and data/workflow orchestration (Azure Data Factory, Airflow, Apache Nifi) would be a plus.
At least 3 years of relevant experience with Hadoop (Azure HDInsights / Hortonworks), Spark and Hive
You are familiar with software development practices such as git, CI/CD pipelines, building APIs (e.g. Flask or Plumber); container (orchestration) technology (Docker and Kubernetes, MLFlow/KubeFlow) would be a plus.
You have experience in working as an external supplier, preferable within multiple industries.
You have the ability to work with analysts and data scientists to gather requirements and translate them into data engineering tasks.
Inquisitive, creative and enthusiastic about sharing your ideas and know-how. Not only with the colleagues in Belgium, but also in close collaboration with the team of Data Engineers at our Center of Excellence in Zoetermeer, NL.
You have experience in coaching colleagues.
Highly focused and results oriented, able to identify goals, set priorities and resolve issues at an early stage.
Able to fluently communicate in French and English.
Ability to work in a team, and at the location of the client. Regular travel to the ORTEC HQ (Zoetermeer, NL) is required, especially during introduction.
What we offer
Immediate excellent pay and conditions
A pleasant, open, informal atmosphere
Ample opportunities to develop yourself
Optimal work-life balance
Inspiring, smart and enthusiastic colleagues
What to expect
We help you to thrive in your field of expertise. We offer development programs, tailored to your individual needs and function requirements, including opportunities to attend courses and seminars. We offer challenging practical hands-on experience with opportunities to work abroad. We operate a flat organizational structure that keeps communication lines short. The atmosphere is open, informal, cooperative and positive. We employ over 1.000 people in the Netherlands (HQ), Belgium, Germany, France, the U.K., Romania, Italy, the U.S., Australia, Brazil, Poland, Denmark and Singapore.
Visit our website www.ortec.com to learn more about our solutions and clients’ experiences.
If interested contact: recruitment.be@ortec.com"
Paris (75),,,Consultant(e) Data senior H/F,Dentsu Aegis Network,- Paris (75),"Pilotage de comptes clients et participation au développement de l'activité au sein du pôle créatif de Dentsu
Job Title:
Consultant(e) Data senior H/F
Job Description:
La mission couvre les sujets suivants :
Participer au design d’expériences innovantes faisant de la data un enjeu stratégique
CRM/PRM avec des problématiques de fidélisation , recrutement, attrition, appétence et performance commerciale
Plan d’animation avec une dimension opérationnelle et une dimension de conseil sur la stratégie relationnelle
Innovation, avec la création de nouvelles solutions pour répondre aux besoins de nos clients avec des propositions différenciantes sur le marché
Participer aux réponses aux appels d’offres
Profil
Vous êtes issu(e) d’une école de statistiques, d’une formation supérieure en économie / gestion / statistiques ou d’un cursus informatique avec spécialisation statistique. Vous avez 5 à 7 ans d’expérience en agence de communication ou chez un annonceur sur le sujet des datas appliquées au CRM et au e-CRM et de l’analyse de données.
Vous maîtrisez parfaitement les outils statistiques et bureautiques du marché (R, sas, Python...)
De nature dynamique, doté d’un bon relationnel, vous appréciez le travail en équipe, et vous souhaitez évoluer dans un contexte stimulant.
Rigueur, autonomie, sens critique, curiosité, leadership et sensibilité marketing et busines sont des qualités que vous avez pu éprouver lors de vos précédentes expériences.
Vous êtes sensible aux problématiques de digitalisation de notre monde et êtes attiré(e) par la mise en œuvre de nouvelles idées.
Vous parlez Français et Anglais couramment.
Location:
Paris - 4 Place de Saverne
Brand:
Isobar
Time Type:
Full time
Contract Type:
Permanent"
Paris 11e (75),Temps partiel,,Lead Instructor Data Analytics PART TIME (Freelance contract),Ironhack,- Paris 11e (75),"We’re looking for a Lead Instructor for our Data Analytics Bootcamp Part Time with a passion for data and for sharing their knowledge with apprentice data analysts. You need to be a strong communicator and very patient - you will find yourself explaining many abstract and complex concepts in math and technology to the first-time data squads. This is a freelance contract opportunity.

The Lead Instructor will be responsible for:
Overseeing the whole academic experience of an Ironhack bootcamp
Teaching at our Paris Campus from 3 June to 18 Dec, frequency: 2 evenings a week (6.30pm – 9.30 pm) + Saturdays (10am - 5pm). One Saturday off per month and 2 week break in August. Teaching is in FRENCH but the material/content is in English.
Supervising Teaching Assistants
Screening our prospective students through technical interviews and coding challenges
Working with the Ironhack education team to improve the data analytics curriculum and teaching practices.

#About Ironhack
Ironhack is an education startup that was founded to disrupt the way we learn about technology. We think it sucks that we’ve been learning the same way since the Industrial Revolution, so we empower students to find meaningful careers in software development or product design by offering immersive learning experiences to extremely motivated people.
Our higher purpose is to transform the education space by making it more customer-centric and outcomes-driven. Students finish our program with a new way of thinking and approaching problems, resulting in new jobs, companies they’ve built, or promotions at their current roles.

Some quick facts:
Founded by Wharton and Harvard grads in the fall of 2013
Campuses in Miami, Madrid, Barcelona, Paris, Mexico City, Berlin, Amsterdam, Sao Paulo… and more opening soon
100% YoY Growth (help us to keep it going!)
Already graduated over 2,000 students
70+ global team members + VC-backed

Availability to teach in-person PART TIME at our Paris Campus in Paris 11e from June to December 2019
Understanding of English, even if the teaching will be in FRENCH.

3-5+ years of experience in Data Analytics, Data Science, and/or Data Engineering, preferably with leadership roles
Solid understanding of and strong technical skills in Python, SQL, and R.
Proficiency in building end-to-end data pipeline:
o Writing Extract-Transform-Load (ETL) jobs to calculate business metrics.
o Understanding of APIs and Datawarehousing concepts.
Familiarity with contemporary industry software and tools (e.g. Linux, git, AWS, Google Analytics, Jupyter).
A big plus if you have experience with one or more of the following:
o Experience in Big Data architecture (e.g. Hadoop, Hive).
o Experience in Analytics and business intelligence tools (e.g. Tableau, Qlikview, MicroStrategy).
o Experience in Dataviz (e.g. D3).
o Experience in AI and machine learning.

Passion for teaching: although we don’t require previous formal teaching experiences, we’re looking for people who will enjoy teaching, mentoring, and giving feedback for students.
Experience managing and keeping a team motivated. Can-do attitude and a good sense of humor.
Great communication skills and an ability to capture people’s attention :)
Start: Mid May 2019 for onboarding
#Perks
Inspiring workplace and smart, passionate team.
Cool events year round.
A community of passionate technology enthusiasts."
Paris (75),CDI,,Senior Data Scientist (F/H),Eramet,- Paris (75),"Lieu: Paris 15,France
Type de contrat: CDI
Pour soutenir la stratégie d’Eramet, la Direction de la Transformation Numérique a lancé en 2019 sa Data Foundry, un centre analytics de 30 experts développant des analyses de données et produits data selon une approche agile mobilisant des compétences multidisciplinaires (designers UX/UI, data scientists, data engineers). Sélectionnés parmi un portefeuille de plusieurs dizaines de cas d’usage couvrant toutes les métiers d’Eramet, plusieurs projets structurants sont en cours dans le domaine de la métallurgie, de la géologie et de la mine, combinant de multiples sources de données (séries temporelles, bases de données industrielles, données textuelles) traitées par des techniques de Machine Learning, Deep Learning (CNN, RNN) ou d’Intelligence Artificielle (simulation, optimisation, apprentissage par renforcement).
Missions
Dans ce contexte, vous participez activement à la réalisation des projets data science de bout en bout, de la qualification des besoins auprès des métiers jusqu’à la mise en production des produits data. Vous accompagnez les métiers dans la compréhension des approches data science et I.A. pour favoriser l’adoption des solutions développées.
De plus, vous veillez à la qualité scientifique des productions en apportant une vision critique sur la cohérence et l’adéquation des modèles prédictifs avec les problématiques à résoudre.
Enfin, vous contribuez à la diffusion du savoir et à la montée en compétences des collaborateurs d’Eramet via la rédaction d’articles techniques et/ou de vulgarisation, et via des prises de paroles en interne ou en externe.
Profil
Vous êtes issu/e d’une formation scientifique et technique de premier rang, en Université ou école d’ingénieur, que vous avez complétée au mieux par un doctorat dans un domaine quantitatif (physique, recherche opérationnelle, ingénierie, Machine Learning, Data science, IA).
Vous avez 4-5 ans d’expérience professionnelle en réalisations de projet data science, depuis l’expression du besoin à la mise en production, en passant par le prototypage.
Idéalement, vous avez également de l’expérience dans l’industrie et une solide connaissance des données industrielles (séries temporelles, systèmes de production, texte libre, images et vidéos).
Vous possédez de solides compétences en Programmation Python (expert) et R (intermédiaire). Enfin, une maîtrise des outils Big Data (Hadoop, Spark, Pig/Hive) et cloud (Azure) serait appréciée.
Vous parlez anglais couramment et avez idéalement travaillé dans un contexte international.
Environ 20% de déplacements à prévoir (Île-de-France, France, Norvège, Nouvelle-Calédonie, Argentine)."
Paris (75),CDI,55 000 € - 80 000 € par an,Data Scientist Senior,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data scientist ml ia nlp dl
Taille entreprise de 21 à 50
Teletravail ponctuel
Technologies Agile
Technologies Aws
Technologies Python
Technologies Scala
Technologies Spark
Expérience 3 à 5 ans
Expérience 6 à 10 ans
Statut CDI
Min 55k€
Max 80k€

L'ENTREPRISE : START-UP BIG DATA SOLUTION SAAS
L'entreprise propose une plateforme web intégrant des analyses de quantification et qualification de flux pour ses clients. Son champ d'action relève du big data.
Quelques informations :
Année de création : 2016
+200 clients grands comptes
Effectif total : 30 personnes
Effectif technique : 10 personnes
Volumétrie de données : 50 gigaoctets par jour
1M€ de revenus récurrents
Activité essentiellement en France et développement récent en Europe
Environnement technique de l'entreprise : Python, Jupyter, Scala, Spark, Zeppelin, AWS, tests unitaires et déploiement continu, revues de code
VOS MISSIONS : STRUCTURER, RECHERCHER, CONCEVOIR, DÉVELOPPER, MENTORER
Au sein de l'équipe R&D vous devrez :
Structurer la démarche de R&D (documentation, méthodologie, bonne pratique...)
Intervenir sur des problématiques de classification et prédiction
Mettre au point des algorithmes permettant d'agréger des données en statistiques
Mentorer les data scientist juniors
Avoir une réflexion en termes de perspectives d'ouvertures de nouveaux algorithmes et use cases
Établir l'état de l’art et l'étude scientifique
Travailler avec les data engineer pour implémenter vos travaux
VOTRE PROFIL : DATA SCIENTIST SENIOR
Rencontrons-nous si :
Vous avez au moins 3 ans d'expérience en data science dans un contexte de R&D
Vous êtes issu(e) d'une formation bac+5 ou PhD en data science
Les mathématiques et statistiques sont vos domaines de prédilection
L'implémentation d'algorithmes complexes dans le but de confronter une théorie à une réalité vous attire
C'est un plus si :
Vous avez déjà travaillé sur des données de géolocalisation
MODALITÉS :
Rémunération : 55/80k€
Remote ponctuel
Locaux en plein coeur de Paris
Processus de recrutement :
Entretien téléphonique
Test technique sur place ou à distance selon disponibilités
Entretien physique avec le CTO et d'autres personnes de l'équipe
Rencontre des autres équipes
Sélectionné par Thomas Gourmelon
Spécialiste Python, Ruby, Go & Data Scientist
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),CDI,50 000 € - 60 000 € par an,CTO - Startup Data de l'automobile,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Cto dsi architecte
Taille entreprise de 1 à 10
Partner fondateur ceo cto
Technologies Bigquery
Technologies Spark
Technologies Sql
Expérience 3 à 5 ans
Statut CDI
Min 50k€
Max 60k€
L'ENTREPRISE
La startup développe une solution d’identification et d’analyses à destinations des acteurs de l'automobile. Créé il y a +1 an par des experts du marché de l’automobile, ils ont depuis développé des référentiels, des APIs et des algorithmes prédictifs déjà utilisés par plusieurs constructeurs, concessionnaires, assureurs, financeurs, loueurs. Ils souhaitent accélérer leur croissance en 2020, en développant notamment une web-app statistique personnalisable et industrialisable.
A PROPOS DE VOUS
Vous savez qu’un bon développeur généraliste, ça existe. Ça tombe bien, vous êtes l’un d’entre eux. Vous êtes polyvalent, rapide, autonome et attaché à la qualité du produit. Vous faites bien l’interface entre les besoins clients et la technique. Vous êtes pragmatique dans vos choix technologiques.

VOTRE RÔLE

Nous cherchons un jeune CTO (expérience 3-5 ans à discuter) polyvalent, capable de développer, d’analyser les données, de spécifier les besoins avec l’aide du métier et de piloter tant en interne que les prestataires. Vous comprenez l’enjeu de votre mission qui est d’accompagner techniquement la croissance. Comme toute mission d’envergure, vous êtes responsable de l’impact de chaque réussite et de chaque échec dans votre travail.

VOS COMPÉTENCES
Autonomie, communication et capacité à prioriser le travail.
Familiarité avec l’état de l’art du développement : tests, revues de code, intégration continue, documentation de l’architecture, etc.
Datastudio Google avec requêtes BigQuery (ou Tableau Software).
Bonnes connaissances d’un langage d’analyse de données type R/Python et du développement côté serveur.
SQL et méthodes de machine-learning (mises en pratique).
Spark.
Conception d’API.
MODALITÉS

Rémunération : 50/60K€
Bureaux situés dans Paris Centre
Autonomie et flexibilité horaire

POUR EN SAVOIR PLUS : THOMAS.CENTOGAMBE@DATARECRUTEMENT.FR
Merci d’envoyer au plus vite votre CV / votre profil LinkedIn par e-mail avec comme objet ""Auto"" à Thomas Centogambe (thomas.centogambe@datarecrutement.fr), Responsable du Pôle Javascript au sein de Data Recrutement.
Sélectionné par Thomas Centogambe
Head Hunter, spécialiste Javascript
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Fontenay-sous-Bois (94),CDI,,DATA SCIENTIST TRAITEMENT D'IMAGES (H/F),Euro Information,- Fontenay-sous-Bois (94),"Présentation de la société
Euro Information Développements a en charge la conception la réalisation et la maintenance des logiciels du système d'information commun utilisé par les fédérations de Crédit Mutuel adhérentes, les banques CIC et partenaires du Groupe.
Mission principale
« L’expertise technologique au service de la clientèle est au cœur de la stratégie de développement du groupe Crédit Mutuel qui enrichit régulièrement son offre de services innovants et sécurisés. C’est dans cet esprit précurseur que l’OCR Factory a été fondée : sa mission consiste à développer, déployer et intégrer des solutions permettant le traitement de documents numérisés pour le compte du groupe Crédit Mutuel et de ses filiales.
L’équipe, localisée à Val De Fontenay (Paris), a vocation à répondre à l’ensemble des demandes OCR, depuis l’optimisation de la reconnaissance de documents, pièces jointes ou photos, jusqu’à l’implémentation d’outils de paramétrage, d’interface ou de statistiques.
En tant que Data Scientist, vous serez garant(e) de l’expertise sur les sujets liés au traitement de données documentaires : évaluation de la pertinence des modèles OCR, élaboration de modèles ad hoc, pré-traitement des documents, etc. »
Activités et tâches spécifiques
En tant que Data Scientist, vous serez garant(e) de l’expertise sur les sujets liés au traitement de données documentaires :
Maîtriser l’état de l’art des techniques d’OCR.
Capacité à réaliser une veille scientifique et technologique concernant les techniques utilisées dans les solutions mises en œuvre.
Tester et livrer des algorithmes (en Python ou C#) sous fortes contraintes d’industrialisation.
Evaluer de manière critique, avec une démarche statistique, les performances de chaque solution.
Communiquer son travail avec des parties prenantes aussi bien techniques que fonctionnelles
Connaissances et compétences
Vous disposez de compétences en Data Science : Machine Learning, Deep Learning, traitement d’images et statistiques.
Des connaissances en OCR seraient un plus.
Vous maitrisez C#, .NET et Python.
De formation supérieure Bac+4/+5, vous justifiez au minimum d’une première expérience sur un poste similaire.
Un niveau d’anglais courant est souhaité.
La maitrise de la méthodologie agile est souhaitée.
Savoir-être - savoir-faire
Vous savez faire preuve d’initiative dans la conduite et la communication de projets techniques.
Vous êtes reconnu pour votre esprit d’analyse, de méthodologie & de synthèse, votre rigueur dans l’analyse et le développement.
Vous avez le souci du respect des normes et standards de qualité.
Vous êtes doté d’un bon relationnel avec un véritable esprit d’équipe, le sens du service clients et l’envie de vous investir dans des projets.
Autres informations
Le poste basé à Fontenay-sous-Bois est à pourvoir en CDI immédiatement.
Vous bénéficierez d’avantages « Convention Collective Banque » comme :
13ème mois,
RTT,
Prime d’intéressement et de participation,
Abondement,
Conditions bancaires avantageuses,
Régime de Frais de Santé et de Retraite très attractif,
Et encore plein d’autres avantages à découvrir…

Vous évoluez dans un environnement stimulant basé sur un management de proximité. Un Groupe qui s’engage pour ses salariés par la formation et l’évolution professionnelle.
Vous recherchez un projet innovant ? Alors Rejoignez la Team EI en postulant!"
Paris (75),"Temps plein, Freelance / Indépendant",480 € par jour,Data engineer habillitation SD obligatoire. / Freelance,EMGS CONSULTING,- Paris (75),"Nous sommes à la recherche pour l’un de nos clients d’un Data engineer pour une mission sur Paris.

Démarrage: Asap
Lieu: Paris
Durée: 3 mois renouvelable
Habilitation: Secret Défense exigé
Secteur publique

Descriptif :
Le data engineer sera sur une phase de prestation sur les tehcnologies Big Data utilisée en interne.

Mission : lié à un projet agile dont les sprints durent 3 semaines, il participe à la conception, aux développements et à la mise en oeuvre d’entrepôts de données spécifiques nécessaires au fonctionnement de l’application.

Compétences requises : Kafka, suite Elastic, Python, Spark, Scala.
Des bonnes connaissances en administration système sont demandées pour le poste.

Merci de nous transmettre votre CV au format Word votre date de disponibilité et votre TJM à l’adresse suivante: consulting(at)emgsgroupcom"
Paris (75),,,Senior Data Scientist H/F,CybelAngel,- Paris (75),"Nous traitons des milliards de documents chaque jour pour en extraire simplement les fuites de données pertinentes concernant nos clients !
Introduire de l’intelligence aux divers niveaux de notre pipeline de traitement est donc un enjeu crucial pour CybelAngel. Notre équipe Data Science a pour mission de rendre nos algorithmes de filtrage les plus intelligents possible, en vue d’optimiser et de faciliter le traitement des incidents de sécurité délivrés à nos clients.

**MISSIONS**
L’équipe Data Science conçoit, implémente, intègre et optimise des modèles de Machine Learning pour automatiser intelligemment le traitement massif de documents.
Au sein de l’équipe, tes missions en tant que Senior Data Scientist seront les suivantes:
Récupération des data, exploration, état de l'art, documentation, benchmarking, développement, déploiement. Pour quoi faire ? Catégoriser, scorer, extraire des informations sensibles (textes et images) !
Développer et optimiser les algorithmes avec le reste de l’équipe Engineering (Software Developers, Full Stack Developers, Devops etc…) pour pouvoir analyser en temps réel des milliards de documents par jour !
Collaborer avec nos Cyber-Risk Analysts et Product Managers pour définir et maintenir des objectifs de précision et performance des modèles;
Encadrer techniquement et valider les bonnes pratiques des data scientists plus junior dans l’exécution des projets;
Concevoir, planifier et prioriser les projets en cours;
Collaborer avec les autres équipes (Engineering, Produit et Cyber Analystes);
Promouvoir les bonnes pratique dans notre équipe;
Réaliser des veilles technologiques et être force de proposition sur toutes les nouvelles technologies.


Les + du Job:
Faire partie d’une équipe soudée et passionnée de Data Scientists et Data Engineers (organisation de CybelKaggle, participation à des conférences, MeetUp et formations).
Les projets Labs : Chez CybelAngel, chaque ingénieur alloue 20% de son temps au projet personnel de son choix (formations sur les nouvelles technos, tester des idées innovantes etc…)
Tu es quotidiennement en lien direct avec les experts analystes en cybersécurité ce qui te permet d'avoir un impact global et stratégique.
Profiter de tous les avantages d’un environnement de travail fun et agréable au quotidien: cours de yoga, petit-déjeuners, bootcamp, afterworks, meetups et bien d'autres !


Stack techno
DBs: Elasticsearch, Mongo, Redis, BigQuery
Infra: GCP, Docker, Kubernetes, Datadog, Gitlab CI, RabbitMQ
Frontend: VueJS/VueX, SCSS, Bulma
Backend: Python
Requirements
Compétences requises
Au minimum 3 ans d’expérience en tant que Data Scientist au sein d'un environnement ML
Passionné par le Machine Learning
Tu est doté d'un esprit d'équipe
Bac +5 ou plus en statistique, probabilité, mathématique ou machine learning
Maitrise de Python
Excellente communication pour pouvoir comprendre, synthétiser et expliquer des problèmes complexes de manière simple avec les équipes Product, Engineering et Analyst.
Autonomie sur la conception et l’implémentation de nouvelles solutions, force de proposition et créativité
Une expériences réussie en gestion et développement de projets Data Science


Compétences appréciées
Compétence en Data/Software Engineering
Bon niveau de compréhension en NLP
A l’aise en Data Viz’
Traitement de datasets volumineux
Expérience avec des technologies Big Data : ElasticSearch, Cassandra, MongoDB, Hadoop, RabbitMQ
Expérience avec Tensorflow/PyTorch
Expérience dans un environnement Agile, idéalement Scrum
Benefits
Localisation: Paris
Contrat: CDI à temps plein
Rémunération: Selon profil et expérience"
Paris (75),CDI,50 000 € - 65 000 € par an,Data Scientist confirmé(e),Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data scientist ml ia nlp dl
Taille entreprise de 21 à 50
Technologies Agile
Technologies Git
Technologies Machine learning
Technologies Nlp
Technologies Python
Technologies Scikit learn
Technologies Spark
Technologies Tensorflow
Expérience 1 à 2 ans
Expérience 3 à 5 ans
Statut CDI
Min 50k€
Max 65k€

CONSEIL EN STRATÉGIE & MANAGEMENT, SPÉCIALISÉ DATA
L'entreprise accompagne ses clients à valoriser leurs données en menant des projets big data et d'intelligence artificielle. Les consultants interviennent de bout en bout, de la conception de la stratégie à l'exploitation des plateformes technologiques.
Rejoindre l'aventure c'est se spécialisér sur des problématiques de machine learning, deep learning et big data.
Année de création : 2016
Effectif : 36 collaborateurs
Très bon positionnement : directions générales, marketing, innovation ou data lab (pas de DSI)
Clients diversifiés : média, banques, industries, retail
Problématiques : spécialisé data, à un niveau conseil en stratégie et management (vs agences)
Pur conseil : les missions sont vendues au forfait et vous revenez au cabinet 1 à 2 jours par semaine
Missions courtes : 2/3 mois
Équipes : grandes écoles et du TOP30 des cabinets de conseil
Top formation : conférences payantes, formations internes… – le bon endroit pour monter en compétence
Top locaux : en plein coeur de Paris
Notre avis chez Data Recrutement, en tant que cabinet de chasse :
Le type de cabinet de conseil avec des missions très intéressantes (courtes, stratégiques, utiles) et une culture d’entreprise startup.
VOTRE MISSION : DATA SCIENTIST – BIG DATA – IA
En étroite collaboration avec le manager et le bureau de Paris, vous devrez :
Contribuer à la réalisation de projets technologiques en Intelligence Artificielle (IA), R&D et/ou auprès de clients Grands Comptes
Apporter des réponses concrètes à un besoin métier grâce à l’IA : concevoir, développer, tester et industrialiser les algorithmes et les solutions
Déployer des cas d’usages data variés, allant du marketing prédictif à l’analyse d’image, en passant par le NLP
Encadrer et mentorer des data scientists juniors
VOTRE PROFIL : DATA SCIENTIST CONFIRMÉ(E)
Rencontrons-nous si :
Vous êtes diplômé(e) d'une top école d’ingénieur avec une formation data (X, CentraleSupélec, Mines, ENSAE, …) ou un bac+5 orienté data
Vous avez idéalement une première expérience dans un cabinet de conseil en stratégie et management
Vos 2 ans d’expérience minimum (hors stage) sur des outils de gestion de la donnée font de vous un(e) expert(e) : R, Python, Spark, Hadoop, NoSQL databases (MongoDB, Cassandra, HBase), TensorFlow
Vous avez de bonnes connaissances en IA : Machine Learning, Deep Learning, NLP, Computer Vision, Transfer Learning
Vous souhaitez participer à l’aventure d’un cabinet déjà très reconnu et en forte croissance dans une culture startup
Parler français/anglais couramment n'est pas un problème
MODALITÉS :
Package : 50/65k€ selon expérience
Processus de recrutement rapide :
Entretien téléphonique
Test technique sur de l'algorithmique en Python
Rencontre avec le directeur technique
Sélectionné par Thomas Gourmelon
Spécialiste Python, Ruby, Go & Data Scientist
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris 8e (75),,,Consultant(e) Data Engineer,Sia Partners,- Paris 8e (75),"Company Description
Sia Partners réinvente le métier du conseil et apporte un regard innovant et des résultats concrets à ses clients à l'ère du digital. Avec plus de 1 650 consultants dans 16 pays, nous allons générer un chiffre d'affaires annuel de plus de 270 millions d'euros pour l'exercice en cours. Notre présence globale et notre expertise dans plus de 30 secteurs et services nous permettent d’accompagner nos clients dans le monde entier. Nous accompagnons leurs initiatives en stratégie, projets de transformation, stratégie IT et digitale et data science. En tant que pionniers du Consulting 4.0, nous développons des consulting bots et intégrons dans nos solutions la disruption créée par l'intelligence artificielle.

Job Description
Pour accompagner son développement, Sia Partners recrute un Consultant Data Engineer. Il aura pour vocation d’assister la business unit Data Science dans la mise en place de solutions performantes d’infrastructure et d'architecture, permettant à la fois le passage à l'échelle ainsi que la réalisation de missions et travaux orientés données (projets internes et externes). Les travaux couvriront les thèmes suivants :
Services Cloud : choix d'architecture, utilisation de services de stockage & calcul avec une préférence pour les services serverless
Docker & Kubernetes : containerisation & orchestration d'applications, gestion du cluster datascience de Sia Partners
Programmation : développement d'outils exécutés côté serveur (traitement de données en masse, serveur API HTTP REST, authentification, ...)
Pipeline CI/CD : gestion de l'intégration et du déploiement continu de nos bots et de nos plateformes internes, appui au déploiement de projets datascience chez nos clients
Système UNIX : administration et décommissionnement progressif de serveurs dédiés (migration vers le cluster Kubernetes)
Infrastructures & Services adaptés au Machine Learning : veille technologique et mise en place de solutions utiles aux datascientists dans l'apprentissage et la mise à disposition de leurs modèles ML.

Qualifications
Vous avez une formation en École d'Ingénieur ou une formation de haut niveau dans le domaine des technologies de l’information et vous justifiez idéalement d'une première expérience en Data Engineering, Architecture Cloud ou DevOps.
Vous disposez d'un très bon niveau en Python et possédez des bases solides dans d’autres langages interprétés ou compilés. Vous êtes familier avec au moins un SGBD SQL (PostgreSQL, MariaDB, Oracle) et êtes capables d’utiliser ses fonctionnalités avancées.
Vous maitrisez au moins une plateforme de services Cloud (GCP, AWS, Azure) avec une expérience mêlant différents services au sein d'un même projet. Une expérience de services serverless de calcul serait un plus.
Vous êtes à l'aise dans l'utilisation de Docker, l'automatisation de pipeline CI/CD et avez une forte appétence pour monter en compétence sur Kubernetes si vous ne maitrisez pas déjà cet outil.
Vous vous inscrivez dans la Culture DevOps : prise en charge du cycle de vie du code, du développement jusqu’au déploiement et maintien des applications (une maitrise de l'écosystème Gitlab-CE est un plus).
Vous êtes sensible aux problématiques de sécurité et avez de l'expérience dans la mise en place de solutions de protection des données (gestion de certificats, sécurisation HTTPS, authentification OAuth2, gestion des credentials, ...)
Vous souhaitez vous impliquer et prendre rapidement des responsabilités sur des missions à forte valeur ajoutée au sein d’une structure dynamique.
Français et anglais professionnel courant indispensable.

Additional Information
Poste basé en plein coeur de Paris (métro George V).
Pour plus d'information sur notre practice Data Science, consultez notre showroom de bots : https://datascience.sia-partners.com/fr
Et une vidéo de présentation de nos ""AI services & solutions"" : https://www.youtube.com/watch?v=hbnEoa9zHQY"
Paris (75),,,Consultant(e) MOA Data Digitales,Smartpoint,- Paris (75),"Le consultant MOA data assurera la gestion des projets et des problématiques autour de la donnée, de leur validation à leur restitution.
Il centralisera les besoins des équipes, les spécifiera, en suivra la bonne réalisation auprès des équipes de développement et effectuera la recette.
Il assurera également la coordination entre les différentes équipes travaillant sur les données et gérera les référentiels métiers.
Le périmètre concerne les données digitales (web et mobile) que ce soit d’un point de vue utilisateurs (trafic) ou d’un point de vue métier.
Les principaux projets auxquels participera le consultant MOA Data sont :
La mise en place et le suivi d’indicateurs de qualité de données sur la nouvelle chaine de traitement et d’analyses statistiques des données pour tous les supports. Cette nouvelle chaine est mise en œuvre via les technologies Big Data (Hadoop, …)
La spécification et la mise en place des outils de restitution (tableau de bord, datamart, …)
Le suivi de la production des tableaux de bord réalisés par l’équipe.
Compétences requises :
De formation bac+5
3 ans d’expérience sur les projets Business Intelligence (modélisation de datamart)
Capacité et intérêt à aller dans le « détail »
Expérience en gestion des projets
Grandes qualités relationnelles
Goût pour le travail en équipe
Intérêt pour le digital, le marketing et les nouvelles technologies
Autonome et curieux
Expérience : mini 3 ans d’expérience."
Paris 2e (75),CDI,,Tech Lead Data Analytics & Visualization F/H,YSANCE,- Paris 2e (75),"Ysance poursuit sa croissance et son développement en intégrant au sein de ses équipes de nouveaux experts en recrutant un profil Tech Lead Data Analytics & Visualization.

En tant que

Tech Lead Data Analytics & Visualization

, vous serez intégré(e) à une équipe et participerez à la mise en place de projets Data Centric en tenant le rôle de :

✔️ Référent technique Data Visualization sur les projets identifiés et sur lesquels vous intervenez (audits technologiques, optimisation, mise en place d’architecture analytique chez nos clients)

✔️ Interlocuteur privilégié au sein des équipes projets mais aussi auprès de nos équipes, vous participerez activement à la mise en place de solutions analytiques dédiées à nos clients,

✔️ Acteur actif dans le cadre des réponses à appels d’offres ainsi que lors des soutenances

Par ailleurs, vous participerez à la formation et à la conduite du changement auprès de nos clients en les accompagnant dans l’ensemble du projet et du processus de prise en mains des solutions mises à en place.

Enfin, au sein même d’Ysance, vous serez amené(e) à former nos équipes, les accompagner dans leur montée en compétences tout en étant capable de les challenger lors de vos interventions ponctuelles ou plus durables sur les projets.

➡️ Environnement technique : Qlik (QlikView et Qlik Sense), Tableau Software, Power BI, Toucan Toco
Profil recherché Issu(e) d’une formation supérieure technique, vous avez à votre actif une expérience d’au moins 5 ans réussie dans la mise en place d’une solution de Data Analytics.

Vous possédez des compétences avancées sur Qlik, Tableau Software, Power BI ou Toucan Toco

L’obtention de certifications éditeurs serait un plus.
Entreprise YSANCE est une société spécialisée dans le traitement de la Data.

Nous couvrons l'ensemble de la chaîne de valeur Data :
✔️ Intégration de données (Talend ETL, ESB, Data Quality)

✔️ Big Data (Cloudera, Hortonworks, Snowflake, Big Query)

✔️ Cloud (Amazon, Microsoft, Google)

✔️ Data Science, prédictif, prescriptif (R, Python, DataIku)

✔️ Analytics (QlikView, QlikSense, Tableau Software, Toucan Toco)

Nous avons également développé des offres autour du Référentiel Client Unique (RCU), du périmètre e-RFM et du Customer Analytics.

Dans le cadre de notre développement et de nos projets, nous recherchons de nouveaux talents passionnés comme nous par la Data.

✔️ Notre valeur ajoutée ?

Une forte expertise technique autour de la Data qui repose sur nos équipes et qui est renforcée par de nombreux partenariats avec les éditeurs dans le domaine du Big Data & Analytics.

✔️Pourquoi nous rejoindre ?

Une forte culture Data, des clients de renoms dans des secteurs variés, une approche orientée autour du besoin client afin de répondre au plus près de leurs enjeux.

Alors si intégrer une structure Data Driven à taille humaine répond à vos attentes professionnelles, c'est avec plaisir que nous échangerons avec nos consultants opérationnels.

A bientôt,"
Paris (75),CDI,,Data Engineer Manager,Sept Lieues,- Paris (75),"PME en forte croissance, sur le secteur de l'immobilier.
LE POSTE / LES MISSIONS
Au sein de l'équipe Data engineer et en collaboration avec l'équipe Data Science vos missions seront les suivantes :

1/ Industrialisation de modèles (économétriques et Machine Learning ainsi que des chaines de traitement de données), Chantier d'intégration, modélisation et intégration de sources de données hétérogènes.

2/ S'assurer de la bonne coordination des projets en terme de d'échéance et de qualité technique.

3/ Faire grandir l'équipe, encadrer des profils plus juniors (management d'une dizaine de Data Engineers).
PROFIL RECHERCHÉ
Vous avez une première expérience réussie sur un rôle d'Engineering Manager au sein d'une équipe Data (10 ingénieurs environ)

D'un point de vu technique :
Compétences en développement en Data (Data pipeline et industrialisation de modèles), jusqu’à occuper un rôle de développeur/se senior
Solides compétences en Machine Learning"
Paris 19e (75),CDI,,Senior Data Engineer F/H,ITmakeSense,- Paris 19e (75),"Notre client a pour mission de favoriser un nouveau mode de consommation favorisant l’

économie circulaire

tout en luttant contre le gâchis électronique et l’obsolescence programmée.

Descriptif du poste

Tu intégreras directement une équipe au cœur de l’innovation : le Bureau Of Technology.

Au sein du BoT, et plus particulièrement de la team Data Engineer, tu contribueras activement à la strategie et à la construction de l'architecture Big Data

Ils ont besoin de toi pour :
Implémenter des algorithmes d’analyse de données pour l’industrialisation ou l’exploration R&D.

Collecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes).

Développer et automatiser les flux de données et leurs visualisations en dashboards, reporting.

S’assurer de la scalabilité, la sécurité, la stabilité et la disponibilité des données de la plateforme.

Analyser des données web pour répondre aux questions métiers et participer à la construction de l’architecture Big Data
Profil recherché Profil recherché

Tu seras comme un poisson dans l’eau si :
Tu possède une excellente maîtrise d’un langage de programmation (Python, Go…)

Tu sais communiquer des résultats de manière claire et synthétique

Tu as des bonnes expériences en Data Mining, Data Warehouse, Big Data, Algorithm, NoSQL, Apache Spark, Parallel Programming

Tu as une excellente capacité d’analyse des données et de leurs visualisations

Tu es flexible et créatif dans la résolution des problèmes

Tu es le roi de la glisse ? Tu surf les vagues autant que les pipes de données ?

Tu es bien organisé, autonome, rigoureux et doté d’un bon esprit d’équipe

T’interesses-tu à plus?

Git, Linux, Django, REST, bash

Data Lakes

Designing and developing RESTful APIs

Multi-threading et integration en continue

Celery, RabbitMQ, ElasticSearch

Scalability and Security tests

Pourquoi devrais-tu rejoindre l'équipe ?

Un salaire attractif (50/70K€), des stocks (BSPCE), avantages multiples (tickets restos, mutuelle, etc…), Fruits et petit dej, plusieurs jours de remote par semaine, journée avec des collègues sympas et évènements offsite fréquents.

Des challenges techniques à relever au quotidien : Tu n’auras pas le temps de t’ennuyer !

Un groupe d’experts qui t’apporteront leur savoir-faire technique et te permettront de monter en compétence sur ton domaine de prédilection mais pas que ! (Guildes techniques, Meet-up & Conférence)

Des perspectives d’évolution avec la possibilité de changer de team feature tous les 1 an et différents plans de carrières possibles.

Un job qui a du sens : à travers ton travail, tu convaincras des gens d’acquérir des produits ayant déjà vécu au lieu de les acheter neufs. Ce qui signifie réduire la production de déchets électroniques et lutter contre la surproduction. Ça compte.

Un projet en forte croissance : Notre client ne comptait que 3 personnes il y a 4 ans. A présent, ils sont plus de 160, et on ouvert dans 6 pays différents.

Du groove, plein : tu auras l’opportunité de bosser avec des gens talentueux et super sympathiques.

Déroulement des entretiens

Entretien téléphonique avec Thierry, Recruteur

Entretien technique + Entretien Fit

Entretien avec le CTO et Thibaud, le CEO
Entreprise ITMakeSense est le site d’emploi IT responsable qui met en relation les entreprises qui veulent sauver le monde avec les ingénieurs informatiques en quête de sens. Si vous êtes de celles et ceux qui préfèrent les actes aux paroles et souhaitent agir au quotidien pour avoir un impact positif sur le monde, nous sommes ici pour vous aider à accomplir vos projets."
Paris (75),CDI,45 000 € - 55 000 € par an,SENIOR DATA SCIENTIST - Tech Startup,Harnham,- Paris (75),"Senior Data Scientist
Paris, France
45-55K
Leader du media publishing sur Internet (vous reconnaitrez certainement leur contenu), la société grandit son pôle Data et recherche aujourd'hui un Data Scientist experimenté. Ce poste offre la possibilité de travailler sur des sujets divers (NLP, Machine Learning, Advanced Analytics...) sur leur plateforme tech qui gère leur contenu media et video, entouré d'une équipe Data Science en place. Aujourd'hui très solide sur le plan financier, avec des records d'audience et d'abonnés, les projets data science seront riches et divers.
LE POSTE:
Encadré par le Head of Data de la société, vous travaillerez avec une équipe de profils seniors et juniors basé sur Paris et en remote
Votre background technique vous permettra d'apporter votre expertise du côté Data Science, Machine Learning et Intelligence Artificielle - la société utilise Python actuellement
Votre seniorité technique vous permettra de diffuser vos idées pour continuer à développer et optimiser les plateformes et le succès du contenu publié (on peut donc penser à divers projets Machine Learning, de la prédiction, des Algos poussés qui automatisent les process, du NLP ...)

VOTRE PROFIL:
Un background académique (bac+5 et plus) orienté Stats/Maths/Finance ou domaine relié
Expérience industrielle en tant que Data Scientist
Expertise sur Python, SQL, et expérience avancée en machine learning
COMMENT POSTULER:
Merci de me faire part de votre CV à jour et je vous recontacterai au plus vite."
Levallois-Perret (92),,,Head of AI M/F,zaion,- Levallois-Perret (92),"Descriptif du poste:
You will take part in the creation of ZAION's R&D pole and will pilot our AI and voice solutions projects (defections of emotions in the voice).
Build, adapt and evolve our services for detecting emotion in the voice
Analyze large databases of conversations to extract emotionally relevant conversations.
Build a database of conversations labeled with emotional labels
Train and evaluate machine learning models for emotion classification
Deploy your models in production
Continuously improve the system for detecting emotions in the voice
Profil recherché:
You have a minimum of 5 years experience as a Data Scientist/Machine Learning applied to Audio and 2 years experience in coaching.
Graduated from an engineering school or Master's degree in Computer Science or a PhD in Computer Science Mathematics with strong signal processing skills (audio preferred)
Strong theoretical background in machine learning and relevant mathematical fields (clustering, classification, matrix factorization, Bayesian inference, deep learning...)
The availability of machine learning models in a production environment would be a plus.
You are proficient in one or more of the following languages: Python, Frameworks of Learning/Deep Learning machine (Pytorch,TensorFlow,Sci-kit learn, Keras) and Javascript
You master the techniques of audio signal processing.
Confirmed experience in the labelling of large BDDs (preferably audio) is essential;
Your personality: Leader, autonomous, passionate about your job, you know how to lead a team in project mode.
You are fluent in English"
Paris (75),,,Senior Data Engineer,Doctrine,- Paris (75),"Our mission: we are advancing open justice around the world.
Our products: we are building legal research and analytics software for legal professionals to search through the law, handle their cases, and grow their business.
Our ambition: in a ""traditional"" industry, we strive daily to offer our customers the latest technologies, especially in the field of artificial intelligence, through simple and well-designed products

-

At Doctrine, we apply cutting edge machine learning (including deep learning) and natural language processing (NLP) technologies to the largest database of court decisions ever gathered. Data is the core of our business. As it takes exceptional people to build the future of law, we are looking for an exceptional Senior Data Engineer to make an impact on how we collect and process data.
As a Senior Data Engineer, you will:
Build a robust and scalable data infrastructure to collect and make available terabytes of data
Unify the data stored on our relational databases by understanding, designing and initiating a reliable, robust and maintainable data model
Design a state-of-the-art acquisition pipeline that will allow Doctrine to always provide the most fresh content to our users
Improve our workflows in Airflow by better specifying our needs and providing flexible solutions to make this infrastructure completely scalable
Identify needs of feature teams in a high-performance context
Lead and participate to many projects in a fast-growing company.
We’re looking for teammates with:
A passion for building large and complex data infrastructures and pipelines
Great software development skills in Python and possibly in Node.js
Excellent knowledge of SQL and its databases (PostgreSQL)
A strong knowledge of cloud environments (AWS)
A knack for sharing your work and make people around you better teammates
Excitement about taking cutting-edge technologies and techniques to one of the most important and most conservative industries
A good knowledge of French, as you will process French court decisions. It is not required to have an experience in the legal field for this job, however, some interest in law is always a plus
English fluency
Bonus points if you have:
An experience with containers in production
An experience with managing large-scale crowd-sourcing data labeling and acquisition (Amazon Turk, Crowdflower, etc.)
Our stack:
AWS (S3, Lambda, EC2, RDS...)
Python is used by Machine Learning Engineers & Backend Engineers and Node.js is used by Backend Engineers
PostgreSQL and ElasticSearch
Airflow to orchestrate workflows
-

Why you should apply:
It's the ideal time to join Doctrine in terms of growth and opportunities
We have a strong team spirit and company culture, we live our values at a daily basis
Top-notch learning environment: ongoing mentorship, weekly best practices sharing
We work in a cool and classy office in the heart of Paris (Métro Sentier)
Regular feedback and compensation reviews - we nurture the feedback culture and reward great work

Benefits:
Competitive package, including stock options
Unlimited time off
Referral bonuses
A great health insurance policy
Lunch coupons

Other perks:
IT equipments
Free coffee, tea, and fresh fruits
Thursday beers, Wednesday breakfasts and monthly events with the team


We are an equal opportunity employer and value diversity at our company. We do not discriminate on any basis including religion, color, origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Remote applicants: This position is based in our office in Paris. If you're interested in remote work, check back soon as our needs may change."
Paris (75),"Temps plein, CDI",,Manager data confirmé (H/F),PHI RH,- Paris (75),"PHI NTIC, division dédiée aux métiers IT du cabinet PHI-RH, recherche pour un client basé à Paris, un un Manager spécialisé en Big Data/Data Sciences.
Notre client est un cabinet de conseil innovant spécialisé en transformation digitale, organisé en Agile et premier du classement FrenchWeb 2019 parmi les meilleures sociétés de conseil.
Missions
En tant que « Manager (big) Data », encadré par un Directeur, vous serez intégré à l’équipe Data Driven Business dont la mission est d’aider ses clients à tirer profit des technologies les plus innovantes pour valoriser leurs données :
- Participation aux missions de conseil en phase d’avant-projet (cadrage, études d’opportunités, faisabilité, choix de solutions technologiques, mise en place de démonstrateurs) et/ou en phase de projet (mise en place de datalake, projets de Data Science – machine learning, Deep learning)
- Contribution à l’atteinte des objectifs majeurs des clients
- Aide au choix de solutions dans le cadre de prestations de conseil,
- Mise en place et expérimentation de Data Science
- Organisation et optimisation du fonctionnement de Data Lab
- Pilotage de projet – du point de vue fonctionnel et technique
- Gestion de relations avec nos partenaires technologiques (éditeurs, startups…)
Business developer, leader d’équipe, vous assurerez l'encadrement d’une équipe de 5 à 6 personnes. Au sein d’une équipe de Data Scientists, Data Engineers, Data Analysts, Data Architects vous prendrez une part active dans l’animation de la communauté Data, et superviserez les travaux de R&D.
Vous contribuerez également activement à l’évolution des offres de service et à la notoriété de notre client en participant à des évènements marketing (prises de parole, points de vue d’experts…).
Profil
H/F, de formation supérieure, vous justifiez de 5 ans d’expérience minimum dans le Conseil ou les métiers du service. Au cours de votre parcours, vous avez réalisé des outils analytiques, applications, bases de données et avez acquis une expérience confirmée et réussie dans le domaine du Big Data ou des Data Sciences.
Un niveau d'anglais courant, à l'oral comme à l'écrit, est requis pour ce poste.
Il s'agit d'un poste à pourvoir en CDI.
Type d'emploi : Temps plein, CDI
Expérience:
manager data confirmé (h/f) ou similaire: 5 ans (Souhaité)"
Paris (75),CDI,,"Consultant(e) (Confirmé, Senior et Manager) Stratégie Data et Data Management",Rhapsodies Conseil,- Paris (75),"Description du poste
Dans un contexte en mutation rapide autour du numérique et du digital, plus que jamais la question de la gestion des données se pose comme étant au coeur des préoccupations des entreprises de tous secteurs. Le Cabinet Rhapsodies Conseil se positionne comme référence sur les sujets de Stratégie Data et de Data Management. Nous nous fixons pour ambition de guider et de conseiller nos clients autour des enjeux de la Transformation Data : Stratégie, Usages, Culture, et Maîtrise des données.

Dans ce cadre et pour accompagner notre forte croissance, nous recherchons des profils Consultant(e) (Confirmé, Senior et Manager) Stratégie Data et Data Management pour mener des missions de Conseil auprès de nos clients et accompagner le développement de notre proposition de valeur.

Selon votre profil et vos domaines de compétences, vous intervenez sur une ou plusieurs missions clients sur les enjeux suivants :
Construire et orienter la stratégie Data, à travers une vision et des convictions, pour valoriser et protéger les données des organisations,
Cadrer les usages Data et faire le design des chaînes de valorisation de données, des sources de données jusqu’aux usages des métiers,
Piloter des projets Data depuis les échanges avec les métiers jusqu’à leur concrétisation,
Contribuer à la construction et à la diffusion d’une culture Data au sein des organisations,
Construire le cadre de gouvernance et de régulation des données (modèle opérationnel, rôles et responsabilités, instances, processus, outils),
Accompagner les avancées réglementaires sur les données (cadrage RGPD, Solvabilité 2, BCBS…) et les transformer en opportunités pour les Métiers
Animer des ateliers Data (recueil des besoins, usages, formation…)
Faire de la modélisation des données un levier d’échange et de valeur avec les métiers, l’écosystème et les projets,
Accompagner les initiatives autour de la Data Science, de l’intelligence artificielle (Machine learning, Deep learning…), des algorithmes, du temps-réel,
Adopter des démarches frugales pour conduire les projets et atteindre les résultats recherchés.


Vous participerez au-delà de vos missions à l’effort commercial de l’équipe en participant à des propositions commerciales et à des soutenances orales afin de développer notre activité. Vous serez aussi un acteur du développement de l’activité de l’équipe en gérant des communications internes et externes et en travaillant à la conception, à l’évolution et à la présentation de nos offres data.

Description du profil

De formation supérieure Bac+5, vous justifiez d’une expérience de 5 années minimum dans la conduite de projets de transformation digitale et/ou de valorisation des données.
Vous êtes reconnu pour vos qualités de rigueur, d’esprit de synthèse, d’organisation et par votre capacité à travailler en mode projet.
Votre sens du service client et votre relationnel vous permettront d’être un interlocuteur crédible auprès de nos clients.
Vous savez faire preuve d’autonomie, d’adaptabilité et de sens de la confidentialité,
Votre créativité et la compréhension du métier de nos clients vous amènera à proposer à nos clients des solutions innovantes et adaptées à leurs problématiques.
Vous parlez un anglais courant (environnement international),
Vous voulez rejoindre notre équipe et participer au développement de l’activité data du cabinet ? Contactez-nous à l’adresse suivante : candidature@rhapsodiesconseil.fr

Présentation de l’entreprise
Nous sommes un Cabinet de Conseil indépendant, à taille humaine, ayant pour objectif d’être un acteur de référence sur ses domaines d’expertises. Notre ADN est orienté autour de 5 sens : l’Expertise, la Transformation pour nous et pour nos clients, la Culture du partage et de la transmission des savoirs, l’Innovation et la Responsabilité par nature. Nous sommes un acteur engagé et citoyen.
Nos consultants évoluent au sein d’un environnement stimulant, bienveillant et convivial fondé sur le développement, le partage de connaissances, l’ouverture d’esprit ainsi que la valorisation des potentiels.
Ce que nous voulons aujourd’hui, c’est partager l’aventure avec les meilleurs d’entre vous !
Et n’oubliez pas, chez Rhapsodies, on se choisit !

Rencontrons-nous, nous aurons le plaisir de vous montrer que ce ne sont pas que des mots."
Courbevoie (92),,,TechU Graduate Technical Trainer,AWS EMEA SARL (France Branch),- Courbevoie (92),"Recently completed or currently studying on a Bachelor’s or Master’s degree in Computer Science, Computer Engineering, or related fields
Experience with one of the following programming languages: Java, Python, Ruby, Node.js, C#, or C++
Experience with Networking fundamentals, Security, Databases (Relational and/or NoSQL), Operating Systems (Unix, Linux, and/or Windows)
Fluent proficiency in English
Must be able to relocate and work for the first 6 months at our in Madrid

Do you have a deep passion for utilizing technology to empower businesses? Are you passionate about collaborating with technology and business leaders to deliver cloud-based solutions?

Amazon Web Services (AWS), a subsidiary of Amazon.com and a leader in Cloud Computing, is seeking early career talent to join our AWS Tech U Program. This is a unique opportunity for driven, self-starters to play a key role in a fast-growing business, and to deliver significant value to AWS customers of all sizes from nimble startups to global brands. You will learn from top AWS subject matter experts and get paid while you train for an exciting career in the tech industry.

These are some of the most challenging and exciting roles in the IT industry today. We work with cutting edge technologies supporting the largest and most innovative businesses, non-profits, and government agencies around the world. This is a an unparalleled opportunity to leapfrog your peers and take a leadership role helping AWS to transform the way the world uses technology to solve their business challenges. The skills and experiences you gain will be highly sought after throughout the industry and give you the opportunity for the career of a lifetime.

Associate Technical Trainer

The Associate Technical Trainer role will allow you to be on the cutting edge of new technology as AWS continues to extend the platform with new features and new cloud services. You will have opportunities to travel the world, work with AWS customers from all over, representing the hottest startups and most established companies, as they learn how to leverage AWS technology to transform their industries. You will have the opportunity to deliver instructor led courses with customers and record e-learning modules that will reach thousands of customers around the world. In addition, you will help identify areas of existing architectural collateral that need updating in order to ensure customers can create world-class solutions built on AWS.

About Tech U

As an Associate Solutions Architect, you will be part of AWS Tech U, which is an accelerated career development program for those who want to advance both their technical and business skills. This unique program consists of a 6-month instructor lead, project-based learning curriculum, followed by a 6-month On-the-Job Training (OJT) learning assignment within Solutions Architecture.

Are you ready to embrace the challenge? Come build the future with us.

Program Starts in September 2020

Excellent communication skills and ability to effectively articulate technical challenges and solutions to both large and small audiences
Experience implementing a cloud-based technology solution in a school project or while working for a company
Experience with one or more of the following domains: systems administration (Linux/Window), network administration (DNS, IPsec, BGP, VPN, Load Balancing), or programming (Node.JS, Java, Ruby, C#, Python, or PHP)
Demonstrated ability to adapt to new technologies and learn quickly

Application and Assessment Process

Eligible candidates will be invited to attend an online assessment. If successful after this, candidates will be invited to complete a technical phone screen. Candidates who pass the technical phone screen will then be invited to attend an in-house assessment centre. This selection process is subject to change but you will be notified if any changes are made.

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build.

Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice to know more about how we collect, use and transfer the personal data of our candidates.

EU Student Programs Team"
Paris (75),Intérim,,Temporary less 6 month (limited contract): SAP Big Data Platform Engineer F/M,SAP,- Paris (75),"Requisition ID: 244820
Work Area: Information Technology
Expected Travel: 0 - 10%
Career Status: Professional
Employment Type: Limited Full Time

COMPANY DESCRIPTION

SAP started in 1972 as a team of five colleagues with a desire to do something new. Together, they changed enterprise software and reinvented how business was done. Today, as a market leader in enterprise application software, we remain true to our roots. That’s why we engineer solutions to fuel innovation, foster equality and spread opportunity for our employees and customers across borders and cultures.
SAP values the entrepreneurial spirit, fostering creativity and building lasting relationships with our employees. We know that a diverse and inclusive workforce keeps us competitive and provides opportunities for all. We believe that together we can transform industries, grow economics, lift up societies and sustain our environment. Because it’s the best-run businesses that make the world run better and improve people’s lives.
HOW TO APPLY?

Are you interested in this position? Check the job description and apply on our French career website.

#cdd #ingénieur #bigdata #paris

WHAT YOU GET FROM US
Success is what you make it. At SAP, we help you make it your own. A career at SAP can open many doors for you. If you’re searching for a company that’s dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment – apply now.

SAP'S DIVERSITY COMMITMENT
To harness the power of innovation, SAP invests in the development of its diverse employees. We aspire to leverage the qualities and appreciate the unique competencies that each person brings to the company.
SAP is committed to the principles of Equal Employment Opportunity and to providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are in need of accommodation or special assistance to navigate our website or to complete your application, please send an e-mail with your request to Recruiting Operations Team (Americas: Careers.NorthAmerica@sap.com or Careers.LatinAmerica@sap.com, APJ: Careers.APJ@sap.com, EMEA: Careers@sap.com).
Successful candidates might be required to undergo a background verification with an external vendor."
Paris (75),"Temps plein, CDI",,Architecte Data,Solantis - Consulting Agency,- Paris (75),"Notre client est un cabinet de conseil interne rattaché à une banque francaise, qui a été créé en septembre 2017. Sa mission est de concevoir, développer, industrialiser des services et des produits digitaux innovants pour toutes les entités du groupe, autour de problématiques fondamentales comme la finance, l’immobilier, la santé ou encore la sécurité dans un environnement agile.

En tant que responsable de la data, vous devrez :
Concevoir et mettre en oeuvre des architectures de données modernes tirant profit des meilleures solutions SQL et NoSQL du marché ;
Accompagner les équipes de développement de l'entité dans l’appropriation de ces technologies ;
Collaborer étroitement avec les développeurs data science de l'entité pour la production de MVP à forte valeur ajoutée en proposant des architectures techniques adaptées;
Accompagner et conseiller nos clients internes pour tirer profit des nouvelles technologies de données ;
Participer à la montée en valeur et à la veille technologique permanente de l'entité et du Groupe sur les problématiques de gestion de données.
Exemples de projets sur lesquels l’architecte Data pourra être impliqué :
Voicebots, Chatbots connectés avec la Google Home (et projets liés à l’IA en général)
Production de POC/POV sur des applications mobiles (internes ou clients finaux)
Construction d’un Datalake pour une entité
Gestion d’un flux de données en temps réel
Extension d’une architecture Big Data
Les bases de données relationnelles SQL : Oracle, MySQL, PostgreSQL ;
L’écosystème Hadoop : HDFS, Yarn, Pig, Hive ;
Les patterns, frameworks et langages de traitement de données : MapReduce, Spark, Kafka, Storm, R, Python, Scala ;
Les architectures DataLake ;
Les méthodes de développement agiles.
Les technologies NoSQL
Votre autonomie et votre esprit entrepreneurial alliés à la bonne compréhension des enjeux de la data dans les services financiers seront vos atouts pour réussir ce poste."
Paris,45 000 € - 55 000 € par an,,Développeur sénior Python | Secteur de l’énergie / big data,In-Team,- Paris,"Vous recherchez un nouveau challenge Python avec de fortes problématiques data science ?
Alors, rejoignez cette société spécialiste de la gestion énergétique au sein de parcs immobiliers !
Existant depuis plus 3 ans, cette entreprise développe une solution Saas qui, à travers la collecte de grande quantité de données, propose des solutions innovantes et impactantes d’optimisation énergétique. Vous l’aurez compris, au cœur de ce projet : la data.
Leurs clients ? JCdecaux, Picard, les plus grands groupes bancaires… leur font déjà confiance
Venant de lever 2.5 millions d’euro, il recherche pour renforcer leur équipe technique de 5 personnes, un développeur Python sénior, afin de travailler sur le développement back-end de leur solution, mais également sur la manipulation de grandes quantités de données.
La stack technique ? Python (Flask) ; JS (VueJS) ; MongoDB ;
Vous êtes curieux d’en savoir plus ?

Votre mission :
Au sein de cette entreprise d’une trentaine de personnes, vos missions seront :
Développement en Python – Flask et JS – VueJS
Créer des architectures logicielles
Travailler avec les SGBD non relationnel
Travailler sur la manipulation de grandes quantités de data
Monter en compétence sur du management (sélection, formation et encadrement des profils juniors)
Veille technique
Votre profil :
Bac +5 école d’ingénieur
2-5 ans d’expérience en développement Python / JS
Vous êtes exigeant sur la qualité de votre code et l’architecture logiciel car c’est quelque chose que vous jugez important
Opportunité :
Travailler sur un poste hybride avec des problématiques de développement et de data science
Être en contact direct avec le top management de l’entreprise
S’épanouir au sein d’une structure pérenne avec un esprit startup, reconnue pour son innovation
Salaire et avantages :
45-55k€
Contrat en CDI
Cette opportunité vous intéresse ? Vous avez envie de vous investir et de progresser ? Alors n’hésitez plus et faites-moi parvenir votre CV !
Si vous souhaitez avoir d’autres informations sur cette opportunité je vous invite à me contacter également."
Paris (75),CDI,,Senior Data Scientist - Tech Company,montreal,- Paris (75),"Data Science
Python,Spark
English
You will join a Tech Company with several offices across Europe and an office in Japan.
This data driven organization analyzes a wide variety of data to generate stable and predictive analytics for the real estate market. They have a start-up environment and an international team ! The role can be based in Paris or Berlin.
They are currently looking for a Senior Data Scientist to growth their team.
Your role:
Identify & analyse trends or patterns in a variety of internal and external sources.
Handle potentially incomplete datasets.
Create & optimize models.
Extend existing internal ML libraries and frameworks.
Productionalize models.
Design new features
Who are you?
You have a Master degree or a Ph.D in Computer Science or Applied Mathematics
You have at least 3years experience
You are proficient in Python
You have experience in Machine Learning model development and productionalization.
You are fluent in english
What are the benefits?
Bonus
Flexible hours
Healthinsurance
Transport
L&D program
Remote
If you are interested by the role, please apply with a cv in english.
Montreal Associates is acting as an Employment Agency in relation to this vacancy.

JN -122019-51822_158800404897598"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Serenity,Adevinta,- Paris 10e (75),"Team :
Serenity provides a common platform and tooling to Adevinta Marketplaces to review any kind of user generated content ensuring that things that get published are of high quality and not fraudulent. Engineers in our team work to make these millions of events going through our system so it gets reviewed both automatically by our services and manually by local moderators team.
This large data set is also one of the most diverse and rich data sets in the world with local moderators team labelling our data in each country. We also need to make our machine learning models eloquent so that our moderators get as much insight as possible when making a decision. You will be able to work with the latest data technologies and have the ability to see your insight turned into knowledge on an ongoing basis.
Responsibilities :
Develop highly scalable classifiers and tools leveraging machine learning, regression, heuristics, and rules-based models.
Code deliverables in tandem with the engineering team using the best development practices and tools
Adapt standard machine learning methods to best exploit our production environment
Communicate the best development practices within the organisation (i.e. code reviews, testing, etc)
Continuously monitor the quality of our models, design measurements to monitor their performance.
Keep on top of the latest and greatest developments in data science fields
Troubleshoot issues in production when things go wrong
Qualifications
Work experience in one or more of the following: NLP, pattern recognition, data mining, anomaly detection, time series predictions, fraud detection, deep learning.
Experience with delivering models from data exploration to production and the required technologies
Experience in systems software or algorithms
Knowledge in python
Strong analytical / problem solving skills
Experience with modern software development and systems tools like Git, Travis or similar
Excellent communication skills, verbal and written
Desirable
Experience with Docker, AWS, GCE, Kubernetes, Kafka and similar technologies
Cross group and cross culture collaboration
Git repo to coding competitions or contributions in open source repositories
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),,,Data Engineer Sénior (H/F),Atos,- Paris (75),"À propos d’Atos

Atos est un leader international de la transformation digitale avec plus de 110 000 collaborateurs dans 73 pays et un chiffre d’affaires annuel de plus de 11 milliards d’euros. Numéro un européen du Cloud, de la cybersécurité et des supercalculateurs, le groupe fournit des solutions intégrées de Cloud Hybride Orchestré, Big Data, Applications Métiers et Environnement de Travail Connecté. Partenaire informatique mondial des Jeux Olympiques et Paralympiques, le Groupe exerce ses activités sous les marques Atos, Atos Syntel, et Unify. Atos est une SE (Société Européenne) cotée sur Euronext Paris et fait partie de l’indice CAC 40.

La raison d’être d’Atos est de contribuer à façonner l’espace informationnel. Avec ses compétences et ses services, le groupe supporte le développement de la connaissance, de l’éducation et de la recherche dans une approche pluriculturelle et contribue au développement de l’excellence scientifique et technologique. Partout dans le monde, Atos permet à ses clients et à ses collaborateurs, et plus généralement au plus grand nombre, de vivre, travailler et progresser durablement et en toute confiance dans l’espace informationnel.

Avec une activité en pleine croissance, le Groupe Atos a besoin de vous pour venir consolider ses équipes sur un poste de Data Engineer Sénior (H/F).

Dans quel environnement de travail interviendrez-vous ?

Référent technique au sein d’une équipe jeune et dynamique en très forte croissance réalisant des activités allant du conseil en architecture et gouvernance de la donnée aux aspects Data analytiques et DataScience, votre valeur ajoutée repose sur votre forte expertise technique et business de la data.

Notre équipe Big Data & Security a un esprit Start-Up de confiance, de partage et de collaboration.

Ce que nous allons faire ensemble :
L’audit, l’analyse et le pilotage des flux de la donnée, séminaire data science, conduite de POC et industrialisation de modèle analytique

La sélection des caractéristiques, la construction et l’optimisation des modèles de données

L’extraction des données de l'entreprise avec des sources d'information tierces lorsque nécessaire

L’amélioration des procédures de collecte de données afin d'inclure des informations pertinentes pour la construction de systèmes analytiques

L’analytique, le machine learning, les problématiques de recherches opérationnels, et le deep learning

Le traitement et vérification de l'intégrité des données utilisées pour l'analyse

L’accompagnement des équipes dans la mise en œuvre du projet (montée en compétences sur les outils et l’optimisation des modèles)

Le profil apprécié pour rejoindre nos équipes :
Diplômé(e) d’une formation Bac +5, vous justifiez d'une expérience minimum de 7 ans dans la collecte et/ou analyse de la donnée. Vous êtes reconnu pour votre maîtrise de l’anglais dans le cadre d'animation de réunions, de rédaction de spécifications.

Les « Skills » nécessaires pour mener à bien votre mission :
Votre sens du service, votre engagement et votre esprit d’équipe vous permettent d’entretenir de bonnes relations avec vos clients et vos collègues.

Vous êtes caractérisé comme force de proposition et bon communicant.

Votre curiosité et votre appétence pour l’innovation vous ont permis de progresser et de vous tenir à jour sur toutes les technologies et architectures.

Votre expérience fait de vous un véritable expert, capable de résoudre des problématiques technologiques complexes et d’intégrer rapidement à des environnements différents.

Les avantages que nous vous offrons :
Rejoindre Atos c’est rejoindre un grand groupe de renommée internationale, en mesure de vous offrir une réelle opportunité de carrière avec une vision sur le long terme. Atos est classé numéro 1 dans l'indice « Forbes CAC 40 Digital Index ».

Vous aurez ainsi la possibilité d’intégrer une équipe dynamique et ambitieuse sur des projets attractifs, souvent avec un rayonnement allant bien au-delà de nos frontières, dans des environnements techniques de pointe, d’ailleurs Google, Microsoft, Amazon et bien d’autres sont des partenaires qui nous font confiance aujourd’hui.

La capacité d’Atos à fournir des services de qualité repose sur l’expertise de ses collaborateurs. Par conséquent, il est essentiel pour Atos d'accompagner le développement des compétences et de carrières de ses salariés : en 2019, 17 550 employés ont été formés sur nos campus. Atos a reçu la certification « Great place to work ».

Nos valeurs :
Chez Atos, nous voulons que nos employés se sentent valorisés, appréciés et libres d'être eux-mêmes au travail. Nos process RH sont conçus pour prévenir la discrimination envers l'identité ou l'orientation sexuelle, la religion, l’origine ethnique, l'âge, la neurodiversité, le handicap, la citoyenneté ou tout autre aspect qui rend nos collaborateurs uniques. Partout dans le monde, nous avons créé plusieurs programmes pour soutenir la culture inclusive d'Atos, et nous travaillons pour nous assurer que tous nos collaborateurs aient une chance égale de sentir qu'ils sont exactement là où ils doivent être."
Paris (75),CDI,,HEAD OF DATA #TRANSPORT #STARTUP #INTERNATIONAL,Urban Linker,- Paris (75),"DESCRIPTIF DE LA SOCIETE
Le marché des transports est considérable (+45 milliards d’euros en Europe) et hyper fragmenté (+ 40 000 entreprises de transports en France) mais ce marché rencontre des problématiques / coûts écologiques, économiques et sociétaux.

Pour toutes ces raisons, il y a quelques années, une startup a décidé de digitaliser ce secteur et de proposer une plateforme qui permet aux expéditeurs et aux transporteurs de se retrouver simplement.

Forte de son succès en France, son nouveau challenge repose aujourd’hui sur la Data Science et l’international.
DESCRIPTION
POSTE
Pour accompagner ce changement, le CTO est à la recherche de son futur Head of Data pour :
Etre en contact avec les différents services
Mettre en place toute la stratégie Data
Examiner la donnée récoltée
Ressortir les tendances
Proposer des solutions en machine learning
Prédire le futur grâce à ces modèles
Management d’une personne dans l’immédiat puis de 2/3

Tu travailleras sur des problématiques de :
Géolocalisation
Cartographie
Temps réel
Scalabilité (France à Europe)
Machine Learning
Dynamic Pricing
R&D tous les vendredis après-midi



Stack : Python / Django / Dataiku / PHP 7 / Symfony 3.4 et 4 / VueJS / NodeJS / Socket.Io / RabbitMQ / Redis / Docker
PACKAGE
Salaire attractif selon profil et expérience
Ticket restaurants de 8€
Mutuelle prise en charge à 100%
Choix de l’ordinateur
LES +
Challenges techniques challengeant & ambitieux
Aspect R&D sur la digitalisation d’un métier
Machine learning & Data Science
Société en phase d’accélération dans un contexte international, reconnue sur son marché
Ambiance startup : 25/30 ans, afterwork, beaux locaux
Management proche & valeurs humaines : tu seras véritablement impliqué dans les choix stratégiques
R&D tous les vendredis après-midi
PROFIL RECHERCHE
Tu es le/la head of data de nos rêves si :
Tu as au moins 5 ans d’expériences dans la datascience
Tu es un véritable couteau suisse entre la BI et le machine learning
Tu sais gérer la BI et les algos
Tu sais développer Python et a des connaissances en SQL
Tu as pour habitude de mesurer constamment tes actions

Idéalement tu as des connaissances sur Dataiku

En perso, tu es passionné(e), autonome et proactif/ve. Sociable et bon(ne) communicant(e), tu as aussi un intérêt pour le métier.

Si tu te reconnais là-dedans, n’hésite surtout pas, l’aventure commence maintenant !"
Paris (75),,,Data Center Security Manager,Amazon Data Services France SA,- Paris (75),"Proficiency in use of Microsoft Office with a good working knowledge of Excel
Good analytical skills and an understanding of quality assurance tools and techniques
Demonstrated knowledge of physical security best practices to include but not limited to application of physical security systems, investigation techniques, management of contract security guards and incident management and workplace safety.
5+ years of experience within similar role in the public or commercial security industry.
Good leadership skills and experience of incident management and management of team performance and their development
Ability to handle confidential information with care
Ability to integrate into an international work environment with a willingness to travel on company business.
Must be prepared and have the ability to work and travel to Data Centres pan-cluster whilst on-call

At Amazon we believe that every day is still day one. A day to take a first step. A day to look forwards to new challenges. And today is that day for you. It's your day to be part of something great. A day to make your ideas come to life. And your day to join a company that redefines itself every day. That's the energy and passion behind Amazon.
For our data centers in London we are looking for Data Centre Security Managers (DSM) to manage our day by day security guarding operation and the Security Control Room.
While on duty, the DSM is responsible for the execution of the Security Program in the Data Centre cluster. The DSM provides on-site direction and guidance to the contract security officers via their chain of command to ensure proper execution and enforcement of security policies and procedures set forth by AWS. Also the DSM assists in investigations upon request and under the direct leadership of the Cluster Security Manager.
Responsibilities:
Respond swiftly and calmly to Security situations as they arise, based on the direction of the Cluster or Regional Security Manager
Support the on-site contractor Security team as the primary security contact during the shift and provides guidance based upon existing Physical Security Standards and local SOP’s.
Reports all unusual events to the Cluster Manager in a timely manner.
Provide guidance and direction to the contract security officers to maximize the effectiveness of the Security department
Produce and modify Amazon.com identification badges using a computer based badge program. Coordinate with Security Operations Center (SOC) to problem solve badge issues
Proficiently utilize and monitor the access control and alarm monitoring system in use (LENEL) and the integrated CCTV monitoring system
Efficiently cooperates and coordinates with the Security Operation Center (SOC) during security incidents or any other security related matter.
Develop specific knowledge of the various operational process paths within the Data Center to identify security vulnerabilities and produce mitigation solutions, as well as being able to effectively conduct investigations
Monitor the Data Center for compliance of company security policies and responding to any security issues noted
Perform various security inspections, audits and investigations as required and as instructed.
Use the information gathered to complete detailed computer based incident reports
Capable of learning and using company tools for data gathering for security purposes and data analysis
Ability to work and travel as required by the business needs, including weekends and on-call requirements.

4 years plus experience in Physical Security and Corporate Security
Considerable knowledge of state of the art security technology including access control & CCTV systems. (Experience with the Access Control & Alarm Monitoring Systems is a plus)
Security Industry Qualifications/Certification or Bachelors Degree
Experience in managing small teams or contract guard force

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We value your passion to discover, invent, simplify and build."
Paris (75),,,"Sales Engineer, Data Management, Google Cloud Platform",Google,- Paris (75),"Minimum qualifications:
Bachelor's degree in Computer Science, related technical field, or equivalent practical experience.
Experience serving in the capacity of a technical sales engineer in a cloud computing environment or experience in a customer facing role.
Experience with database technologies.
Experience with data migration strategies and moving large scale production systems.

Preferred qualifications:
Master's degree in Computer Science or other technical field.
Experience with optimizing database performance with respect to transactional and/or analytic workloads.
Technical sales experience or professional consulting experience in the fields of systems integration, large scale data transfer/management, and enterprise database performance.
Experience in disaster recovery (DR) and data backup strategies.
Ability to quickly learn, understand, and work with new emerging technologies, methodologies, and solutions in the Cloud/IT technology space.
Ability to travel as required.
About the job
The Google Cloud Platform team helps customers transform and evolve their business through the use of Google’s global network, web-scale data centers and software infrastructure. As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.
As a Customer Engineer, you will work hand-in-hand with technical Sales teams as an enterprise database subject matter expert to differentiate and paint the vision of Google Cloud to our customers. You will help prospective customers and partners understand the power of Google Cloud, explaining technical features, helping customers design architectures, engage in proof of concepts, and troubleshoot potential roadblocks related to database (and app) migration and data back ends for new app development.
Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what’s next for their business — all with technology built in the cloud. Our products are engineered for security, reliability and scalability, running the full stack from infrastructure to applications to devices and hardware. And our teams are dedicated to helping our customers and developers see the benefits of our technology come to life.
Responsibilities
Work with teams to identify and qualify business opportunities, understand key customer technical objections and develop the strategy to resolve technical blockers.
Share in-depth storage and database expertise to support the technical relationship with Google’s customers.
Work with customers to demonstrate and prototype Google Cloud product integrations in customer/partner environments.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices on Google Cloud.
At Google, we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Palaiseau (91),"Apprentissage, Contrat pro",,Alternance Dietary Data Manager Junior (H/F),Danone,- Palaiseau (91),"Vous voulez participer au développement des Innovations dans un environnement en pleine transformation ?
Vous souhaitez comprendre les habitudes consommateur pour une alimentation plus saine ?
Vous cherchez à avoir un vrai impact business ?

Une alimentation saine nécessite une planète saine et c’est ce que notre signature « One Planet, One Health » incarne. Les équipes R&I mettent leurs expertises scientifiques et technologiques au service des consommateurs. Ils partagent leur passion pour l’innovation dans l’objectif de répondre au mieux à la mission de Danone : apporter la santé par l’alimentation au plus grand nombre.

Danone Research, ce sont près de 1500 hommes et femmes répartis sur 6 centres. Nous construisons chaque jour des ponts entre science et nutrition, tout en s'adaptant aux habitudes culturelles et alimentaires des différentes régions du monde et en s'engageant pour améliorer la qualité nutritionnelle et l'impact environnemental des produits.

L'apprentissage se déroulera au Centre de R&I Daniel Carasso dans le département iSN (Innovation Science et Nutrition). Ce département a pour objectif d’impacter positivement l’alimentation et la santé des consommateurs en apportant des solutions adaptées aux personnes dans les pays où nous opérons. Nous délivrons la science de la nutrition qui cible la santé ainsi que des opportunités business grâce à l’identification de bioactifs, de services ou de solutions alternatives visant à promouvoir des pratiques alimentaires plus saines.
Dans ce contexte, l’étude de l’alimentation est incontournable. Elle assure que nos projets ciblent le consommateur en connaissant ses habitudes, ses besoins et ses apports nutritionnels.
Localisation : Sur le plateau de Paris-Saclay à Palaiseau (91), accessible en transports en commun

MISSIONS :
Grâce à un mélange de curiosité et d'appétence pour creuser des données, vous participerez à des projets d'exploration et analyse de données de diète et comparaison de populations au sein de nos projets avec l'équipe Dietary Intakes. Vous garantirez ainsi la robustesse et l'excellence dans l'exécution de tous les sujets reliés aux données alimentaires au sein d'iSN.

Vous pourrez évoluer sur les missions suivantes :

Préparer (nettoyage et organisation / structuration) de bases de données alimentaires pour pouvoir faire de l’analyse de données, du clustering de population
Commencer les premières analyses permettant de nourrir des scénarios d’analyses : codage simple pour voir ce qui est pertinent, significatif
Participation à la discussion pour caractériser les populations : par exemple « Caractériser une population sur base de sa consommation en fibres, sur des notions de macro et micro-nutriments, de groupes d’aliments absents ou présents dans la diète, de données socio-démographiques. »
Choisir et appliquer les méthodes statistiques existantes les plus pertinentes sur des corpus de données

VOTRE PROFIL :
Etudiant(e) en sortie de BTS ou IUT sur les biostatistiques ou statistiques appliquées agro-alimentaire ou santé
Vous maitrisez les outils d’analyse statistique et gestion de bases de données.
Vous avez des notions en épidémiologie et en diététique/nutrition
Vous avec une bonne connaissance des analyses statistiques et du logiciel R
Vous êtes autonome, curieux, volontaire
Vous faites preuves d’organisation et de rigueur
Vous avez un esprit pratique tourné résolution de problème
Vous maitrisez l’anglais
L’offre est à pourvoir pour septembre 2020 pour une durée de 1 ou 2 ans.

ET MAINTENANT ?

Si cette offre vous correspond, n’attendez-plus et postulez !

Le process de recrutement se déroulera en deux étapes :
Une entretien téléphonique RH
Un entretien physique avec le manager du poste"
Paris (75),,,Développeur - pôle Market Data (H/F),Natixis,- Paris (75),"Nous souhaitons renforcer le pôle « Market Data », qui comporte environ 20 personnes, dont deux tiers de développeurs basés à Paris et Porto et un tiers de business analysts, placées sous la responsabilité du responsable de pôle.
La principale application du pôle vise à alimenter en données de marchés (risk factors) les systèmes FO de booking et les systèmes des risques, pour les calculs quotidiens de risques et de valorisation de fin de journée.
Elle gère les workflows de collecte, contrôle et mise à disposition des market data de la totalité des classes d’actifs traités sur les marchés par la BFI de Natixis.
Ce référentiel transverse est donc une pièce importante et critique du SI Marchés et alimente également de nombreux autres clients de Natixis et du groupe BPCE.
Les challenges sont très nombreux, avec notamment des évolutions majeures à réaliser pour répondre aux nouvelles exigences règlementaires (FRTB, TRIM, IMM, RIM) et aux besoins accrus de maîtrise de la qualité des process métiers et des données utilisées (BCBS 239).
L’application connaît un développement important qui nécessite le renfort des capacités internes.
Son architecture technique est en cours de transformation, avec une place importante donnée aux technologies de type Hadoop (stockage de gros volumes, machine learning, etc.).
Les process SI sont gérés en mode agile.
Votre rôle dans l’équipe :
Projets et évolutions fonctionnelles :
Design des solutions, en interaction avec la MOA et le responsable d’équipe
Développement et tests
Documentation de maintenance et d’exploitation ; formation du support
Préparation des releases
Support :
Participer (rotations) aux astreintes et aux permanences de support
Prise en charge des actions correctives

De formation supérieure d’ingénieur en informatique ou équivalent. Vous avez des connaissances techniques autour du Big Data (Hadoop, Spark, Scala) et des Data Sciences (Machine Learning, Python).
Vous avez également des connaissances sur les opérations de marchés en vision FO ou Risques, acquises à travers une expérience professionnelle significative en CIB.
Vous maîtrisez le développement .Net C#,SQL et les Outillages complémentaires supportant les best practices agiles.
Vous possédez le goût du travail en équipe dans un environnement exigeant, avec de nombreuses interactions.
Vous savez communiquer de manière claire et concise.
Vous êtes dynamique, réactif et orienté client.
Vous êtes également organisé, rigoureux et force de proposition.
Votre niveau d'anglais est courant.
Site géographique: 30 Avenue Pierre Mendès-France - 75013 PARIS

Informations complémentaires sur le poste :
Convention collective applicable: Convention Collective de la Banque.
Responsable de recrutement: Marie Laure BERTIN."
Montigny-le-Bretonneux (78),CDI,,INGÉNIEUR SIG (GIS) DATA MANAGEMENT F/H,OneSide Consulting,- Montigny-le-Bretonneux (78),"Pour le compte d'un acteur majeur du secteur de l'offshore oil & gas - énergies marines renouvelables, au sein d'un service dédié aux Systèmes d'Information Géographique (SIG) :

Rédiger des procédures de standardisation des bases de données SIG
Assurer la réception des données contractuelles issues des pre-engineering (études préalables)
Compléter les geodatabases internes/externes en fonction des standards en vigueur
Vérifier la complétion des tables attributaires (tags, attributs, métadonnées, hyperliens, données horaires)
Utilisation des outils de Trackings pour suivre les mises à jours
Réalisation des analyses sur des données géographiques en produisant des documents cartographiques ou des rapports
Croiser et superposer les données spatiales, attributaires et horaires entre-elles afin de faire ""parler"" les données (big data)
Développer ou utiliser potentiellement des scripts FME
Gestion des interfaces internes et externes
Déplacements à l’étranger à prévoir
Profil recherché -Ingénieur ou Master SIG (GIS), Data Management, Géomatique, minimum 3 ans d'expérience

Maitrise du logiciel ArcGIS for Desktop 10.2 et extensions
Maitrise des SIG (Géoréférencement, modélisation de base de données, I/O, ...)
Maitrise de la géodésie et des systèmes de coordonnées
Maitrise des bases de données Access (.mdb), Geodatabase ESRI (.gdb)
Connaissance des standards et normes pour les données et métadonnées géographiques (OGC, OGP, ISO, INSPIRE, FGDC, ...)
Programmation Python, SQL, VBA serait un plus
Gestion de projet SIG
Maitrise de l'anglais (écrit et oral)
Profils Oil & Gas Offshore / Onshore appréciés
Expérience dans des sociétés d'ingénierie type EPC appréciée
Entreprise Société spécialisée dans le conseil en ingénierie, OneSide Consulting s'implique aux côtés de ses clients dans les secteurs de l'énergie sur des projets d'envergure nationale et internationale."
Paris (75),,,Data Scientist Senior,La Javaness,- Paris (75),"Tu te sens prêt à plonger au cœur de la révolution IA ?!
En 5 ans, La Javaness s’est imposée comme leader français de l’IA pour les entreprises (BtoB). Sans tambour ni trompettes (mais avec beaucoup de R&D !), nous avons concentré nos forces à déployer l'Intelligence Artificielle à grande échelle au sein d’organisations publiques et privées en France et en Europe.
Mais pas n’importe comment ! Nous croyons en une IA éthique, responsable, au service des salariés et des citoyens européens. Nous militons pour la souveraineté des données et l’indépendance des entreprises européennes.
Pragmatiques et rationnels, nous déployons quotidiennement nos solutions « prêt-IA-porter » à un niveau industriel. Nous faisons aussi de la haute couture en développant des solutions IA sur-mesure pour répondre aux défis de certains de nos clients. Notre R&D bout sans relâche pour inventer, tester et déployer l'IA de demain.
En d'autres termes, dans la boutique de La Javaness, tu trouveras : Conseil data & IA, accélération par le design, développement front & back de pointe, défis business dans un joyeux mix exigeant d'intelligences. Avec ce super cocktail d'expertises et de créativité, nous intervenons sur tous les secteurs d'activité pour cracker les problèmes de nos clients !
Nous sommes le partenaire Data et IA de référence pour l'AMF, LCL, la Banque de France ou encore Pôle Emploi. Nous accélérons également des projets d'innovation digitale pour la Société Générale, Facebook, Enedis, Saint Gobain, Louvre Hôtels Group...
Comment ça marche au quotidien ?
4 labs : Design, IT, Data, Delivery & Business, travaillent ensemble sur tous les projets afin de concevoir et déployer des solutions complètes et innovantes répondant aux besoins de nos clients.
Fort d’un collectif unique, la Javaness investit sans cesse dans des talents pointus, atypiques et complémentaires qui lui confèrent une force de frappe hors norme. Et parce qu'on est pas que des machines, la ""Fullstackerie"" s'exprime aussi joyeusement lors de nos fameux apéros au débotté et de notre séminaire annuel.
Si ça te semble une aventure à ta mesure, c’est par ici pour nous rejoindre !

Descriptif du poste
En rejoignant notre Lab Data, tu intégreras un environnement très collaboratif au sein d'une équipe qui n'hésitera pas à t'encourager et t'aider dans la résolution de problèmes complexes. Tes activités s’orienteront autour de plusieurs grands axes :
Réaliser des missions sur des cas d’usage réels avec les données de nos clients.
Effectuer un travail de R&D autour de l’état de l’art technologique et scientifique des méthodes de machine learning, dans le but de perfectionner les outils utilisés en interne.
Collaborer avec les autres métiers (IT, Design, Business…), pour concevoir des solutions complètes et innovantes répondant aux besoins clients.
Participer aux data meetings hebdomadaires, au cours desquels chacun partage ses dernières avancées et découvertes.
Requirements
A La Javaness, nous valorisons la diversité de cultures, de compétences et d’expériences. Nous recherchons des personnes passionnées, capables de prendre en main n’importe quelle technologie et de s’adapter à n’importe quel type de problème.
Caractéristiques recherchées :
Tu attaches beaucoup d’importance à la lisibilité et la simplicité de ton code.
Tu maîtrises les fondamentaux de probabilités, statistiques et machine learning.
Tu as à ton actif un grand nombre de projets impliquant la manipulation de données et la modélisation d’algos avec Python et ses librairies (fastai/ pytorch, keras/ tensorflow, scikit-learn, etc…).
Tu as des expériences confirmées dans la mise en production de modèles de machine learning.
Tu as démontré une appétence certaine pour les bonnes pratiques de coding : tests unitaires, code reviews, documentation…
Tu sais adapter ton discours à tes interlocuteurs et expliquer des idées et des algorithmes complexes de manière compréhensible


Minimum expérience requise: 3 ans"
Paris 13e (75),,,"Senior Product Manager, Data Integration",CapsuleTech,- Paris 13e (75),"The Sr. Product Manager, Data Integration role will be a key driver our organization’s growing ambitions to enhance how we integrate to existing and prospective leading healthcare organizations, develop and maintain a strategic roadmap to meet industry direction, develop pricing strategies for market segments and channels, and collaborate cross-functionally to ensure all product specifications are synergistic to other product roadmaps. The role will collaborate closely with marketing and sales to ensure the correct programs in place to support execution of the product strategy and sales pipeline growth.

Essentials Duties and Responsibilities

Product Ownership - Creates comprehensive business and use cases for new feature development with strong focus on customer and market inputs. Functions as a central resource for other teams, as features move through the product lifecycle, and provides inputs on competitive positioning for products. Works with technical teams to define, prioritize, and deliver the Product Roadmap. Develop and support pilot sites in their adoption of new features. Provide support and training for cross functional teams on evolving industry trends, product roadmap, and strategic positioning of new features.
Methods - Be proficient and conversant in cloud deployment strategies (SaaS, PaaS, IaaS). Establish a strategy for each deployment method, define key success factors for expansion and integration.
Standards - Be proficient and conversant in standards of the industry (HL7, IHE, etc.), as well as the medical devices we support. Establish a strategy for each standard and define key success factors for each standard.
Marketing and Sales - Work closely with the marketing, sales and support organizations to communicate strategic positioning & roadmap strategy for new features & products. Develop success stories and customer testimonials for products. Work closely with technical sales to scope solutions based on new customer use cases.fine key success factors for each standard.
Marketing and Sales - Work closely with the marketing, sales and support organizations to communicate strategic positioning & roadmap strategy for new features & products. Develop success stories and customer testimonials for products. Work closely with technical sales to scope solutions based on new customer use cases.
Multiple years of experience in a product management role (or related experience in marketing, implementation, and sales). Strong product/project management skills.
Multiple years of experience in a healthcare technology role.
Experience in go-to-market product strategies across direct and partner channels.
Problem solver with strong communication and cross-functional collaboration skills.
Demonstrate an entrepreneurial spirit with focus on revenue-generating results and product innovation.
Ability to work directly with customers; comfortable in a clinical healthcare environment.
Must be able to travel 25 - 30% of the time, including international travel
Bachelor's degree in Engineering, Information Systems, Computer Science, Business Management, or related field
Certification in Pragmatic Marketing, or Product Management Professional (PMP), a plus"
Paris (75),CDI,,Développeur - pôle Market Data (H/F),Natixis,- Paris (75),"Présentation de l'entreprise
Bienvenue chez Natixis, l’entreprise qui vous offre bien plus qu’un job !
https://www.youtube.com/watch?v=DdaoWX466VY&list=PLCffxNP5tKRS4JIutLJW04CvFxAAJrT95&index=11
Chez Natixis, nous concevons des solutions en gestion d’actifs et de fortune, financement, investissement, assurance et paiements.
Notre ambition : nous dépasser collectivement pour mieux accompagner nos clients et leur proposer les meilleures solutions pour leur développement.
Chez Natixis, nos talents sont notre principal atout.
Rejoignez-nous et vous aurez les clés pour faire bouger les choses et avoir un réel IMPACT.
Rejoignez-nous et vous découvrirez un monde d’OPPORTUNITÉS.
Rejoignez-nous et vous donnerez du sens à votre poste par votre ENGAGEMENT en faveur de la société comme de l’environnement.
Signataire de la Charte de la diversité, Natixis veille à promouvoir tous les talents et à accompagner le développement de chacun de ses 16 000 collaborateurs présents dans 38 pays. Pour la 3e année consécutive, elle est certifiée Top Employer France 2019.
La DSI de Natixis est au cœur des enjeux stratégiques pour développer de nouveaux services & usages clients et adapter son modèle aux nouvelles réglementations bancaires. DSI internationale, implantée dans 12 pays (en Europe, en Amérique, en Asie et au Moyen-Orient), elle est dotée d’une forte culture clients et innovante grâce aux nouvelles méthodologies & technologies IT (Digital, Big Data, Blockchain, IT bi-modal, Agilité, Expérience utilisateur, Collaboratif, Sécurité de l’Information, Robotique). Elle s’adapte régulièrement pour apporter le maximum de valeur aux Métiers de Natixis. Ses collaborateurs et les challenges qu’ils relèvent en sont sa meilleure vitrine.
Le département IT Directions Fonctionnelles (DFO) accompagne le développement des fonctions supports centrales de Natixis (Finance & Risques, Gestion Financière, Secrétariat Général, Ressources Humaines). A la croisée des productions réglementaires et prudentielles, les DSI DFO déploient des solutions mondiales qui servent les besoins de pilotage opérationnel, à l’échelle des entités et de Natixis.
Le département DSI RPA implémente les outils nécessaires au suivi des Risques, PnL & ALM.
Mission
Nous souhaitons renforcer le pôle Market Data , qui comporte environ 20 personnes, dont deux tiers de développeurs basés à Paris et Porto et un tiers de business analysts, placées sous la responsabilité du responsable de pôle.
La principale application du pôle vise à alimenter en données de marchés (risk factors) les systèmes FO de booking et les systèmes des risques, pour les calculs quotidiens de risques et de valorisation de fin de journée.
Elle gère les workflows de collecte, contrôle et mise à disposition des market data de la totalité des classes d’actifs traités sur les marchés par la BFI de Natixis.
Ce référentiel transverse est donc une pièce importante et critique du SI Marchés et alimente également de nombreux autres clients de Natixis et du groupe BPCE.
Les challenges sont très nombreux, avec notamment des évolutions majeures à réaliser pour répondre aux nouvelles exigences règlementaires (FRTB, TRIM, IMM, RIM) et aux besoins accrus de maîtrise de la qualité des process métiers et des données utilisées (BCBS 239).
L’application connaît un développement important qui nécessite le renfort des capacités internes.
Son architecture technique est en cours de transformation, avec une place importante donnée aux technologies de type Hadoop (stockage de gros volumes, machine learning, etc.).
Les process SI sont gérés en mode agile.
Votre rôle dans l’équipe :
Projets et évolutions fonctionnelles :
Design des solutions, en interaction avec la MOA et le responsable d’équipe
Développement et tests
Documentation de maintenance et d’exploitation ; formation du support
Préparation des releases
Support :
Participer (rotations) aux astreintes et aux permanences de support
Prise en charge des actions correctives
Profil recherché
De formation supérieure d’ingénieur en informatique ou équivalent. Vous avez des connaissances techniques autour du Big Data (Hadoop, Spark, Scala) et des Data Sciences (Machine Learning, Python).
Vous avez également des connaissances sur les opérations de marchés en vision FO ou Risques, acquises à travers une expérience professionnelle significative en CIB.
Vous maîtrisez le développement .Net C#,SQL et les Outillages complémentaires supportant les best practices agiles.
Vous possédez le goût du travail en équipe dans un environnement exigeant, avec de nombreuses interactions.
Vous savez communiquer de manière claire et concise.
Vous êtes dynamique, réactif et orienté client.
Vous êtes également organisé, rigoureux et force de proposition.
Votre niveau d'anglais est courant.
Site géographique: 30 Avenue Pierre Mendès-France - 75013 PARIS

Informations complémentaires sur le poste :
Convention collective applicable: Convention Collective de la Banque.
Responsable de recrutement: Marie Laure BERTIN."
Suresnes (92),,,Application Security Engineer,Talend,- Suresnes (92),"WHO WE ARE:

Talend, a leader in data integration and data integrity, enables every company to find clarity amidst the chaos.

Talend Data Fabric brings together in a single platform all the necessary capabilities that ensure enterprise data is complete, clean, compliant, and readily available to everyone who needs it throughout the organization. It simplifies all aspects of working with data for analysis and use, driving critical business outcomes.

From Domino’s to L’Oréal, over 4,250 organizations across the globe rely on Talend to deliver exceptional customer experiences, make smarter decisions in the moment, drive innovation, and improve operations. Talend has been recognized as a leader in its field by leading analyst firms and industry publications including Forbes, InfoWorld and SD Times.

Talend is Nasdaq listed (TLND) and based in Redwood City, California.

We are looking for a Application Security Engineer to join our Global Information Security team.

You will be based in Suresnes (Paris area).

You will work closely with the Product Management, Architecture, Development and Cloud Operations teams on all aspects of security along the entire product development lifecycle, from concept to deployment.
Responsibilities:
Provide subject matter expertise on secure design and coding practices, assist in building and rolling out related guidelines and standards, perform manual source code reviews for high risk components
Coach and train developers on best security practices; create and deliver training content when necessary
Audit/research/identify flaws and coach Development teams to mitigate vulnerabilities and threats
Strive for making it as easy as possible for Development teams to create secure designs and code, ie think “Security as a service”
Continuously develop your knowledge of cyber-defense and cyber-offense mechanisms, potential threats and attack vectors;
Requirements:
Understanding of application security in context of SDLC and CI-CD
Strong understanding of common web application vulnerabilities and mitigations (OWASP Top10, OWASP API Top10, SANS Top 25)
Proficient in one or more programming languages such as Java, Scala, Javascript, Python, React etc.
Practical experience with using cloud security and compliance products (e.g. AWS, Azure)
Familiarity with automated dynamic, static and open source scanning tools.
Working knowledge of secure coding principles, application security vulnerabilities, and countermeasures.
Ideally a BS degree in Computer Science or related field and a MS in Cybersecurity
Practical experience with identity management, authentication and authorization, applied cryptography would be a plus
Ability to build strong rapport and relationships with colleagues as well as customers so as to gain in-depth understanding of customers’ problems and needs
Ability to understand and value ideas from internal team members
Fluency in English, Fluency in French is a plus
What we offer you:
You’ll work in a company that makes decisions based on facts and data, where your work makes a difference
With a small and diverse team that welcomes the knowledge and experience you bring and values your contribution
Supported by an energetic management team that provides unmatched transparency into the business and welcomes diverse ideas and critical thinking
With opportunities to learn and continue to develop your expertise by attending and speaking at conferences or meetups, writing blogs or papers, or working with awesome colleagues!
#LI-HW1

AND NOW, A LITTLE ABOUT US:

Talend has received some pretty impressive accolades along the way:
""2018 Best Public Cloud Computing Companies To Work For"" by Glassdoor
Named a Leader for Data Integration Tools in the Gartner Magic Quadrant
Named a Leader in Big Data Fabric for the Forrester Wave
Ranked in the DBTA “100 Companies that Matter Most in Data”
Listed in the CRN Big Data 100 Companies

We are passionate about helping companies become more data driven; and, if we can be honest, we are all geeks at heart who pride ourselves on the vibrant company culture that we have built.

As a global employer, at Talend, we believe our success depends on diversity, inclusion and mutual respect among our team members. We seek to recruit, develop and retain the most talented people from a diverse candidate pool. We are committed to making all employment decisions on the basis of business need, merit, capability and equality of opportunity. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin."
Paris 2e (75),CDI,,Cloud Data Engineer F/H,YSANCE,- Paris 2e (75),"Afin d’agrandir notre équipe de Data Engineer, nous recherchons des

Cloud Data Engineer

, pour qui les traitements de la donnée n’ont plus de secret et leurs optimisations un vilain défaut.

Le/La Cloud Data Engineer sera amené(e) à intervenir directement chez nos clients ou à intégrer une équipe projet.

En tant que Cloud Data Engineer, vous serez amené(e) à :
✔️ Accompagner des équipes métiers dans leurs travaux d’identification et expression des besoins sur la data,

✔️ Concevoir des solutions nécessitant l’utilisation de technologies Big Data pour répondre à des cas d’usages métiers,

✔️ Développer et tester des flux d’ingestion de données de Data Lake et de traitement des données,

✔️ Contribuer à la mise à disposition des données au travers d’outils d’exploitation simples et rapides pour les clients,

✔️ Déployer et optimiser au quotidien des pipelines de données dans le Cloud,

✔️ Assurer la stabilité de la plate-forme de données,

✔️ Travailler en collaboration avec les Data Engineer en soutenant le développement de nouvelles fonctionnalités.

➕ En bonus :
✔️ Devenir un de nos futurs référents technique « Cloud »,

✔️ Participer aux recrutements de nouveaux collaborateurs,

✔️ Participer activement à la veille technologique,

✔️ Animer des sessions de formations techniques en interne mais aussi en externe.

➡️ Environnement technique : Cloud, AWS, GCP, Azure, BigQuery, Redshift, Snowflake, Spark, SQL, Python, Scala, Docker, Terraform, Ansible, ETL
Profil recherché Vous êtes titulaire d’un Bac +5 en informatique, avec une première expérience de 3 ans minimum dans des déploiements « Cloud Public » AWS, GCP, AZURE,

Vous possédez des connaissances liées au Cloud telles que BigQuery, Redshift ou Snowflake,

Vous êtes familier du Framework Spark,

Vous possédez des compétences avancées autour des langages suivants : SQL et Python ou Scala,

Vous avez une bonne maîtrise de l’optimisation des déploiements (Docker),

Vous détenez des connaissances autour des processus d’industrialisation (Terraform ou Ansible) et des outils d’orchestration,

L’obtention de certifications éditeurs sur un cloud provider, outils ETL ou base de données serait un plus.
Entreprise YSANCE est une société spécialisée dans le traitement de la Data.

Nous couvrons l'ensemble de la chaîne de valeur Data :
✔️ Intégration de données (Talend ETL, ESB, Data Quality)

✔️ Big Data (Cloudera, Hortonworks, Snowflake, Big Query)

✔️ Cloud (Amazon, Microsoft, Google)

✔️ Data Science, prédictif, prescriptif (R, Python, DataIku)

✔️ Analytics (QlikView, QlikSense, Tableau Software, Toucan Toco)

Nous avons également développé des offres autour du Référentiel Client Unique (RCU), du périmètre e-RFM et du Customer Analytics.

Dans le cadre de notre développement et de nos projets, nous recherchons de nouveaux talents passionnés comme nous par la Data.

✔️ Notre valeur ajoutée ?

Une forte expertise technique autour de la Data qui repose sur nos équipes et qui est renforcée par de nombreux partenariats avec les éditeurs dans le domaine du Big Data & Analytics.

✔️Pourquoi nous rejoindre ?

Une forte culture Data, des clients de renoms dans des secteurs variés, une approche orientée autour du besoin client afin de répondre au plus près de leurs enjeux.

Alors si intégrer une structure Data Driven à taille humaine répond à vos attentes professionnelles, c'est avec plaisir que nous échangerons avec nos consultants opérationnels.

A bientôt,"
Vélizy-Villacoublay (78),,,APPRENTISSAGE - Ingénieur Développement Cloud et Big Data (H/F),Dassault Systèmes,- Vélizy-Villacoublay (78),"Imaginez demain…
Au sein du département PaaS (Platform as a Service) de la R&D Dassault Systèmes, notre équipe développe une plateforme Big Data permettant de superviser en temps réel des milliers de services déployés sur le Cloud. Dans le cadre d’une adoption de plus en plus large du cloud, la plateforme de supervision doit répondre à des besoins de plus en plus exigeants en termes de fonctionnalités de disponibilité et de capacité de traitement.

Passionné(e) par les nouvelles technologies et souhaitant évoluer dans les domaines du Cloud et du Big Data, tout en ayant la possibilité de participer à des projets en Machine Learning, vous intégrerez notre équipe pour prendre part aux travaux d’évolution technologique et fonctionnelle de la plateforme de supervision.

Vos futurs défis…
Dans ce cadre vous participerez aux missions suivantes :

Moteur de streaming :
Etude et évaluation de différentes plateformes de stream-processing, telles que : Apache Spark, Apache Flink, Kafka Stream, et Apache Beam.

Conteneurs :
Adaptation de la plateforme de supervision pour passer d’une architecture à base de VM (Virtual Machine) vers une architecture à base de conteneurs Docker orientée micro-services et ciblant une infrastructure Kubernetes.

Web Services et Sécurité :
Développement d’une nouvelle génération de services RESTful sécurisés, qui seront basés sur des briques technologiques modernes telles que : GraphQL, WebSocket, …
Amélioration de la gestion des droits d’accès (ACL) à la plateforme de supervision et création d’environnements personnalisés.

Machine Learning :
Mise en place d’une fonctionnalité de Root Cause Analysis (RCA) permettant d’assister les utilisateurs dans l’analyse et la compréhension des causes de défaillances.
Développement d’algorithmes Machine Learning permettant la prédiction des défaillances et la recommandation de procédures de remédiation (Predictive Maintenance).
Mise en place d’un mécanisme d’auto-scaling prédictif basé sur les prédictions des évolutions de charge de l’infrastructure.

Vos atouts pour réussir…
Etudiant(e) préparant un diplôme de niveau BAC+3, Ecole d'ingénieur ou Cycle universitaire, avec spécialisations ou options en Cloud et Big Data.
Connaissance de technologies Big Data et base de données NoSQL, telles que : Apache Storm, Apache Spark, Apache Kafka, Hbase, Redis, etc.et une expérience dans le domaine du Cloud sera très appréciée.

Maitrise d’un langage de programmation orienté objet (Java, C++, …) et connaissance d’un langage de script (Script shell, Python, ...).
Intérêt pour les technologies Machine Learning.
Rigueur, autonomie, curiosité scientifique et force de proposition sont des qualités attendues pour mener à bien cette mission."
Neuilly-sur-Seine (92),CDI,,Architecte CLOUD/BIG DATA Paris F/H,NOVAGEN CONSEIL,- Neuilly-sur-Seine (92),"Dans le cadre du développement de notre agence parisienne, nous recherchons des Architectes CLOUD/BIG DATA, passionnés d’innovation et de développement informatique relatifs aux données.

Notre contexte :
Forte innovation et complexité technique à la pointe des technologies Data actuelles,

Développement de projets Big Data / Smart Data répondant aux besoins de nos clients,

Une montée en compétences encadrée par des sachants, experts des technologies IT Big Data et Datascience,

Travaux de veille IT, veille R&D et développement de solutions prêtes à l’emploi.

Environnement de travail :
Vous interviendrez au sein d'une équipe spécialisée sur les technologies et concepts Big Data /Smart Data et Data Science.

Vos missions :
Vous serez en charge de :
Concevoir et déployer des architectures techniques, cloud ou on-premise, dédiées au stockage, à la transformation et à la valorisation des données,
Développer au sein d’une équipe Data Novagen des cas d’utilisation des données : Business Intelligence à l’échelle BigData, Industrialisation d’algorithmes de Machine Learning, création de solutions sur les flux de données (Streaming), etc.
Etre garant des bonnes pratiques de développement (Software Craftmanship, Qualité / Développement / Déploiement Continus),
Partager vos accomplissements lors d’événements internes et avec les clients de Novagen.
Profil recherché - De formation bac+5 Ingénieur en Informatique et/ou Datascientist, vous disposez d’une expérience significative dans le domaine du Big Data.

Une maîtrise des principales technologies big data en terme de bases de données NoSQL (Elasticsearch, Cassandra, Redis, Hbase), d'écosystèmes (Hadoop, Spark) et de gestion de flux (Kafka, Flink) est nécessaire pour mener à bien vos missions.
Une culture cloud affirmée, qu’elle soit AWS, Azure, GCP ou OpenStack
L’excellence dans au moins un langage : Scala, Java, Python, Kotlin
Véritable pilier de l’équipe Big Data, vos talents de communication sont avérés.
Entreprise Novagen Conseil mène des actions de Conseil, développement de projets et Formations sur les métiers du Big Data.

Notre but : l'excellence au service des Innovations métiers de nos clients.

Présents sur les Hauts-de-France et l'Ile de France, nous déployons deux offres principales :

Un cabinet de conseil Data : Stratégie / Changement / Architectures ...
Une Data Factory : Développement de solutions : Tableaux de Bord, DataLake, Briques Big Data ..."
Paris (75),,,Data Engineer / Développeur Big Data H/F,Group onePoint,- Paris (75),"Description de l'entreprise
Nous sommes des architectes de la transformation des entreprises et de la modernisation des Etats, courageux, authentiques, ouverts, engagés et élégants. L'organisation de nos
expertises en communautés ouvertes, permet d'apporter à nos clients une proposition de valeur depuis la réflexion stratégique jusqu’à sa mise en œuvre en intégrant les
compétences métiers et tech les plus avancées.
Nous sommes aujourd'hui 2300 collaborateurs, répartis dans 15 implantations dans le monde (Paris, Bordeaux, Toulouse, Nantes, Lyon, Amsterdam, New-York, Bruxelles,Luxembourg, Melbourne, Singapour, Montréal, Tunis, Zele).
Mission : Nous aidons chacun de nos clients à dessiner concrètement un chemin d’avenir en étant audacieux, en allant au-delà de l’évidence, pour créer de nouvelles façons de travailler, de nouveaux modèles économiques et de nouveaux lieux. Autrement dit, chaque matin, nous nous levons pour contribuer à dessiner un nouveau monde.
C’est ainsi qu'est définie notre raison d’être – Design a New World – et notre signature : Beyond the Obvious, au-delà de l’évidence
Description du poste
Vous bénéficierez également d’un écosystème de partenaires technologiques de premier plan, de formations certifiantes et pourrez participer aux nombreux événements que nous organisons régulièrement autour de la Data et de l’IA.
Vos missions :
Concevoir et développer les architectures et solutions Big Data en utilisant les modules les plus pertinents ;
Proposer des solutions de stockage (sur site ou en lien avec la stratégie cloud)
Extraire, uniformiser et structurer les données depuis les datalakes de nos clients
Participer à la mise en place de référentiels
Mettre en place des flux de données entre les systèmes en ingestion et en exposition (batch, API, temps réel …)
Développer des composants pour monitorer les activités des plateformes Big Data
Explorer de nouvelles technologies et assurer veille;
Rédiger les documents et rapports associés à la conduite de ces missions
Expérimenter, évaluer, faire de la veille technologique
Qualifications
Vous êtes diplômé(e) d'une Grande École d'Ingénieur généraliste, informatique ou Master spécialisé en Big Data et avez une expérience minimum de 3-4 ans en environnement Big Data
Vous avez déjà participé au développement de solutions Big data en réponse à des besoins métier
Vous maîtrisez plusieurs des compétences et solutions listées ci-dessous :
Hadoop et son écosystème : Spark, HDFS, Hive, HBase, Kafka, Mesos, CouchBase…
Une ou plusieurs des distributions : HortonWorks, Cloudera, MapR.
Suite ELK.
Langages Big Data : Scala, Javascript,Python, R, …
Outils de virtualisation et container : Docker, Kubernetes,...
Orchestrateurs : KVM / Vagrant / Puppet / Ansible / Chef / Luigi,
Une certification relative à l’une des technologies ci-dessus est un plus
Vous disposez éventuellement d’une certification sur une des solutions Cloud Public Azure, GCP ou AWS
Vous souhaitez vous confronter et contribuer à une communauté d’experts, pour qui l’évolution des pratiques et l’apprentissage continu font particulièrement sens.
Vous disposez d’un très bon relationnel, d’un bon sens de l’écoute et d’empathie,
Vous faites preuve d’initiative, vous êtes naturellement force de propositions, vous avez envie de partager tes connaissances et savoir-faire et d’apprendre de vos pair
Informations complémentaires
La data est l’un des déclencheurs de la quatrième révolution industrielle. En rejoignant la communauté brAIn de onepoint, vous participez à notre ambition auprès des marchés européens, américains et asiatiques, d’accompagner cette mutation, de bout en bout en construisant et délivrant des services basés sur solutions performantes, scalables et sécurisées qui révèlent tout le pouvoir de « la data ».
L’une des particularités de onepoint est que vous aurez la possibilité d’intervenir auprès de grands comptes mais aussi d’accompagner des start-up prometteuses dans leur développement via le Big Data."
Paris (75),,,Data Engineer / Développeur Big Data H/F,onepoint,- Paris (75),"Description de l'entreprise
Nous sommes des architectes de la transformation des entreprises et de la modernisation des Etats, courageux, authentiques, ouverts, engagés et élégants. L'organisation de nos
expertises en communautés ouvertes, permet d'apporter à nos clients une proposition de valeur depuis la réflexion stratégique jusqu’à sa mise en œuvre en intégrant les
compétences métiers et tech les plus avancées.
Nous sommes aujourd'hui 2300 collaborateurs, répartis dans 15 implantations dans le monde (Paris, Bordeaux, Toulouse, Nantes, Lyon, Amsterdam, New-York, Bruxelles,Luxembourg, Melbourne, Singapour, Montréal, Tunis, Zele).
Mission : Nous aidons chacun de nos clients à dessiner concrètement un chemin d’avenir en étant audacieux, en allant au-delà de l’évidence, pour créer de nouvelles façons de travailler, de nouveaux modèles économiques et de nouveaux lieux. Autrement dit, chaque matin, nous nous levons pour contribuer à dessiner un nouveau monde.
C’est ainsi qu'est définie notre raison d’être – Design a New World – et notre signature : Beyond the Obvious, au-delà de l’évidence

Description du poste
Vous bénéficierez également d’un écosystème de partenaires technologiques de premier plan, de formations certifiantes et pourrez participer aux nombreux événements que nous organisons régulièrement autour de la Data et de l’IA.
Vos missions :
Concevoir et développer les architectures et solutions Big Data en utilisant les modules les plus pertinents ;
Proposer des solutions de stockage (sur site ou en lien avec la stratégie cloud)
Extraire, uniformiser et structurer les données depuis les datalakes de nos clients
Participer à la mise en place de référentiels
Mettre en place des flux de données entre les systèmes en ingestion et en exposition (batch, API, temps réel …)
Développer des composants pour monitorer les activités des plateformes Big Data
Explorer de nouvelles technologies et assurer veille;
Rédiger les documents et rapports associés à la conduite de ces missions
Expérimenter, évaluer, faire de la veille technologique

Qualifications
Vous êtes diplômé(e) d'une Grande École d'Ingénieur généraliste, informatique ou Master spécialisé en Big Data et avez une expérience minimum de 3-4 ans en environnement Big Data
Vous avez déjà participé au développement de solutions Big data en réponse à des besoins métier
Vous maîtrisez plusieurs des compétences et solutions listées ci-dessous :
Hadoop et son écosystème : Spark, HDFS, Hive, HBase, Kafka, Mesos, CouchBase…
Une ou plusieurs des distributions : HortonWorks, Cloudera, MapR.
Suite ELK.
Langages Big Data : Scala, Javascript,Python, R, …
Outils de virtualisation et container : Docker, Kubernetes,...
Orchestrateurs : KVM / Vagrant / Puppet / Ansible / Chef / Luigi,
Une certification relative à l’une des technologies ci-dessus est un plus
Vous disposez éventuellement d’une certification sur une des solutions Cloud Public Azure, GCP ou AWS
Vous souhaitez vous confronter et contribuer à une communauté d’experts, pour qui l’évolution des pratiques et l’apprentissage continu font particulièrement sens.
Vous disposez d’un très bon relationnel, d’un bon sens de l’écoute et d’empathie,
Vous faites preuve d’initiative, vous êtes naturellement force de propositions, vous avez envie de partager tes connaissances et savoir-faire et d’apprendre de vos pair

Informations complémentaires
La data est l’un des déclencheurs de la quatrième révolution industrielle. En rejoignant la communauté brAIn de onepoint, vous participez à notre ambition auprès des marchés européens, américains et asiatiques, d’accompagner cette mutation, de bout en bout en construisant et délivrant des services basés sur solutions performantes, scalables et sécurisées qui révèlent tout le pouvoir de « la data ».
L’une des particularités de onepoint est que vous aurez la possibilité d’intervenir auprès de grands comptes mais aussi d’accompagner des start-up prometteuses dans leur développement via le Big Data."
Courbevoie (92),,,Manager Data Science,KPMG,- Courbevoie (92),"#NoRoutine

Leader de l'audit, du conseil et de l’expertise-comptable, KPMG France est membre de KPMG International, réseau de cabinets indépendants constitué de près de 210 000 professionnels exerçant dans plus de 150 pays.

Savez-vous que l'exploitation des données est un des enjeux majeurs des entreprises ?
Avec 200 consultants au sein de notre centre d’excellence Lighthouse en France, et un réseau mondial de plus de 14 000 personnes, notre équipe Data & Analytics accompagne des grands comptes internationaux dans leurs projets de transformation, en les aidant dans le développement et l’implémentation de solutions de Machine Learning et d’Intelligence Artificielle.
Pour faire face aux besoins de nos clients et accompagner notre développement, KPMG Data & Analytics cherche à renforcer ses effectifs, et recrute un Data Scientist expérimenté, doté à la fois d’une forte expertise en développement informatique et modélisation, et d’un intérêt marqué pour les enjeux métiers.
Pourquoi nous rejoindre ?
Vous serez intégré(e) dans notre équipe d’ingénieurs et PhD, spécialisés sur les problématiques Data & Analytics et Big Data. A ce titre, vous interviendrez de façon opérationnelle sur des missions de conseil autour des sujets de stratégie, de transformation Data & Analytics, et de modélisation de données.

Vous avez envie de :
De comprendre les enjeux et attentes métier de nos clients et de les traduire d’un point de vue analytique
De cadrer méthodologiquement les travaux d’analyse de données et de modélisation, répondant aux enjeux et aux attentes du client
D’encadrer les travaux de Data Scientists et Data Analysts, en s’assurant du respect des règles méthodologiques définies en amont et de la réponse aux besoins du client
D’intervenir sur la définition d’une stratégie Data & Analytics
De participer à des missions de transformation Data & Analytics : mise en œuvre de solutions Data & Analytics / Big Data, développement et mise en œuvre de cas d’usage et industrialisation de ses solutions.
D’encadrer et suivre le développement de l’équipe de data science, en assurant une acquisition continue des compétences techniques et de conseil
Vous êtes garant de la qualité et de la fiabilité des modèles produits. Vous êtes sensibilisé aux enjeux éthiques et réglementaires liés aux données personnelles et/ou sensibles et à l’utilisation qui en est faite
Vous développerez vos compétences techniques, les appliquerez à des contextes sectoriels et fonctionnels variés, et aurez l’occasion de prendre en charge vos travaux de façon autonome.

Votre profil :
Vous êtes diplômé(e) d’une école d’ingénieur ou équivalent universitaire. Vous avez une solide formation en mathématiques appliquées/statistiques/Machine Learning, éventuellement dans le cadre d’un double diplôme avec une école de commerce.
Vous justifiez d’au moins 6 années d’expérience dans le domaine de la Data Science et du Big Data, au sein d’un cabinet de conseil ou du département Analytics d’une grande société.
Vous avez l’expertise d’un ou plusieurs langages de programmation (Python, R, java, C, C++, Scala…)
Vous maîtrisez une ou plusieurs solutions de visualisation : Tableau, Qlik Sense, Power BI, …
Idéalement, vous êtes déjà intervenu dans un environnement Big Data et/ou Cloud (VM, Hadoop, Spark…)
Vous avez une bonne connaissance des outils de gestion des versions (Git...)
Des connaissances en développement front (html, css, javascript, D3.js, React) sont un plus.
Vous maîtrisez les principales techniques d’analyse de données et modélisation :
o régressions, classifications, segmentations, séries temporelles, réseaux de neurones, etc.
Vous maîtrisez les principales étapes d’un projet analytique :
o cadrage projet, data cleansing, modélisation, validation, interprétation et restitution des résultats, documentation
Vous êtes curieux(se), autonome, entreprenant(e) et doté(e) d’une bonne capacité de travail
Vous disposez d’excellence capacités relationnelles et de présentation, et appréciez le travail en équipe
Vous êtes dynamique, organisé(e) et méthodique
Vous maîtrisez l’anglais dans un environnement professionnel

Localisation :
Vous serez basé(e) à Paris, avec d’éventuels déplacements en province et à l’étranger.

#2Coupsd’AvancePourPostuler
Convaincu de rejoindre un cabinet pourvoyeur de formations, d’opportunités de mobilité et de responsabilités, adressez-nous votre dossier de candidature. Comment présenter votre futur métier ? Regardez ceci : « Il est temps que votre oncle comprenne votre métier d’Advisory »"
Paris (75),45 000 € - 60 000 € par an,,Ingénieur système Linux / Courant Devops – Solution Saas machine learning et big data,In-Team,- Paris (75),"Parce que vous souhaitez rejoindre une société en pleine croissance qui aide les sociétés à travers de la big data à mieux comprendre les attentes des utilisateurs.
Parce que vous êtes persuadé que pour traiter des données aussi conséquentes, il faut une infrastructure de dernière génération avec des outils innovants.
Parce que vous savez que l’avenir se jouera avec des acteurs qui savent traiter toutes ces données et les interpréter de façon claire afin de continuer à être compétitif sur leur marché.
Plus simplement, vous souhaitez travailler sur des projets d’évolution d’une infrastructure qui doit tout le temps se renouveler pour être la plus efficace possible afin que les entreprises puissent adapter de façon plus précise leur stratégie.
Le poste :
Cette société qui édite une solution SAAS permet aux entreprises à travers de la big data de mieux comprendre les attentes de leurs clients. Le poste proposé est très varié et va vous permettre de vous former dans un secteur en pleine croissance.
Sous la responsabilité de la Direction R&D vous travaillerez des projets variés type :
Continuer la migration de nos serveurs dédiés legacy vers le cloud
Automatiser ce qui ne l’est pas encore et ce qui va arriver
Etre force de proposition sur les solutions techniques à choisir dans l’équipe R&D et les mettre en place.
Plus concrètement :
De formation ingénieur, vous êtes passionné par les nouvelles technologies et accompagné du lead tech, vous réaliserez des sessions de veille technique.
Vous avez de très bonnes connaissances sur l’environnement Linux
Vous êtes à l’aise avec Python, Ansible, Docker
Vous avez déjà des connaissances en BDD (MangoDB est un gros plus)
Vous voulez monter en compétence sur des problématiques cloud
Vous voulez travailler sur l’évolution de l’infra conçu pour la haute dispo.
Salaire et avantages :
Entre 45/60 k euros en fonction de votre profil
Des locaux d’exception en plein cœur de Paris avec Rooftop pour les bbqs de l’été
Un baby et une grosse équipe de compétiteurs sur Mario Kart
Pas de dress code, ambiance détendue et apéros d’équipe"
Montigny-le-Bretonneux (78),,,Ingénieur Lead Big Data H/F,RIDCHA DATA,- Montigny-le-Bretonneux (78),"Description
Nous recherchons pour le compte de notre client un ingénieur Lead Big Data H/F sur Paris en CDI.
Responsabilités
Vous aurez pour mission :
L’analyse et la formalisation métier des sujets Big Data
Piloter la roadmap de réalisation et de déploiement des différents modules de la solution
D’opérer les choix d’orientations stratégiques produit et R&D, en coordination technique avec les responsables Big Data et Data Science
Contribuer à la veille technologique de la plateforme Big Data et diffuser les bonnes pratiques au sein de l’équipe
Qualifications
Passionné par le monde du web et du Big Data, vous justifiez d’une expérience d’au moins 5 ans sur un poste similaire (mise en œuvre de projets et solutions Data orientés utilisateur final).
Vous avez déjà travaillé sur des projets d’ingestion de données consommateurs dans un Datalake / Datawarehouse.
Autonome et rigoureux, vous souhaitez intégrer une équipe soudée et motivée afin de mener à bien un projet innovant d’envergure internationale.
De nature curieuse et ouverte, vous savez gérer la pression et aimez travailler dans des environnements exigeants et en forte évolution.
Compétences techniques:
Ecosystème Big Data
Expérience Data management / Data Visualisation / Data Science
Microsoft Azure
Langages R, Python, Spark
Contacts
emna.kammoun@ridchadata.com
ridcha@ridchadata.com"
Paris 10e (75),"Temps plein, CDD, CDI",,Machine Learning Engineer - Image Recognition,Adevinta,- Paris 10e (75),"Team
You will be part of the Cognition team which is based in Paris and whose mission is to deliver Image recognition and NLP ML models for our marketplaces. As a member of Cognition you will develop modern computer vision technologies based on deep learning algorithms at scale for our brands around the world, for a variety of purposes, such as classification, metadata extraction, search and discovery, and understanding and moderating content.
Cognition is a multidisciplinary team of 6 members with data scientists, data engineers and backend developers. We embrace agile values by iterating on our developments, shipping features gradually and constantly and continuously looking for improvements in our processes and technologies. We encourage a diverse, collaborative and creative work environment, where you will develop and push for the state-of-the-art in image recognition at the same time as building reliable and highly scalable services. Our team is very autonomous and self organising; they are empowered to define the stack, approach to agile and architecture as a collective rather than from the top down. As an Adevinta engineer, you will also have the opportunity to learn from and share knowledge with our ML community across the company.
Today, we are looking for an experienced ML Engineer to join us in our Paris office.
Technical Context
Cognition team is developing a wide range of ML services : image classification, object detection, object segmentation, visual search... using recent CNN backbones and algorithms like YOLOv3.
We are constantly analysing State-of-the-art models and papers to improve our solutions. Our ML stack is based on TensorFlow, Keras, Kubernetes and deployed on AWS Cloud.
Job
Selection of the right machine learning algorithm for business goals ;
Engineer and implement highly scalable and reliable systems, using the best development practices and tools ;
Experiment with different models and assess their potential in offline evaluations and by setting up A/B tests ;
Collaborate in cross-functional teams consisting of product managers, data engineers and analysts to build a great search product that correspond to the needs of our marketplaces ;
Contribute to the end-to-end deployment of your machine learning models to ensure your high performing model ends up in production as intended. ;
Help define our development environment, and communicate the best development practices within the organization (i.e. code reviews, testing, etc) ;
Continuously monitor the quality of our systems and models, design measurements to monitor their health (both the data quality and inference performance) ;
And popularize search initiatives via Medium posts and meetup talks and our internal community
Qualifications
At least Bachelor’s degree in Computer Science, Applied Mathematics, Statistics or any quantitative field.
+4 years experience in industry in a similar role
Experience with development in programming languages such Java, Scala, or Python
Experience applying machine learning modelling to create data products.
Experience with TensorFlow and familiarity with current state-of-the-art in image processing and recognition
Experience with setting up ML pipelines and training jobs as well as wrangling data from a variety of sources, e.g. csv, SQL, S3, etc.
Experience with streaming tools such as Kafka and Spark Streaming is a plus.
Experience with AWS and/or other cloud providers is a plus
Experience with microservices architectures and containers (using Docker, Kubernetes) is a plus
Interest in keeping abreast with machine learning and field of image recognition
Proven track record of shipping technology while dealing with ambiguity, managing cross-team dependencies and relationships
Familiarity with devops, concurrent/multi-threaded programming, or distributed systems are all advantageous.
Additional Information
Adevinta is an equal opportunity employer and value diversity in our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status or disability status. If any of the above ticks your boxes, then why not Apply Now to find out more."
Paris (75),CDI,,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Data Scientist (H/F) pour renforcer ses équipes.
Dirigée par le Chief Data Officer et rattachée au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques met en œuvre la stratégie DATA avec comme principales préoccupations
D’améliorer la gouvernance des données ;
De contribuer à la data réputation de la Banque de France ;
De tirer le meilleur parti des masses et de la diversité des données disponibles au sein de la banque Centrale,
De développer des projets d’intérêt commun
De développer une culture de la donnée au sein des unités métier

Présentation du Service
Au sein de la DDSA, le SIAD (Service Industrialisation et Algorithmique des Données) a pour missions de construire et entretenir les socles techniques BIG DATA, de réaliser des prototypes de solutions basées sur les approches Data Science et IA et de mettre à disposition des solutions business intelligence pour les équipes métier.

Descriptif de mission
Le pôle « Data Science et IA » cherche à renforcer ses capacités en recrutant un(e) Data Scientist.
Les missions de ce pôle, partie intégrante du domaine « conseil et expertise », sont les suivantes :
Cartographier de façon continue, en relation avec les équipes d’innovation et les urbanistes, les processus métier pour lesquels une approche Data Science pourrait procurer un avantage compétitif ou préserver un territoire acquis
Épauler les métiers dans la définition et la stabilisation de leurs besoins
Mettre en place de façon continue les Proofs of Concept (POC) fonctionnels et techniques issus des analyses d’opportunité
Benchmarker de façon régulière les outils du Big Data
Préparer l’industrialisation des POC identifiés comme pertinents
Accompagner la montée en compétence des équipes métier et des équipes techniques sur le Big Data
Sous l’autorité du « Lead Data Scientist », vous serez en charge plus particulièrement :
De la prise en charge des besoins métier et de leur analyse ;
De l’identification des solutions potentielles et du choix de la solution la plus adéquate au regard des besoins et contraintes tant métier que techniques ;
De la conception et de la mise en œuvre de la solution (POC, prototype, MVP),
De l’accompagnement et du soutien aux équipes projets en charge de l’industrialisation des solutions.

Profil recherché
De formation supérieure en informatique ou métiers de la donnée (Ingénieur ou équivalent), vous avez minimum 2 ans d’expérience dans la mise en œuvre de solutions mobilisant des connaissances statistiques et/ou mathématiques avancées, y compris en contexte d’apprentissage/alternance dans des contextes de travail variés (recherche, entreprises commerciales, sphère publique ) constituera un avantage clé.
Vous disposez d’une forte appétence pour la concrétisation de solution dans un environnement Bigdata.Par ailleurs, vous avez la maîtrise :Des sous-jacents mathématiques aux approches Bigdata / Data Science (mathématiques et statistiques, Machine Learning, réseaux de neurones ) et des bibliothèques de Machine Learning (Scikit Learn, PyTorch, )
Du développement en Python
Seraient en outre appréciées, dans l’un ou plusieurs des domaines suivants :
Une très bonne connaissance en développement sur la stack Hadoop (Oozie, Sqoop, Hive, Hbase, ), sur les technologies Spark (MLlib, SQL, GraphX et Streaming), en langages PySpark, Java et R (SparkR).
Une très bonne maitrise des outils de Search (ElasticSearch) et de streaming (Kafka)
Une bonne connaissance des bases de données NoSQL telles que Mongodb et Neo4J
Une bonne capacité à intégrer des sources de données multiples, internes / externes, structurées / non structurées et des interconnexions entre les SGBD et Hadoop
Une bonne capacité à restituer les résultats visuellement à l’aide de Kibana ou PowerBI
Une facilité à développer dans un environnement innovant en méthodologie Devops et Scrum
Rigoureux et apte à anticiper, vous avez le sens du résultat au service du client et êtes doté d’excellentes capacités de communication pour faciliter le travail « en réseau » :
Force de proposition et aisance de communication pour démontrer la valeur ajoutée des solutions Big Data et Machine Learning.
Excellente méthodologie de travail et de gestion de projet, vous travaillerez en mode agile.
Très bon relationnel, capacité à s'adapter, esprit d’équipe, ouverture d’esprit et curiosité naturelle, vous suivez l’évolution des technologies et nouveautés relatives au Big Data, Datascience et IA
Une bonne pratique de l’anglais est nécessaire.
Ce poste, en contrat à durée indéterminée, est basé à Paris (1er), avec des déplacements ponctuels dans les sites banque de France à Paris et en régions.
La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes."
Paris (75),,,Cloud Software Engineer,Cloudreach,- Paris (75),"Reach New Heights

As the leading cloud solutions provider, we're on a mission to elevate technology and people so you can reach new heights.

Yes, you. Empowering people to keep growing, learning and succeeding is what we do for our customers and colleagues alike.

As a Cloudreacher you'll belong to a diverse and dynamic growing global community, play an integral role in shaping an industry at the forefront of technological transformation, and receive constant opportunities to progress in your career.

We passionately believe that innovation is something that's lived and breathed. Our culture isn't a nice-to-have but key to who we are and what we can deliver. When we look ahead, we see a bright future.

You too? Let's talk.

Which team will you be part of?

Cloudreach is adding highly motivated, self-starters to its core team to help the company realise the significant, multi-year shift that is happening with businesses moving their infrastructure onto the cloud.

We are currently hiring a full stack software engineer to join our development team. As a member of this team, you will help Cloudreach create a cutting edge application lifecycle management suite. You will have an opportunity to develop features that will help our customers improve their business goals and have a major impact on the growth of the company.

What will your role be?

Help drive the company-wide advancement of software products to enable our customers to meet their cloud journey
Creating well designed, documented, and tested software features that meet customer product requirements.
Identify and address product bugs, deficiencies, and performance bottlenecks
Remain up-to-date on emerging technologies and architecture and propose ways to use them in current and upcoming projects.
Collaborate with sharp people, and taking time to explore and understand solutions.
Mentor other team members to improve software development and delivery skills. Whereverpossible, also mentor other Cloudreach staff in their career transitions towards software development
Leveraging technical knowledge to improve the quality and efficiency of product applications and tools

With Cloudreach aiming to become a leader in Software Enabled Cloud Services, this is a fantastic opportunity to help create this Enterprise Cloud Software platform!

What are we looking for?

Programming Languages - 3+ years experience in several of the following: Django, Python, C, Java, Javascript
AWS - using a mixture of EC2, AMI, ELB, EBS Volumes, EBS snapshots, RDS, DynamoDB, S3, VPC, SQS, ACM, APIGateway, Cloudfront, Cloudtrail, ECS, KMS, Lambda, SNS, IAM, WAF
Management - Experience in at least one of the following: Chef, Puppet, Active Directory, MS SQL
DevOps - Skilled in one or more of the following: PostgreSQL, Terraform, Cloud Devops, and Data Analytics
Qualifications/Experience - 4 year degree in Engineering, Electrical Engineering, Computer Science, or related. 2+ years of experience

What you'll get:
Becoming a Cloudreacher gives you much more than a job title. We reward your skills and expertise by delivering value back, through the Cloudy Deal:

Compensation & Wellbeing: We base your total compensation on the skills, knowledge and behaviors you bring to Cloudreach and aspire to provide flexible benefits, enabling you to achieve a work-life balance that helps you thrive.
High Impact: We want you to make a personal impact: delivering results that help grow the business and make a difference to our customers, your colleagues and your community. Job satisfaction at its best.
Career Development: You'll find constant opportunities to take on new roles and grow with Cloudreach, as well as training, coaching, and continuous feedback to boost your expertise and give you career-enhancing skills.
Culture & Engagement: We have a dynamic and inclusive working environment built for collaboration, flexibility, openness – and fun, with managers who listen, engage and empower your actions.

The Experience:
Recharging your batteries: When you need time to recharge, our uncapped holiday allowance will do the trick.
Feeding your mind: Expand your mind through our excellent learning platforms and become a fully-fledged Cloudreacher before you know it.
Taking care of your body: We help take care of your body through our health and wellness programmes, and sustain you throughout the day with snacks and drinks from our well-stocked kitchens.
Lifting your spirit: Our dynamic workspaces are designed to accommodate individual working styles, complete with pool tables and beanbags for more playful moments.
Giving you flexibility : You'll feel immediately plugged in with a brand new Macbook and smartphone for the office and beyond, helping you work where and how you want.
Connecting you : Our regular Cloudy Lunches bring everyone together to bond over a plate – or two – of free food.

We strive to remove barriers, eliminate discrimination and ensure equal opportunity through our transparent recruitment process. We are open to all groups of people without regard to age, disability, marital status, gender identity, race, colour, sexual orientation, religion, military status, veteran status or any other legally-protected characteristic."
Paris (75),,,Devops,Blade,- Paris (75),"COMPANY DESCRIPTION

After raising a total of 60 million euros in 2 years, Blade is going international in 2018 with the expansion of Shadow in Europe and in the US.

Shadow is a high-end Windows 10 PC accessible from anywhere at anytime. Thanks to our apps (Windows, Mac, Linux, Android and iOS) and to the Shadow Box, the service is available on any kind of device (laptop, smartphone, tablet, Android TV…). This way, any connected device with a screen becomes a powerful gaming or working station offering a unique experience.
Shadow’s software is frequently updated and the hardware components are improved in our highly secured data centers. No need to change your computer every few years, Shadow is the end of obsolescence!

We truly believe that Shadow represents a whole new way of using computers. Much more than a PC, Shadow is THE answer to the increasing need of computing power, mobility and hardware replacement.
Help us make this incredible dream come true.

JOB DESCRIPTION

Blade is looking for a talented DevOps to make scale and manage our in-house solution. You will work very closely with our performance & orchestration team. What is the project? It’s about big scaling capacities and increasing by 10 (to start with) the number of machines.

Your main responsibilities will include to:
Design, build, and operate infrastructure services that are reliable, scalable
Regularly write and review infrastructure automation, configuration management
Write and review functional specifications and scoping documents for large infrastructure projects
Investigate gaps and limitations in existing infrastructure and come up with well-thought-out long-term solutions
Qualifications:
Education and Background:
BS or MS degree in Computer Science or equivalent
+3 years of experience in a similar role
Fluency in English
Technical Skills:
Strong knowledge of Python
Strong knowledge in Linux systems
Strong knowledge in production environment
Strong Linux and TCP/IP networking skills
Strong knowledge of REST API
Working knowledge of cloud infrastructure
Experience with configuration management tools and managing infrastructure as code (Ansible)
Able to perform deep technical analysis and fix applications, systems, and networks
Knowledge of Netbox
Soft skills:
Ownership
Loving challenges
Understands the value of collaboration
Working with closely with several tech teams
Pragmatic, detail-oriented, self-motivated"
Paris (75),,,Data Engineer H/F,Avanade,- Paris (75),"Vous aimez manipuler La Data ? Rejoignez notre équipe de consultants experts en Data Engineering ! Cette dernière a pour responsabilité de répondre aux besoins clients en termes d’Architecture et de de mise en place des solutions Big Data.

Vos missions

Au sein de notre équipe Enterprise Technology Architecture (ETA), dans le cadre de projets Big Data nationaux et/ou internationaux pour des grandes entreprises, vous participerez aux missions suivantes :

Design et développement du traitement des données streaming avec Spark Scala, Python, Java
Développement des APIs pour alimenter des données dans le Data Lake (Kafka, Spark Streaming, Azure…)
Monitoring de l’environnement Big Data et l’optimisation de performance
Performance Review des plateformes Big Data
Rédaction de spécifications techniques
Vous serez également amené(e) à contribuer à :
L’accompagnement des développeurs juniors dans l’optimisation de leurs traitements / de leurs requêtes
Aux avant-ventes (définition et validation de la solution, contribution à la rédaction d’Appels d’Offres, participation aux soutenances des propositions).
La veille technologique autour des solutions de Big Data
Environnement technique :
Spark Scala, Python, HDFS, Linux
Vous êtes

Vous êtes un ingénieur ou vous avez un diplôme universitaire équivalent en IT. Vous avez une expérience de minimum 3 à 4 ans dans le développement Spark Scala ou Python. Vous maîtrisez plusieurs de ces technologies : Spark Scala, Python, Java, C/C++/C#, Linux, Cloud (Azure/AWS/GCP), Hadoop, Kafka, Base(s) de données SQL, Base(s) de données NoSQL, outils de visualisation des données (Kibana, Grafana…)

Un bon niveau d’anglais à l’écrit comme à l’oral est indispensable."
Courbevoie (92),,,AWS Learning Architect - France,AWS EMEA SARL (France Branch),- Courbevoie (92),"BASIC QUALIFICATIONS
Requirements
7-10 years of experience in programming, systems architecture or systems administration
2-5 years of experience leading small to medium sized (virtual) teams
Ability to connect complex technical solutions to customer business requirements
Experience in developing & managing large complex training programs
Experience conducting classroom training for related technology products and services
Technical degree (i.e. Computer Science) or relevant work experience required
Recent experience architecting, deploying, and operating Internet scale applications

Amazon Web Services (AWS) provides a highly reliable, scalable, and low-cost infrastructure platform in the cloud that powers hundreds of thousands of businesses in 190 countries around the world. AWS Training and Certification team is looking for a Learning Architect that develops and manages the delivery of world-class AWS Training programs.

To meet the growing demand for AWS Services around the globe, we need exceptionally talented, bright, and driven people. If you have previous training or consulting experience and can communicate highly technical concepts to audiences at different stages in the AWS journey, we’d like to speak with you. We are looking for a dynamic, organized self-starter to join our Training Team.

Here's your chance to work as a Learning Architect on a newly formed team, with high visibility and significant customer impact. You will execute on enterprise customer training programs covering various technology domains such as Artificial Intelligence (AI), Machine Learning (ML), Big Data, Internet of Things (IoT), Serverless computing, System Architecture, System Operations, Application Development, DevOps, and Systems Migration.

In this role you will be responsible for developing, architecting and managing AWS Training engagements with large enterprise customers and prospects. This will be achieved by uncovering opportunities in collaboration with the Business Development Managers, building strategic relationships with customers and leveraging a network of internal stakeholders, including ProServe and Solution Architects.

Responsibilities:

Architect complex learning engagements aligned to the customers’ business goals across the lifecycle of their AWS cloud adoption strategy
Analyze data from multiple sources to uncover opportunities
Align AWS training engagements to customer digital transformation initiatives
Capable of delivering “business awareness” sessions or lead train the trainer courses where appropriate
Scope and deliver training skills assessments with recommended learning plans
Craft organizational skills and development plans based on data gathered
Project manage the execution of customer learning programs
Engage with Strategic and Large Enterprise Customers (at C level), AWS Sales, Solution Architects and ProServe
Establish and maintain strategic partnerships with AWS cross-functional organizations.
Address each customer's unique training needs, establish customer value, and present learning proposals that align to their expected ROI
Maintain a positive, professional, total customer service attitude.
Demonstrate a subject matter expertise across education and learning, AWS solutions, industry knowledge and competitive differentiators
Provide innovative ideas that positively impact all areas of the AWS business
Help shape the ongoing strategy and mission of the AWS training program

PREFERRED QUALIFICATIONS
Knowledge and/or hands-on experience with AWS infrastructure services highly desired
Proven record of developing and retaining top technical trainer talent
Self-sufficient, self-starter with proven success taking ownership of training projects
Excellent oral presentation skills, interpersonal communication, and writing skills
A strong “stage presence” and ability to manage a classroom of adult learners
Experience designing and developing instructor-led content with technical subject matter content
Subject matter experience and experience in at least two of the following:
Artificial Intelligence (AI)
Big Data
DevOps
Internet of Things (IoT)
Large scale application or data center migration
Machine Learning (ML)
Serverless computing
Software Engineering or Application Development
Solutions Architecture
System Operations
Experience with Windows and Linux at the command line
Ability to travel globally. Travel will be about 50% for the first year."
Suresnes (92),,,IT Systems Devops Engineer,Talend,- Suresnes (92),"WHO WE ARE:

Talend, a leader in data integration and data integrity, enables every company to find clarity amidst the chaos.

Talend Data Fabric brings together in a single platform all the necessary capabilities that ensure enterprise data is complete, clean, compliant, and readily available to everyone who needs it throughout the organization. It simplifies all aspects of working with data for analysis and use, driving critical business outcomes.

From Domino’s to L’Oréal, over 4,250 organizations across the globe rely on Talend to deliver exceptional customer experiences, make smarter decisions in the moment, drive innovation, and improve operations. Talend has been recognized as a leader in its field by leading analyst firms and industry publications including Forbes, InfoWorld and SD Times.

Talend is Nasdaq listed (TLND) and based in Redwood City, California.

alend is hiring an IT Systems DevOps Engineer to join our dynamic IT operations team in our Suresnes office to build and extend our infrastructure and applications services to enable our customers to meet their business goals. Reporting to the Infrastructure system Manager, the main responsibilities are to ensure our core systems and applications are running smoothly and meets our growing needs.

We are looking for motivated individuals focused on systems and network administration. Talend’s IT Systems Devops Engineer works with team members on exciting projects that impact our products and customers (external and internal) experience. Working either independently or with the IT team, this individual brings a combination of technical depth, written/verbal communication skills, and project management expertise.
Responsibilities:
Build, administer and maintain servers, security updates and patches;
Ensure system design allows all components to work properly together;
Perform information systems needs assessments, reviews information gathering and recommends appropriate systems and IT infrastructure.
Work with systems team management to define requirements and timelines for new projects and environment upgrades/changes;
Develop and improve tools to aid operations and maintenance.
Be an actor in private cloud infrastructure management as a code
Provide user support to IT infrastructure (systems and network) and services.
Produce feedback, reports, documentation, webinars
Required Skills and Experience:
Degree in Computer Science or equivalent work experience in a technical field;
5-7 years of IT systems administration in UNIX/Linux environment and Network administration;
Working experience in Perl, shell scripts, PHP, Python and MySQL;
Experience with LDAP, Active Directory, Jira, WordPress, Confluence, source control systems, and Zendesk;
Experience with VMware operations/platforms, ESXi, vCenter;
Experience with Automation (Puppet, Chef), Monitoring (Nagios), containerization (Docker) and Configuration Management (Ansible);
Professional level in French and English (spoken, written)
AND NOW, A LITTLE ABOUT US:

Talend has received some pretty impressive accolades along the way:
""2018 Best Public Cloud Computing Companies To Work For"" by Glassdoor
Named a Leader for Data Integration Tools in the Gartner Magic Quadrant
Named a Leader in Big Data Fabric for the Forrester Wave
Ranked in the DBTA “100 Companies that Matter Most in Data”
Listed in the CRN Big Data 100 Companies

We are passionate about helping companies become more data driven; and, if we can be honest, we are all geeks at heart who pride ourselves on the vibrant company culture that we have built.

As a global employer, at Talend, we believe our success depends on diversity, inclusion and mutual respect among our team members. We seek to recruit, develop and retain the most talented people from a diverse candidate pool. We are committed to making all employment decisions on the basis of business need, merit, capability and equality of opportunity. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin."
Courbevoie (92),,,Senior Consultant - Cloud Infrastructure,AWS EMEA SARL (France Branch),- Courbevoie (92),"3+ years hands on experience in IT implementation or leading IT Projects in Architecture, Engineering, or Development
Designed virtual infrastructure using services (e.g. EC2, ECS, ELB, RDS, Route53 & S3 or comparable virtualization/ experience) preferably using Container
Successfully implemented Infrastructure automation through CI/CD, DevOps scripting (E.g. shell, Python, CloudFormation, Terraform, Docker).
Worked in a customer facing (external or internal), consulting role or project organization delivering IT solutions
Business fluent verbal and written communication skills in French and English

Amazon Web Services () Professional Services helps customers design and build innovative solutions, and, migrate existing solutions to our platform. We provide the “how” of the move to the .

Our customers are global enterprises and necessitate high standards and big ideas! We adopt modern architectures, consulting and project methodologies embracing a multi-disciplinary team setup. Large-scale transformation, mass migrations, complex application architectures, Artificial Intelligence, Data Science and Big Data are our trade.

The French Professional Services Team is looking for a Infrastructure who is interested in:
Designing enterprise scale, globally distributed, highly available solutions using our Compute, Container, Storage, Database and Network Services
Work hands-on with new Services, including AI/Machine Learning, Serverless/Lambda IoT and Security Services to build Products and Solutions with our Customers
Structure and Guide our Customers through their -Journey
Migrate Data Centers from on-premise into the cloud.
Engage as part of our global Professional Services Community to learn and share you expertise

We offer a versatile team, modern offices, an open feedback culture, and a high pace of innovation. Take the chance and join us to Work Hard. Have Fun. Make History.

AWS Certification in Solutions Architecture, DevOps, or other specialty
Experience implementing AWS services and solutions on Customer Projects
Knowledge and experience using Container technologies (e.g. Kubernetes, Docker)
Experience working within large-scale, global Architectures
Deep understanding in Networking, Storage or Compute
Business fluent verbal and written communication skills in French and English

Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build.

By submitting your resume and application information, you authorize Amazon to transmit and store your information in the Amazon group of companies' world-wide recruitment database, and to circulate that information as necessary for the purpose of evaluating your qualifications for this or other job vacancies.

aws-proserv-ea"
Suresnes (92),,,"Technical Support Engineer, Stitch and Cloud",Talend,- Suresnes (92),"WHO WE ARE:

Talend, a leader in data integration and data integrity, enables every company to find clarity amidst the chaos.

Talend Data Fabric brings together in a single platform all the necessary capabilities that ensure enterprise data is complete, clean, compliant, and readily available to everyone who needs it throughout the organization. It simplifies all aspects of working with data for analysis and use, driving critical business outcomes.

From Domino’s to L’Oréal, over 4,250 organizations across the globe rely on Talend to deliver exceptional customer experiences, make smarter decisions in the moment, drive innovation, and improve operations. Talend has been recognized as a leader in its field by leading analyst firms and industry publications including Forbes, InfoWorld and SD Times.

Talend is Nasdaq listed (TLND) and based in Redwood City, California.

What you'll do as our Technical Support Specialist, you'll be responsible for directly providing great support to our customers, answering their questions, and investigating and resolving the issues they raise. You'll also be involved in initiatives that reduce support request volume and help develop communication practices that ensure quality and consistency in technical support. You'll focus on customers' satisfaction with Talend Stitch by not only managing support SLAs, but also advocating for customers in product development conversations and coordinating efforts with customer engagement and sales colleagues. The successful Technical Support Specialist will be highly analytical (SQL and Excel should be exciting to you) and be interested in helping to solve our users' most difficult challenges. This includes not only specific help requests from our users, but also proactive problem solving to prevent issues from arising in the first place by identifying bugs, user experience issues, and missing or outdated documentation.
What you will need
To succeed in this role, you'll need to be excited by the idea of learning about data replication, software as a service, data warehouses, and how those elements come together. You should be open to learning enough about how those technologies work to be able to effectively communicate with current and prospective customers. You should also have:
1-2 years of customer-service oriented professional experience.
Ability to extract, analyze and report on data by writing complex DB queries in SQL language.
Excellent communication and interpersonal skills. In addition to working directly with current and prospective customers, you'll need to collaborate with sales, engineering, product, and more.
Meticulous attention to the detail and excellent time-management skills. A core part of the job is being able to juggle many conversations at once. Organization and prioritization are key. While it's not required, it would be nice if you had:
Experience in SaaS support in general (strong preference)
Experience in chat-based support at scale
Technical knowledge of SaaS software, and perhaps the software development process.
Preferred Skills:
Knowledge of DI/ETL or Data Governance tools is a plus.
Basic knowledge of BigData architecture and components along with an understanding of distributed file systems.
Knowledge with Cloud computing is a plus (AWS/Azure/GCP)
Good to have understanding on at least one of the programming languages (PHP, Java, Python)
Knowledge of Excel or Google Sheets (vlookups, index,match, indirect,address,arrays,etc) is a plus.
#LI-IW1

AND NOW, A LITTLE ABOUT US:

Talend has received some pretty impressive accolades along the way:
""2018 Best Public Cloud Computing Companies To Work For"" by Glassdoor
Named a Leader for Data Integration Tools in the Gartner Magic Quadrant
Named a Leader in Big Data Fabric for the Forrester Wave
Ranked in the DBTA “100 Companies that Matter Most in Data”
Listed in the CRN Big Data 100 Companies

We are passionate about helping companies become more data driven; and, if we can be honest, we are all geeks at heart who pride ourselves on the vibrant company culture that we have built.

As a global employer, at Talend, we believe our success depends on diversity, inclusion and mutual respect among our team members. We seek to recruit, develop and retain the most talented people from a diverse candidate pool. We are committed to making all employment decisions on the basis of business need, merit, capability and equality of opportunity. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin."
Villeneuve-Saint-Georges (94),CDI,,Architecte Integration Data F/H,Orange,- Villeneuve-Saint-Georges (94),"Le département a pour objectif de délivrer des prestations de qualité en analyse statistiques, mise en oeuvre de dataviz et utilisation de machine learning, avec une forte compréhension des enjeux fonctionnels des clients dans le cadre de projets d'intelligence opérationnelle :
Etudier et analyser les données collectées afin de répondre aux demandes marketing et/ou équipes techniques.
Accompagner le client dans des ateliers projets fonctionnels et techniques
Concevoir et mettre en oeuvre les solutions d'alimentation et de manipulation de données
Se tenir au courant des évolutions du marché sur les technologies innovantes
Des formations seront proposées pour monter en compétence sur la solution Splunk.
about you
De formation BAC+5 en informatique, vous justifiez d'au moins 5 ans d'expérience dans le développement ou la manipulation de données.
Passionné(e) par votre métier, curieux, dynamique et force de proposition, vous pourrez vous investir sur des activités au coeur des nouvelles technologies au sein de nos équipes projet d'intelligence opérationnel.
Compétences techniques et qualités requises :
Connaissance des langages de développements : Python, Java et Javascript
Connaissance en requêtage SQL, noSQL
Bonne maitrise de l'environnement Linux
Bonne maîtrise écrite et orale de l'anglais
Bonnes compétences rédactionnelles.
Savoir analyser, modéliser et présenter les données
department
Digital & Data
Partenaire de la transformation digitale des entreprises, Orange Digital&Data est l'entité d'Orange Business Services spécialisée dans la conception et le développement de services applicatifs et l'intégration de systèmes.
Implantés dans plusieurs grandes villes françaises comme Paris, Rennes, Lyon, Bordeaux, Lille et Toulouse … nous accompagnons au quotidien près de 20 000 entreprises tout au long du cycle de vie de leurs projets, dans les domaines clés de l'expérience digitale, de la Data Analytics et l’Intelligence Métier.
Pour la 4ème année consécutive, Orange reçoit la certification « Top Employer Global » 2019. Cette certification consacre les meilleures politiques et pratiques en termes de programmes de ressources humaines.
L’innovation est essentielle à votre métier, construisons la ensemble !
contract
CDI"
Courbevoie (92),,,"AWS Solutions Architect, Startups",AWS EMEA SARL (France Branch),- Courbevoie (92),"Technical Degree (Computer Science, Maths, Engineering or equivalent) and/or relevant tech experience
CTO/co-founder/architect experience for a VC-backed technology startup company or strong interest in the Startup ecosystem
Experience of Software, Systems or Data Design
Passion for technology and for learning
Fluency in French and English

Startup Solutions Architects work hand in hand with technical co-founders, engineers and developers to help them make the most of the Cloud. They are at the crossroads of business and technology and engage with organizations at all stages of cloud adoption. Solutions Architects also take a leading role in creating and presenting technical content and best practices.

Solutions Architects own the overall technical relationship between customers and AWS and make recommendations on security, cost, performance, reliability and operational efficiency. They work to understand the customer's business needs and give prescriptive guidance on how to create business value with technology. To do this they collaborate with other teams such as account management, professional services, support, product teams and the AWS partner ecosystem.

In this role you will get to practice your creativity, linking technology to tangible solutions and educating Startups about the art of the possible. You will have the opportunity to define or invent cloud-native reference architectures for a variety of scenarios. (e.g. Artificial Intelligence, Deep Learning, Genomics, Analytics and Big Data, DevOps or Security).

The Solutions Architecture team is a diverse group of technologists from a variety of backgrounds. Practical knowledge of the AWS platform is desired but not required, provided you have a sound technical foundation and a desire to learn.

You will have the support to grow your expertise in industry and technology areas of depth. Every day you will learn something new from your customers, your peers and your own experiments.

At Amazon you will be encouraged and rewarded for doing what is right for the long-term success of the customer. We value your passion to discover, invent and build on behalf of customers.

Amazon has always been, and always will be, committed to diversity and inclusion. We seek builders from all backgrounds to join our teams, and we encourage our employees to bring their authentic, original, and best selves to work.

Roles and Responsibilities
Collaborate within the startup ecosystem (accelerators, incubators, VCs and meetups) to educate startups and support their growth
As a Solutions Architect, you will work directly with customers to accelerate their projects and recommend best-practice architectures in line with their long-term business outcomes.
You will own the technical relationship with the customer and operate as their trusted advisor. The best interests of the customer will shape the guidance you provide.
Share the voice of the customer to influence the roadmap of new features and services for the AWS platform.
Create and capture best practices, technical content and new reference architectures (e.g. white papers, code samples, blog posts).
Evangelize and educate about AWS technology (e.g. workshops, user groups, meetups, public speaking, online videos or conferences).
Contribute to the growth of the Solutions Architecture organization by hiring, coaching and mentoring others.
Develop areas of depth in technical domains relevant to your interests and your customer's outcomes..

Knowledge of a modern programming language (Python, JavaScript, Go, .Net, Java, etc.)
In depth working knowledge in a technology domain such as distributed internet-scale web or mobile applications, DevOps, Serverless, Big Data, analytics, Machine Learning, highly secured workloads etc.
AWS certification (e.g. AWS Solutions Architect Associate or Professional)"
Issy-les-Moulineaux (92),,,Software Engineer - Stealthwatch,Cisco Systems,- Issy-les-Moulineaux (92),"What You'll Do

You will build security detection systems for our customers using current technologies. You will make technology choices and put them into practice. Technologies like Spark, Kubernetes, Docker, AWS and other Enterprise Commercial software may be knowledge areas where we start. Our destination will change based on what we learn. You will be an active learner and work with your team to deliver innovative security software solutions (not writing shelfware) for our customers. You will be part of a strong collaborative Agile/Scrum team. You will be challenged and have the opportunity to play to your strengths. Individuality in a team environment reflects the culture you will need to support. You will be helping our customers protect what's important from cyber threats. You will be challenged in working to solve some tough engineering problems using some of the latest tools, technologies and approaches. You will get to leverage your strengths and have the opportunity to master existing skills and learn new ones. You will look to apply lean startup principles to validate the growth and value potential in all that we do.
Making the world a safer place. Big company resources w/ small company culture/feel.

Who You'll Work With

You will work on strong cross functional teams that own their outcomes. We believe in building strong teams and look for people that feel the same. You and your teammates believe in healthy discussions around ideas and how to deliver quality solutions to our customers. You will be part of a small team that engages in unfiltered conflict around ideas. You will be part of an established but fast-growing organization that continues to thrive in the security industry. You will follow our solutions with your team to our customers and will work with the people and departments on the way to ensure success. You and your team will hold one another accountable for delivery. We are not satisfied until the customer's problem is solved. The team will focus on achievement of collective results. The team is willing to experiment and adapt. Where forks in the road are approached, they will use data to drive their decisions.

Who You Are

A software engineer with excellent communication skills who is willing to pitch in and help the team to succeed. Strong technical and analytical skills. A healthy interest and curiosity in alternative/functional languages. Technologies like Docker, microservices, distributed systems and TDD are part of your skillset or have a strong desire to learn them. You collaborate with other engineers and people in the organization to improve our solution delivery. You believe in Lean/Agile principles and actively work to incorporate them in the organization. You have skills in Functional Programming + Object Oriented Programming and have the ability to pick the right tool for the right job. You also have experience or passion for big data, streaming analytics and continuous delivery.

Profile characteristics: At least 3 years professional experience Experience in Java, Scala Experience with Python, Ruby, Spring, Akka and Docker is a plus Familiarity with Linux environment Strong software design and development skills An understanding of application performance tuning Able to work in a Lean/Agile Scrum environment BS/MS in Computer Science or equivalent Strong English written and verbal communication skills
Why Cisco

We connect everything: people, processes, data, and things. We innovate everywhere, taking bold risks to shape the technologies that give us smart cities, connected cars, and handheld hospitals. And we do it in style with unique personalities who aren’t afraid to change the way the world works, lives, plays and learns.

We are thought leaders, tech geeks, pop culture aficionados, and we even have a few purple haired rock stars. We celebrate the creativity and diversity that fuels our innovation. We are dreamers and we are doers.

We Are Cisco."
Paris 19e (75),"Temps plein, CDI",70 000 € par an,DATA ARCHITECT,Hire.fr,- Paris 19e (75),"HIRE Un service innovant et sur mesure dans le secteur digital du recrutement sur les fonctions Cadres et Managers, recrute pour l'un de ses clients, acteur du monde de la santé, un Chef de Projets Informatique ""Data Architect"" H/F en CDI.
La mission :
Gestion de la mise en place d’un nouvel Entrepôt de données (en collaboration directe avec la DSI) : - Gérer et encadrer la construction et l’exploitation d’un nouvel entrepôt de données (SQL et NoSQL) basé sur une technologie propriétaire. - Rédaction des spécifications générales et détaillées du projet - Mise en place des structures du projet et des règles de fonctionnement (méthodes, outils de pilotage, indicateurs...) - Évaluation des risques et hypothèses associés au projet et définition d’un plan d’actions - Pilotage et mesure de l'état d'avancement (création des tableaux de bord, choix des indicateurs, planification des comités de pilotage...) - Validation des livrables et organisation des déploiements - Gestion et réalisation des tests et recettes - Formation et aide à la conduite du changement - Organisation des interfaces et des reprises de données - Pilotage opérationnel des prestataires - Organisation de la gestion des droits utilisateurs - Mise en place de procédures écrites formalisées concernant l'utilisation des applications - Suivi des applications dans le temps (paramétrage, maintenance corrective et évolutive) - Supervision des interfaces inter applicatives, connaissance des protocoles d’échange - Accompagnement et support technique de projets métiers Dans le cadre de l’accompagnement métier réalisé par l’Unité Data Science, la/le Data Architecte devra apporter son expérience et expertise sur des problématiques métiers précises, notamment dans le domaine de la recherche en santé. En appui au Responsable de l’unité Data Science, il/elle sera en charge d’accompagner, d’encadrer et de réaliser techniquement des projets Data métiers (structuration de bases de données exploitables à partir de données très variées et provenant d’une grande diversité de sous bases (SQL, No SQL, fichiers, images, vidéos, son). Autres Être force de proposition en termes d’évolution de l’environnement Data (environnement Big Data Open Source notamment). Assurer une veille technologique : actualité, nouveauté, applicatifs, outils, progiciels, matériel, ..
Le profil recherché :
- Ecole d’ingénieur, Formation supérieure Bac+4 /+5 - 5 ans d’expérience ou plus dans le domaine des bases de données, Business Intelligence, Entrepôts de données structurées et non structurées - Compétences fortes en bases de données (Oracle, SQL Server) et langages afférents (SQL) - Mise en œuvre effective de DataWarehouse, ou mieux, de DataLake - Maitrise de solutions de type Power BI ou Qlick Sense - Bonne compréhension des architectures informatiques (infrastructure, réseaux, sécurité) - Rigoureux, autonome et responsable, organisé et aimant travailler de façon collaborative - A l’écoute des besoins utilisateurs et esprit de synthèse - Langages : SQL, Java, Python, Scala - Idéalement : connaissance du milieu médical, connaissance forte voire mise en œuvre de solutions de type NoSQL, technologies Hadoop, …"
Courbevoie (92),,,Partner Solutions Architect - Systems Integrators,AWS EMEA SARL (France Branch),- Courbevoie (92),"Expertise in these technology areas: devops, containers, serverless, application/cloud-native development and design, CI/CD
Hands on experience within the last three years in networking, security, database administration or development, application development, or system administration
Past experience leading white boarding sessions and delivering multi-day workshops to architects, operations staff, developers, and cloud technologist
Demonstrated ownership of a large IT project or software development effort
Experience writing technical training course content, white papers, technical articles, or blog posts
Technology Breadth: Demonstrate architectural best practices applied across a breadth of technologies to solve organizational problems, articulate views/roadmaps for future development, and understand the interaction between infrastructure, operations, and development
Technology Depth: Demonstrate detailed knowledge of concepts, implementation, patterns, and issues of at least four technology areas
Strong leadership capabilities, having the ability to communicate effectively with a diverse set of customers or partners, across multiple disciplines.
Strong presentation and written communication skills; high degree of comfort with technical and Executive audiences.
Demonstrate a strong bias for action and hands on approach
Degree required, computer science, business or math background preferred
French and English speaker

Would you like to be part of a team that is redefining the IT industry? Amazon Web Services is leading the next paradigm shift in computing and is looking for a world class candidate for the role of Partner Solution Architect, focused on a Global Systems Integrator (GSI) within our EMEA Public Sector organization.

This is an ideal role for someone who has experience working for a Global Systems Integrator, a large IT consulting firm, or a Fortune 1000 company. The Global PSA will help develop the technical capabilities of this GSI so they can be successful in the building and selling Cloud solutions to Public Sector customers. Working with this large partner is a team effort that will require influence and coordination with many stakeholders. You should be just as comfortable talking storage and networking with the VP of Infrastructure or continuous deployment with the DevOps team, TCO with the CFO, and cloud strategy with the CIO. If you are a problem solver with a broad technical-skills, and have the ability to drive technical initiatives and cloud migration projects with GSIs you will enjoy this role.

In this technical role, you will architect enterprise-grade Amazon Web Services solutions, own the technical relationship and deliverables with a GSI, develop and execute multi-day workshops, lead white boarding sessions, author white papers and blog posts, and respond to complex technical inquiries. As a Partner Solution Architect focused on GSIs, you will have the opportunity to help shape and deliver on a strategy to build mind share and broad use of the AWS platform across the partner community.

The ideal candidate will possess deep technical skill in software architecture, information security, compliance initiatives, software deployment and cloud computing as well as customer facing skills at all levels of a partner organization. The ideal candidate should also have a demonstrated ability to think strategically about business, product, and technical challenges. The ideal candidate is also an influencer by nature and must be seen as someone the partners are eager to engage with and have a strong hands-on approach.

Key Responsibilities:
Technical leader and trusted adviser in the area of cloud computing for our partners
Drive development of repeatable assets, solutions, products & accelerators
Own the technical relationship and deliverables for one of the global system integrators
Assist the global systems integrator in building an AWS center of excellence within their organization enabling them to offer and deliver AWS based solutions to our joint customers.
Assist this global system integrator to earn the trust of customers by delivering multi-day technical workshops, lead white boarding sessions, executing on Proof of Concepts, and contributing to the construction of scalable, secure, and highly available AWS solutions.
Demonstrate a bias for action and deep technical skills by authoring joint technical whitepapers with the GSI, technical case studies, and Public Sector focused blog posts.
Dive deep on AWS Services as you develop reference architectures and presentations.
Exhibit a combination of technical vision, creativity, technical acumen, and deep AWS technical skills by jointly designing and developing industry and vertical solutions.
Assist the partner to define the approach, tools, and end state architecture as they migrate customers to Amazon Web Services.
Work with specific Innovation Centers within the global systems integrators enabling them to deploy prototype solutions using high-level services in the Machine Learning, Voice, Chatbots, IoT and Augmented/Virtual Reality domains

Exhibit the attributes of learn and be curious by demonstrating the ability to quickly assimilate information about new technologies and business models
Experience designing and implementing enterprise-grade architectures for Fortune 1000 companies
Passion for working with global systems integrators
Broad based technology experience including: cloud computing, applications development, DevOps, IoT, relational databases, NoSQL databases, analytics, networking, security, storage, compute, continuous deployment, containers, and management and monitoring
Demonstrated ability to think strategically, and act tactically, about business, product, and technical challenges
Experience executing large scale data center transformation or application migration and modernization projects
Cloud and/or AWS experience; AWS Certifications: AWS Certified Solutions Architect - Associate Level, AWS Certified Developer - Associate Level, AWS Certified SysOps Administrator - Associate Level; and AWS Certified Solutions Architect – Professional, AWS Certified Devops Engineer - Professional
Visible IT Industry thought leadership on relevant topics related to enterprise IT infrastructure
International technical sales and delivery experience w/ global F500 enterprise customers and partners
Use of AWS services in distributed environments with Enterprise Software
Advanced degrees in engineering and/or business"
Paris (75),CDI,50 000 € - 60 000 € par an,Data Engineer / DevOps,Harnham US,- Paris (75),"Data Engineer / DevOps
50-60K par an
Paris, France
Cette Start-Up en pleine croissance spécialisée dans le secteur des médias et forte d'une grosse levée de fonds (+15 millions !) recherche un profil de Data Engineer avec une certaine affinité pour le DevOps.
La société a créé une plateforme de contenu média tourné autour de l'IA et du Maching Learning identifiant notamment les grandes tendances sociales sur différentes plateformes de réseaux sociaux.
Dans ce rôle, vous serez amené à travailler sur l'implantation et l'amélioration d'algorithme mais également à intervenir sur un nombre massif de données généré par ces contenus.
LE POSTE :
Au sein de l'équipe Data :
Vous optimiserez et construirez des pipelines de données
Vous mènerez une démarche d'amélioration continue afin d'enrichir le Data Model et les infrastructures existantes
Vous serez amené à être force de proposition et accompagnerez les membres de l'équipes sur notamment des bonnes pratiques de codes, méthodologies de travail innovante
Vous participerez avec l'équipe Infra et Développement à l'optimisation des outils et des processus Data
Vous pourrez être amené à discuter de la mise en place d'un nouveau modèle data au sein de la société
LE PROFIL :
Vous avez une première expérience en tant que Data Engineer ou DevOps
Vous justifiez d'un excellent niveau sur Python et avez l'habitude de travailler sur les bases de données SQL
Vous connaissez AirFlow et les principes DevOps
Vous êtes force de proposition et savez prendre le lead sur des sujets data
Vous aimez partager vos connaissances et vous avez la capacité à travailler en équipe
COMMENT POSTULER :
Si vous êtes intéressé(e), merci de faire part de votre CV à Pierre Gerbeau."
Palaiseau (91),,,Data engineer DevOps H/F,HAYS,- Palaiseau (91),"Www.hays.fr
Notre client recherche un Data engineer DevOps.

A ce poste, vos missions sont :
Accompagner les équipes et les projets pour assurer la qualité et l'innovation dans le cycle de vie de la donnée R&I avec l’utilisation de technologies Big Data principalement sur des données.
Coordonner l’ensemble des activités opérationnelles de gestion des données concernant différents projets basés sur une stack technique Big Data Cloudera.
Assurer la compliance réglementaire de Data Privacy sur l’ensemble des données de la R&I sur des projets incluant des données personnelles et en assurer le suivi.
Assurer la traduction des besoins utilisateurs en besoins fonctionnelles et techniques.
Assurer la conception et développement des flux de données (ingestion, data modeling, data warehousing, data cleaning) avec des technologies Big Data.
Assurer l'ingestion, la modélisation conceptuelle, la qualité, et la disponibilité des données.
Développer, déployer et maintenir la stratégie de méta données, y compris le déploiement d'outils, gouvernance, bonne pratiques, formations et animation du sujet.
Proposer une expertise opérationnelle et de gestion adaptée à chaque projet.
Gère au quotidien ces projets dans le respect des plannings et budgets définis en méthode agile
Assurer la continuité des interactions et le déroulement de l'activité en l'absence du Responsable Data & Information Management.
Assurer la mise en œuvre des missions suscitées dans le respect des standards de qualité, du planning et du budget.

Bsc ou Msc en Data Engineering ou équivalent
2 ans d'expérience en tant que Data Manager/Data Engineer ou équivalent
Forte expérience opérationnelle en gestion de la donnée
Expérience avec l'environnement Hadoop, Hive, Impala, Kudu, HBase. Kafka serait un plus.
Expérience avec Python est obligatoire. Spark, Scala, SQL serait est un plus.
Expérience avec un système ETL e.g. Alteryx, Talend, Informatica, Trifacta, Knime, Dataiku etc.
Expérience dans un environnement de développement Agile/Kanban

Forte expérience en gestions de projets.
Excellentes qualités interpersonnelles avec la capacité à interagir efficacement avec les personnes, en interne.
Excellentes qualités de présentation à l'écrit et à l'oral.
Esprit d'équipe au-delà de ses propres responsabilités et capacités de synthèses.
Leadership, autonomie et proactivité. #1212986"
Paris (75),,,Manager Software Engineer (m/f/d),Artefact,- Paris (75),"Who are we ?
Artefact is a new generation of a data service provider, specialising in data consulting and data-driven information system, dedicated to transforming data into business impact across the entire value chain of organisations. We are proud to say we’re enjoying skyrocketing growth.
Our broad range of data-driven solutions in data consulting and information system are designed to meet our clients’ specific needs, always conceived with a business-centric approach and delivered with tangible results. Our data-driven services are built upon the deep AI expertise we’ve acquired with our 1000+ client base around the globe.
We have 1000 employees across 20 offices who are focused on accelerating digital transformation. Thanks to a unique mix of company assets: State of the art data technologies, lean AI agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client.
To support and develop its growth, Artefact is looking for the next talents of the data divizion to join the engineering team. Organized in feature team, you will work in project mode (ou pizza team) to advise your clients on their IA problematics, machine learning and Big Data. The projects you will work on can go from the migration of infrastructure to the Cloud (Deezer) to the construction of a predictive model of the water rises (Greenpeace).
Your assignments :
Management : You work within a team where mutual aid and development of competences are key, you coach interns and juniors, you carry out technological monitoring, you take part in technical training given by our partners such as Google or Azure.
Delivery: You are full owner of the front to back solution, responsible for devising, implementing and deploying it. You work within a team made up of engineers, consultants, data scientists, strategic planners to identify your client needs and define innovative solutions.
Project: You are a key actor to company success participating in pitches and securing deals. Your technical capacities will allow you forge ties with your clients while accompanying and guiding them in their data and digital transformation. You will contribute to making Artefact an essential business partner.

Consulting: You are adept at choosing and setting up the most suitable technical stack based on your client's needs. You have a critical mindset to understand and optimize the organisational functioning of large firms.
Your mindset
Curious, you are always on the lookout for the latest solutions to best meet client needs. You’re actively involved in the entire value chain, whether it be front-end, back end, big data infrastructure, ML model…
Entrepreneurial spirit, you come up with solutions, new ideas not only within your team but also within the entire Artefact world

Benevolent, your team fulfillment is key for you, thanks to constructive feedback you guide,drive and make your collaborators grow
Advocate of knowledge sharing, you actively participate in circulating information within Artefact (seminars, trainings, certifications, online KM)


Profile:
Ideally you hold a masters in Software Engineering or possibly machine Learning, mathematics, or computer science
Minimum three years of experience developing and implementing data driven solutions within a consulting firm

You have the capacity to actively participate in all the project value chain ( building infrastructure and platforms, collecting data, machine learning application models, setting up API’s REST, tests and continuous deployment)

You have in-depth knowledge of Python, you have a strong interest for DevOps, you’re familiar with Cloud technologies such as GCP or Azure. You master data technologies like Spark or Beam, with previous experience of Docker (Kubernetes is a plus)
You’re a ninja of the use and exploitation of data bus like Kafka or PubSub
You have practiced indexation system such as ElasticSearch and Vespa. Ideally, you have implementation experience of a LETOR

You have a proven capacity to vulgarize technical terms and solutions for those coming from the business field, you are a key player in a diverse team
You can foresee projects risks and mitigate them through your technological choices

You have a working command of business English

Why us ?

Cutting edge stack : Python,Kubernetes, Spinnaker, Kafka, Spark, Google Cloud Platform (BQ, Dataflow, Compute Engine, PubSub, AppEngine…) , Airflow, Docker
Wide variety of projects :
– Datalake set up
– Chatbot building
– Industrialisation of machine learning algorithms
– Define the data strategy
Young and challenging environment of skilled engineers , grow your skills thanks to our mentoring program
Internationally renowned : offices in Dubaï, London, Hong Kong, Sao Paulo
Come join us #FR !
Talents-fr@artefact.com"
Paris (75),,,Software Engineer - Collection Technologies,FactSet Research Systems,- Paris (75),"Role/Department Description:
At FactSet, we're working to be the best financial data provider on earth. To get there, we need highly motivated, talented individuals who are empowered to find answers through creative technology.
As a Data Science Engineer in Content Engineering, you will be part of our Digital Transformation, a mission to automate our data acquisition, quality assurance, content creation and analytics in a scalable cloud environment. With the guidance of financial experts, you will leverage these large data sets to improve the quality and extend the scope of FactSet's existing and next generation products.
Responsibilities:
Ingest and analyze various data sources to drive innovation in content creation.
Automate the acquisition, relevance scoring and storage of incoming sources.
Develop processes for data mining, data concordance and data production.
Explore and evaluate new data technologies to build a scalable, cloud oriented data platform.
Optimize data retrieval, develop dashboards and other visualizations for financial experts.
Required Skills:
Python fluent
Some relevant experience in Data Science or Machine Learning or Data Science
Ideally at least one year of professional experience after graduation
Has repeatedly developed, tested and deployed high quality, stable changes with success and in a timely manner
Proven ability to adapt to changes in requirements and learn new tools and practices where needed
Proven ability to describe FactSet’s business, client base and where their work fits into the bigger picture.
Ability to contribute to code review feedback for other engineers and contribute to forward design ideas
Ability to communicate effectively with peers within the organization"
Saint-Denis (93),,,DATA ENGINEER EXPERIMENTE (H/F),ITNOVEM.,- Saint-Denis (93),"Filiale privée technologique du groupe SNCF, ITNOVEM se positionne comme accélérateur des projets Digitaux, numériques et de la transformation des Systèmes d’information du groupe. Porteuse de grands projets de la révolution digitale, notre société est en constante recherche de profils pour rejoindre la grande aventure de l’Internet des objets, de la data science, de la cybersécurité et de l’accompagnement des projets digitaux. Qu’il s’agisse de maintenance prédictive, d’aide à la décision sur la maintenance des infrastructures, de gare 4.0, d’usine du futur, ou de sécurisation des assets, nos équipes font valoir à la fois une expérience métier et une expertise technique sans cesse renouvelée, dans le respect des valeurs du groupe : Excellence, Innovation, Collectif, Agile, Engagement.

LE POSTE
Au sein de la division Data Science et Engineering, notre futur data engineer expérimenté (H/F) interviendra pour les projets de la Direction du Digital SNCF et notamment au sein la Big Data Fab. Structure transverse qui réunit infrastructures Big Data et expertise Big Data pour l'ensemble du groupe, la Fab s'est constituée en juillet 2015 afin de traiter avec les différentes entités les projets nécessitant des moyens Big Data pour être menés à bien. Elle se compose de 5 pôles : Pilotage et valorisation projet, Datascience et Developpement, Usine IT, Qualité de Service et Sécurité, Datalake.

Le pôle Data Science & Engineering d’ITNOVEM. recherche un(e) data engineer expérimenté (H/F), en soutien du pilotage et du développement de son activité. Le pôle comprend environ 20 personnes (50% data scientists, 50% data engineers), dont la moitié est expérimentée. Vous travaillerez sur des thématiques très variées liées aux problématiques industrielles, opérationnelles et stratégiques des métiers du groupe SNCF, comme par exemple :
La maintenance du matériel roulant et l’optimisation des process ;
La maintenance des voies et caténaires ;
La surveillance du réseau et des cartographies déclinées sur les problématiques prioritaires ;
L’analyse du langage naturel, notamment sur des enquêtes et rapports techniques
L’optimisation des plans horaires, la prévision de perturbations ;
L’analyse des données IoT.

MISSIONS
Travailler sur des analyses Data Science / Data Engineering en réponse aux problématiques des métiers du Groupe SNCF portées par les clients internes de la Fab Big Data (POC, prototypes et industrialisation) ;
Participer comme expert à la démarche de conseil technique et scientifique du pôle d’expertise auprès des métiers du groupe SNCF ;
Améliorer la qualité de nos projets par la mise en place d’outils et de bonnes pratiques liés à la qualité de code (craft, CI/CD, documentation) ;
Favoriser l’adoption de ces outils et bonnes pratiques par un accompagnement de l’équipe :
Revues de code,
Workshops,
Création de librairires ;
Industrialiser les projets ou les services data en développant une chaîne de traitement de données robuste et automatisée ;
Spécifications techniques :
Release plan des différents livrables,
Ingestion et mise en qualité des données selon les bonnes pratiques de la Fab,
Traitement, agrégation et sauvegarde des données avec spark-scala, spark-python ou python,
Intégration continue (versionning, packaging, tests et déploiement) avec Git-SBT-Nexus-Jenkins,
Exposition des APIs sous forme de webservices Rest,
Configuration des briques logicielles ,
Monitoring des briques logicielles avec OMS (Azure) ou Nagios,
Etroite collaboration avec le chef de projet, PO, OPS et architectes,
Participation aux activités d'architecture, conception et développement,
Recette et mise en production ;
Contribuer proactivement à la veille scientifique et technique, aux projets R&D, et à la construction d’assets et de services techniques orientés data ;
Participer à l’animation de la filière Data et à l’implémentation des pratiques Data au sein des métiers (formations, conseil et expertise) ;
Participer aux autres activités du pôle Data Science & Engineering (reporting d’activité, communication interne et externe, collaboration avec les universités et laboratoires associés).

LE PROFIL RECHERCHÉ

COMPETENCES TECHNIQUES
Maîtrise experte
Principes architecturaux et algorithmes de traitement de données (ETL, streaming, SQL, graphes…)
Construction d’un projet Data de bout-en-bout et son passage en exploitation

Maîtrise théorique et utilisation appliquée
Langages Scala et Python
Framework Spark
Intégration continue : sbt/maven, Gitflow, jenkins, nexus
Une ou plusieurs bases de données NoSql (Cassandra, mongoDB)
Composants Azure (HDInsight, Azure Databricks, Azure Function, ACI, AKS, OMS, etc.) ou de leur équivalent cloud concurrent
APIs REST, y compris leurs mécanismes de sécurisation
Cycle de vie des données

Connaissances théoriques
Technologies Big Data : Hadoop (Hortonworks, HDF), sécurité et ressources (Yarn, Ranger), monitoring (Ambari, Datadog)
Elasticsearch et Kibana
Architecture microservice
Gouvernance des données, notamment personnelles (Traçabilité, Sécurité Authentification et Autorisation, Audit)

QUALITES PERSONNELLES ET COMPETENCES FONCTIONNELLES
Capacité et volontarisme dans l’accompagnement client sur le lien technico-fonctionnel
Transversalité et capacité à travailler avec des équipes pluridisciplinaires
Orienté client, qualité et résultat (jusqu’à l’industrialisation des projets)
Rigueur, autonomie et organisation
Posture d’excellence technique et organisationelle dans les projets, pour l’équipe
Implication dans les communautés data (meetups, blog, medium, etc.)
Qualité et sérieux dans le développement de code
Bonne communication scientifique et bon sens de la pédagogie

EXPÉRIENCES ET FORMATIONS
Formation
Bac +5 (école d’ingénieur ou/ master spécialisé en software / data engineering)
Ou titulaire d’un doctorat en informatique / data engineering
Expérience requise
Vous justifiez d’une expérience significative (minimum 5 ans) dans des équipes de développement orienté Data. Vous avez occupé au minimum un poste d’expert technique, idéalement sur des cas d’usage industriels. Vous avez déjà idéalement occupé un poste de responsable d’équipe, lead ou Scrum Master.

Poste basé à La Plaine Saint Denis (RER D, Saint Denis Stade de France) avec des déplacements ponctuels (en moyenne 2-3 fois par mois) à prévoir, généralement en Ile-de-France."
Paris 9e (75),CDI,,Software Engineer - Infrastructure,Criteo,- Paris 9e (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

Most of all, we are creators. From designing ground-breaking products to finding unique ways to tackle technical challenges at an extraordinary scale, our tech teams work with state of the art methodologies to shape the future of advertising.
Our Infrastructure teams are designing and operating the overall capacity and connectivity supporting the Criteo platform. They are in charge of designing, planning, scaling and operating hardware, system, network and datacenter layers.

What you will do

As a software engineer in the Data center team you will be responsible of building and maintaining the software to manage our DCIM (Data Center Infrastructure Management) assets which is the Criteo Internal Cloud. It is infrastructure as a code in a hyper large-scale way.
We are constantly opening new DC, adding or replacing devices such switches, routers... and the Data Center, along the devops team need to make these actions quicker, fully automate in a continuous integration way.

Who you are :

Experience writing production backend code in Python (Django is a plus).
Experience in writing scalable and maintainable software.
Demonstrated understanding of front-end technologies, including modern Javascript, HTML and CSS.
Having worked with Git, APIs, MySQL, MariaDB, Jira is a plus

#LI-VL1

Benefits:
Competitive compensation package
35+ annual holidays days
Health insurance
Discounted transport
Personalized relocation package if moving from abroad
Catered lunch and breakfast
Private nursery
Maternity and paternity leave
Annual cross teams hackathon
2 conferences per year of your choice
Internal mobility programs
Tailored educational resources

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Courbevoie (92),,,"Principal AWS Solutions Architect, Startups (France)",AWS EMEA SARL (France Branch),- Courbevoie (92),"Background in any of the following: Cloud Architecture, Systems Design, Software Development, Infrastructure Architecture, Data Engineering or DevOps
Experience driving technical and/or organizational change of significant complexity
Technical Degree (Computer Science, Maths, Engineering or equivalent) and/or relevant tech experience.
Fluent written and verbal communication skills in English and French
Passion for technology and for learning

Startup Solutions Architects work hand in hand with AWS customers to help them make the most of the Cloud. They are at the crossroads of business and technology and engage with startups at all stages of their lifecycle.
Solutions Architects are responsible for the overall technical relationship between customers and AWS and make recommendations on security, cost, performance, reliability and operational efficiency. They work to understand the customer's needs and give prescriptive guidance on how to create business value with AWS technology. Solutions Architects lead activities such as architecture reviews, white-boarding sessions, demos and technical workshops. They collaborate with other teams such as account management, professional services, support, product teams and the AWS partner ecosystem.
Principal Solutions Architects work on the most complex customer challenges and opportunities. They have a leading role in developing both the strategy and the team itself. They combine an informed view of the Startup market with their understanding of emerging technology trends to speed-up innovation across their customer segment. Externally, they are recognized thought leaders and influence the strategy of our customers. Internally, they earn a reputation of role models and deliver bar-raising guidance to the broader Solutions Architecture team.
In this role you will get to practice your creativity, linking technology to tangible solutions and educating AWS customers about the art of the possible. You will have the opportunity to define or invent cloud-native reference architectures for a variety of use cases (e.g. Artificial Intelligence, Machine Learning, Serverless and Container based architectures, Analytics and Big Data, DevOps or Security).
The Solutions Architecture team is a diverse group of technologists from a variety of backgrounds. Practical knowledge of the AWS platform is desired but not required, provided you have a sound technical foundation and a desire to learn. You will have the support to grow your expertise in industry and technology areas of depth. Every day you will learn something new from your customers, your peers and your own experiments.
At Amazon you will be encouraged and rewarded for doing what is right for the long-term success of the customer. We value your passion to discover, invent and build on behalf of customers.
Amazon has always been, and always will be, committed to diversity and inclusion. We seek builders from all backgrounds to join our teams, and we encourage our employees to bring their authentic, original, and best selves to work.
Roles and Responsibilities
Collaborate within the startup ecosystem (accelerators, incubators, VCs and meetups) to educate startups and support their growth
Work directly with high growth startups to accelerate their projects and recommend best-practice architectures in line with their long-term business priorities
Build technical relationships with technical co-founders and operate as their trusted advisor. The best interests of the customer will shape the guidance you provide.
Share the voice of the customer to inform the roadmap of AWS features. Proactively work within the organization to influence the evolution of the platform to better serve Startups of all sizes.
Take a leading role in the creation and sharing of best practices, technical content and new reference architectures for startups (e.g. white papers, code samples, blog posts).
Evangelize and educate about AWS technology and industry trends (e.g. through workshops, user groups, meetups, public speaking, online videos or conferences).
Contribute to the growth of the Solutions Architecture organization by interviewing candidates and having a voice in hiring decisions. You will also be helping others develop new skills by identifying talent needs in the organization.
Develop areas of depth in technical domains relevant to your interests and your customer's outcomes.

The following qualifications are desired but not required:
Experience designing, building, refactoring or operating large scale apps in the cloud
Knowledge of a modern programming language (Python, JavaScript, Go, .Net, Java, etc.) and/or scripting, Infrastructure as Code etc.
In-depth working knowledge in a technology domain such as distributed internet-scale web or mobile applications, DevOps, Serverless, Big Data, Analytics, Machine Learning, high-performance databases (SQL and/or NoSQL)
Experience having co-founded or worked for a VC-backed Startup
Experience working in a customer-facing role and/or public speaking
AWS certification (e.g. AWS Solutions Architect Associate or Professional) or other industry certification

“Protecting your privacy and the security of your data is a longstanding top priority for Amazon. Please consult our Privacy Notice (https://www.amazon.jobs/en/privacy/eu ) to know more about how we collect, use and transfer the personal data of our candidates.”"
Courbevoie (92),,,Principal Solutions Architect,AWS EMEA SARL (France Branch),- Courbevoie (92),"Background in any of the following: Cloud Architecture, Systems Design, Software Development, Infrastructure Architecture, Data Engineering or DevOps
Experience driving technical and/or organizational change of significant complexity
Technical Degree (Computer Science, Maths, Engineering or equivalent) and/or relevant tech experience.
Fluent written and verbal communication skills in English and French
Passion for technology and for learning

This role is within the France organization.
Solutions Architects work hand in hand with AWS customers to help them make the most of the Cloud. They are at the crossroads of business and technology and engage with organizations at all stages of cloud adoption. Solutions Architects are responsible for creating and presenting technical content and sharing best practices.

Solutions Architects are responsible for the overall technical relationship between customers and AWS and make recommendations on security, cost, performance, reliability and operational efficiency. They work to understand the customer's needs and give prescriptive guidance on how to create business value with AWS technology. Solutions Architects lead activities such as architecture reviews, white-boarding sessions, demos and technical workshops. They collaborate with other teams such as account management, professional services, support, product teams and the AWS partner ecosystem.

Principal Solutions Architects work on the most complex customer challenges and opportunities. They have a leading role in developing both the strategy and the team itself. They combine an informed view of the market with their understanding of emerging technology trends to speed-up innovation across their customer segment. Externally, they are recognized thought leaders and influence the strategy of our customers. Internally, they earn a reputation of role models and deliver bar-raising guidance to the broader Solutions Architecture team.

In this role you will get to practice your creativity, linking technology to tangible solutions and educating AWS customers about the art of the possible. You will have the opportunity to define or invent cloud-native reference architectures for a variety of use cases (e.g. Artificial Intelligence, Machine Learning, Serverless and Container based architectures, Analytics and Big Data, DevOps or Security).

The Solutions Architecture team is a diverse group of technologists from a variety of backgrounds. Practical knowledge of the AWS platform is desired but not required, provided you have a sound technical foundation and a desire to learn.

You will have the support to grow your expertise in industry and technology areas of depth. Every day you will learn something new from your customers, your peers and your own experiments.

At Amazon you will be encouraged and rewarded for doing what is right for the long-term success of the customer. We value your passion to discover, invent and build on behalf of customers.

Roles and Responsibilities
Work directly with strategic customers to accelerate their mission-critical projects and recommend best-practice architectures in line with their long-term business outcomes.
Build technical relationships with customers up to the C-suite and operate as their trusted advisor. The best interests of the customer will shape the guidance you provide.
Share the voice of the customer to inform the roadmap of AWS features. Proactively work within the organization to influence the evolution of the platform.
{Take a leading role in the creation and sharing of best practices, technical content and new reference architectures (e.g. white papers, code samples, blog posts).
Evangelize and educate about AWS technology and industry trends (e.g. through workshops, user groups, meetups, public speaking, online videos or conferences).
Help develop the technical elements of the AWS go-to-market strategy, and the plan to engage with customers and partners, within your area of responsibility.
Contribute to the growth of the Solutions Architecture organization by interviewing candidates and having a voice in hiring decisions. You will also be helping others develop new skills by mentoring team members and identifying talent needs in the organization.
Develop areas of depth in technical domains relevant to your interests and your customer's outcomes.
Amazon has always been, and always will be, committed to diversity and inclusion. We seek builders from all backgrounds to join our teams, and we encourage our employees to bring their authentic, original, and best selves to work.

Technical degree; Computer Science, Engineering or Math background highly desired, or equivalent work experience
History of successful technical sales consulting and architecture engagements with large-scale customers or enterprises
Experience architecting, migrating or transforming customer solutions to the cloud
Familiarity with common enterprise services (Directory Services, Information Assurance, Virtual Desktop, etc.), products (i.e., Oracle, SAP) and frameworks (ITIL, Zachman, TOGAF, etc.)
Professional experience architecting/operating solutions built on AWS or another cloud platform"
Paris (75),,,Infrastructure Software Engineer,Liftoff,- Paris (75),"At Liftoff, we're solving one of the core problems faced by every mobile app: growth. To do so, we build Machine Learning and Big Data-driven technology that can accurately predict which apps a user will like, and connect them in a compelling way. Our systems operate at a scale unseen outside of the largest Internet companies – processing over a million requests per second and interacting with over a billion users. Our technology is innovative and we have strong product-market fit; as a result, we've already reached profitability and are seeing tremendous growth.

Across our engineering teams, we offer a wide range of opportunities for different skill levels and experiences.

As an Infrastructure Software Engineer at Liftoff, you will:
Design and build the next generation of Liftoff's Machine Learning (ML) infrastructure, working alongside our ML engineers.
Have end-to-end ownership of Liftoff's ML infrastructure, including distributed data stores and data processing pipelines.
Grapple with running state-of-the-art ML software and libraries at scale.
Be part of an ""engineering excellence"" culture through state-of-the-art tools, risk-driven testing, explainable systems, and code review.
Become an expert in Clojure, Go, and the many other cutting-edge open source technologies that maximize our development velocity.
Join a nimble, consistently excellent, and experienced engineering team.

Desired qualities and experiences:
Very strong coding ability.
Solid core CS fundamentals (data structures, algorithms, architecting systems).
An incredible desire for quality and perfection, and the ability to temper it when necessary to ship.
Sets ego aside in pursuit of finding the best solution, no matter where it comes from.
Self-motivated and a great ability to hustle.

Excited to work on all parts of the stack (UI, backend, operations, data analysis) .
B.S. or higher in Computer Science (or equivalent work experience).
4+ years software engineering experience.
Machine Learning experience a plus.
Experience building large distributed systems a plus.
A healthy sense of fun!

Working at Liftoff is fast-paced, fun, and challenging, and we thrive on innovation. Come join our team and help shape the future of the mobile app ecosystem. If this role sounds interesting to you, we would love to hear from you.

Liftoff is committed to inclusion and diversity and is an equal opportunity employer. All applicants will receive consideration regardless of race, age, religion, gender identity, sexual orientation, national origin, disability, or veteran status."
Paris (75),,,Senior Data & API Architect (F/M),AXA,- Paris (75),"Based on proven enterprise architecture practices, the purpose is to support AXA entities in the definition and implementation of data capabilities aligned with their business and data strategies (*), leveraging the scale of AXA. In current AXA Architecture vision, the specific functional domains to focus on – so called “data platforms”, are BI & Analytics, Master & Reference Data, Meta Data, Data Quality, Data Modelling/Data Exchanges through APIs (and other means).

(*) each entity data strategy is expected to state a local vision and a multi-year plan, covering use cases as well as the following underpinning capabilities: delivering value from data, managing risks pertaining to data, designing and running a data operating model, increasing data culture and skills, managing data as an asset, building and running IT foundations for data (BI & Analytics, Master & Reference Data, Meta Data, Data Quality, Data Exchanges).

The main activities for the job are to:
Define/leverage Reference Architecture documents on above functional domains;
Co-lead incubation projects with entities and/or at GO/rev;
Define/scale progressively a common Data Modelling & API Design practice and content across AXA, starting with customer and health data

Technical and professional skills:
Enterprise Architect, TOGAF certified (from the Open Group)
Familiar with the Data Management Body of Knowledge (DMBOK, from DAMA)
Familiar with ACORD standard
At least a global 10 years’ experience in the design and implementation of:
Master & Reference Data Management
Metadata Management
Data Quality Management
Data Analytics and BI
Data Modelling
API Design
Data Exchanges
Experience in the activation of Cloud services
English - Fluent in speaking and writing

Soft skills and competencies:

Able to interact with a vast variety of stakeholders: business, compliance, developers, data managers, project managers
Strong problem-solving skills
Result oriented
Self-motivated, proactive and able to work in a complex organization
Leadership, influence and conflict resolution
Team player in a multi-cultural work environment, able to see the big picture as well as deep dive into details when necessary."
Paris 9e (75),Stage,,Software Engineer Internship – Infrastructure (6month),Criteo,- Paris 9e (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

What is it like to work in our R&D
Most of all, we are creators. From designing ground-breaking products to finding unique ways to tackle technical challenges at an extraordinary scale, our tech teams work with state of the art methodologies to shape the future of advertising.
Our Infrastructure teams are designing and operating the overall capacity and connectivity supporting the Criteo platform. They are in charge of designing, planning, scaling and operating hardware, system, network and datacenter layers.
What You’ll Do
The topic we are proposing concentrates on refactoring provisioning tools: each year we deploy hundreds of network devices on top of the 5K+ existing already. The key is focusing on automation, monitoring and provisioning. Technical stack: Python and basic system skills (Linux).
In a team of 5-7, you will be working closely with your mentor to drive your project, design and ensure best practices are applied.
You will participate in all knowledge sharing sessions/ workshops.
You will gain a better understanding of a unique infrastructure in Europe (50K+ servers) and work on real and impactful projects that are used by leading retailers and brands.
You are encouraged to actively voice your ideas whilst learning how to build and ship quality code into production which will likely affect millions of users instantly.
You will work with and learn from talented engineers, with a diverse set of backgrounds.

Who You Are
You are in your final year of study in System/Software Engineering or related field.
You have experience in developing web-based applications and basic Linux knowledge. You occasionally participate in coding competitions.
You are experienced in Object Oriented Programming.
You have a strong sense of ownership and a dislike for passing the buck.
You are a problem solver, a fixer, and a creative technologist. We believe coding is a talent and a passion, not just a skill.
You are a strong communicator and a team player who can work efficiently with others.
You are fluent in English.

Want to Know More?
What does it feel like to be part of something big? Get a snapshot
Get the story directly from our R&D engineers, check our Medium R&D blog
Interested in discovering your Criteo community first? Let’s meet
Check out our NEW career website. Take a look

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Paris 8e (75),55 000 € - 65 000 € par an,,Ingénieur DevOps / Data,Sept Lieues,- Paris 8e (75),"Startup intervenant dans le domaine de la proptech.
Crée en 2019, elle développe une plateforme d'aide à la collecte de données par différents capteurs et propose différents services permettant d'avoir une gestion stratégique des fonds immobiliers .
Exemples :
Augmentation de revenu
Réduction des couts opérationnels
Réduction de l'impact environnemental des bâtiments

Ouvert au remote (1/2 jour semaine)
Participation conférences locales
10 RTT
LE POSTE / LES MISSIONS
Aujourd'hui, c'est l'équipe Engineering (3 personnes) qui s'occupe de la partie DevOps.
Ils recherchent un DevOps afin d'harmoniser et être garant des bonnes pratiques.
Déploiement multicloud car exigences clients sur differents Cloud
Automatisation des infra dans le cloud

Vous travaillerez en collaboration avec les équipes Data & développement.
PROFIL RECHERCHÉ
Vous avez une première expérience sur un rôle similaire.

Détails sur l'environnement technique :
OS Linux
Plateforme interne sur AWS + GCP
Script Python
Terraform / Cloud Formation
Déploiement via Kubernetes (utilisation simple)

Le plus ?
Connaissances sur les bases de la configuration réseau (clients très à cheval sur les aspects Sécurité des données)"
Boulogne-Billancourt (92),Stage,,Stagiaire Ingénieur Data H/F,Hewlett Packard Enterprise,- Boulogne-Billancourt (92),"Chez Hewlett Packard Enterprise (HPE), nous vivons selon trois valeurs fondamentales qui guident notre activité: Collaborer, Innover, Agir.
Ces valeurs se combinent pour nous aider à créer un métier valorisant pour faire avancer la façon dont les gens vivent et travaillent.
Notre organisation de services informatiques innovants s’appelle HPE PointNext. Nous avons l'expertise pour conseiller, intégrer et accélérer le business de nos clients issu de leur transformation digitale.
Ce que nous ferons ensemble
Dans une journée typique en tant que stagiaire ingénieur Transformation Digitale :
Vous avez des formations techniques
Vous êtes coaché et encadré par un membre de l'équipe de consultants sur vos propres premiers projets
Vous travaillez sur vos propres projets
Vous êtes, selon le besoin, en phase d’avant–vente, contribuant à des Réponses à Appel d’Offre ou sur des phases de réalisation, en immersion chez le client avec l’équipe projet.
Les principales missions concernent:
La mise en œuvre d'infrastructures : création ou consolidation de datacenters, virtualisation d'environnement, migration vers des infrastructures cloud et hybrides
La mise en œuvre et le maintien en condition opérationnelle de solution Big Data basée sur Hadoop, de solutions d’analyse de données et d’intelligence artificielle (Data labs)
Les outils du datacenter : supervision, sécurité, automatisation, performance, ...
La mise en place et l’évolution de réseaux voix ou données
L’IOT et l’intelligent edge
Si …
Vous êtes doué pour le travail d’équipe, êtes friand d’innovation et aimez faire bouger les choses - vous êtes en harmonie avec nos valeurs fondamentales
Vous êtes en dernière année d’école d’ingénieur ou équivalent universitaire
Vous avez des notions en langage de programmation Python, bash, PowerShell, Ruby
Vous êtes informés des méthodes de développement Agile, devops
Vous vous intéressez aux applications du big data et de l’intelligence artificielle; les sujets proposés porteront sur l’un des domaines suivants:
IA/analyse prescriptive
Classification d’image (application du Deep Learning)
Orchestration de cas d’usages IA (construction et déploiement de cas d’usage IA)
Gestion de modèles IA (maintenance/évolution des modèles)
Data Engineering (ingestion des données, intégration système, déploiement sur le terrain)
Vous avez des connaissances sur l’un des domaines IT suivants
Compréhension des infrastructuresserveurs et réseau
Administration système Linux (Redhat)
Hadoop (Hortonwork, Cloudera et/ou MAPR)
Bases de données (PostgreSQL, MySQL)
Outils d’automatisation et orchestration (Ansible, Chef, ou Puppet)
Outils de gestions de conteneurs d'applications (Docker, Kubernetes…)
Framework de développement d’applications Machine Learning et Deep Learning (Tensorflow …)
Algèbre linéaire, Python, (Spark, Scala seraient un plus)
... alors, postulez maintenant!
Qui vous êtes
Etudiant en école d’ingénieurs vous possédez une première expérience dans le domaine et souhaitez évoluer au sein du d’une grande entreprise IT. Vous maitrisez les outils Microsoft Office (Excel, Word, PowerPoint…). Vos qualités d'organisation, de rigueur et d'adaptation à un environnement complexe et en perpétuelle évolution, votre sens d’initiative, communication aisée, facilité d’intégration et sens d’organisation, ainsi que votre dynamisme, aisance relationnelle et aptitude à l'autonomie sont autant de gage de réussite. Vous disposez d’une bonne culture et d’un intérêt certain pour l’IT et des enjeux liés à la digitalisation de notre économie.
Nous offrons :
un salaire compétitif et de nombreux avantages sociaux
Un environnement de travail diversifié et dynamique
Un équilibre travail-vie personnelle et un soutien à votre développement de carrière
Vous voulez en savoir plus sur HPE? Alors restons connectés!
https://www.facebook.com/HPECareers
https://twitter.com/HPE_Careers
2 langues de travail: français et anglais
Durée: 6 mois
Localisation: Boulogne Billancourt et Puteaux
1043767"
Cachan (94),,,3D Software Engineer - Scene Layers,ESRI,- Cachan (94),"Overview
If you have stayed abreast of the great strides 3D computer graphics and web-based 3D have made in the last decade, there may be a role for you in our 3D software development group. Our ideal candidate will be up to speed in the areas of mesh and massive models processing, level of detail generation, texture compression, mesh simplification and compression techniques, real-time rendering, and the application of spatial data structures to create optimized 3D content.
We are actively looking for more colleagues to join us in creating the world’s best geospatial mapping and data analysis platform. As a platform that serves millions of users and domains, our software needs to be modular, reusable, and well crafted. We iterate rapidly, constantly learning from feedback, metrics, and the mission and goals of our broad user community.
Strong math skills and the ability to design and implement data structures leveraging non-trivial algorithms are among the traits we are looking for.
Responsibilities
Build C++ software components that follow industry-standard design patterns, development methodologies, and deployment models
Work closely with product engineers to implement requirements and create application architectures and API to meet product goals
Design and develop stable software that includes automated test validation
Develop reusable components and libraries for use internally and as open source
Work within agile processes for short cycle, fast-paced delivery
Take on complex goals that push the boundary of the possible
Solve and articulate complex problems through application design, development, and exemplary user experiences
Requirements
Experience with 3D graphics APIs such as WebGL, OpenGL ES, OpenGL, or DirectX
Strong knowledge of C++ (STL, C++ 11, Boost)
Understanding of algorithms, data structures, and design patterns
Knowledge of Agile development methodologies and test-driven development processes
Experience developing software that runs in a cloud
Experience with application scripting languages (e.g., Python, JavaScript) and web protocols and formats such as REST and JSON
Bachelor’s or master’s in computer science, engineering, mathematics, GIS, or related field, depending on position level (master’s preferred)
Recommended Qualifications
Experience with data visualization, mapping, and GIS
Experience in mesh processing and simplification, texture optimization
Familiarity with Esri ArcGIS or other web mapping technologies

About Esri
Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.

Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.

Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.

If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address."
Paris (75),,,Software Engineer (Palantir Foundry),EPAM Systems,- Paris (75),"Are you passionate about technology and its application in industry? Are you customer-focused and enjoy delivering innovative digital solutions to clients? Do you have an eye for detail, while being able to keep sight of the bigger picture?

Then you have an opportunity to work with the best-in-class engineering and design teams as a Palantir Foundry Software Engineer to deliver high profile solutions for our Global client portfolio.

You are curious, persistent, logical and enjoy crafting and developing elegant solutions for complex problems. If this sounds like you, keep reading to learn more about this exciting role!

Come and join EPAM where Engineering is in our DNA.
JOB OVERVIEW

EPAM recruits exceptionally talented people who have a passion for and take pride in their work, they are perfectionists in what they do. We pride ourselves on being an organisation that supports your technical growth, unleashing your real potential, whilst still nurturing the core values of what it means to be an EPAMer.

Due to growth with a longstanding and highly prestigious client, EPAM are looking to build a Palantir Foundry ‘Centre of Excellence’ which will be responsible for supporting this client in Global project delivery in additional to supporting growth and development across a mix of sectors.

The CoE team of Engineers can be based in multiple EPAM locations across Europe and can expect on site customer visits including primarily US and Switzerland.

This is an exciting opportunity to join a highly visible and key customer project whilst also being at the forefront of investment into growing the EPAM Palantir Foundry capability.

As there are multiple positions available, we are open to considering Software Engineers with a range of experience but previous practical experience in Palantir Foundry is a MUST.
Responsibilities
Strong engineering background in fields such as Computer Science, Mathematics, Software Engineering, and Physics
Familiarity with data structures, storage systems, cloud infrastructure, front-end frameworks, and other technical tools
Strong coder with demonstrated proficiency in programming languages, such as Java, C++, Python, JavaScript, or similar languages
Ability to collaborate and empathize with a variety of individuals. You can iterate with users and non-technical stakeholders and understand how your technical decisions impact them
Demonstrated ability to learn and work independently and make decisions with minimal supervision
A desire to work on software that can change the world and a passion for creating intuitive, scalable products that augment our users' ability to work with data
Requirements
Strong experience in working with Palantir Foundry (ideal candidates have 3+ years of experience, though as we are building a capability, we are open to considering those with less practical experience
Nice to have
A variety of languages, including Java and Go for back end and Typescript for front end
Open-source technologies like Cassandra, Spark, ElasticSearch, React, and Redux
Industry-standard build tooling, including Gradle, Webpack, and Github
We offer
Competitive compensation depending on experience and skills
Opportunity to work on leading edge platforms, working in a fast-paced, agile, software engineering culture
Knowledge-sharing with colleagues from EPAM's global tech communities
Regular performance feedback and salary reviews
Opportunities for professional growth
Unlimited access to LinkedIn learning solutions"
Paris (75),,,Software Developer II,ANSYS,- Paris (75),"Ansys is the global leader in engineering simulation, helping the world's most innovative companies deliver radically better products to their customers. By offering the best and broadest portfolio of engineering simulation software, Ansys helps companies solve the most complex design challenges and engineer products limited only by imagination.

SUMMARY

The ANSYS Licensing team islooking for a skilled and highly motivatedSoftware Developer to contribute to the development of ANSYS'srapidly evolvinglicensing technology.Youwill design and develop frameworks thatsupport new business models and simplify customer interaction with licensing.You will design and developdata management/analysisprogramsand processes to curate and analyze largedatasets, andpresent the data in various formats depending on the audience.

RESPONSIBILITIES

Design, implement, and maintain high-performance and scalable technology that can interface with both desktop and web/cloud-based technologies.

Deliver code that meets requirements on schedule. Ensure that code is scalable, maintainable, extensible, robust,and easy to understand.

Understand customer (internal & external) requirements andworkflows andtranslate them into functional and design specifications.

Create unitand system-level tests tothoroughlyvalidate new features or changes.

Diagnose internal and external runtime issues, provide appropriate workarounds, and implement corrections.


MINIMUM QUALIFICATIONS

Bachelor's Degree or equivalent in computer science, software engineering, or related fieldwith five years of experience.

A minimum of 2 years of experience in developing web applications usingJavaScript/NodeJS frameworks such as Angularor Flutter.

Experiencewith data visualization tools and statistical programming.

Experience developing web services using object-oriented languages such as Java, Python,andC#.

Good understanding of web architecture, distributed systems,and web APIs such as RESTandWeb Sockets.


PREFERRED QUALIFICATIONS

Master's degree in Computer Science, Engineering orrelated field withtwoyears of experience.

Experience with Docker and Kubernetes.

Experience with charting and data visualization tools such asPower BI,D3.js,andGrafana.

Experience with automated testing tools such as Mocha, Jasmine, Karma,andSelenium.

Previous experience with Azure deployment scripting and execution.

CULTURE AND VALUES

Culture and values are incredibly important to Ansys. They inform us of who we are, of how we act. Values aren't posters hanging on a wall or about trite or glib slogans. They aren't about rules and regulations. They can't just be handed down the organization. They are shared beliefs - guideposts that we all follow when we're facing a challenge or a decision. Our values tell us how we live our lives; how we approach our jobs. Our values are crucial for fostering a culture of winning for our company:
Customer focus
Results and Accountability
Innovation
Transparency and Integrity
Mastery
Inclusiveness
Sense of urgency
Collaboration and Teamwork

WORKING AT ANSYS
At Ansys, you will find yourself among the sharpest minds and most visionary of leaders, collectively aiming to change the world with innovative technology and remarkable solutions. With the prestigious reputation in servicing well-known, world-class companies, standards at Ansys are high, met by those willing to rise to the occasion and meet those challenges head-on. Because at Ansys, it's about the learning, the discovery and the collaboration. It's about the ""what's next"" as much as the ""mission accomplished"". It's about the melding of disciplined intellect with strategic direction and results that have, can and will impact real people in real ways, forged within a working environment built on respect, autonomy and ethics.

At Ansys, you will find yourself among those eager to drive the world towards the next best thing with hands planted firmly on the wheel.

Our team is passionate about pushing the limits of world-class simulation technology so our customers can turn their design concepts into successful, innovative products faster and at lower cost. As a measure of our success in attaining these goals, Ansys has been recognized as one of the world's most innovative companies by prestigious publications such as Bloomberg Businessweek and FORTUNE magazines.

Ansys is an S&P 500 company and a component of the NASDAQ-100.

For more information, please visit us at www.ansys.com

Ansys is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran status, and other protected characteristics.

Ansys does not accept unsolicited referrals for vacancies, and any unsolicited referral will become the property of Ansys. Upon hire, no fee will be owed to the agency, person, or entity."
Cachan (94),,,3D Software Engineer - Scene Layers,"ESRI, Inc.",- Cachan (94),"Overview:
If you have stayed abreast of the great strides 3D computer graphics and web-based 3D have made in the last decade, there may be a role for you in our 3D software development group. Our ideal candidate will be up to speed in the areas of mesh and massive models processing, level of detail generation, texture compression, mesh simplification and compression techniques, real-time rendering, and the application of spatial data structures to create optimized 3D content.
We are actively looking for more colleagues to join us in creating the world’s best geospatial mapping and data analysis platform. As a platform that serves millions of users and domains, our software needs to be modular, reusable, and well crafted. We iterate rapidly, constantly learning from feedback, metrics, and the mission and goals of our broad user community.
Strong math skills and the ability to design and implement data structures leveraging non-trivial algorithms are among the traits we are looking for.
Requirements:
Experience with 3D graphics APIs such as WebGL, OpenGL ES, OpenGL, or DirectX
Strong knowledge of C++ (STL, C++ 11, Boost)
Understanding of algorithms, data structures, and design patterns
Knowledge of Agile development methodologies and test-driven development processes
Experience developing software that runs in a cloud
Experience with application scripting languages (e.g., Python, JavaScript) and web protocols and formats such as REST and JSON
Bachelor’s or master’s in computer science, engineering, mathematics, GIS, or related field, depending on position level (master’s preferred)
The Company:
Our passion for improving quality of life through geography is at the heart of everything we do. Esri’s geographic information system (GIS) technology inspires and enables governments, universities, and businesses worldwide to save money, lives, and our environment through a deeper understanding of the changing world around them.

Carefully managed growth and zero debt give Esri stability that is uncommon in today's volatile business world. Privately held, we offer exceptional benefits, competitive salaries, 401(k) and profit-sharing programs, opportunities for personal and professional growth, and much more.

Esri is an equal opportunity employer (EOE) and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status, or any other characteristic protected by law.

If you need a reasonable accommodation for any part of the employment process, please email humanresources@esri.com and let us know the nature of your request and your contact information. Please note that only those inquiries concerning a request for reasonable accommodation will be responded to from this e-mail address."
Paris (75),,,Database Developer,IQVIA,- Paris (75),"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.
Main responsibilities:
Within the OneKey governance team, under the guidance of the Database Reference Manager, this key role will be primarily focused on cleaning and distribution of OneKey reference data.
Responsibilities include but are not limited to:
Quality
Management and implementation of OneKey data corrections (OKDATCOR) in relation with the development and the support teams
Participate to pro-active data cleaning
Coordinate cleaning with the production teams and the countries
Contribute to the Standard Operating Procedure and the documentation
Reporting
Elaborate statistics to support the business
Create and maintain standard reports for governance
Support
Third line support of internal customers
Requests' evolution management
Trainings
Products
Management of the OneKey data dictionary (OneKeypedia)
Management of an API of Master Data Management
This role liaises principally with the teams OneKey development, production, countries and internal customers.
Our ideal candidate will have:
Master’s degree in computer science or related field with least 3 years of professional experience
Very good knowledge in database design and programming (Oracle)
Other useful skills would be: container-orchestration system (Kubernetes), Data Virtualization (TEEID), Web developments (Python)
Excellent communication skills (written and oral) including technical aspects of a project, ability to develop usable documentation, results interpretation and business recommendations
Languages: French and English at an advanced level (spoken and written)
Strong analytic mindset and logical thinking capability, strong Quality Control mindset
Demonstrates consulting, creativity, critical thinking, project planning, and attention to detail capabilities
Knowledge of pharmaceutical market and experience with pharmaceutical data (medical, hospital, pharmacy, claims data) would be a plus, but not a must
Join Us
Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.
Forge a career with greater purpose, make an impact, and never stop learning.

Job ID: R1036129"
Paris (75),CDI,,"DATA ARCHITECT - Teachnical Lead (3D : DIGITAL, DATA, DISSEMINATION) H/F",CACEIS,- Paris (75),"Type de métier
Types de métiers Crédit Agricole S.A. - Systèmes d'information / Maîtrise d'Ouvrage
Type de contrat
CDI
Poste avec management
Non
Cadre / Non Cadre
Cadre
Missions
La filière métier Systèmes d'information de CACEIS (300 personnes) assure le choix des solutions applicatives et l'optimisation constante des systèmes d'information pour l'ensemble des sociétés du Groupe CACEIS. Elle propose des solutions répondant aux besoins de ses clients-utilisateurs.

Au sein de la Direction des Etudes dans la ligne IT 3D pour Digital, Data et Dissémination : le métier a pour ambition de couvrir l’ensemble du cycle de vie de la donnée, de son acquisition et sa redistribution, en passant par sa manipulation via différentes technologies scalables

La ligne métier 3D recouvre les pôles suivants :
Le pôle Digital and Data Client Services : à la fois pour accompagner les clients, et faire remonter de manière plus directe leurs besoins en termes de solutions digitales auprès des deux autres pôles,
Le pôle Data Projects : qui regroupe notamment les équipes Big Data et Data Analytics de CACEIS.
Le pôle Digital Transformation : qui a le challenge de mettre en oeuvre le programme de transformation digitale de CACEIS : IA, MailBot

En tant que Data Architect au sein de la ligne IT-3D, vous :
Définissez la roadmap technique de la plateforme Big Data en place
Veillez à l’application des règles de développement et à la bonne utilisation des outils
Contribuez à l’élaboration du Technical Design, validez le Technical Design fourni par les équipes de développement, que les équipes soient internes ou externes
Assurez la cohérence et l’homogénéité de l’architecture technique de l’ensemble des applications sur son périmètre d’intervention
Etes le point d’entrée des fournisseurs / prestataires externes sur les sujets techniques pour la filière IT
Participez à l’amélioration ou à la création de nouvelles applications ou services en appliquant les principes d’urbanisation retenus
Assurez la collecte, le stockage et le traitement des données provenant de l’ensemble des systèmes d’informations historiques
Challengez, appliquez et faites respecter les normes de développements définies
Implémentez les solutions adéquates après validation du besoin, testez
Pilotez des projets IT au sein du pôle 3D
Faites de la veille technique sur des sujets autour de l’IA, blockchain, Bigdata…,
Animez les comités de projets et de pilotages,
Préparez et présentez les dossiers de choix de startup,

La connaissance des technos suivantes : Talend, Kafka, HDFS, Vertica sera indéniablement un atout majeur
Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 75 - Paris
Ville
PARIS
Critères candidat
Niveau d'études minimum
Bac + 5 / M2 et plus
Formation / Spécialisation
Vous êtes idéalement diplômé d'une école d'ingénieur ou d'une formation universitaire de niveau Bac+5 .
Niveau d'expérience minimum
6 - 10 ans
Compétences recherchées
Capacité à concevoir des solutions et d'assurer leur implémentation
Capacité à définir et comprendre un modèle de données
Rigueur
Expérience projet en mode agile
Autonomie et qualités relationnelles et rédactionnelles
Capacité d'adaptation aux changements
Connaissance du métier de l'Asset Management
Culture global IT avec une bonne vision sur les nouveaux sujets : Big data, IA, Blockchain…
Très bon niveau relationnel
Bon niveau sur les tests de validation et les tests de non régression
Outils informatiques
Maîtrise des outils bureautiques (Powerpoint, Word, Excel, Access, Visio, MS Project)
Bonne connaissance du langage SQL, python, Shell,
Connaissance du monde open : Java, UML.
Connaissance pointue sur les technologies suivantes : Talend, Kafka, HDFS, Streamset
Langues
Travaillant dans un contexte international, l'anglais est demandé."
Paris (75),,,"Senior Cloud Architect (Data), PAR",DoiT International,- Paris (75),"As a Cloud Engineer (Data), you will guide customers on how to ingest, store, process, analyze and explore/visualize data on the Google Cloud. You will work on data migrations and transformational tasks, and with customers to design large-scale data processing systems, develop data pipelines optimized for scaling, and troubleshoot potential platform issues.
In this role you are the engineer working with our most strategic Google Cloud customers. Together with the team you will support customer implementation of Google Cloud products through: architecture guidance, best practices, data migration, capacity planning, implementation, troubleshooting, monitoring and much more.
The Google Cloud team helps customers transform and evolve their business through the use of Google's global network, web-scale data centers and software infrastructure. As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers.
Responsibilities:
Act as a trusted technical advisor to customers and solve complex Big Data challenges.
Create and deliver best practices recommendations, tutorials, blog articles, sample code, and technical presentations adapting to different levels of key business and technical stakeholders.
Communicate effectively via video conferencing for meetings, technical reviews and onsite delivery activities.
Requirements:
BA/BS degree in Computer Science, Mathematics or related technical field, or equivalent practical experience.
Experience with data processing software (such as Hadoop, Spark, Pig, Hive) and with data processing algorithms (MapReduce, Spark).
Experience in writing software in one or more languages such as Java, C++, Python, Go and/or R.
Experience working data warehouses, including data warehouse technical architectures, infrastructure components, ETL/ELT and reporting/analytic tools and environments.
Experience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments such as Amazon Web Services, Azure and Google Cloud.
Experience working with big data, information retrieval, data mining or machine learning as well as experience in building multi-tier high availability applications with modern web technologies (such as NoSQL, MongoDB, SparkML, Tensorflow)"
Paris (75),CDI,,Graphène Advisory - Data Architect,Beijaflore,- Paris (75),"Fondé en 2000, Beijaflore est un cabinet de conseil opérationnel en stratégie digitale présent à l’international avec des bureaux à Paris, Bruxelles, Rio de Janeiro, Sao Paulo et New York. Il regroupe plus de 1250 collaborateurs animés par une mission commune : accompagner de manière opérationnelle les entreprises dans la mise en œuvre de leur stratégie digitale.
Avec son entité Graphène Advisory, Beijaflore accompagne les entreprises dans la valorisation de leurs données par des projets d’Intelligence Artificielle. En proposant des solutions complètes, partant de l’identification des use cases au développement de la solution et son déploiement, Graphène Advisory amène les entreprises à créer leurs business de demain. Ces solutions sont basées sur du Machine Learning et l’IA articulés sur des architectures flexibles, modulaires et scalables appelées architectures Big Data.
Vous souhaitez rejoindre une équipe multidisciplinaire et complémentaire qui accompagne ses clients dans la réalisation de projets autour de l’IA et du Machine Learning ?
En tant que Data Engineer, vous êtes en charge de l’architecture des applications autour de la data en proposant les meilleures configurations technologiques en fonction du contexte client. Vous aurez pour objectif de préparer et déployer les technologies big data pour sourcer, stocker et de préparer les données afin de tirer le meilleur parti de leurs analyses à l’aide d’algorithmes.
Vous également un rôle de conseil et d’accompagnement dans l’utilisation de ces architectures et technologies durant les phases de traitements analytiques.
Vos enjeux : déployer une architecture data performante pour une structuration des données adéquate à leur valorisation. Mettre en place les outils big data pour exploiter les données.
Vous avez plus particulièrement été amené à :
La mise en place de l’architecture Hadoop dans un environnement « Devops »
Responsable de la stratégie de surveillance de serveurs et applicatives (logs) pour détecter les points de rupture ou de latence
En charge des choix des outils de la distribution Hadoop (Cloudera) selon les besoins métiers (parcours client, détection de fraudes, métrologie…)
Garant de la qualité du code et du respect des bonnes méthodes de développement
Référent technique et soutient sur les développements et le paramétrage des services Hadoop
Formateur auprès de l’équipe de développeurs sur les différents outils
Responsable du bon suivi des méthodes big data et Agiles
Profil recherché
Diplômé(e) d’une Grande Ecole d’ingénieur ou d’une Université en Mathématiques Appliquées, Statistique ou Informatique (Bac+5 ou PhD) avec une spécialisation en Data science option technologies big data. Vous justifiez d’une première expérience en tant que Data Architect (minimum 2 ans).
A cette occasion vous avez développé une ou plusieurs des compétences suivantes :
Maîtriser totalement les technologies Big Data
Maîtriser différents systèmes de base de données (SQL et NoSQL)
Avoir une appétence pour les technologies utilisées dans le Big Data (Hadoop, Map Reduce, Spark, Kafka…)
Être familier(e) avec les concepts et algorithmes de statistiques, de data science, de deep learning et d’optimisation en général (recherche opérationnelle notamment)
Avoir une bonne connaissance/expérience de méthodologies d’ingénierie informatique : contrôle des sources, tests unitaires, revue de code
Maîtriser un ou plusieurs langages structurés (Scala, Javascript, Java, C/C++,…)
Être curieux(se) et avoir une forte capacité d’adaptation dans un environnement en mutation constante
Démontrer la capacité à collaborer avec des personnes d’autres disciplines.

Doté d’une bonne expression orale et écrite, vous avez développé une réelle capacité de vulgarisation des sujets techniquement complexes et vous souhaitez évoluer au sein d’un environnement innovant et dynamique ?
Rejoignez-nous !"
Paris 9e (75),CDI,,Software Engineer - Algorithms,Criteo,- Paris 9e (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

Most of all, we are creators. From designing ground-breaking products to finding unique ways to solve technical challenges at an exceptional scale, our tech teams work with state of the art methodologies to shape the future of advertising.

The Software Engineering team builds the products that make Criteo tick: from developing industry leading machine learning techniques, to building high scale/low latency real-time applications (over 5M qps, handling over 300 Bn HTTP requests daily), to delivering first class client interfaces, both API and UI, with forward-thinking UX at their core, all using state of the art technology.
What you'll do
Build large-scale pipelines and systems that make the best decision in a very short time, half a million times per second.
Work with engineering teams to develop long-term roadmaps and architectures to scale our machine learning algorithms.
Find the signal hidden in tens of TB of data per hour, and constantly keep getting better at it while measuring the impact on our business. You will be using over a thousand nodes on our Hadoop cluster for this.
Develop open source projects. As we are working at the forefront of technology, we are dealing with problems that few companies have faced.

Who you are
MS or PhD in Computer Science or equivalent.
You like working with problems involving huge amounts of data (Hadoop stack).
You are proficient in, at least one programming language such as C#, Scala, Java, Python, C++. You can adapt very quickly, choose and use the best tool for the job.
You love algorithms and new technology. You are also a great team worker and a great communicator in English, both written and spoken. You are strongly committed to quality designs, automated testing and documentation.

What we offer
Competitive compensation package
35+ annual holidays days
Health insurance
Discounted transport
Personalized relocation package if moving from abroad
Catered lunch
Private nursery
Maternity and paternity leave
Annual cross teams hackathon
2 conferences per year of your choice
Internal mobility programs
Tailored educational resources

Want to know more?
What does it feel like to be part of something big? Get a snapshot
Get the story directly from our R&D engineers, check our Medium R&D blog
Interested in discovering your Criteo community first? Let’s meet

#LI-LL1

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Paris (75),Stage,,Intern in software development,LOKAD,- Paris (75),"As an intern in software development at Lokad you will help us to design and implement our Big Data apps. Lokad is seeking young passionate software developers. We are proud to already achieve a 12/12 score on the Joel Test. Designing good software is enormously challenging, and our goal will be to ramp up your skills as swiftly as possible.
Mission
Developing at Lokad is the opportunity to get hands-on experience with:
cloud computing.
machine learning.
Big Data.
enterprise apps.
Our goal is to give you a unique opportunity to acquire or refine your development skills - especially around cloud computing and/or compilation - while working on interesting projects where your contribution will matter. You will benefit from the fact that more than half of our current development workforce is (or has been) teaching software and/or mathematics at University level.

Depending on your interests, it's possible to do a PhD in Computer Science (*) at Lokad after your internship.

(*) The PhD is co-directed by Lokad and a French university. More details on about the Thèse CIFRE (in French).
Profile
We do not hire based on a specific list of buzzwords in your resume. We are looking for people that will be able to master any language, technology or development environment that we may use tomorrow.

Lokad happens to use C# / .NET / Microsoft Azure, but our partners are using Java / C++ / Python / PHP / Delphi / Apex ...

We are looking for people who want to acquire:
Incredible coding skills, with open source contributions.
A strong community voice, blogs and forum contributions.
Excellent command of written and spoken English.
The position is in our office in Paris intramuros (France).
Salary depends on the experience. The duration of the internship is 3 to 9 months.
Application
If you interested by Lokad, you can apply by sending your resume to contact@lokad.com. Please attach your resume as a plain text, Word, PDF or HTML file. In your email, please shortly explain why you think you would be a good fit for this job. If you have a website, please send us the URL."
Paris (75),,,SENIOR DEV OPS / DATA OPS,DeepLife,- Paris (75),"DESCRIPTIF DU POSTE
Our team is developing digital twins of human cells using sequencing data. Your work is to develop a scalable architecture on the cloud for the industrialisation of machine learning applications developed by the R&D team.
You will also be in charge of the construction of a scalable python package integrating proprietary and public codes.
PROFIL RECHERCHÉ
3 years experience as Data Ops or Data Engineer or DevOps (SRE)
Good knowledge of Cloud providers (Amazon AWS, Microsoft Azure, Google Cloud Platform)
Good knowledge of Python
Knowledge of Kubernetes
Knowledge of Airflow, MLFlow, Kubeflow or another ML lifecycle pipeline framework
Knowledge of CI/CD tools (Jenkins...)
Knowledge of Terraform
Easy communication with various profiles (engineering managers, devops, developers, data scientists...) in the company
Background in Data science, Data mining, Multivariate statistics, Machine learning
Familiar with data analysis tools such as Tableau
Excellent problem solving and communication skills
Ability to communicate effectively and clearly in English, both verbally and in writing.
Experience in working within a distributed & international agile team environment.
PROCESS DE RECRUTEMENT
One technical meeting with the CTO.
One personal meeting with the CEO & CTO
INFORMATIONS COMPLÉMENTAIRES
Type de contrat : CDI
Date de début : 01 juin 2020
Lieu : Paris, France (75013)
Niveau d'études : Bac +5 / Master
Expérience : > 3 ans
Télétravail ponctuel autorisé"
Paris (75),,,Senior Big Data engineer,LOKAD,- Paris (75),"As a senior Big Data engineer at Lokad, you will help us scale up to the largest supply chain challenges. Supply chains are incredibly complex, and produce heaps of data which need to be crunched from many angles. See Ionic data storage for high scalability in supply chain to get a sense of what's happening at Lokad.

At Lokad, you will benefit from the coaching of an awesome dev team. You will gain skills in advance distributed systems, designing auto-scaling logic and other similar features made possible by cloud computing. You will tackle our infrastructure challenges, in order to improve both performance and reliability. Our codebase is clean, documented and heavily (unit) tested. Our offices are quiet (no open space!), bright, and you can get three monitors.
Skills & Requirements
We expect a vivid interest for distributed architecture. A taste for low-level high performance computing and compilation is also a big plus. Contributions to open source projects are also highly regarded. We are located in front of Chevaleret in Paris (France).

We are a C#/.NET shop, and you will be developing under Visual Studio, the source code being versionned in Git. Our apps are hosted on Microsoft Azure. With the advent of .NET Core, we anticipate a few strategic migrations toward Linux.

The position is in our office of Paris intramuros (France).
Gross salary range: 40,000€ to 60,000€ (depending on your experience)
Application
If you are interested in Lokad, you can apply by sending your resume to contact@lokad.com. Please attach your resume as a plain text, Word, PDF or HTML file. In your email, please shortly explain why you think you would be a good fit for this job. If you have a website, please send us the URL."
Paris (75),CDI,55 000 € - 60 000 € par an,DEVELOPPEUR BIG DATA - SPARK,Harnham,- Paris (75),"Développeur Big Data - Spark
Paris, France
50000 - 55000
Dans le cadre de son développement, une start up d'une vingtaine de personnes localisé sur Paris grandit ses équipes techniques. Après la réussite de leur levée de fond, ils ont maintenant les moyens de leurs ambitions et recherche un Développeur d'Algorithmes, focalisé sur le Big Data. La société développe des recommandations en temps réel pour des sociétés dans l'industrie digitale. Le poste est un CDI basé à Paris.
LE POSTE:
Vous développerez des algorithmes de recommandations personnalisé
La base de données sur laquelle vous travaillerez comprend une quantité massive de données
Environnement temps réel, plateforme scalable et solutions à la pointe du machine learning
Vous serez encouragé à rester en veille technologique sur d'autres outils et à utiliser les outils/langages open source du marché
VOTRE PROFIL:
Doté dans bac+5, vous avez plusieurs années d'expérience dans le domaine de développement Big Data
Expérience en Scala et le domaine Big Data (Spark, Hadoop..)
Maîtrise de la plateforme .Net
Curieux, Passionné, Flexible, vous êtes prêt à vous investir dans ce projet challengeant et plein de promesses
POUR POSTULER:
Merci de me faire part de votre CV à jour et je vous recontacterai au plus vite."
Paris (75),Stage,,PYTHON SOFTWARE DEVELOPMENT INTERN,Data&Data,- Paris (75),"JOB DESCRIPTION
We are looking for a developer to help us implement new functionalities in our product. You will have the possibility to work on a wide variety of projects, including:
Enhancing our crawling and scraping algorithms.
Untangling the APIs of services from around the world.
Designing data processing and analysis algorithms.
Scaling our architecture to process more bytes faster.
Implementing a bulletproof strategy for testing and maintenance.
Developing internal monitoring or productivity tools.
Why join us?
Challenges: never short of those, you’ll have the opportunity to apply many skills.
Responsibilities: expect your first release into production on week one.
Work life: flexible hours, flat hierarchy, casual Fridays everyday.
Team: a small and dynamic team.
Location: Station F, the largest startup incubator - Paris.
Salary: €6k – €18k
PREFERRED EXPERIENCE
You:
Are fluent in at least one scripting or OO language, ideally Python.
Know the basics of SQL, and can find your way around in a Unix terminal.
Are driven, with strong interpersonal, analytical and problem solving skills.
Are well rounded, proactive, can multitask and ship high-caliber solutions on time.
Skills
Python, Machine Learning, SQL, Cloud Computing, Big Data, Databases, DevOps, Backend Development, Unix, Microsoft Azure
A unicorn would have experience with:
Big data, cloud or NoSQL technologies (Hadoop, Azure, Neo4j, etc.).
Applied machine learning or computer vision.
Working with startups or agile teams.
Foosball and perks of working at STATION F.
ADDITIONAL INFORMATION
Contract Type: Internship
Location: Paris, France (75013)"
Paris 2e (75),,,Lead Software Developer,Ubble,- Paris 2e (75),"In less than 2 years, ubble has become an iconic French player in online identity verification. Its technologies based on real-time video recognition is unique in the world. Traditional players (Carrefour, Crédit Agricole, etc.) and start-ups (Heetch, Bolt, Side, Stuart, etc.) are already among our convinced customers. In the heart of French-tech, ubble offers a pleasant, inspiring and dynamic work environment. 30 employees have already joined us to make the project grow.

Challenges of this role
Architect, design, develop, test and maintain our next-generation user-facing services.
Ship awesome infrastructure and tools on time and at very high quality.
Full stack development, you are able to roll up your sleeves and help the team on frontend/backend development when needed.
Get stuff done. A problem partially solved today is better than a perfect solution next year. Have an idea during the night? Code it in the morning, push it at noon, test it in the afternoon and deploy it the next morning.
Our Tech Stack
Front: React.js
Back: Python, Django, Golang
Data: Keras, Postgresql, DynamoDB
DevOps: Kubernetes, Docker, AWS, Datadog, Terraform, Vault
Workflow: Github, CircleCI, Sentry, LogRocket

Our Hiring Process
1. We receive your application, a member of the technical team will contact you for a video alignment discussion.
2. If the impressions are good on both sides a second video call is organized with you and another team member.
3. We then send you a ""home assignment"",you will have 1 week to complete and send back to us.
4. We invite you to come and meet us physically for an half-day of immersion.
This will allow you to meet 6 of your future colleagues, during 4 interviews - in a period of confinement these interviews will of course take place remotely.

You would be a good fit at Ubble.ai, if you have:
MS or PHD in Software Engineering or related field
a rock-solid foundation in Computer Science (data structures, algorithms, system design)
3+ years of experience in developing web-based applications
Significant experience in Python or another Object Oriented Programming language
Strong commitment to quality designs, automated testing, and documentation
Continuous integration aficionado (CircleCI)
Great communication skills in English, both written and spoken
Even better if you have…
Experience with developing and extending large and complex systems
Experience taking initiative/ownership and acting as a technical lead
Experience with Kubernetes
Experience of Machine/Deep Learning or Computer Vision
Experience with Video Streaming
Experience with web technologies such as modern Javascript, ideally React.js"
Paris (75),CDI,,DATA SCIENTIST - Spanish Speaker,Harnham,- Paris (75),"Data Scientist - C#
Paris, France
40000K-45000
After two successful rounds of funding (several millions of ), this startup known in the insurance sector is looking for a Spanish Data Scientist to join their Data Science team in Paris. The technical environment is C#.
THE ROLE:
Solid knowledge in algorithm coding and programming
Designing and developing solutions that will detect insurance frauds and errors
You will be joining a team of 50 data scientists
You will be traveling occasionally (a few days a month) to clients' sites in Spain to implement your solutions
You will be working closely and tailoring your technical work to the needs of the companies
Each individual project can last up to 4 months
YOUR PROFILE:
Master's or Engineering Degree in Applied Mathematics, or other similar quantitative fields
Ideally a first experience in data science and machine learning
Good knowledge of C#, or willingness to learn (experience with Java or C/C++ is a plus)
You are ambitious and passionate about your job
Fluent Spanish and English

WHY SHOULD YOU APPLY?
Expending startup, financially stable
High earning potential (variable can be 50-100% of the basic salary)
The company develops state of the art algorithms

HOW TO APPLY?
Please register your interest by sending your CV via the Apply link on this page."
Paris (75),,,Consultant.e à Senior Manager - Data Microsoft H/F,Accenture,- Paris (75),"Vos connaissances disent souvent que vous êtes au fait des dernières innovations ? Votre entourage est étonné par votre capacité à apprendre toujours plus ? Vous portez une attention particulière à votre bien-être dans votre environnement de travail et vous pensez que la diversité permet à toutes et à tous de progresser et d’innover ensemble ?

Rejoignez Accenture et réalisez demain. Dès maintenant.

Accenture et Microsoft ont récemment annoncé le lancement d’Accenture Microsoft Business Group (AMBG).

Accenture Microsoft Business Group renforce une alliance stratégique de longue date entre Avanade, Accenture et Microsoft en combinant des capacités de service, une envergure mondiale et le développement de solutions communes pour aider les clients à transformer numériquement leurs activités et à obtenir un avantage concurrentiel grâce au plein effet de Microsoft.

AMBG représente à ce jour le plus important investissement visant à exploiter le potentiel des solutions Microsoft à l’échelle de l’entreprise et rassemble le plus grand groupe d’experts en solutions Microsoft au monde.

En tant que partie du groupe AMBG, nous formons une équipe de conseil leader du marché pour aider certaines des sociétés les plus importantes et les plus connues au monde à maîtriser leur processus de transformation numérique avec Microsoft.

L'équipe grandit rapidement et a besoin de recruter des consultants passionnés par les problématiques métiers et la technologie, pour contribuer à la conception, la vente et la fourniture de solutions transformationnelles qui font la différence pour nos clients.

Votre rôle :

Proposer des solutions clients et sectorielles en utilisant la puissance des données.

Développer des stratégies et des architectures de données pour répondre aux besoins spécifiques des clients dans le cadre de parcours de transformation de bout en bout basés sur les solutions Cloud.

Intervenir en tant qu’expert données sur des projets avec une expérience technique et une connaissance des solutions technologiques clés (par exemple, Microsoft Azure AI and Data Platform including SQL Server, Azure SQL, DataBricks, CosmosDB, Business Intelligence, Advanced Analytics, Machine Learning, Cognitive Services, IOT et PowerBI).

Collaborer avec d'autres experts pour créer des architectures d'entreprise de premier plan du point de vue des données, des applications et de l'infrastructure.

Assister et conseiller les équipes de vente, les équipes projet sur les méthodologies et la stratégie des données.

Développer des points de vue, des ""assets"", des bonnes pratiques et contribuer à la croissance de l'équipe de conseil du groupe Microsoft Accenture d'Accenture.

Établissez des relations avec les experts d'Accenture, Avanade, Microsoft à travers le monde et de l'écosystème technologique au sens large.

Vous êtes diplômé(e) d’une école de commerce, ingénieur ou universitaire
Vous justifiez au minimum de 5 ans d’expérience en architecture de données et technologies connexes et en technologies de données.

Vous justifiez au minimum de 3 ans d’expérience de conseil auprès de clients, accompagnant idéalement des programmes de transformation de technologies à grande échelle.

Expérience démontrée du travail avec les technologies Microsoft avec au moins l'une des technologies suivantes: SAS, SPSS, RevR, Azure ML, MapR, etc.

Expérience démontrée dans la préparation de données avec des outils standard tels que R et Python et des outils de visualisation tels que SAP, QlikView, PowerBI, etc.

Accenture, c’est une communauté de plus de 450 000 talents qui innovent ensemble afin d’améliorer nos modes de vie et de travail. C’est en combinant nos expertises en stratégie, digital, consulting, technologie, opérations et sécurité que nous servons les plus grandes entreprises mondiales et les aidons à se transformer et à dynamiser leur croissance.
Envie d’en savoir plus sur le quotidien des collaborateurs Accenture ? Posez-leur directement vos questions.
Déjà prêt(e) à passer à la vitesse du changement ? Postulez."
Paris (75),,,Digital - Content - Automation Engineer,FactSet Research Systems,- Paris (75),"Responsabilities
Ingest and analyze various data sources to drive innovation in content creation.
Automate the acquisition, relevance scoring and storage of incoming sources.
Develop processes for data mining, data concordance and data production.
Explore and evaluate new data technologies to build a scalable, cloud oriented data platform.
Optimize data retrieval, develop dashboards and other visualizations for financial experts.
Required Skills:
Bachelor or Master Degree in Computer Science, Math, or Engineering
1 to 3+ years of working experience in software development
1 to 3+ years of relevant experience in Data Science or Machine Learning
1 to 3+ years of experience in building data ingestion and ETL pipelines/supporting a large data platform and data pipelining
Strong experience and proficiency with Python, Pandas, Numpy and AWS APIs
Organized, self-directed, and resourceful with the ability to appropriately prioritize work in a fast-paced environment
Able to work in a team of data scientists as well as in projection in other teams for the duration of the projects
Desirable Requirements:
If possible, but not essential, some experience in one or more of those areas:
Experience with modern data platforms such as Spark, Hadoop or other map/reduce big data systems and services
Experience with a variety of data stores such as ArangoDB, MongoDB, Cassandra, HBase, DynamoDB
Experience with AWS environment"
Paris (75),CDI,55 000 € - 75 000 € par an,DATA ENGINEER SENIOR,Harnham,- Paris (75),"Data Engineer
55-75K par an
Paris, France
Cette société développant une solution innovante basée sur l'IA et le Machine Learning permet aux entreprises d'anticiper en temps réel des problématiques décisionnelles et informatiques.
LE POSTE :
Au sein de cette Start Up vous rejoindrez l'équipe technique Data Engineering composé de profil Data Engineer/Scientist
Vous développerez des jobs avec Python et Spark
Vous traiterez une grande volumétrie de donnée en temps réel
Vous travaillerez sur le produit Data
Vous avez une réelle appétence pour la partie Data Engineering
Vous serez amené à mettre en place et consolider des pipelines de données
Vous serez amené à travailler en collaboration avec les équipes Data Science
LE PROFIL :
Vous justifiez d'une expérience réussie d'au moins 4 ans en tant que Data Engineer
Vous avez une première expérience dans le traitement de grandes volumétrie de données.
Vous maitrisez des technos streaming comme Hadoop/Kafka/Spark
Vous avez une apétence pour la programation et maitrisez Python ou Scala
Vous êtes une personne autonome et sachant s'approprier des problématiques Data
La maitrise de Airflow et Kafka est un plus.
COMMENT POSTULER :
Si vous êtes intéressé(e), merci de faire part de votre CV à Pierre Gerbeau."
Paris (75),CDI,45 000 € - 70 000 € par an,CONSULTANT DATA SCIENTIST SENIOR,Harnham US,- Paris (75),"Consultant Data Scientist Senior
Paris, France
45-75K
Cette société de conseil Parisienne est en pleine croissance et se spécialise sur les métiers data&analytics. Elle recrute aujourd'hui de nouveaux profil de consultant Data Scientists Senior afin d'intervenir chez ses clients (industries variées : Retail, E-Commerce, Finance, Banque) sur des projets stratégiques et a haute valeur ajoutée.
LE POSTE:
Orienté service, ce poste vous permettra de côtoyer différentes grandes sociétés dans des secteurs liés au monde du web, mais pas seulement. Vous interviendrez sur des missions de plus ou moins longue durée (de ,3 mois à plusieurs années) au sein des bureaux des clients et aurez un impact sur les décisions stratégiques des clients
Vous travaillerez sur des projets Data Science complet - de la réception des données, jusqu'à la mise en production d'algo et l'industrialisation de POCs
Votre panel de connaissance et votre relationnel vous permettra de concrétiser des projets de grande envergure
Acquisition, extraction, transformation, management, et manipulation de large quantité de données.
Environnement technologique: Machine Learning, Statistiques, Programmation (Python, R, Scala, Spark), outils Analytics.
VOTRE PROFIL:
Doté d'un bac+5 ou d'un doctorat, vous avez un bagages solide en Data Science et Machine Learning
Esprit Mathématique et excellente communication
Connaissances des outils principaux Data et Analytics sur le marché
Une experience du monde du conseil est un plus
Autonome ET team player

COMMENT POSTULER:
Merci de me faire part de votre CV à jour et je vous recontacterai au plus vite pour partager plus d'info avec vous.

MOTS-CLÉS:
Algorithme, Data Science, Machine Learning, design patterns, ElasticSearch, Hadoop, Spark, Paris, France, R, Visualisation, Python, Statistiques, stats"
Paris (75),CDI,55 000 € - 70 000 € par an,SENIOR DATA ENGINEER,Harnham,- Paris (75),"Senior Data Engineer
Paris, France
50-70K
Ce groupe international (100 000 employés) est un acteur majeur dans le domaine de la finance / investissement. Avec divers projets tourné autour de la Data Science, le Machine Learning et l'intelligence artificielle, le CEO de la société a établie une vision 100% data driven pour les années à venir. Le but pour eux est de devenir une véritable société tech dans leur domaine d'activité. Nous recherchons aujourd'hui un Data Engineer avec plusieurs année d'expérience pour rejoindre leur équipe sur Paris.
LE POSTE:
Encadré par le Head of Data de la société, vous travaillerez avec une équipe de profils variés et seniors sur Paris et à l'international (Data Scientists, Data Analysts, Data Engineers)
En tant qu'ingénieur expérimenté, vous créez des solutions robuste et évolutive et contribuerez à l'infrastructure ETL de la société
Implémentassions de divers solutions Data en vue d'automatiser les process, d'optimiser le flux de données, en s'assurant du potentiel de continuellement faire évoluer ces solutions (scalability)
Création et amélioration des infrastructures de données sur lesquels les équipes data science pourront ensuite travailler
Outils/Languages : SQL / NoSQL, Python/Java/Scala/, API

VOTRE PROFIL:
Un background académique (bac+5 et plus) orienté Informatique/Data Management/Maths ou domaine relié
Expérience de plusieurs années en tant que Data Engineer
Expérience solide sur SQL, et idéalement des bases de données NoSQL
Connaissance d'un ou plusieurs langages orientés object (Python, C++, Java, Scala....)
Français et Anglais fonctionnel
COMMENT POSTULER:
Merci de me faire part de votre CV à jour et je vous recontacterai au plus vite."
Courbevoie (92),,,Senior EMEA Analytics Specialist (Amazon QuickSight),AWS EMEA SARL (France Branch),- Courbevoie (92),"The right person will be technical, analytical, with good knowledge of value selling, and possess several years of business development enterprise sales, or program/product management experience,
Strong verbal and written communications skills in English is a must (Other major European languages i.e. German, French, Italian, Spanish, etc. is a plus), as well as leadership skills. Demonstrated ability to work effectively across internal and external organizations is key,
Technical degree required; MBA, Computer Science, and/or Engineering/Math background highly desired; working knowledge of software development practices and Business Intelligence / data center / infrastructure / networking technologies highly desired.

Amazon Web Services (AWS) is the pioneer and recognized leader in Cloud Computing. Our web services provide a platform for IT infrastructure in-the-cloud that is used by hundreds of thousands of developers and businesses around the world. These customers range from start-ups to leading web companies to Global 500 companies in financial services, pharmaceuticals, and technology.

Are you a Business Intelligence / data visualization specialist? Do you like to solve the most complex and large-scale data challenges in the world today? Do you want to have an impact in the development and adoption of new ways to explore data? Want to make history? Come and join the AWS Analytics team in EMEA.

Amazon Web Services (AWS) offers a comprehensive set of services to handle every step of the analytics process chain including data warehousing, business intelligence, batch processing, stream processing, machine learning, and data workflow orchestration. Amazon QuickSight delivers fast, easy-to-use business analytics and visualization for customers looking to build new applications.

As a Business Development Manager within Amazon Web Services, you would be able to shape the future of the Analytics industry and further establish Amazon as the leader in the cloud computing space.

You would use your business savvy to drive revenue, develop sales programs and identify new markets and opportunities. You would work directly with the most interesting and demanding customers to understand their requirements and turn them into reality.

Working hand in hand with our sales teams and solution architects, you would help deliver the finest solutions based on our platform of database services. Your in-depth technical background in databases would help customers understand how to improve their businesses using the right database services. Your excellent verbal and written communication skills will allow you build sales enablement tools, evangelize our platform with our enterprise customers, start-ups and valued partners.

The ideal candidate will possess both a business background that enables them to drive an engagement and interact at the CxO/VP level, as well as a technical background that enables them to easily interact with software developers and architects. He/she should also have a demonstrated ability to think strategically and analytically about business, product, and technical challenges, with the ability to build and convey compelling value propositions, and work cross-organizationally to build consensus. A keen sense of ownership, drive, and scrappiness is a must.

Roles & Responsibilities
Serve as a key member of the Analytics Business Development team focused on helping to drive overall AWS market and technical strategy for Amazon QuickSight in EMEA.
Help define the AWS market segments, customer base, and industry verticals we target.
Set a strategic business development plan for target markets and ensure it is in line with the AWS strategic direction.
Execute the strategic business development plan while working with key internal stakeholders (e.g. sales teams, product service teams, legal, support, etc.).
Identify specific prospects/partners to approach while communicating the specific value proposition for their business and use case.
Fill the business development pipeline by engaging with prospects, partners, and key customers.
Work closely with our customers to ensure they are successful using our web services, and that they have the technical resources required.
Understand the technical requirements of our customers and work closely with the internal development teams to guide the direction of our product offerings for developers.
Prepare and give business reviews to the senior management team regarding progress and roadblocks to closing new customers.
Manage complex contract negotiations and liaison with the legal group.
Develop long-term strategic partnerships in support of our key markets.
Handle a high volume of engagements and the fast pace of the cloud computing market.
Experience with account management (Enterprise, SMB and startup) and solution selling ability.
Strong business intelligence knowledge with ability to go deep enough on technical aspects to differentiate between varied approaches (reporting from relational, non-relational, data warehousing)
Serve as a key member of the Analytics Services Business Development team focused on helping to drive overall AWS market and technical strategy.
Help define the AWS market segments, customer base, and industry verticals we target.
Set a strategic business development plan for target markets and ensure it is in line with the AWS strategic direction.
Execute the strategic business development plan while working with key internal stakeholders (e.g. sales teams, product service teams, legal, support, etc.).
Identify specific prospects/partners to approach while communicating the specific value proposition for their business and use case.
Fill the business development pipeline by engaging with prospects, partners, and key customers.
Work closely with our customers to ensure they are successful using our web services, and that they have the technical resources required.
Understand the technical requirements of our customers and work closely with the internal development teams to guide the direction of our product offerings for developers.
Prepare and give business reviews to the senior management team regarding progress and roadblocks to closing new customers.
Manage complex contract negotiations and liaison with the legal group.
Develop long-term strategic partnerships in support of our key markets.
Handle a high volume of engagements and the fast pace of the cloud computing market.
Experience with account management (Enterprise, SMB and startup) and solution selling ability.

· Experience working within the technology industry and extensive contact network in both customers and partners highly desired."
Paris (75),CDI,60 000 € - 70 000 € par an,Senior Data Engineer / Python,Data Recrutement,- Paris (75),"Soyez alerté de la prochaine offre similaire en cliquant ici.
Senior Data Engineer / Python
Offre publiée le 18-05-2020.
Paris
Fonction Python engineer
Fonction Data engineer hadoop spark
Taille entreprise de 11 à 20
Teletravail ponctuel
Technologies Django
Technologies Gitlab
Technologies Gitlab ci
Technologies Python
Expérience 3 à 5 ans
Statut CDI
Min 60k€
Max 70k€
L’ENTREPRISE : Une Startup e-santé qui développe une solution de diagnostic précoce du cancer de la vessie
Equipe de 16 personnes
Projet d’intérêt médical : détection des cancers à un stade précoce
Solution primée à deux reprises
Dernière levée en juin 2019 : 4M€
Bureaux situés à Montparnasse
Stack technique : Python, Django, Linux, DevOps, Docker, Sql, Json, Machine Learning, GitLab, GitLab CI

LA MISSION : Contribuez au développement de nouveaux outils de la solution dans un souci d’optimisation et de performance de la plateforme existante
En tant que Senior Data Engineer, vous serez rattaché à l’équipe technique ainsi que les parties prenantes de la startup et effectuerez des missions transverses autour de deux enjeux principaux : la création à distance d’un laboratoire technique d’analyses & le lancement d’un nouvel essai clinique. Vos missions seront de :
Créer plusieurs outils permettant la collecte, la gestion et la visualisation des données
Monitorer les algorithmes déjà existants
Concevoir une infrastructure - le squelette - permettant la collecte des données via l’API
Optimiser le workflow des données déjà existants et potentiellement en créer d’autres
Rédiger les spécifications techniques des futurs outils développés

VOTRE PROFIL : Sénior data engineer / Python
Vous êtes diplômé d’une école d’ingénieur ou d’informatique
Vous avez au moins 3/5 années d’expériences réussie sur un poste similaire
Vous maîtrisez parfaitement python et Django
Vous avez une expérience réussie avec GitLab / GitLab CI
Vous disposez de bonnes pratiques de Workflow, Machine Learning et DevOps
MODALITÉS :
Package de rémunération selon profil et expériences : 60 / 70 K€
Télétravail possible : 1 à 2 jours par semaine

PROCESSUS DE RECRUTEMENT :
1 call avec Data Recrutement
1 call avec le CTO
1 rencontre avec le CTO et les opérationnels dans les locaux
Proposition

Sélectionné par
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),CDI,,DATA SCIENTIST - H/F,La Banque de France,- Paris (75),"Présentation de la Direction générale
La Banque de France recrute un Data Scientist (H/F) pour renforcer ses équipes.
Dirigée par le Chief Data Officer et rattachée au gouvernement de la Banque de France, la Direction des Données et des Services Analytiques met en œuvre la stratégie DATA avec comme principales préoccupations
D’améliorer la gouvernance des données ;
De contribuer à la data réputation de la Banque de France ;
De tirer le meilleur parti des masses et de la diversité des données disponibles au sein de la banque Centrale,
De développer des projets d’intérêt commun
De développer une culture de la donnée au sein des unités métier

Présentation du Service
Au sein de la DDSA, le SIAD (Service Industrialisation et Algorithmique des Données) a pour missions de construire et entretenir les socles techniques BIG DATA, de réaliser des prototypes de solutions basées sur les approches Data Science et IA et de mettre à disposition des solutions business intelligence pour les équipes métier.

Descriptif de mission
Le pôle « Data Science et IA » cherche à renforcer ses capacités en recrutant un(e) Data Scientist.
Les missions de ce pôle, partie intégrante du domaine « conseil et expertise », sont les suivantes :
Cartographier de façon continue, en relation avec les équipes d’innovation et les urbanistes, les processus métier pour lesquels une approche Data Science pourrait procurer un avantage compétitif ou préserver un territoire acquis
Épauler les métiers dans la définition et la stabilisation de leurs besoins
Mettre en place de façon continue les Proofs of Concept (POC) fonctionnels et techniques issus des analyses d’opportunité
Benchmarker de façon régulière les outils du Big Data
Préparer l’industrialisation des POC identifiés comme pertinents
Accompagner la montée en compétence des équipes métier et des équipes techniques sur le Big Data
Sous l’autorité du « Lead Data Scientist », vous serez en charge plus particulièrement :
De la prise en charge des besoins métier et de leur analyse ;
De l’identification des solutions potentielles et du choix de la solution la plus adéquate au regard des besoins et contraintes tant métier que techniques ;
De la conception et de la mise en œuvre de la solution (POC, prototype, MVP),
De l’accompagnement et du soutien aux équipes projets en charge de l’industrialisation des solutions.

Profil recherché
De formation supérieure en informatique ou métiers de la donnée (Ingénieur ou équivalent), vous avez minimum 2 ans d’expérience dans la mise en œuvre de solutions mobilisant des connaissances statistiques et/ou mathématiques avancées, y compris en contexte d’apprentissage/alternance dans des contextes de travail variés (recherche, entreprises commerciales, sphère publique ) constituera un avantage clé.
Vous disposez d’une forte appétence pour la concrétisation de solution dans un environnement Bigdata.Par ailleurs, vous avez la maîtrise :Des sous-jacents mathématiques aux approches Bigdata / Data Science (mathématiques et statistiques, Machine Learning, réseaux de neurones ) et des bibliothèques de Machine Learning (Scikit Learn, PyTorch, )
Du développement en Python
Seraient en outre appréciées, dans l’un ou plusieurs des domaines suivants :
Une très bonne connaissance en développement sur la stack Hadoop (Oozie, Sqoop, Hive, Hbase, ), sur les technologies Spark (MLlib, SQL, GraphX et Streaming), en langages PySpark, Java et R (SparkR).
Une très bonne maitrise des outils de Search (ElasticSearch) et de streaming (Kafka)
Une bonne connaissance des bases de données NoSQL telles que Mongodb et Neo4J
Une bonne capacité à intégrer des sources de données multiples, internes / externes, structurées / non structurées et des interconnexions entre les SGBD et Hadoop
Une bonne capacité à restituer les résultats visuellement à l’aide de Kibana ou PowerBI
Une facilité à développer dans un environnement innovant en méthodologie Devops et Scrum
Rigoureux et apte à anticiper, vous avez le sens du résultat au service du client et êtes doté d’excellentes capacités de communication pour faciliter le travail « en réseau » :
Force de proposition et aisance de communication pour démontrer la valeur ajoutée des solutions Big Data et Machine Learning.
Excellente méthodologie de travail et de gestion de projet, vous travaillerez en mode agile.
Très bon relationnel, capacité à s'adapter, esprit d’équipe, ouverture d’esprit et curiosité naturelle, vous suivez l’évolution des technologies et nouveautés relatives au Big Data, Datascience et IA
Une bonne pratique de l’anglais est nécessaire.
Ce poste, en contrat à durée indéterminée, est basé à Paris (1er), avec des déplacements ponctuels dans les sites banque de France à Paris et en régions.
La Banque de France est une institution socialement responsable, attachée à la diversité de ses personnels. Des aménagements de poste peuvent être organisés pour tenir compte des handicaps des personnes."
Paris (75),,,Senior Data Scientist,Fifty-Five,- Paris (75),"Contexte
fifty-five accompagne les entreprises dans l’exploitation de leurs données au service d'un marketing et un achat-média plus performants. Partenaire des annonceurs de la collecte à l'activation des données, l'agence aide les organisations à devenir de véritables entités omnicanales maîtrisant l'efficacité de leur écosystème digital et ses synergies avec le monde physique. Pilier data stratégique de You & Mr Jones, premier groupe de BrandTech au monde, fifty-five propose des prestations associant conseil, services et technologie. L’agence compte aujourd'hui des bureaux à Paris, Londres, Hong Kong, New York et Shanghai. Le poste concerne le bureau de Paris.
Afin d'accompagner les annonceurs dans l'amélioration de la conversion sur leurs sites et applications et l'optimisation de leur stratégie média, fifty-five consolide diverses bases de données. En interaction avec les data engineers et consultants, les data scientists exploitent ces données brutes pour en tirer des informations utiles (insights) ou activer des stratégies d'optimisation data driven.
Le processus de recrutement contiendra plusieurs test techniques.

Vos missions
Encadrement de juniors dans leur projet client. Vérification de la méthodologie et du bon déroulé du projet.
R&D, veille scientifique
Synchronisation avec les autres équipes (consultants, ingénieurs, experts marketing, clients)
Participation à la création de la solution
Participation à la construction de nouvelles offres innovantes Data Science
Mise en place et suivie de l’approche Data Science pour répondre à un problème client donné (forecast, scoring d’engagement / de churn, systèmes de recommandations, …)
Compétences et expérience
2 ans minimum en tant que Data Scientist à plein temps ou PhD
Diplômé d’une grande école majeure statistiques/économétrie/machine learning
Avoir participé à plusieurs projets Data Science de la prise du besoin à la création de la solution
Une très bonne connaissance de l’ensemble des techniques existantes en machine learning
Une forte appétence pour l’innovation et les nouvelles solutions
Une expérience quantitative en marketing digital est un plus
Appétence pour l’encadrement de profils plus juniors
Fortes compétences en :
Python, R, SQL, Bash, Bitbucket
Statistique descriptive et analyse de données (ACP, ACM, Classifications…)
Inférence statistique (régressions linéaires, logistiques, séries temporelles …)
Expérience avec les environnements cloud
Résolution de problèmes business marketing grâce à des modèles statistiques/machine learning
Capacité à spécifier et concevoir l'industrialisation des prototypes sur de gros volumes de données
Capacité à partager ses résultats de façon claire et accessible à une audience non technique
Qualités rédactionnelles et esprit de synthèse
Bon niveau écrit et oral en anglais et français"
Paris (75),"Apprentissage, Contrat pro",,Alternance - 1 à 3 ans - Concepteur développeur Big Data (H/F) - Paris,Natixis,- Paris (75),"Because you deserve much morethan just a job
Bienvenue chez Natixis, l’entreprise qui vous offre bien plus qu’un job.
Chez Natixis, nous concevons des solutions en gestion d’actifs et de fortune, financement, investissement, assurance et paiements.
Notre ambition : nous dépasser collectivement pour mieux accompagner nos clients et leur proposer les meilleures solutions pour leur développement.
Chez Natixis, nos talents sont notre principal atout.
Rejoignez-nous et vous aurez les clés pour faire bouger les choses et avoir un réel IMPACT.
Rejoignez-nous et vous découvrirez un monde D’OPPORTUNITÉS.
Rejoignez-nous et vous donnerez du sens à votre projet professionnel par votre ENGAGEMENTen faveur de la société comme de l’environnement.
Signataire de la Charte de la diversité, Natixis veille à promouvoir tous les talents et à accompagner le développement de chacun. Elle est certifiée Top Employer France 2020, pour la 4ème année consécutive, et HappyTrainees.
Digital & Technology est au cœur des enjeux stratégiques de Natixis pour développer de nouveaux services & usages clients et adapter son modèle aux nouvelles réglementations bancaires.
Digital & Technology est doté d’une forte culture clients et innovante grâce aux nouvelles méthodologies & technologies IT (Digital, Big Data, Blockchain, IT bimodal, Agilité, Expérience utilisateur, Collaboratif, Sécurité de l’Information, Robotique).
Digital & Technology s’adapte régulièrement pour apporter le maximum de valeur aux Métiers de Natixis. Ses collaborateurs et les challenges qu’ils relèvent sont sa meilleure vitrine.
Vous intégrez Digital & Technology de Natixis, implantée dans 12 pays et 4 continents (3 300 collaborateurs), à la croisée des enjeux stratégiques de développement de nouveaux services & usages clients et de la nécessaire adaptation de son modèle aux nouvelles réglementations bancaires.
Mission
Vous rejoignez notre équipe IT Global Markets, qui recherche un Concepteur Développeur Big Data, pour une alternance de 1 à 3 ansà partir de septembre 2020.
Vous intégrerez une équipe agile de 4 personnes évoluant dans un environnement DevOps (TDD,Continuus Testing, Packaging & Continuus Delivery).
Vous participerez à l’élaboration d’une application de Business Activity Monitoring (BAM) visant à offrir aux différentes équipes IT et aux équipes métiers une vision globale de la chaîne.
Passionné(e) par les nouvelles technologies, vous participerez à l’implémentation de la BAM s’appuyant sur les services et composants de la plateforme Big Data (Kafka, ElasticSearch, Grafana, …).
Vous interviendrez sur :
le développement de nouvelles fonctionnalités (calcul de KPI via des analyses statistiques, implémentation de nouveaux dashboards, ...),
la revue de l'architecture de l'application (modèle de données, infra back end et front end, disaster recovery plan, ...),
l'optimisation (insertion des données et leur restituation),
le design de l'interface utilisateur (grafana & angular).
Profil recherché
C’est avant tout votre personnalité et votre état d’esprit qui nous intéresse.
Vous préparez un diplôme universitaire ou d’école d’ingénieur de niveau bac +5 en informatique.
Vous êtes reconnu pour vos compétences en Python, base NoSQL comme ElasticSearch.
Vous avez développé des connaissances sur la méthode Agile.
Votre agilité et votre sens du service sont reconnus de tous.
Vous aimez travailler en équipe.
And last but not least, you are perfectly fluent in English.
Vous vous reconnaissez dans ce profil ?
Alors vous êtes fait pour ce job et nous avons besoin de VOUS !
Vous bénéficierez d’un accompagnement dédié pour vous donner toutes les chances de réussir cette nouvelle mission."
Paris (75),CDI,,Data Engineer - FinTech,Sept Lieues,- Paris (75),"PME, de plus de 200 personnes, présente en France et à l'international. L'entreprise est un acteur de la fintech.
LE POSTE / LES MISSIONS
Vous rejoindrez l'entreprise en tant que data engineer. A ce titre, vous aurez différentes missions, notamment:

Modélisation de données sous la forme de datamarts
Développement d'API
Mise en production de modèles machine learning que les data scientists développent
Participation au développement des architectures big data
Création de reporting
PROFIL RECHERCHÉ
- Formation d'Ingénieur - Bac +5
Expérience de 2 ans sur des problématiques liées à la data / big data
Maitrise de Python / Spark

Les plus: fort intérêt pour les technos big data, connaissance de la suite Microsoft BI"
Paris (75),CDI,,Senior Customer Success Data Scientist,craft ai,- Paris (75),"Paris, Bercy
CDI
Retour
Senior Customer Success Data Scientist
craft ai recrute !
À propos
craft ai est une API qui permet aux équipes métiers & produit de déployer et d'opérer des Intelligences Artificielles explicables (XAI). craft ai décode les flux de données pour propulser des services auto-apprenants.
craft ai apprend comment chaque utilisateur, capteur ou système se comporte, dans son contexte pour automatiser des processus métiers, personnaliser la relation client, ou faire de la maintenance prédictive.
craft ai est utilisé par des acteurs de divers marchés: Énergie (Dalkia, Total Direct Énergie), Utilities, Santé (Medclinik), Défense (Dassault Aviation), Éducation (Dauphine)... en étant intégré dans des dashboards métiers, des applications mobiles, des objets connectés ou bien des bots.
Fondée en Juin 2015, l'équipe de craft ai se compose aujourd'hui de 18 spécialistes en Intelligence Artificielle (IA), Machine Learning (ML) et API qui travaillent main dans la main pour faire que l'IA explicable soit adoptée et déployée à grande échelle par les entreprises dont c'est devenu un enjeu majeur de compétitivité.
Rejoindre craft ai c’est se retrouver acteur et moteur d'une équipe enthousiaste, fun et passionnée dont l'ambition est de faire avancer le sujet de l’explicabilité, opérationnaliser des IAs qui changent les entreprises et soutenir le développement d’une IA éthique & responsable. Mais c'est aussi et surtout être plongé au cœur de l’écosystème IA ! Nous sommes co-fondateurs de l’AI Factory avec Microsoft & INRIA et co-fondateurs d’Impact IA. Et tout ça... depuis les bureaux les plus cools de Paris : WeWork, rue des Pirogues de Bercy !
Descriptif du poste
Ce que vous allez faire
Chez craft ai, nous aimons nos clients ! Nous avons une équipe dédiée à leur bonheur : l'équipe ""Customer Success"", en charge d'accompagner clients et prospects pour leur faciliter l'usage de notre API. Nous les aidons aussi bien sur les aspects techniques que sur des sujets plus stratégiques liés à l'intégration d'Intelligence Artificielle dans leur business. Les ingénieurs de l'équipe customer sucess interviennent donc chaque jour auprès de nos clients pour les conseiller, les former, mais aussi pour participer à la conception et au développement de leurs différents projets IA. Un super exemple de cas client géré par l'équipe Customer Success est disponible là. Il résume parfaitement l'activité réalisée par l'équipe dans le cadre d'un projet mené par la Mairie de Paris en collaboration avec Suez.
L'équipe Customer Succes est aujourd'hui en forte croissance et en pleine structuration, nous cherchons à la renforcer par un(e) Data Scientist confirmé(e) qui pourra lui faire bénéficier de son expérience dans la réalisation de projets Data au plus près des enjeux métier, idéalement dans un contexte grand comptes. Ce poste de mentor pourra évoluer rapidement vers plus de responsabilités.
En outre, en tant que contributeur à l'équipe, votre rôle consistera à :
Comprendre les problématiques métiers & techniques de nos clients et prospects, plus particulièrement autour de l'exploitation de leurs données ;
Imaginer, concevoir et développer, en collaboration avec nos clients, des applications & services à forte composante ""IA"", utilisant craft ai ;
Participer aux phases d'avant-vente, en support de l'équipe commerciale, notamment en réalisant et présentant des études & prototypes ;
Contribuer à la conception et au développement de nouvelles fonctionnalités du produit sur base des cas clients.
Environnement technique
Les environnements techniques sont variés, mais voici nos outils de prédilection :
Python / Pandas / Jupyter
Node.JS
React / d3.js
Profil recherché
Ce dont nous avons besoin
Alignement avec la vision produit (SaaS, Operationalized AI, Explainable AI) de craft ai,
Expérience significative en Data Science appliquée à des problématiques métier concrètes & de la relation avec des experts métier / équipes produits,
Passion pour la satisfaction utilisateur et les cycles de développement très courts,
Compétences socles en ingénierie logiciel, idéalement expériences des environnements industriels data (APIs, ETL, Data Lake, ...),
Compétences rédactionnelles et orales, en Anglais et en Français.
Ce que vous allez apprendre
Les enjeux métiers & IA au sein de marché variés, tous impactés par la révolution ""IA"",
La structuration d'une équipe de Data Science répondant aux spécificités de chaque cas client en déployant un produit technologique unifié,
L'opérationalisation d'IA dans des environnements technologiques variés,
Et vous serez acteur du développement d'une startup tech ambitieuse en pleine croissance !
Informations complémentaires
Type de contrat : CDI
Lieu : Paris, France (75012)
Niveau d'études : Bac +5 / Master
Expérience : > 2 ans"
Paris 8e (75),"Temps plein, CDI",,Lead Software Engineer,Quantmetry,- Paris 8e (75),"Qui sommes-nous ?
Présentation de Quantmetry
Pure player en Data et Intelligence Artificielle, Quantmetry est un cabinet de conseil qui aide ses clients à valoriser leur patrimoine de données et à mettre en œuvre des solutions d’Intelligence Artificielle en s’appuyant sur ses expertises en Conseil Stratégique et Opérationnel, Data Science, Architecture et Data Engineering.
Nos réalisations tournent autour de thématiques telles que :
Industrie 4.0 : maintenant prédictive, suivi de la qualité de production…
Détection de fraude mais également de corruption, de blanchiment d’argent…
Supply Chain : optimisation de stocks, prédictions de ventes, optimisation de tournées…
Connaissance client : segmentation client, détection de churn, scoring client…
Hors mission, nous avons également la chance de pouvoir explorer des projets transverses (R&D, rédaction d’articles) et surtout, de pouvoir compter à tout instant sur la communauté Quantmetry, très active sur Slack, notre système de messagerie interne.
*
Enfin, très active au sein de la communauté Data et IA de Paris, Quantmetry est également connue pour ses projets de veille et de R&D, ainsi que pour des initiatives telles que DataJob, le salon des métiers de la Data, et les meet-ups Paris Data Ladies et AI Engineering.
Présentation de l’expertise AI Product
Afin de répondre aux enjeux d’industrialisation de projets IA de plus en plus complexes et de concrétisation de ROI tangible, Quantmetry a lancé son expertise AI Product. Au sein de Quantmetry, AI Product est donc un pôle d’expertise qui accompagne nos clients dans la conception et la mise en oeuvre de produit IA sur mesure. Ainsi, nos experts interviennent de bout en bout, du cadrage à la mise en production, en passant par la conception et le développement. Voici quelques exemples de nos réalisations :
Transport : Co-construction d’un logiciel de visualisation et d’optimisation d’une offre de service de transport
Energie : Développement d’une application mobile utilisant la computer vision pour identifier des défauts liés à l’entretien d’un réseau de gaz par ses techniciens.
Santé : Développement d’une application pour la télésurveillance médicale
Assurance : Développement d’un Chatbot connecté utilisant des techniques de NLP pour assister les équipes commerciales
Actuellement, nous utilisons notamment les technologies suivantes :
Front-end : TypeScript, ReactJS, React Native
Back-end : Python, Scala, MongoDB, NodeJs, GraphQL,
Infrastructure : AWS, GCP, Azure, D3js, ECharts
Si tu aimes développer et que tu souhaites participer au développement des produits IA de demain, AI Product est fait pour toi !
Descriptif du poste
En tant que Software Engineer chez Quantmetry, vous serez amené à travailler sur des problématiques de :
Ingestion de données (structurées / déstructurées), à des fréquences variables (batch, micro-batch, temps réel)
Mise en œuvre d’outils de stockage appropriés (base de données SQL, No-SQL, espaces de stockage distribués…)
Modélisation du schéma de stockage des données
Mise en œuvre de pipeline de données permettant de gérer les normalisation, enrichissement, mise en qualité, calculs de KPI
Industrialisation et optimisation d’algorithmes de Machine Learning
Gestion du cycle de vie des modèles
Conception et développement d’APIs pour permettre d’exposer la donnée à divers usages
Les développements sont réalisés sur des infrastructures on-premise ou sur des environnements Cloud, et afin d’assurer un haut niveau d’exigence, ces derniers s’appuient sur différentes couches :
Sécurité : authentification, autorisation, audit, logs
Scalabilité, résilience : l’infrastructure matérielle et l’architecture logicielle doivent être en mesure de répondre à ses exigences
Gestion d’équipe et culture :
Développer, maintenir et alimenter la motivation de votre team par une veille technologique constante et un challenge constant du code réalisé
Accompagner votre équipe dans le développement de leurs compétences et dans leur trajectoire de carrière
Participer à l’identification, le test et le recrutement des développeurs de votre équipe pour développer l’activité de Quantmetry
Delivery
Revue régulière de la qualité du code et de l’architecture pour développer des produits performants et scalables
Être garant de la méthodologie, des best practices pour développer un produit data performant et de qualité qui match avec les attentes de nos clients
Développer l’agilité de votre équipe pour améliorer les cycles de production et apporter de la valeur à nos produits : Concevoir, designer et implémenter nos produits data & Utiliser les technologies Front End et/ou Back End
Et, comme nous savons à quel point il est primordial pour vous de garder un lien avec la technique, nous encourageons nos équipes à consacrer de votre temps sur l’année à des projets transverses de R&D en abordant des sujets d’architecture et de développement de produits IA.
Profil recherché
Vous avez…
Un diplôme d’ingénieur ou en informatique
Au moins 3 ans d’expérience en tant que Software Engineer ou sur un poste similaire, ou l’envie de vous orienter vers la Data
De solides compétences en Python, Spark (ou autre technologie similaire type Beam), Hadoop, SQL/MySQL/NoSQL, Scala et l’envie de travailler avec des technologies telles que Kubernetes
Travaillé sur le Cloud (AWS, Azure, Google Cloud Plateform) et connaissez l’architecture serverless
Une culture CI/CD
Un mindset « programmation objet/fonctionnelle »
Point Bonus : des connaissances en technologies Front-end !
Nous recrutons avant toute chose des personnes ayant une forte appétence pour l’IA, capables d’assumer la double casquette de consultant et expert technique alors, n’hésitez plus !
Date de début : ASAP
*
Statut : Cadre
Type d'emploi : Temps plein, CDI
Expérience:
Software Engineer: 3 ans (Souhaité)"
Issy-les-Moulineaux (92),Stage,,Stage Data Science (H/F),Withings,- Issy-les-Moulineaux (92),"Fondée en 2008 par Eric Carreel, Withings a su préserver son agilité et son esprit start-up.
En quête incessante d’innovation, nous travaillons chaque jour avec passion et innovation afin d’ouvrir de nouvelles voies dans le domaine de la santé connectée.
Nous croyons en un monde où nous pourrions prévenir plutôt que guérir et ainsi redonner aux individus le contrôle de leur santé.
Notre exigence d’excellence nous permet de développer des objets connectés et des applications qui permettent à tous de mesurer, de suivre ce qui est important pour leur santé et de prendre les bonnes décisions pour atteindre leurs objectifs :
Suivre son poids
Être plus actif
Mieux dormir
Surveiller sa tension artérielle
Surveiller son rythme cardiaque
Etc
Chaque jour, des milliers de produits beaux et au design non intrusifs sortent de nos usines grâce à la collaboration entre nos équipes pluridisciplinaires. Nos balances connectées, nos montres hybrides, nos tensiomètres et nos moniteurs de sommeil sont aujourd’hui utilisés par des millions d’utilisateurs à travers le monde.
Nos bureaux à Issy les Moulineaux, Boston et Hong Kong nous permettent d’avoir une vue d’ensemble du marché des objets connectés en santé et de rester parmi les leaders du secteur.
Notre objectif à moyen terme ? Agrandir notre tribu et travailler tous ensemble pour révolutionner la manière dont on prend soin de notre santé !

Vos missions
Intégré(e) au sein de l’équipe Data science, tu auras la responsabilité suivante:
Maîtrise du corpus des données disponibles et de leur qualité
Recherche algorithmique pour analyser les données pertinentes et partage avec l’équipe
Réalisation de prototypes par la mise en pratique des méthodes retenues
Implémentation de services sur la plateforme ou dans les produits Withings, en tenant compte des contraintes de ressources et de temps d’exécution
Proposition de fonctionnalités nouvelles pour les applications et produits Withings
Lien avec les équipes de Recherche Appliquée et de Développement Produit pour comprendre les données recueillies (notamment leur qualité, leur lien avec la physiologie et le fonctionnement interne du produit) et proposition d’améliorations
Requirements
Formation bac+5 ou doctorat, type école d’ingénieur ou équivalent
Solides connaissances théoriques en statistiques, machine learning, algorithmie
Fortes compétences informatiques : calcul scientifique, Python
Rigueur, autonomie, initiative, curiosité
Connaissances en traitement de signal, R, C/C++ appréciées
Anglais
Benefits
Tu hésites ? On te dit pourquoi il faut nous rejoindre :
Nos équipes sont jeunes, dynamiques et travaillent avec passion
Nous avons gardé notre esprit start-up et aimons célébrer ensemble chacune de nos réussites !
L’agilité et la réactivité sont nos maitres mots
Tu deviendras beta testeur et tu contribueras directement au développement et à l’amélioration continue de nos produits
Nous sommes des mordus de sport et t’accueillerons avec plaisir dans nos différentes teams
Nous sommes situés sur la ligne 12 (Porte de Versailles ou Corentin Celton), entourés de plusieurs restaurants (italien, libanais, asiatique, fast-food etc) mais aussi de parcs et de complexes sportifs
Travailler chez nous, c’est bien plus qu’un simple job, c’est devenir un Withinger à part entière (avec toute la bonne humeur et l’excellence que cela exige)"
Paris (75),CDI,60 000 € - 70 000 € par an,Lead Technique Data Science,Harnham US,- Paris (75),"Lead Technique Data
Paris, France
60-70K
Au sein d'une belle société dans le domaine de l'assurance à taille humaine, vous rejoindrez un datalab pluridisciplinaire de 20 personnes pour travailler sur des sujets novateur dans le domaine assurance et qui touchent à tous les métiers de l'entreprise. Vous jouerez le rôle de référent technique et apporterez une seniorité et une maturité sur des problématiques d'industrialisation de POCs data, et avez un esprit DevOps afin d'améliorer le code en permanence.
LE POSTE
Hiérarchiquement directement du Head of Data, vous avez un rôle stratégique avec de l'impact sur tous les projets tech du datalab
Vous ferez un état des lieux des solutions techniques en internes, des plateformes, et amorcerez la roadmap data science
Vous tirerez profit de la grande volumétrie de donnée
Vous travaillerez sur la création d'algos du côté Machine Learning et Deep Learning, qui appuieront le business sur tous les pans (Assurance, Marketing, Opération, Plateforme tech..)
Environnement technique : Python, Spark, Scala
VOTRE PROFIL:
Background académique sur un sujet pertinent (IT, Computer Science, Data Science...)
Idéalement au moins 4 ans d'expérience sur des problématiques Data Science et Engineering
Un doctorat, ou une sensibilité recherche et POCs sera un plus, car vous pourrez être amené à travailler sur des sujets de recherche
Grande rigidité dans le développement, création de code qualitatif, et esprit DevOps
Expérience prouvée sur des problématiques Data Science au sein d'une équipe data dans l'industrie (non académique)
COMMENT POSTULER:
Merci de me faire part de votre CV à jour et je vous recontacterai au plus vite."
Paris (75),,,P&C Actuarial Analyst - (F/H),GIE AXA,- Paris (75),"Would you like to wake up every day driven and inspired by our noble mission and to work together as one global team to empower people to live a better life?
Here at AXA we strive to lead the transformation of our industry. We are looking for talented individuals who come from varied backgrounds, think differently and want to be part of this exciting transformation by challenging the status quo so we can push AXA - a leading global brand and one of the most innovative companies in our industry - onto even greater things.
In a fast-evolving world and with a presence in 64 countries, our 166,000 employees and exclusive distributors anticipate change to offer services and solutions tailored to the current and future needs of our 103 million customers.
The headquarters of the AXA Group, based in Paris 8th, brings together the Group's corporate activities. It coordinates the various entities with the Group's strategy and is responsible for managing international projects. The headquarters has approximately 830 employees and is distinguished by its strong international culture (45 nationalities).
Direction Presentation:

GRM’s mandate is to ensure a sustainable and profitable growth of AXA activities worldwide and promote excellence on both Risk Management and Technical areas (e.g.: Product, Pricing, Underwriting, PMP, Claims, Reserving, …).
Inside the GRM, P&C Retail Team has multiple roles and responsibilities, of which the promotion of Technical Initiatives to foster profitable and sustainable growth to the entities.
Primary Missions:
The main mission of this internship will be to study and find a way to monitor and promote efficiently the Customer Value of a client corresponding to the global profitability of a customer throughout several lines of business. This study will be done in partnership with one entity of AXA, multiple interactions must be planned to fulfil their requirements.
The mission will include at least the following points:
Define an efficient way to measure the Customer Value
Use statistical approach(es) to analyse the future Profitability
Compare the result of a Customer Value vs a Mono Product Strategy and identify strengths and weaknesses of the two methodologies
Use Technical approach(es) to derive metrics to foster profitable and sustainable growth
Present the results of the study to the AXA community through a Webex or a Conference with several entities.
Ideally, propose a generalisation of the methodology through Guidelines, Tools, etc.
In addition to that mission, the intern could provide ad-hoc support to P&C Retail Team missions (pricing review, tools development, technical innovations identifications, technical communities participation/animation …)
Qualifications
Technical & Professional Skills:
Strong P&C Retail Mathematical Skills, preferably knowledge of P&C Retail Pricing
Good programming skills in R and/or Python, eventually SAS and/or SQL
A strong interest in understanding of personal lines products from an Underwriting & Pricing perspective
Data science skills would be a bonus
Soft Skills & Competencies:
Ability to work in network
Good autonomy in research and execution
Strong skills in communication
English: Fluent
Background & Experience:
Student in Actuarial Science or Engineering
You wish to give a new orientation to your career within an International & Dynamic Group, join us. Please apply on line.

About AXA
Would you like to wake up every day driven and inspired by our noble mission and to work together as one global team to empower people to live a better life? Here at AXA we strive to lead the transformation of our industry. We are looking for talented individuals who come from varied backgrounds, think differently and want to be part of this exciting transformation by challenging the status quo so we can push AXA - a leading global brand and one of the most innovative companies in our industry - onto even greater things.
In a fast-evolving world and with a presence in 64 countries, our 165,000 employees and exclusive distributors anticipate change to offer services and solutions tailored to the current and future needs of our 107 million customers.
The headquarters of the AXA Group, based in Paris 8th, brings together the Group's corporate activities. It coordinates the various entities with the Group's strategy, and is responsible for managing international projects. The headquarters has approximately 800 employees and is distinguished by its strong international culture (39 nationalities).
What We Offer
We provide you regular career opportunities in international teams. If you want to join us, don’t hesitate to apply !
Information provided by applicants will be processed in strict confidentiality and may be used exclusively for recruitment processes."
Paris (75),,,"Senior Manager, Supply Chain Data Science EU",Amazon France Services SaS,- Paris (75),"A Master Degree in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics) or equivalent experience
10+ years of industry experience in predictive modeling, data science, and statistical analysis
Track record of leading complex and ambiguous data science projects with multiple stakeholders to deliver measurable business value
Experience managing virtual teams
Ability to write production level code in R or Python
Knowledge and experience of writing and tuning SQL
Experience using ML/data libraries, such as scikit-learn, Pandas, and DL frameworks such as Theano, Keras, TF
Experience in building models based on Recurrent Neural Networks (e.g. LSTM) to forecast time series
Track record of working hand in hand with business and operations partners at all levels to deliver multi-million dollars business impact
Ability to speak and write about complex technical concepts to broad audiences in a simplified format

Excited by using massive amounts of data to develop Machine Learning , Deep Learning, and Operations Research models? Want to help set the standard in data science for operations? Want to solve complex problems with science and see your solution implemented in the field, impacting hundreds of thousands employees and dozens of millions customers?
At Amazon Supply Chain & Analytics Europe, we are forecasting, planning, and optimizing in real time the flow of millions of products and orders each day across Europe throughout our fulfillment network. We apply machine learning, operations research, and commons sense to large volumes of data and against a wide spectrum of problems.
In particular, our Supply Chain Data Science team is solving for the most complex of those challenges. This is a very exposed team at the cross-road between Retail, Operations, and Software Development. If you have experience with machine learning, analytics, and operations research, we’d like to have you join our team. You will get to work within an innovative company, with great teammates, and have a lot of fun.

The position is based in Amazon European headquarter in Luxembourg, Europe’s most multicultural capital with 152 foreign nationalities representing 65% of its population!
It could also be based in London, UK or Paris, France if any of these locations are more suitable to the successful candidate.

A successful candidate will be a person who enjoys diving deep into data, doing analysis, discovering root causes, and designing long-term solutions. It will be a person who likes to have fun, loves to learn, and wants to innovate in the world of industry-AI.
Responsibilities will include:
Design a vision for Data Science and OR in Supply Chain Operations and execute it
Build and maintain a healthy portfolio of short-term incremental and longer-term paradigm shifts projects
Recruit, coach, grow, and manage a team of scientists and engineers
Imagine and design innovative OR and ML models (inc. deep learning) aimed at optimizing or forecasting Amazon Supply Chain flows (anomaly detection, granular forecasting, automated planning and optimization)
Deliver ML / DL / OR projects from beginning to end, including understanding the business need, aggregating data, exploring data, building & validating predictive models, and deploying completed models to deliver business impact to the organization.
Be a thought partner to our global software product development team to improve current algorithms and foster innovation.
Proactively propose new workflows to either improve accuracy, optimization or automation with ML.
Perform advanced statistical analysis of operational and performance metrics.
Be part of the Amazon data science community: get inspired by and inspire others. In particular, run our EU Operations wide Data Science community
Example of projects you could work on: forecast what products 3rd party sellers will store in our fulfillment center, real time estimation of the impact of deviating from our plan , anomaly detection in inbound flows, reinforcement learning based flow optimization, end-to-end supply chain surrogate simulation
Amazon is an equal opportunities employer. We believe passionately that employing a diverse workforce is central to our success. We make recruiting decisions based on your experience and skills. We value your passion to discover, invent, simplify and build.

By submitting your resume and application information, you authorize Amazon to transmit and store your information in the Amazon group of companies' world-wide recruitment database, and to circulate that information as necessary for the purpose of evaluating your qualifications for this or other job vacancies.

PhD in a highly quantitative field (Computer Science, Machine Learning, Operational Research, Statistics, Mathematics, etc.)
Proficiency in Operations Research (LP, nLP, IntP, goal programming etc)
12+ years of industry experience in predictive modeling and analysis
Publications in recognized Machine/Deep Learning, Statistics, Applied Mathematics, or Computer Science journals or conferences
Track record of hiring and developing scientists and engineers
Experience with AWS technologies like Redshift, S3, EC2, Data Pipeline, Sagemaker, Lambda, & EMR
Track record of dealing well with ambiguity, prioritizing needs, and delivering results in a fast pace environment
Experience with data visualization tools (e.g. Tableau, Shiny, d3.js, Matplotlib)"
Paris (75),CDI,,Docteur en Data Science / Deep Learning et Computer Vision,Sept Lieues,- Paris (75),"Filiale médicale développée il y'a trois ans avec une équipe à taille humaine (15aines de personnes).
Structure historiquement portée sur l'innovation, la R&D notamment en imagerie.
Vous travaillez sur des dispositifs médicaux à destinations de spécialistes.
LE POSTE / LES MISSIONS
Vous travaillez au sein d''une équipe pluridisciplinaire, en lien direct avec le CTO en méthode Agile.
Vos missions seront les suivantes :
Etre charge de l'ingénierie, du développement et de la validation scientifique et médicale d'algorithmes IA
Assurer une veille scientifique Computer Vision et IA en imagerie médicale
Développer et implémenter des algorithmes de deep learning
Travailler sur des projets de reconnaissances cellulaires
Analyse de données médicales
Rédaction de papiers
PROFIL RECHERCHÉ
Profil recherché :
Vous êtes Docteur
Avoir une première expérience professionnelle
Compétences en Machine et Deep Learning
Maîtrise de Python, JAVA
Environnement cloud"
Montrouge (92),"Apprentissage, Contrat pro",,Alternance - Inspecteur-Auditeur SI/Data H/F,Crédit Agricole S.A.,- Montrouge (92),"Société cotée, Crédit Agricole SA est l'organe central de contrôle du Groupe Crédit Agricole.
Son organisation est au service de la stratégie et de la performance du Groupe en coordination avec les filiales et les lignes métiers.
Crédit Agricole SA regroupe et anime ses filiales spécialisées, au service des Caisses régionales et des réseaux bancaires du Groupe.
Référence
2020-47425
Date de parution
17/05/2020
Description du poste
Type de métier
Types de métiers Crédit Agricole S.A. - Inspection / Audit
Types de métier complémentaires
Types de métiers Crédit Agricole S.A. - Systèmes d'information / Maîtrise d'Ouvrage
Type de contrat
Alternance / Apprentissage
Durée (en mois)
12
Date prévue de prise de fonction
01/09/2020
Poste avec management
Non
Cadre / Non Cadre
Non cadre
Missions
Pour que votre candidature soit prise en compte, merci d'indiquer sur votre CV le type de contrat d'alternance préparé et le rythme d'alternance.
Présentation du service:
L'Inspection Générale Groupe veille à la bonne maîtrise des risques et au respect de la réglementation. Elle joue un rôle clé pour permettre d'inscrire le développement du Groupe Crédit Agricole dans une trajectoire de risques maîtrisés.
Les équipes d’Inspection réalisent des missions dans l’ensemble du Groupe (banque de proximité, banque de financement et d'investissement, gestion d'actifs, assurance vie et dommages, services financiers spécialisés…), tant en France qu'à l'International.
Descriptif de la mission:
Rejoignez les équipes d’inspection pour contribuer, sous la supervision d’un Chef de mission, à l’évaluation du dispositif de maîtrise des risques informatiques (sécurité du SI, projets, production informatique, etc.) et data sur le périmètre de la mission. Vous participerez aux différentes phases de la mission (cadrage, investigations, rédaction) et serez amené à assurer la restitution de vos constats et conclusions auprès des audités sur le périmètre qui vous aura été confié.
Vous contribuerez à la veille technologique et participerez aux chantiers et projets transverses de la direction.
Cette expérience vous permettra de travailler sur des sujets à forts enjeux, dans un environnement dynamique et évolutif, en vous appuyant sur des méthodologies rigoureuses et des techniques innovantes (analyses big data, nouvelles technologies).

Si vous aimez le travail en équipe, le challenge, faites preuve de rigueur, d’esprit d’analyse et de synthèse et avez une forte capacité d’organisation, alors rejoignez-nous !

Tous nos postes sont ouverts aux personnes en situation de Handicap.
Localisation du poste
Zone géographique
Europe, France, Ile-de-France, 92 - Hauts-De-Seine
Ville
Montrouge
Critères candidat
Niveau d'études minimum
Bac + 5 / M2 et plus
Formation / Spécialisation
Formation : École d'ingénieurs, 3ème cycle universitaire, école de commerce.

Spécialisation :
SI ;
Informatique décisionnelle ;
Statistiques ;
Audit.
Niveau d'expérience minimum
0 - 2 ans
Compétences recherchées
Compétences métiers :
Maîtrise du traitement informatique des données à des fins d'analyse ou de statistiques (SQL Server, SAS, Access).

Compétences transverses :
Rigueur, discrétion, capacités d'analyse, de synthèse, d'organisation et à hiérarchiser ses priorités.
Goût du travail en équipe, faculté d'adaptation, curiosité intellectuelle.
Bonne communication orale et écrite, sens pédagogique.

Rythme préféré : Présence continue en entreprise sur la période de septembre à décembre ou janvier à avril ou mai à juillet.
Outils informatiques
Pack office, access, SQL Server, SAS.
Connaissances appréciées en DataViz (Power BI, MicroStrategy…), en programmation (Python, R, Cypher…), en Big Data.
Langues
Anglais opérationnel courant – la maîtrise d'une autre langue est un plus"
Paris (75),,,Supply Chain Engineering,NeuroChain,- Paris (75),"If you are a thinker, risk-takers, and problem solver, we would love for you to join our team. The team is responsible for end-to-end execution within the supply chain handling quote to delivery and everything in between. We are working to integrate new technology such as Blockchain, artificial intelligence and big data into the process and day-to-day lives. With dual headquarters in Paris, France, you are sure to bump into executives and senior leaders in the elevator, in the cafeteria or in one of our high competition corn hole tournaments.
There are many Engineering opportunities in the Global Supply Chain varying from roles in Procurement, Fulfillment, Packaging, and Operations. You will also gain exposure across multiple disciplines in our engineering organization such as Manufacturing, Test, Systems and Quality.
your will provide you with the opportunity to gain understanding of the organization, expand your network, find mentors, and to explore and attain new skills while gauging interest in multiple fields and roles. If you are looking for more than just an opportunity, this is a place for you to grow, develop and learn.
What You Will Do:
As a Global Supply Chain Engineering, you may have the opportunity to:
Leverage and analyze data to develop dashboards
Understand python code and error logs to identify root causes
Familiarize yourself with the test cycle and process of products
Research certain aspects of problems or tasks and provide a recommendation
Transform large data into meaningful insights
Develop interactive dashboards on visualization tools with cross-functional teams
Challenge existing engineering concepts and improving system processes
Support decision-making by leveraging data analytics
Explore various project management tools and promote productivity.
Develop applications within Sharepoint and Redmine for teams within Lenovo to improve work efficiency.
Work with the command line in a Linux environment.
Position Requirements
You definitely are:
Pursuing a degree in Electrical Engineering, Mechanical Engineering, Industrial Engineering, Systems Engineering, Computer Science or related
An excellent student who has earned at least a GPA of 3.2
Able to think critically and use your problem solving skills to determine the number of ping pong balls in a 10ft box
Enthusiastic and eager to communicate with teammates from China, Scotland, and Mexico
A team player with good interpersonal skills
Eager to brainstorm fresh and creative approaches to problems
Self-motivated and driven to perform across diverse work environments
Unapologetically curious
It would be a plus if you:
Have experience in using tools and software related to your major
Are able to effectively and succinctly present your ideas
Are a self-starter who can hit the ground running with some initial guidance
Are willing to explore and try new things

For information on how to apply for a job, please send your application to hiring@neurochaintech.io"
Paris (75),,,Data engineer - Paris (FR) - Video/Photo Production,Digital Source,- Paris (75),"Company Overview:
Our client is a community platform taking care of every image needs of their customers. They work with diverse and international professionals to deliver creative and authentic work. Their mission is simple: taking care of video/photoshoots for every type of businesses.
Your Missions:
As a Data Engineer, you will:
Add value to the business team by optimizing the existing tools
Create and optimize the data warehouse
Maintain the platform quality
Be a bridge between the business and the data environment
Deliver high-quality data that will help to take business decisions
Your profile:
You have 2/3 years of experience as a Data Engineer.
Soft Skills
You are creative, and you like to propose new ideas.
You are persuasive, and you have strong communication skills.
You can adapt, and you are confident about working with the non-technical teams.
You speak and write perfect French.
You speak and write great English.
Hard skills
You have strong knowledge in Python and SQL (Pandas libraries, NLP)
You can build and maintain ETL and Data Warehouse
AWS/GCP first experience
Bonus
You like Statistics/Machine Learning
Scala experience
Docker knowledge
Their offer
Competitive salary
Offices in the heart of Paris
Join a company with great growth at international
Do you want to integrate this position?
Don’t wait, and apply right now! You can also send your CV directly to frederic@digitalsource.io


8124"
La Défense (92),Stage,,Stage de recherche – Outil BI pour la TRA (GOTTRA) -Altran Research,Altran,- La Défense (92),"Le candidat devra :
Enrichissement et amélioration des études effectuées sur les découpages et structuration des projets établis pour les différents projets TRA Altran
Proposition et développement de nouveaux indicateurs de base pour qualifier l’offre TRA et élaborer de nouveau KPI
Développement d’une structure de projet standard basée sur des standard comme le ISTQB® (International Software Testing Qualifications Board)
Elaboration d’un outil d’intégration de données permettant de reconnaître de manière semi-automatique les structures et découpages projet et de faire le mapping entre ces structures et le format standard adopté
Proposition de reporting pour représenter les KPIs proposés
Implémentation des modules d’integration de projets et des KPIs développés dans la version actuelle de l’outil l’outil GOTTRA
Proposition d’une extension de l’outil GOTTRA à une plateforme Big Data
Formaliser les travaux effectués et tous les résultats obtenus dans un rapport de stage accompagné de l’ensemble des algorithmes et programmes développés.
Vos responsabilités
Formation ingénieur
Programmation : javascript, HTML, JAVA J2EE, Python ou Perl
Formalisation et conception : architecture MVC et SOA, modèles UML et MCD
Framework : Spring MVC
Connaissance en BI (intégration des données + reporting)
Connaissance en statistiques
Autonomie, ouverture d’esprit
Maitrise des outils informatiques
Votre profil
Depuis quelques années, le test est reconnu comme une activité essentielle pour garantir le niveau de qualité d’un système d’information livré, de ce fait il est devenu un domaine d’expertise spécifique en termes d’outillage et de méthodologie. Néanmoins, chiffrer précisément un projet de tests reste aujourd’hui une tâche complexe, même pour un acteur expérimenté. Nos clients se servent donc le plus souvent du Taux Journalier Moyen comme référence afin d’évaluer une prestation, sans prendre en compte l’efficacité atteinte par l’équipe en question grâce , entre autre, aux processus ou au professionnalisme des intervenants.
L’objectif global du projet GOTTRA –Généralisation des OuTils de TRA- est d’industrialiser le processus de chiffrage des Tiers-Recettes Applicatives (TRA) et de capitaliser sur les expériences faites en termes d’impact de l’industrialisation du test sur son efficacité et sur les charges associées, notamment dans le contexte d’une TRA. Nos travaux se concentrent donc initialement sur l’estimation des charges de tests en s’appuyant sur des technologies BI et d’Intelligence Artificielle. Les résultat escompté de ces travaux est un outil pour le chiffrage des TRA.
Afin d’arriver à cet objectif, les axes d’investigation suivants sont à poursuivre :
Industrialiser l’estimation des activités de test.
Capitaliser sur notre expérience faite sur des projets de recette.
Calculer une charge normalisée basée sur des techniques statistiques et du Machine Learning.
Développer des facteurs d’analyse globeaux pour la TRA.
Comme indiqué dessus, la capitalisation sur l’expérience acquise dans les projets réalisés est un axe majeur de développement de GOTTRA. Cette capitalisation concerne l’amlioration de la qualité des chiffrage des projets futurs et la maîtrise de leur risques, et l’élaboration et l’alimentation d’un ensemble d’indiquateurs permettant de mieux qualifier l’offre TRA chez Altran. La deuxième partie est en soit une application BI pour qualifier l’offre TRA d’Altran. Dans ce stage nous envisageons développer des indicateurs de performances pour qualifier l’offre TRA chez Altran avec des possibilités de faire des prédiction de l’évolution de cette offre. En plus nous essayerons de répondre à la problématique de l’intégration des données projets. Ces données ont des structures différentes en fonction des découpes et de l’organisation projet établie par les responsables de ces projets. Ces indicateurs et cette intégration seront embarqués dans un portail web.
A propos d’ALTRAN RESEARCH
Altran Research est le département de Recherche interne d’Altran en France. Ses programmes de recherche adressent les domaines de l’e-santé, des transports terrestres et de la mobilité, de l’aéronautique et du spatial, de l’industrie et des services du futur, de l’énergie, des systèmes complexes.
Les projets, développés dans une perspective de développement durable, font intervenir des expertises variées en vue de développer :
de nouvelles méthodologies, de nouveaux outils, de nouvelles offres de services permettant d’apprécier la vraie valeur durable des solutions en évaluant leur impacts sociaux, environnementaux et économiques
de nouveaux produits, démonstrateurs ou systèmes complexes. Ces solutions sont modélisées et validées, à la fois sur le plan fonctionnel, technologique et systémique.
Altran Research intègre dès les premières phases de la vie d’un produit ou d’un service, l’ensemble des impacts potentiels d’une solution, et participe ainsi à la création d’innovations « responsables »."
Paris (75),CDI,,Senior Data Engineer,Client Server,- Paris (75),"Senior Data Engineer (ETL Python). Would you like to progress your career at a global technology company?

As a Senior Data Engineer you will contribute to the core product, a cutting edge valuation and forecasting system for the real estate / property markets. You'll take ownership of substantial parts of the data engineering systems, mining a wide range and variety of new datasets; your work will span many aspects from building the infrastructure (Spark on Kubernetes) to creating Machine Learning models to extract features from raw data and generating data pipelines to process and expose new data sources. You'll consolidate, improve and link data to generate data sets that no-one else has available, continually seeking improvement and coming up with ideas to improve engines and products.

You'll join an upbeat team based in Central Paris with casual dress code, free fruit and a friendly team atmosphere. The company is able to help with relocation to Paris for European citizens but is cannot sponsor visas.

Driven by technology the company is able to conduct a remote interview and onboarding process during the current social distancing measures.

Requirements:
Outstanding record of academic achievement; MSc or PhD preferred in Computer Science or Applied Mathematics (will consider other scientific / numerate disciplines)
Strong commercial experience as a Data Engineer
Strong Python coding skills
Advanced knowledge of basic Data Structures and Algorithms
Strong ETL skills and experience with data processing tools such as PySpark, PostgreSQL, Luigi
Familiar with software engineering practises such as clean code, TDD
Ideally you will also be familiar with Docker, Kubernetes and core Machine Learning concepts
Fluent English language skills required

As a Data Engineer you will earn a competitive salary (to €70k, depending on skillset and depth of knowledge) plus bonus and benefits.

Apply now or call to find out more about this Senior Data Engineer opportunity."
Paris (75),"Temps plein, CDI",60 000 € - 80 000 € par an,Développeur Backend / Data - Senior H/F,EASY PARTNER,- Paris (75),"Contexte du poste
Une Startup extrêmement ambitieuse de mise en relation entre entreprises et travailleurs s'appuyant sur l'innovation technologique recherche un(e) Développeur(se) Backend orienté(e) Data pour rejoindre son équipe tech.
Missions
* Contribuer aux développements backend de modèles de données et d'algorithmes
* Grande autonomie et développement de fonctionnalités de plus en plus stratégiques
Stack technique
* Frontend: React/Redux
* Backend: NodeJS, Mongodb, Elasticsearch, RabbitMQ
* Mobile: Kotlin/Swift
* Data: Python, Segment, RedShift
* SRE & Test automation: Heroku, Kibana, Docker, Selenium
Profil
* Idéalement 6 ans d’expérience en développement backend avec Node.js et Python dans un environnement Data
* Des connaissances en Data Science, algorithmie avancée, Mongodb et Elasticsearch sont un gros plus !
* Expérience dans un environnement agile à très forte croissance
* Esprit d'équipe et entraide
* Bon niveau d'Anglais écrit et oral
* Capacité d’adaptation et apprentissage rapide de nouvelles technologies
Avantages
* Télétravail possible le jeudi
* RTT
* Perspectives d'évolution rapide
Pourquoi les rejoindre
* Une équipe solide et très compétente (les leads ont plus de 10 ans d’expérience)
* Forte autonomie
* Entraide
* Rejoindre un projet et une entreprise qui décollent, et ce n'est que le début !
Avantages :
Titre-restaurant / Panier
RTT
Participation au transport
Type d'emploi : Temps plein, CDI
Salaire : 60 000,00€ à 80 000,00€ /an
Expérience:
développeur backend / data - senior h/f ou similaire: 6 ans (Souhaité)"
Paris (75),,,Junior Software Engineer,Alkemics,- Paris (75),"ABOUT ALKEMICS
Alkemics connects brands and retailers to help them market & sell their products everywhere, driving business growth, by allowing them to collect, enrich, and share product data across the retail ecosystem.
Our mission is to connect every brand with every retailer in the world. Our platform streamlines the management of digital product content (i.e., packaging, ingredients, visuals, promotions, rich media), extracts structured metadata for optimal quality and usability, and automates delivery to retail partners and third party service providers.

Founded in 2011, and backed by world renowned investors (Index Ventures, Serena Capital, Cathay Innovation, Partech Ventures, among others), Alkemics consists of 70+ talented employees, and has offices in the very heart of Paris.

Our startup culture allows for very flat hierarchy, and for everyone, regardless of seniority, to have a big impact. We are looking to continue building a kickass team, so if you're looking for a new challenge, give us a sign!


At Alkemics, every day is different, but your main missions will include:
Participate in sprint planning to analyze, negotiate, evaluate tasks of our SaaS platform
Design solutions as a team taking account debt creation, planning and timing, development cost
Implement solutions that are scalable and reliable using cutting edge technologies:
Python and Golang for backend
Javascript with ReactJS + Redux for frontend
Mysql, Couchbase, and Elasticsearch as data storage
Anticipate and propose needed technical and architectural changes to ensure the implementation of upcoming features
Requirements
What we're looking for in you:
A broad knowledge and a genuine curiosity about software development
A deep capacity to get things done
A passion to work with cool technologies to better the world
Experience designing scalable systems following architecture best practices
1+ years of XP working in a strong engineering environment
Fluency in English. French is a plus.
Benefits
What you’ll get from us ?
A true startup experience in one of the fastest growing startup in Paris: no bureaucracy and daily successes that have a real impact on the business
You will participate to the team's growth and the revolution of the CPG industry
A fast-learning curve with growing responsibilities
Pushing the limits: use semantic analysis, ontologies, big data and machine learning to solve complex problems in the CPG industry.
Working with dynamic, smart and passionate people
Extras: weekly sport sessions, meditation, hackathons, team offsites, lunch sessions."
Paris (75),,,Data Privacy and AML Legal Advisor - (F/H),GIE AXA,- Paris (75),"The “Data Privacy and AML Legal Advisor” role is to assist the Global Program Manager in steering and running the Global Financial Crime Compliance Technology Programme (GFCCT) on Data privacy & legal topics

The GFCCT is a Group wide initiative and covers all AXA entities and all relevant business lines. The strategic intent is to ensure that AXA has the capability to meet its current and future FCC regulatory obligations (wherever they arise) by creating a common “backbone” of technology this is both flexible and cost effective.

There is a compelling set of internal and external drivers and imperatives for AXA to enhance its current FCC technologies which will also improve our Group oversight and FCC Framework. This is an opportunity to take our FCC controls to the next level, contributing to the creation of the ‘strong backbone’ across the Compliance function.
Technology is a strong enabler - the backbone of FCC technology solutions includes:
Transaction monitoring for suspicious activity (AMM), based on a single view of customers
Automated customer AML risk-ranking (CDD/CRR) - based on customer attributes, behaviour patterns, customer screening – and then automatically integrated with transaction monitoring to risk-rank transaction alerts that are generated.
Automated customer identity verification (ID&V), using new biometric/facial recognition technology
Automated processes to ascertain the beneficial owners (World-Check, BVD, Factiva, …) of entity customers, using new specialized ownership databases.
“Real-time” pre-screening (RT WLM) of new customers against sanctions lists (instead of after-the-fact batch screening).
In October 2018 decided to launch a Global FCC Technology (GFCCT) Programme established under our collective sponsorship, adopting a “One AXA” approach to a centralized roll-out of new FCC technology solutions to operate FCC controls.

Dimensions
The GFCCT Program is a key initiative over a period of 3 to 4 years
All entities of AXA must comply to Financial Crime Compliance regulations as relevant to their business lines
The Programme Sponsors are Deputy Group CEO & General Secretary, Group Chief Operating Office, Head of Group Risk Management
The AML IT Center of Excellence, operating in AXA Group Operations in France, is responsible for Business as Usual (BaU) management of the FCC technologies and associated IT systems
The Global FCC Center of Excellence, operating in AXA Group Operations in India, is responsible for processing the alerts (Level 1 and part of Level 2) that are generated by these controls from the FCC IT systems (BAE Norkom/NetReveal)
Key Accountabilities:

The GFCCT “Data Privacy and AML Legal Advisor” has the key mission to support the Global Programme and AXA entities in the local implementation of FCC controls and provide progress report to the Management.

With a strong legal background, he/she is accountable to translate regulatory requirements into operational needs and find solutions & recommendations on areas where there are conflicting interpretations between Data Privacy and AML regulation. This person should collaborate closely with Group Financial Crime Compliance Officers and entities Data Privacy Officers to propose solutions for Group Data Privacy Officer to validate and approve.

He/she will report on a day-to-day basis to the Global FCCT Program Manager.

The “Data Privacy and AML Legal Advisor” will have the following responsibilities under scope:
Support process to conduct Data Privacy Impact Assessment (DPIA) to evaluate jointly with local Data Privacy Officers (DPO) the regulatory implications of rolling out the NetReveal platform for AML and Sanctions into their respective entities
Assess international and local laws (Data Privacy, AML, Sanctions, …) in order to provide insights on root causes of legal issues and propose solutions and/or work-arounds for approval by relevant legitimate topic owner (DPO or AMLO)
Collaborate with Data Privacy Officers (DPO) of AXA for better understanding of the project and broader mobilization and solutioning on Data Privacy issues
Support on procurement processes and contract reviews

Qualifications
Qualifications:
Bachelor and/or Master’s degree from Business School, Technology or Master in Business Administration (MBA)
Profile
Law graduate
Experienced on Data Privacy, and AML will be a plus
Strive for excellence with deliverables of high quality and ability to work in sometimes tight planning
Demonstrate to be a strong team member with a collaborative mindset.
Experience in the insurance industry
Fluent (both written and oral) in English and French
Technical and professional skills (technical expertise):
Professional experience on Big Data related projects
Experienced in working on complex international projects in AXA and roll-outs into AXA entities
Operational experience with AXA Data Privacy and Chief Data Officer communities
Capacity to challenge status-quo
Capacity to understand AXA business operations and products
Soft skills:
Leadership i.e. exhibits strong results orientation, Change Leadership, adaptability and the ability to drive Collaborative Behavior.
Communication skills, i.e. exhibits strong skills in listening, spoken and written communication, Collaboration and the ability to work in a global team.
Openness and reaching out, i.e. strong human relationship skills, exhibit curiosity and can see opportunities in situations, not just problems.
International profile, i.e. a proven ability to work effectively in an international environment. In addition, exhibits a strong proficiency in English and French minimum skill is a plus

About AXA
Would you like to wake up every day driven and inspired by our noble mission and to work together as one global team to empower people to live a better life? Here at AXA we strive to lead the transformation of our industry. We are looking for talented individuals who come from varied backgrounds, think differently and want to be part of this exciting transformation by challenging the status quo so we can push AXA - a leading global brand and one of the most innovative companies in our industry - onto even greater things.
In a fast-evolving world and with a presence in 64 countries, our 165,000 employees and exclusive distributors anticipate change to offer services and solutions tailored to the current and future needs of our 107 million customers.
The headquarters of the AXA Group, based in Paris 8th, brings together the Group's corporate activities. It coordinates the various entities with the Group's strategy, and is responsible for managing international projects. The headquarters has approximately 800 employees and is distinguished by its strong international culture (39 nationalities).
What We Offer
We provide you regular career opportunities in international teams. If you want to join us, don’t hesitate to apply !
Information provided by applicants will be processed in strict confidentiality and may be used exclusively for recruitment processes."
Paris (75),,,Retail Technical Analyst - (F/H),GIE AXA,- Paris (75),"Would you like to wake up every day driven and inspired by our noble mission and to work together as one global team to empower people to live a better life?
Here at AXA we strive to lead the transformation of our industry. We are looking for talented individuals who come from varied backgrounds, think differently and want to be part of this exciting transformation by challenging the status quo so we can push AXA - a leading global brand and one of the most innovative companies in our industry - onto even greater things.
In a fast-evolving world and with a presence in 64 countries, our 166,000 employees and exclusive distributors anticipate change to offer services and solutions tailored to the current and future needs of our 103 million customers.
The headquarters of the AXA Group, based in Paris 8th, brings together the Group's corporate activities. It coordinates the various entities with the Group's strategy, and is responsible for managing international projects. The headquarters has approximately 830 employees and is distinguished by its strong international culture (45 nationalities).
Direction Presentation:

GRM’s mandate is to ensure a sustainable and profitable growth of AXA activities worldwide and promote excellence on both Risk Management and Technical areas ( e.g. : Product, Pricing, Underwriting, PMP, Claims, Reserving, …).
Inside the GRM, P&C Retail Team has multiple roles and responsibilities, of which the promotion of Technical Initiatives to foster profitable and sustainable growth to the entities.
Primary Missions:
Among these Technical Initiatives, one concerns the Mid-Term Adjustments (MTA) that modify Policy characteristics (e.g: replacement of vehicle, policyholder address …) during its lifetime. These MTA events occurs frequently but their impact on Growth and/or Profitability is rarely assessed within entities.
As part of the P&C Retail Team, the main mission of the intern will be to participate to the MTA Project:
Analyse Portfolio and Market situation on MTA
Identify, Propose & Develop technical initiatives on MTA:
Understand the elements embedded in Pricing (risk models, retention models, …).
Use Technical approach(es) to derive metrics to analyse the future Profitability.
Propose & Develop Optimization methods to determine MTA Pricing Strategies that maximize Profitability in regards with Business Constraints (Growth, Distribution Channels, …).
Evaluate & Compare the strengths and weaknesses of different Optimization methodologies
Share MTA conclusions throughout AXA:
Present the results of the initiatives to the AXA Community
Ensure a clear, efficient & reproducible enough deliverable to be fully handled by local entities.
Provide ad-hoc support in executing MTA technical innovations
This study will be done in partnership with one entity of AXA, multiple interactions must be planned to fulfil their requirements.
In addition to that mission, the intern could provide ad-hoc support to P&C Retail Team missions (pricing review, tools development, technical innovations identifications, technical communities participation/animation …)
Qualifications
Technical & Professional Skills:
Strong Mathematical Skills with attention on Statistical Methods, Pricing and Optimization
Good Programming Skills in R and/or Python, eventually SAS and/or SQL
Data Science Skills would be appreciated
Interest in Retail Products from an Underwriting & Pricing perspective
Soft Skills & Competencies:
Good autonomy in research and execution
Good communication skills
Appetite for innovation
English: Fluent
Background & Experience:
Student in Actuarial Science or Engineering
You wish to give a new orientation to your career within an International & Dynamic Group, join us. Please apply on line.

About AXA
Would you like to wake up every day driven and inspired by our noble mission and to work together as one global team to empower people to live a better life? Here at AXA we strive to lead the transformation of our industry. We are looking for talented individuals who come from varied backgrounds, think differently and want to be part of this exciting transformation by challenging the status quo so we can push AXA - a leading global brand and one of the most innovative companies in our industry - onto even greater things.
In a fast-evolving world and with a presence in 64 countries, our 165,000 employees and exclusive distributors anticipate change to offer services and solutions tailored to the current and future needs of our 107 million customers.
The headquarters of the AXA Group, based in Paris 8th, brings together the Group's corporate activities. It coordinates the various entities with the Group's strategy, and is responsible for managing international projects. The headquarters has approximately 800 employees and is distinguished by its strong international culture (39 nationalities).
What We Offer
We provide you regular career opportunities in international teams. If you want to join us, don’t hesitate to apply !
Information provided by applicants will be processed in strict confidentiality and may be used exclusively for recruitment processes."
Vélizy-Villacoublay (78),Stage,,Stage– Traitement sémantique des données – Conception d'un ETL – Data analyse (TNT) - Altran Research,Altran,- Vélizy-Villacoublay (78),"La mission consiste à assembler un cahier des charge de la plateforme décisionnelle prédictive à partir des études déjà réalisées et en émuler le fonctionnement dans un démonstrateur dont certaines parties sont déjà développées (traitements statistiques des données passées, acquisition des données d’avenir)
Accompagner d’un Chef de projet et d’un comité d’experts technique,, vous devrez en partant des éléments ci-dessus mettre en œuvre les éléments suivants :
Rédiger un document de synthèse de la plateforme décisionnel TNT (documents sur sharepoint)
Elaborer le modèle de données complet et en réalsier une maquette (avec Excel, MySQL)
Intégrer les processus statistiques et sémantique de préparation des données (ETL) pour détection des signaux faibles
Rédiger le cahier des charge du système décisionnel prédictif et première maquette simulant l’intégration
Créer les supports de communication,
Animer des scéances d’information.
Vos responsabilités
Formation type École Ingénieur, ENSC - IMS (École nationale supérieure de cognitique)
Maitrise technique/développement/paramètrage Sharepoint 2013
Autonomie, ouverture d’esprit
Maîtrise du français
Votre profil
Depuis 2009, Altran Research[1](AR) est la structure qui initialise, porte et pilote nos travaux de recherche pour la France. Les responsables scientifiques, chacun dans leur domaine d’expertise, élaborent et mettent en œuvre leur programme de recherche et d'innovation ainsi qu’avec nos partenaires académiques et industriels en mobilisant les forces vives d’Altran. Ils apportent leur savoir et savoir-faire dans le développement de nouvelles connaissances sur six programmes[2] : Conception augmentée, E-santé, Machine-Driven Big Data, Mobilité connectée, Smart Energies et Usine intelligente.
Ces projets de recherche collaboratifs ou autoportés ont cette vertu cardinale de faire travailler ensemble des experts de différentes disciplines pour construire des solutions aux problématiques complexes découlant des défis auxquels notre monde est confronté.
L’un de ces problèmatique est dans notre domaine de forte innovation, est de prévoir ou prédire les besoins en compétences de nos clients dans les 2 années à venir.(Projet TNT) et de décider d’une stratégie d’investissement sur des effectifs capables de les satisfaire (recrutement, formation consultant, débauchage chez les concurrents ) (Projet MATS.P).
Pour cela, dans le cadre du projet TNT/MATS.P, nous sélectionnons ou créons des sources de données nouvelles concernant les compétences, développons une palette de traitements mathématiques ou sémantiques originale et élaborons une plateforme décisionnelle prédictive pour les décideurs en matière de recrutement de consultants.

[1] http://www.altran.fr/innovation/altran-research/a-propos.html
[2] http://www.altran.fr/innovation/nos-programmes-de-ri/6-programmes-de-ri.html

A propos d’ALTRAN RESEARCH
Altran Research est le département de Recherche interne d’Altran en France. Ses programmes de recherche adressent les domaines de l’e-santé, des transports terrestres et de la mobilité, de l’aéronautique et du spatial, de l’industrie et des services du futur, de l’énergie, des systèmes complexes.
Les projets, développés dans une perspective de développement durable, font intervenir des expertises variées en vue de développer :
de nouvelles méthodologies, de nouveaux outils, de nouvelles offres de services permettant d’apprécier la vraie valeur durable des solutions en évaluant leur impacts sociaux, environnementaux et économiques
de nouveaux produits, démonstrateurs ou systèmes complexes. Ces solutions sont modélisées et validées, à la fois sur le plan fonctionnel, technologique et systémique.
Altran Research intègre dès les premières phases de la vie d’un produit ou d’un service, l’ensemble des impacts potentiels d’une solution, et participe ainsi à la création d’innovations « responsables »."
Paris 9e (75),CDI,,"Technical Solutions Engineer, Paris (French speaker)",Criteo,- Paris 9e (75),"Who we are
Criteo (NASDAQ: CRTO) is the global technology company powering the world’s marketers with trusted and impactful advertising. 2,800 Criteo team members partner with over 20,000 customers and thousands of publishers around the globe to deliver effective advertising across all channels, by applying advanced machine learning to unparalleled data sets. Criteo empowers companies of all sizes with the technology they need to better know and serve their customers.

Overview

Based in our Paris office, we are seeking a highly motivated Technical Solutions Engineer for our EMEA Supply team with focus on France and Italy. You will be responsible for qualifying, integrating and supporting the publisher’s solutions offered by Criteo on desktop and mobile environments. This role acts as the hub of the organization, partnering with business development, account management, product and engineering.
What you'll do
Grasp a deep understanding of the Criteo supply offering from a technical perspective
Partner with publishers to understand their business objectives and develop scalable solutions
Manage the technical integration of new publishers and partners on desktop and mobile (including IOS and android applications)
You communicate effectively and clearly to our most important EMEA clients
Test and troubleshoot the publisher’s implementation while providing feedback to their technical engineering team
Solve publisher problems using a variety of analytical and technical tools including traffic analysis, querying databases, troubleshooting client-side code or app SDK
You coordinate with related team members in identifying, reporting, and resolving product issues
Collect regional input and consolidate feature requests that will help to growth the business.

Who you are
You have an engineering background ideally with a computer science related degree as you must demonstrate technical proficiency and interest
You are able to review and debug code in web development technologies such as HTML and JavaScript as well as execute data base queries in SQL
If you have experience on mobile app development and integrating SDK, this is a strong plus
Excellent communication skills, both written and oral, particularly in making technical requirements easy for clients and non-technical partners to understand
You are fluent in French and English; Italian would be a plus
You are an exceptional problem solver, that is you are able to quickly understand varied business needs and translate them into a technical solution.

Why you'll love us
Fun and passionate work environment
35+ annual holidays days
Health insurance
Discounted transport
Private nursery
Maternity and paternity leave
Competitive compensation package
Central location in Paris and amazing rooftop!

Join us to contribute to one of the fastest growing, leading edge technologies in online industry. We work hard, play hard and we share the same passion for e-Commerce, Advertising and Technology. We value team work, openness, technical innovation, and results-orientated thinking.

#LI-JS1

At Criteo, we dare to be different. We believe that diversity fuels innovation and creates an energy that can be seen and felt all over Criteo. We champion different perspectives and are committed to creating a workplace where all Criteos are heard and feel a sense of belonging.

Criteo collects your personal data for the purposes of managing Criteo's recruitment related activities. Consequently, Criteo may use your personal data in relation to the evaluation and selection of applicants. Your information will be accessible to the different Criteo entities across the world. By clicking the ""Apply"" button you expressly give your consent."
Châtillon (92),,,Thèse sur les équilibres corrélés et l'apprentissage - F/H,Orange,- Châtillon (92),"La théorie des jeux est une branche des mathématiques dédiée à la formalisation et à l'analyse de la prise de décisions en situations d'interactions (ex. échecs, Go, économie, enchères, etc.). Les principaux objectifs de l'analyse « non-coopérative » sont la définition de concepts de solutions pertinents, la recherche de profils de stratégies « stables » (existence et calculs) ainsi que l'analyse des propriétés des règles ou algorithmes d'apprentissage implémentés par les joueurs.
Plusieurs notions de stabilités ont été définies. Le concept dominant est appelée équilibre de Nash. Au-delà de la pertinence du concept en lui-même, son succès est essentiellement due à une existence systématique dans les jeux finis [6][7] et à des conditions relativement faibles dans un grand nombre d'autres classes de jeux. En dépit de ces propriétés, il peut être difficile de calculer un équilibre de Nash [8] à cause de la combinatoire sous-jacente.
Un concept de solution plus général, appelé « équilibre corrélé » a été proposé en [1]. Les équilibres corrélés généralisent les équilibres de Nash en introduisant une synchronisation collective sous la forme d'une distribution jointe des stratégies aléatoires (non réduite à une forme produit, i.e. supposant l'indépendance des stratégies aléatoires). Cette corrélation peut être due à une communication entre les joueurs, à une recommandation par un médiateur ou à une synchronisation émergeant d'un partage d'information. En dépit de la généralisation, les équilibres corrélés bénéficient de la propriété d'existence des équilibres de Nash. Ils sont également moins complexes à calculer [8].
Du point de vue de l'apprentissage et du machine learning, les équilibres corrélés ont également montré leur intérêt. Des conditions (assez faibles) sur les jeux et schémas d'apprentissage basés sur le regret induisant la convergence de la séquence de profils de stratégies jouées vers l'ensemble des équilibres corrélés ont été obtenues [3].
Il a également été montré en [5] que tout jeu fini peut être projeté en une réduction duale ou un jeu élémentaire plus simple (moins de stratégies) mais héritant tout de même de certains équilibres corrélés du jeu de départ…
Les propriétés précédentes ont d'importantes conséquences algorithmiques mais servent aussi d'appui pour justifier des équilibres corrélés comme d'une alternative pertinent au concept de Nash.
Du point de vue pratique et des applications, les équilibres corrélés, leurs propriétés et les méthodes de réductions sont particulièrement pertinents pour l'analyse des systèmes complexes et des jeux où les équilibres de Nash sont difficilement calculables ou pour lesquels le comportement collectif a un rôle important (ex. réseaux, économie, biologie).
Cependant, en dépit des attrayantes propriétés des équilibres corrélés, une difficulté persiste, il s'agit de la multiplicité des équilibres et de leur sélection [4], notamment dans le cadre dynamique de l'apprentissage. Dans cette thèse, on propose de mener une recherche innovante sur ces sujets.
Etat de l'art : Les équilibres corrélés, l'apprentissage dans les jeux et le problème de sélection d'équilibre sont le sujet de nombreuses études et d'une riche littérature. Ce socle de connaissance garantit une base solide à la thèse. Récemment, le problème d'apprentissage dans les jeux a mis en évidence [2] le rôle clé des équilibres corrélés.
Le sujet de cette thèse est à la frontière de la théorie des jeux « classique » et de développements plus récents motivés par l'algorithmique et le machine learning.
about you
Formation demandée (master, diplôme d'ingénieur, domaine …) :
Master 2 ou école d'ingénieur avec spécialité en mathématiques, mathématiques appliqués (optimisation, jeux, machine learning, etc.) ou computer science
Expériences souhaitées (stages, …) :
une expérience passée en théorie des jeux ou machine learning est un plus
Compétences (scientifiques et techniques) et qualités personnelles souhaitées par le poste
Compétences scientifiques et techniques
Mathématiques (la théorie des jeux est un plus mais pas obligatoire)
Algorithmes & machine learning
Programmation : python
Soft skills
rigueur, patience, logique
autonomie
sociabilité
flexibilité et souplesse d'esprit
additional information
Objectif scientifique - verrous à lever
En dépit d'attrayante propriétés, les équilibres corrélés continuent de poser la question de la multiplicité et du problème de sélection [4] dans le cadre statique ou dynamique de l'apprentissage.
En effet, dans un jeu, il peut exister plusieurs équilibres corrélés. Le problème d'identification du plus « pertinent » n'est que partiellement résolu par les méthodes de réduction ou les concepts affinés. Ce problème se pose également dans le cadre de l'apprentissage dans les jeux [2] car même si les règles d'apprentissage impliquent une convergence vers un sous-ensemble d'équilibres corrélés, les mécanismes de sélections et d'ajustement ne sont pas encore clairs.
Dans cette thèse, on cherchera à résoudre les problèmes précédents,
en étudiant les équilibres corrélés, leurs propriétés et les techniques de réduction ou projection de jeux,
en étudiant le problème de sélection d'équilibres corrélés et ses liens aux jeux coopératifs,
en concevant et analysant des propriétés pertinentes, algorithmes et règles d'apprentissage résolvant cette difficulté.
Approche méthodologique-planning
Etude préliminaire et état de l'art,
Identification ou conception d'exemples jouets montrant les difficultés et défis résoudre,
Identification d'hypothèses sur l'origine de ces difficultés et de solutions candidates,
Validation et mise-à-jour des hypothèses et solutions candidates sur les exemples jouets,
Rédaction d'article(s)
Généralisations, definition de nouveaux problems, etc.
Rédaction du manuscrit
Références
[1]Robert Aumann. Subjectivity and correlation in randomized strategies. Journal of Mathematical Economics, 1(1):67{96, 1974.
[2]Holly P. Borowski, Jason R. Marden, and Je_ S. Shamma. Learning efficient correlated equilibria. CoRR, abs/1512.02160, 2015.
[3]Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge University Press, USA, 2006.
[4]ROGER B. MYERSON. Game Theory: Analysis of Conict. Harvard University Press, 1991.
[5]Roger B. Myerson. Dual reduction and elementary games. Games and Economic Behavior, 21(1):183-202, 1997.
[6]John Nash. Non-cooperative games. Annals of Mathematics, 54(2):286 295, 1951.
[7]John F. Nash. Equilibrium points in n-person games. Proceedings of the National Academy of Sciences, 36(1):48{49, 1950.
[8]Noam Nisan, Tim Roughgarden, Eva Tardos, and Vijay V. Vazirani. Algorithmic Game Theory. Cambridge University Press, USA, 2007.
department
description de l'équipe
Au sein d'Orange Labs, vous serez intégré à une équipe de recherche dont les membres sont des chercheurs en mathématiques, informatiques, machine learning ou data science.
La mission de cette équipe est d'éclairer le futur en concevant ou analysant des données, modèles mathématiques et algorithmes résolvant des problèmes théoriques ou appliqués (typiquement dans le cadre network science ou économie).
Les travaux de recherche et innovations sont dirigés par des chercheurs permanents, des doctorants ou des post-docs conjointement avec des partenaires académiques prestigieux dans le cadre de projets nationaux ou internationaux.
qu'est ce qui fait la valeur ajoutée de cette offre ?
Ce doctorat vous offre l'opportunité de prendre part à une équipe de recherche au sein d'un grand groupe et d'être guidés par des chercheurs dynamiques sur un problème important à l'interface des mathématiques, de l'informatique et de l'économie.
contract
Thèse"
Paris (75),,,Senior Machine Learning Engineer - Speech Recognition,SoundHound Inc.,- Paris (75),"At SoundHound Inc., we believe every brand should have a voice. As the leading innovator of conversational technologies, we're trusted by top brands around the globe. Houndify, our independent Voice AI platform, with 70,000+ users, allows brands to create custom voice assistants that deliver results with unprecedented speed and accuracy.

Our mission is to enable humans to interact with the things around them in the same way we interact with each other: by speaking naturally. We're making that a reality through our SoundHound music discovery app and Hound voice assistant and through our strategic partnerships with brands like Mercedes-Benz, Hyundai, Deutsche Telekom, and Pandora. Today, our customized voice AI solutions allow people to talk to phones, cars, smart speakers, mobile apps, coffee machines, and every other part of the emerging 'voice-first' world.

Our diverse team of engineers, UX/UI designers, writers, data scientists and linguists are all passionate about creating a world with more conversations. With more than 14 years of expertise in voice technology, we have hundreds of millions of end users, and a worldwide team in six countries building solutions for a voice-first world.

About the Role:
Innovate on state-of-the-art deep learning systems for speech recognition and speaker recognition

Apply deep learning techniques to improve acoustic models and keyword spotting

Requirements:
Understanding of modern machine learning techniques

Experience with Deep Learning / Neural Network frameworks such as Tensorflow, PyTorch, Caffe, Torch, MxNet, etc.

Strong programming skills on Linux using C++ and/or Python

Solid knowledge of algorithms and probability / statistics

MS / PhD in Computer Science or Electrical Engineering or Statistics or equivalent

5+ years of relevant industry experience

Nice to Haves:
Experience working with automatic speech recognition systems

Experience working with speaker recognition and keyword spotting, including wake-up phrase detection

Experience in computer vision and pattern recognition

Knowledge of DSP principles, noise reduction, echo cancelation"
Paris (75),"Temps plein, CDI",,Docteur R&D – Intelligence Artificielle / Natural Language Processing - PAC,RD2 CONSEIL,- Paris (75),"RD2 Conseil est un cabinet de recrutement spécialisé sur la recherche de jeunes docteurs pour les besoins en R&D des PME innovantes et entreprises privées, souhaitant se doter de compétences pointues et de réelles ressources humaines en matière d’Innovation.
Nous recrutons actuellement un(e) Docteur (H/F) en Natural Language Processing / Intelligence Artificielle.
Créé en 2018, notre client a développé une solution automatisée, basée sur l’Intelligence Artificielle, de maintenance prédictive pour les infrastructures informatiques et travaille avec plusieurs entreprises du CAC 40.
L’outil est précurseur par sa capacité à gérer la complexité (à la fois par sa capacité à monitorer des architectures distribuées et gérer un volume significatif de données). Il permet à la fois de prédire les incidents IT et également d’accompagner les ingénieurs dans la résolution des problématiques (gain de 50% du temps d’intervention). La qualité de service et l’expérience utilisateurs et ainsi considérablement améliorée.
Forte d’une récente levée de fonds de plus de 2 millions d’euros, la start-up est en plein développement. Elle a également été nominée comme la start-up la plus innovante et a remporté le « Trophée Start-up Numérique » organisé par la région Île-de-France.
Notre client souhaite aujourd’hui renforcer son expertise R&D par le recrutement d’un Docteur (H/F) en Intelligence Artificielle / Natural Language Processing avec pour objectif d’améliorer la solution sur la rapidité et la précision de la détection des comportements anormaux.
Dans une équipe Data Science de 4/5 personnes et en lien direct avec le co-fondateur de la société, Docteur en Intelligence Artificielle, vous interviendrez principalement sur l’analyse des logs des systèmes informatiques et vos missions seront les suivantes :
Développement de nouveaux modèles de Machine Learning pour la prédiction, la classification et le clustering
Analyse de données volumineuses (Big Data) dans le cadre du développement de systèmes apprenants et prédictifs
Déploiement et tests des modèles Machine Learning à grande échelle
Coopération avec l’équipe développement pour intégrer les modules de machine learning dans le produit final
Nous cherchons un candidat disposant en particulier des compétences suivantes :
De formation initiale en Informatique, vous avez réalisé un Doctorat en Natural Language Processing ou Intelligence Artificielle
Vous maîtrisez également la programmation informatique permettant de concevoir, d’’implémenter les solutions sur des données volumineuses et les tester à grande échelle (en particulier Python)
Une expérience dans la construction de modèles Deep Learning (utilisant des réseaux de neurones profonds) est un plus. Vous devez être à l'aise avec d'autres techniques de ML plus traditionnelles
Maîtrise de l’anglais obligatoire
Notre client recherche surtout des collaborateurs engagés et dynamiques. Vous disposez des qualités suivantes :
Force de proposition et proactif
Esprit d’équipe
Pragmatique et orienté résultat
Si vous pensez être cette personne, que vous êtes titulaire d’un Doctorat et n’avez jamais été embauché en CDI après l’obtention de votre thèse (contrainte impérative pour respecter les critères du CIR), nous vous invitons à nous faire parvenir votre CV et lettre de motivation par mail sous la référence PAC.
Type d'emploi : Temps plein, CDI"
Paris (75),,,Senior Software Engineer - Backend,Doctrine,- Paris (75),"Our mission: we are advancing open justice around the world.
Our products: we are building legal research and analytics software for legal professionals to search through the law, handle their cases, and grow their business.
Our ambition: in a ""traditional"" industry, we strive daily to offer our customers the latest technologies, especially in the field of artificial intelligence, through simple and well-designed products

-

In order to fulfill our mission, Backend Engineers play an essential role within Doctrine's Engineering Team. We are therefore looking for a Senior Backend Software Engineer, to develop, redesign and maintain core features of our products by working closely with ML engineers, product designer and product management to provide the best experience to our customer.

In this role, you will:
Design, develop and maintain REST APIs
Implement and maintain optimized Elasticsearch and SQL queries.
Work with Machine Learning Engineers to help them prepare data adapted to fast real-time querying in the application.
Lead code reviews and write tests to keep the code clean
Build and maintain monitoring dashboards/tools.
Review and improve the legacy code to prevent production bug
Write technical documentation
And globally as all Engineering contributors you will:
Mentor and challenge your peers
Educate others to best practices in use in the company and elsewhere
Participate to all our in-house rituals for knowledge sharing
Contribute to hire other outstanding colleagues
For these responsibilities, we are looking for teammates with:
5+ years of industry experience working as a Software Engineer
Experience in building API and other web services
Very good knowledge of NodeJS and/or Python
Experience or willingness to work with frameworks like ExpressJS, React, Flask.
Proficiency in SQL
A passion for code quality and overall development best practices (testing, CI/CD...)
Familiar with agile process and product-oriented.
The ambition of delivering highly-available and highly-reliable applications
A commitment to build the best user experience
A knack for sharing and make people around you better teammates
Excitement about taking cutting-edge technologies and techniques to one of the most important and most conservative industries; your work will have a deep impact on Doctrine’s growth and how legaltechs will shape the future of law jobs!
English fluency
-

Why you should apply:
It's the ideal time to join Doctrine in terms of growth and opportunities
We have a strong team spirit and company culture, we live our values at a daily basis
Top-notch learning environment: ongoing mentorship, weekly best practices sharing
We work in a cool and classy office in the heart of Paris (Métro Sentier)
Regular feedback and compensation reviews - we nurture the feedback culture and reward great work

Benefits:
Competitive package, including stock options
Unlimited time off
Referral bonuses
A great health insurance policy
Lunch coupons

Other perks:
IT equipments
Free coffee, tea, and fresh fruits
Thursday beers, Wednesday breakfasts and monthly events with the team


We are an equal opportunity employer and value diversity at our company. We do not discriminate on any basis including religion, color, origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Remote applicants: This position is based in our office in Paris. If you're interested in remote work, check back soon as our needs may change."
Paris 2e (75),,,Directeur Data Science & Marketing Analytics H/F,Edgar People,- Paris 2e (75),"Notre client est un une start up du conseil spécialisée dans le marketing digital et la data.

Au croisement entre cabinet de conseil et agence web marketing, localisé au coeur de Paris, notre client est en très forte croissance et a rejoint en 2018, un grand groupe international qui offre des solutions intégrées en SEM, SEO, Data, Programmatique & E-Retail.
ll mène des projets innovants avec de prestigieux clients, directions marketing de grands comptes, e-commerçants et groupes média tels que La Française des Jeux, Groupe Bayard, Kenzo, OVH, Vente-Privée.com, …
Dans le cadre de sa croissance, notre client recrute son :
Directeur Data Science et Marketing Analytics H/F.
En relation directe avec les associés, vous prenez la Direction du pôle marketing sciences englobant des projets de Data Engineering, Data Science & Data Visualisation pour des Directions Métier, Marketing ou Digital.
Vous assumez la responsabilité et assurez le développement du pôle :
Identification des besoins clients
Pilotage et réalisation des missions
Recrutement, management, gestion de charge de l’équipe
Création et développement d’offres commerciales, réponse à appel d’offre, propositions commerciales
Développement des compétences et des expertises du pôle.
Profil recherché :
Bac +5, grande école d’ingénieurs ou de commerce
Au minimum 7 ans d’expériences dans le secteur de la data, du digital ou du marketing
Solide expérience en matière de traitement de données :
Data engineering : construction d’infrastructures de données basées sur le cloud, flux de données entre différents outils de l’écosystème data-marketing, …
Data science : algorithmie, analyse descriptive et prédictive, machine learning, …
Data visualisation : construction de dashboards adaptés aux enjeux opérationnels et managériaux
Approche analytique démontrée, rigoureux/euse et méthodologique
Expertise forte des techno et de l’écosystème digital et data : (Google Cloud & co), les langages (SQL, Python, etc.) et les librairies de traitements de données
Vous avez un esprit entrepreneurial et souhaitez participer à l’aventure d’un jeune cabinet en forte croissance
Anglais courant, et ouvert(e) à des missions ponctuelles à l’étranger"
Paris (75),45 000 € - 65 000 € par an,,Data Engineer,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data engineer hadoop spark
Taille entreprise de 11 à 20
Teletravail ponctuel
Technologies Agile
Technologies Aws
Technologies Emr
Technologies Python
Technologies Scala
Technologies Spark
Min 45k€
Max 65k€

L'ENTREPRISE : START-UP BIG DATA SOLUTION SAAS
L'entreprise propose une plateforme web intégrant des analyses de quantification et qualification de flux pour ses clients. Son champ d'action relève du big data.
Quelques informations :
Année de création : 2016
+200 clients grands comptes
Effectif total : 30 personnes
Effectif technique : 10 personnes
Volumétrie de données : 50 gigaoctets par jour
1M€ de revenus récurrents
Activité essentiellement en France et développement récent en Europe
Environnement technique de l'entreprise : Scala, Spark, Python, Jupyter, Zeppelin, AWS, EMR, S3, Athena, tests unitaires et déploiement continu, revues de code
VOS MISSIONS : PROPOSER, DÉVELOPPER, METTRE EN PRODUCTION
Au sein de l'équipe tech de 10 personnes, et en collaboration avec 3 data engineer vous devrez :
Être force de proposition dans les choix technologiques ou dans le développement des produits
Mettre en production des pipelines de données
Développer en Spark et Scala dans un environnement à fortes problématiques de performance
Extraire des métriques à partir des jeux de données
Interagir avec l'équipe data science
VOTRE PROFIL : DATA ENGINEER CONFIRMÉ(E)
Rencontrons-nous si :
Vous avez au moins 2 ans d'expérience en tant que data engineer
Vous avez déjà travaillé sur des sujets à fortes contraintes opérationnelles (volumes de données et production)
Vous êtes issu(e) d'une formation bac+5
Vous connaissez l'environnement AWS
Les bonnes pratiques sont essentielles pour vous
C'est un plus si :
Vous avez déjà travaillé sur des données de géolocalisation
MODALITÉS :
Rémunération : 45/65k€
Remote ponctuel
Locaux en plein coeur de Paris
Processus de recrutement :
Entretien téléphonique
Test technique sur place ou à distance selon disponibilités
Entretien physique avec le CTO et d'autres personnes de l'équipe
Rencontre des autres équipes
Sélectionné par Thomas Gourmelon
Spécialiste Python, Ruby, Go & Data Scientist
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),CDI,55 000 € - 80 000 € par an,Data Architecte,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Cto dsi architecte
Technologies Aws
Technologies Azure
Technologies Elastic search
Technologies Java
Technologies Mongodb
Technologies No sql
Technologies Python
Technologies Spark
Expérience 6 à 10 ans
Statut CDI
Min 55k€
Max 80k€
L'ENTREPRISE : STARTUP CONSEIL EN MANAGEMENT BIG DATA PARIS
Un acteur du conseil en organisation & management :
70+ consultants
Multi secteurs : public, distribution, banque, télécom, cosmétique, …
Basé au coeur de Paris
Vos activités s’appuieront sur le Lab du cabinet et sur son catalogue d’outils et technologies :
Développement : Angular, React, TypeScript, ES6, Vue.js, Node.js, Express.js
Bases de données : MongoDB, ElasticSearch, PostgreSQL, Redis
DevOps : Docker, Jenkins, Vagrant, AWS, CircleCI, GitHub
Data science : Dataiku DSS, Vertica, Spark, Python
VOTRE MISSION : MONTER DES INFRA AFIN D'EXPLOITER LA DATA
Vous intervenez comme Data Architecte auprès de groupes du CAC40 (DSI, datalab, ...) dans la mise en place et l'optimisation d'infrastructures fiables et scalable :
Étude d'opportunité / cadrage
Choix d’architecture en anticipant les besoins de scalabilité
Assurer la conception et l’installation des architectures en passant par les spécifications et la documentation.
Automatiser l’amorçage de leurs projets d’applications (pour le compte du cabinet ou de leurs clients)
Définition de cadre de référence Big Data (archi, normes, standards)
VOTRE PROFIL : ARCHITECTE ORIENTÉ DATA
Vous êtes issu d'une formation BAC+5 type école d'ingénieur ou d'informatique
Vous avez 5 à 8 ans d'expériences réussies idéalement dans un environnement Data
Vous justifiez d'une forte culture startup : veille active, environnement en forte croissance, ...
Vous êtes parfaitement à l'aise en Anglais
Les pré-requis tech :
Système : Linux & développement bash.
Big Data : Hadoop (HortonWorks ou Cloudera), Hive, Spark …
ETL : Talend ou Informatica
Langage de programmation : Java, Python.
Cloud : Azure ou AWS

Sélectionné par Deborah Peter
Spécialiste Infra / DevOps / QA
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris 1er (75),CDI,,"Senior Product Owner orienté Data, Graphe F/H",ATTINEOS,- Paris 1er (75),"Attineos recherche pour l’un de ses clients dans le domaine de l’énergie un senior Product Owner fortement orienté Data. Effectivement la chaine technique est complexe et elle est composée de 4 équipes de développement et de 3 services internes dépendants du produit. Vous serez en contact permanent avec des ingénieurs Data Science et Innovation. Le produit est hautement Data orienté et utilise des technologies de pointe. Vous serez intégré dans une équipe de 4 Product Owner et vos réalisations seront les suivantes :

Être le référent du métier sur l’ensemble de la chaine

Maîtriser l’impact des évolutions sur le produit et les services

Piloter les fonctionnalités développées avec le métier et les autres Product Owner

Communiquer les avancements au travers de démonstrations périodiques

Animer les stand-up quotidien, rétro, partage des alertes (Agiles et Kanban)

Définir les plans d’actions correctifs avec le Tech Lead, le QA et le Product Manager

Au quotidien, vous serez en charge de :
Encadrer les équipes Métiers, Data, QA et Tech

Être le référent métier

Rédiger des cahiers de tests en collaboration avec l’équipe

Valider la qualité des développement réalisés avec les testeurs

Rédiger les spécifications ainsi que les User Stories

Prioriser le backlog de l’équipe

Suivre les développements

Définir et piloter les KPIs produits

Vous maîtrisez les compétences techniques suivantes :
Gestion de base de données NoSQL, orienté Graphe

Développement Python, Java, GO et NIFI

Spécifications techniques des API (API REST : framework Flask, Django)

Profil recherché Ce qu’il vous faut pour cette mission :
Être force de proposition et gérer des problématiques de scale-up informatique

Avoir une expérience en Data Management et/ou des compétences en Data Science

Être rigoureux, organisé et avoir le soin du détail

Savoir mener un projet de bout en bout

Avoir une bonne connaissance de Kanban, Scrum

Être doté de bonnes capacités d’analyse, de synthèse, d’expression et de rédaction

Avoir une forte capacité d’adaptation, une bonne aisance relationnelle et l’esprit d’équipe

Avoir une expérience internationale et maîtriser parfaitement l’anglais à l’oral et à l’écrit

Si vous aimez relever de nouveaux challenges dans un contexte international, ce poste est fait pour vous !

Le démarrage de la mission peut se faire soit en télétravail soit directement sur le site client.

Afin de respecter les directives du gouvernement, et préserver la santé de nos équipes, nous sommes en full télétravail !

Nous vous proposerons donc des entretiens en visio.

Prenez soin de vous et de vos proches
Entreprise Attineos n'est pas une ESN (Entreprises de Services Numériques) comme les autres !

Nous avons une conviction : L'attitude vaut autant que les compétences !!

Nous surfons sur un état d'esprit positif qui place l'humain au coeur de l'entreprise : l'adaptabilité, la créativité et la bonne humeur sont nos points forts !

Nous accompagnons nos clients dans leurs projets applicatifs.

Conseils et expertises techniques, conceptions et développements, tests..., nous sommes au service de la transformation numérique de clients de tout secteur d'activité.

Intervenant au coeur des équipes clientes en Ile de France et à Rouen ou dans notre centre de services à Rouen, nous couvrons un large spectre de technologies pour des projets variés :

Applications logicielles spécifiques
Portail Intranet-Extranet
Sites internet
Sites E-commerce
Sites mobiles
Sites institutionnels
Applications de business intelligence
Applications Big Data
Déjà rejoints par plus de 220 collaborateurs, nous souhaitons poursuivre notre développement et étoffer nos équipes par l'intégration de nouveaux talents ayant le sens du service et le goût du challenge !"
Paris (75),"Temps plein, CDI",,Audio DSP Engineer – Voice Processing / Hearing Aids,USA Recruitment,- Paris (75),"Audio DSP Engineer – Voice Processing / Hearing Aids / Cochlear Implants:
A Top-Tier company is looking for algorithm designers and audio DSP product engineers to join their team in Paris and help with the design and development of their world-leading products. If you have solid experience in voice processing, hearing aids or cochlear implants, this is the perfect role for you. To take your voice processing career to the next level, please apply below…

What You Need:

Solid experience in voice processing, hearables and/or hearing aids (HA and CI)
Experience in low latency audio/voice algorithm design
Experience with Python, Matlab or C

Even Better if You Have:
Machine learning experience
Digital and analog ANC experience
Full stack development experience (from algorithm design to on-target implementation)

Key Words:
Audio / DSP / Voice Processing / Hearing Aids / Cochlear Implants / HA / CI / Python / C / Matlab / C++ / Algorithm Design / Machine Learning / ML / ANC / Low Latency / Full Stack / Analog / Digital

#Audio DSP jobs

By applying to this role you understand that we may collect your personal data and store and process it on our systems. For more information please see our Privacy Notice https://eu-recruit.com/about-us/privacy-notice/"
Paris (75),,,"Research Engineer, Neural Text-to-Speech (TTS)",SoundHound Inc.,- Paris (75),"At SoundHound Inc., we believe every brand should have a voice. As the leading innovator of conversational technologies, we're trusted by top brands around the globe. Houndify, our independent Voice AI platform, with 70,000+ users, allows brands to create custom voice assistants that deliver results with unprecedented speed and accuracy.

Our mission is to enable humans to interact with the things around them in the same way we interact with each other: by speaking naturally. We're making that a reality through our SoundHound music discovery app and Hound voice assistant and through our strategic partnerships with brands like Mercedes-Benz, Hyundai, Deutsche Telekom, and Pandora. Today, our customized voice AI solutions allow people to talk to phones, cars, smart speakers, mobile apps, coffee machines, and every other part of the emerging 'voice-first' world.

Our diverse team of engineers, UX/UI designers, writers, data scientists and linguists are all passionate about creating a world with more conversations. With more than 14 years of expertise in voice technology, we have hundreds of millions of end users, and a worldwide team in six countries building solutions for a voice-first world.

About the Role:
Conduct research and development of neural TTS systems

Improve the stability and reliability of neural TTS generation

Innovate on methods of emphasis and prosody control

Build systems for multiple languages

Opportunity to work on production deployment of TTS

Opportunity to attend the relevant deep learning conferences and publish

Success for this role: build world class production neural TTS

Requirements:
Experience with designing, developing, and training deep neural networks

Experience with a deep learning library such as PyTorch, TF, Keras, etc.

Strong programming skills on Linux using Python and/or C++

MS / PhD in Computer Science, Electrical Engineering, Physics, or equivalent

Fluency in written and spoken English

Nice to Haves:
Previous work in text to speech, either in building neural TTS or in concatenative / unit-selection / parametric approaches

Experience with automatic speech recognition (ASR) such as with neural acoustic or language modeling

Published work in Deep Learning"
Versailles (78),CDD,25 000 € - 35 000 € par an,Apprentissage profond pour l’estimation et l’optimisation du trafic avec des données de véhicules flottants (FCD),VEDECOM,- Versailles (78),"Apprentissage profond pour l’estimation et l’optimisation du trafic avec des données de véhicules flottants (FCD)
Réf ABG-91983
Sujet de Thèse

11/05/2020
> 25 et < 35 K€ brut annuel

VEDECOM
Lieu de travail
Versailles - Ile-de-France - France
Intitulé du sujet
Apprentissage profond pour l’estimation et l’optimisation du trafic avec des données de véhicules flottants (FCD)
Champs scientifiques
Mathématiques
Mots clés
Machine learning, Deep learning, Optimisation, Floating Car Data, GPS, Trafic routier, Mobilité
Description du sujet
L’objectif de cette thèse est de développer des solutions innovantes aux problèmes de mesure et d’optimisation du trafic routier, sans avoir recours à la mise en place des capteurs physiques ou de nouvelles infrastructures. Pour ce faire, nous proposons d’exploiter, via l’IA notamment les techniques d’apprentissage automatique et profond, une nouvelle source de données - les Floating Car Data (FCD) - afin d’en extraire des indicateurs dynamiques, fiables et représentatifs pour la mesure et l’optimisation du trafic. Ainsi, nous visons à remplacer les boucles de comptage physiques par des capteurs virtuels qui peuvent transformer, grâce à un modèle d’apprentissage profond, les informations sur la vitesse des véhicules obtenues par les données GPS en estimations de flux. De plus, contrairement aux boucles de comptage standard, notre contribution à base d’IA permettra de déterminer l’origine-destination et les types des véhicules passant par chaque tronçon. Ces informations supplémentaires sont cruciales pour la gestion et le contrôle du trafic routier ainsi que pour assurer une planification durable.
Nature du financement
Financement public/privé
Précisions sur le financement
Présentation établissement et labo d'accueil
VEDECOM
L’Institut VEDECOM est un Institut français de recherche et de formation dédié à la mobilité individuelle décarbonée et durable qui rassemble des partenaires publics (Universités, Écoles d’ingénieurs ...) et privés (constructeurs, équipementiers, sociétés de services,...). Il a été sélectionné en tant qu’Institut de Transition Énergétique (ITE) dans le cadre du Programme des Investissements d’Avenir (PIA) de l’état Français. VEDECOM ambitionne de devenir un leader européen en matière d’innovation dans les domaines des véhicules électrifiés, autonomes et connectés grâce à des infrastructures et services de mobilité et d’énergie partagée.
Profil du candidat
Formation/ Qualification :
Étudiant en Master 2 ou en dernière année d'études d'école d’ingénieurs dans le domaine de la science des données, mathématiques appliquées ou informatique avec une spécialisation en science des données.
Compétences savoir-faire/ savoir-être:
Base solide en apprentissage automatique et profond.
Base solide en programmation Python.
Connaissance en théorie de graphe serait un plus.
Autonomie, esprit d’analyse, travail collaboratif.
Intérêt pour la recherche appliquée.
Date limite de candidature"
Paris (75),CDI,,Architecte Data,Nexworld,- Paris (75),"Missions principales
L’Architecte Data est responsable de la conception, du déploiement et de l’administration de plateformes de calculs distribués et de stockage de données massives (Big Data).
Il travaille de concert avec les équipes de développement, de Data Science, de Business Intelligence et d’administration système pour concevoir des Architectures Data qui correspondent aux besoins métiers. Il doit anticiper les besoins futurs et respecter les contraintes imposées par les Architectures existantes. Il est le garant du bon fonctionnement, de la haute disponibilité et de la résilience des plateformes Data.
Compétences principales
Technologies
Framework Big Data : Hadoop (HDFS, Map reduce), Spark, Hive, HBase, Ozzie, Pige, Impala
Framework de traitement temps réel : Kakfa, Kafka Stream, Flink, Spark Streaming, Samza
Search : Elastic, Solr
Bases de données NoSQL : Cassandra, MongoDB, Redis, CouchBase, Neo4j
Solutions éditeurs : Horton Works, Cloudera, MapR, Trifacta, Attunity
Cloud :
Amazon : EMR, Kinesis, Redshift, DynamoDB
Google : Cloud Storage, Big Table, Big Query, DataFlow, DataProc
Azure : HD Insight, Data Factory, DataBricks, CosmosDB
Architecture :
Expérience dans la conception et la mise en place d’Architecture Data : Data Lake, Data Hub
Capacité à dimensionner les Architectures et à en estimer le coût
Connaissance sur la mise en place de solutions hybrides (Cloud + On-premise)
Connaissance des SI Legacy et des contraintes associées
Compétences additionnelles souhaitées
Bonne maîtrise du développement sur les langages : Java, Python, Scala
Connaissance du système Linux et Réseaux
Qualités recherchées
Avoir un bon relationnel
Ouvert d’esprit, curieux et synthétique
Communiquer en anglais à l’écrit et à l’oral
Aimer partager, être rigoureux et autonome
Attitude Conseil
Postuler
Le poste
Poste en CDI, basé à Paris,
Statut Cadre.
Vous êtes Architecte SI ou Chef de Projet technique, d’une formation BAC+5 et passionné par la transformation digitale et son potentiel business, vous disposez d’un solide bagage technique sur lequel vous appuyer dans le cadre de vos projets.
Vous avez minimum 5 ans d’expériences dans notre métier et idéalement au sein d’une société de conseil en nouvelles technologies."
Paris (75),,,VIE - COMPUTATIONAL CHEMIST ENGINEER M/W - FRANKFURT,Air Liquide,- Paris (75),"Company presentation
World leader in gases, technologies and services for Industry and Health, Air Liquide is present in 80 countries with approximately 66,000 employees and serves more than 3,6 million customers and patients.
Oxygen, nitrogen and hydrogen are essential small molecules for life, matter and energy. They embody Air Liquide’s scientific territory and have been at the core of the company’s activities since its creation in 1902.
Air Liquide’s ambition is to lead its industry, deliver long-term performance and contribute to sustainability.

Entity and activity description
The R&D Center in Frankfurt is one of Air Liquide’s eight R&D Centers worldwide. With the target of contributing to the energy transition, it concentrates on the hydrogen/syngas production with low CO2 emission and carbon management, where sustainability and computational solutions constitute more transversal fields of activity. We concentrate on innovative methods for the generation and application of industrial gases, where our special strength is the scale-up of results from numerous pilot plants to large scale and in close collaboration with internal and external partners from industry and academia.

Missions and Responsibilities
Data acquisition and aggregation from pilot and commercial plants
Physical modeling of chemical processes (steady-state and dynamic) using commercial or custom simulation tools
Data-driven modeling of chemical processes using machine learning methods
Mathematical optimization of chemical processes based on physical and data-driven process models
Implementation of advanced process control strategies for pilot and commercial plants
Communication with internal and external collaboration partners for the development and deployment of computational solutions in a product-oriented mindset

Competencies and Profile
Fundamentals of chemical process engineering
Expertise in modeling, data science, and process control
Competency in simulation tools (e.g. Aspen Plus, gPROMS)
Competency in programming languages (e.g. Matlab, Python)
Excellent academic record
Relevant industrial internships in process modeling and data analytics domain in an international environment

Additional information
We offer personal training on-the-job and an international environment of the world’s largest industrial gas company.
Position based in Frankfurt, Germany for 12 months extendable. A few travels across Europe are expected.
Position open only for candidates eligible to the VIE program.Therefore, only the applicants meeting the requirements of the French V.I.E program will be taken into consideration. Please visit this website for more information about these requirements:
https://www.civiweb.com/EN/le-volontariat-international/VIE_CONDITIONS.aspx
The V.I.E., an international young graduate program, enables young professionals who are less than 28 and European Union nationals to work for a French company in any country of the world. Becoming part of this program means going abroad to carry out a professional assignment for up to 24 months whilst benefiting from social care coverage and an interesting salary, which depends on the host country.
Business France, the French agency for international business development, is in charge of all the administrative procedures of your assignment. For further information, please visit the following link: https://www.civiweb.com/EN/index.aspx

Job Reference: FR09568"
La Défense (92),"Temps plein, CDI",,Architecte Big Data,Black-belt,- La Défense (92),"Notre client , l'un des leaders mondiale dans le domaine du numérique,propose l'un des portefeuilles d'offres les plus complets du marché (conseil, intégration de systèmes, édition de solutions métier, infrastructure management et business process services) recherche un(e) architecte Big Data afin d'accompagner ses clients dans la mise en place de lac de données et d'applications Data.
Vos missions seront:
- Définir et/ou mettre en oeuvre des solutions / architectures / projets autour de l'écosystème Big Data
- Participer à des avant-ventes
- Mettre en place des benchmark de solutions, des prototypes et des projets
- Contribuer à définir et diffuser les bonnes pratiques au sein des équipes sur le Big Data
- Supporter les équipes de réalisation par une expertise sur les solutions et/ou démarches Big Data
- Contribuer à la veille technologique sur les solutions Big Data
- Elaborer et présenter nos retours d'expérience auprès de nos clients
Environnement technologique/fonctionnel:
- Architecture et Infrastructure Hadoop (Nifi, Kafka, Sqoop, Flume, Spark, Hive) et distributions associées
(HortonWorks, Cloudera, MapR)
- Solutions Editeurs (Microsoft APS, IBM Big Insight / Watson?)
- Data Science (Python, Scala, R)
- Data Visualisation
- Base de données noSQL
Profil recherché:
Titulaire d'un Bac +5 en informatique, vous disposez d'une expérience de 3 à 8 ans, avec des références significatives dans la définition d'architectures et la mise en oeuvre de projets et solutions Big Data chez des clients.
Vous êtes un architecte système d'informations reconnu sur les systèmes de gestion des données.
Vous savez identifier et positionner les principales solutions évoquées ci-dessus, dans le domaine principal du Data Management, et éventuellement dans les domaines de Data Science et Data Visualisation gravitant autour de l'écosystème Big Data.
Vous êtes reconnu pour votre capacité à animer, à fédérer autour d'une vision, pour votre rigueur, vos
capacités d'analyse, de synthèse et d'innovation.
Vous disposez d'un très bon niveau d'anglais.
A compétences égales, tous nos postes sont ouverts aux personnes en situation de handicap.
Postulez dès maintenant !
Type d'emploi : Temps plein, CDI
Salaire : 70 000,00€ à 110 000,00€ /mois
Expérience:
architecte big data ou similaire: 3 ans (Requis)"
Paris (75),"Temps plein, Stage",,STAGE - ACTUARIAT MODELES STATISTIQUES ET ETUDES TECHNIQUES (3 mois) H/F,CNP Assurances,- Paris (75),"Missions :
En s'appuyant sur des techniques de Data Science, de Machine Learning et sur des technologies de développement de pointe, le candidat sera amené à développer au sein du dataLab des modèles de Machine Learning supervisés ou non supervisés (ciblages clients, détection de fraude), des outils de Computer Vision (OCR, reconnaissance d'images…), de Natural Language Processing (Named Entity Recognition, classification de textes), ou encore à réaliser des travaux de R&D autour de sujets IA innovants.

En plus des projets particuliers sur lesquels la personne pourra être amenée à contribuer, les travaux récurrents seront les suivants:
Collecter les données nécessaires pour répondre aux cas d'usage
Implémenter les analyses statistiques sur les données afin de produire des insights
Développer, adapter, optimiser et analyser des algorithmes et des modèles de Machine Learning ou de Deep Learning
Participer aux groupes de travail du R&Data Lab
Participer aux travaux de veilles technologiques et de R&D
Participer au développement de l'activité du service

Stage à suivre avec alternance
Profil
Diplômé d'un Master d'une école d'ingénieurs ou d'une université avec une spécialisation en Data Science, Machine Learning, Mathématiques Appliquées ou équivalent, le candidat devra notamment disposer :
De solides connaissances théoriques et pratiques en analyse de données et en Machine Learning (algorithmes d'apprentissage supervisés, non supervisés, par renforcement, Deep Learning…)
D'une forte dimension scientifique (mathématiques, statistiques, probabilités, optimisation…)
De fortes compétences en programmation
D'une maîtrise du logiciel Python et de l'environnement Unix
De connaissances en bases de données (SQL…)
D'une capacité d'adaptation, d'analyse et de synthèse ainsi qu'un sens de la rigueur et de l'organisation
D'un bon relationnel, une proactivité et un goût pour le travail en équipe
Classe CCNA
3
Localisation du poste
Localisation du poste
Europe, France, Ile-de-France, Paris (75)
Ville
Paris
Critères candidat
Niveau d'études min. requis
Bac+4
Domaine / Spécialité
Actuariat
Assurances
Niveau d'expérience
Plus de 10 ans"
Paris (75),,,Data architecte Senior,IPANEMA CONSULTING,- Paris (75),"Contexte :
Dans le cadre de son développement d’activité, IPANEMA CONSULTING recherche data architecte.
La mission sera en étroite collaboration avec les fondateurs du projet et le CTO.

Mindset ipanema :
Notre Vision est que la Révolution Numérique est une opportunité à saisir pour chaque entreprise, que les entreprises ont le droit à développer une vision augmentée d’elles même, Nous croyons aux démarches de conduite du changement pour faire évoluer les organisations dans une culture « Data Centric »
A l’ère du Digital, notre vision est que les entreprises ont plus que besoin de se ré-inventer grâce à des solutions non fantasmées, alignées et coordonnées avec précision.
Intégrer une communauté de « Data Refiners » et de mettre la puissance de l’intelligence artificielle au cœur de la transformation des entreprises et des administrations.

Notre mission :
IPANEMA CONSULTING est un cabinet d’accompagnement à la transformation Numérique qui fédère des talents autour de la stratégie, du change management et de la data.
En plaçant la technologie et l’humain au cœur de la transition, nos équipes proposent des solutions pour les challenges des entreprises de demain.
La force de notre ecosysteme :
Nous avons développé un écosystème fort pour accompagner nos clients dans leurs enjeux d’innovation et pour leur adresser des solutions les plus complètes possibles.
(M&A spécialisé en Tech, lab de starts up, accélérateur de starts up, expertises stratégie, expertise Océan Bleu, expertise Design thinking, expertise Data et blokchain).
Talent recherche :
Issu d’un cursus statistiques, mathématique ou ingénieur école top 5, expérience dans l’intelligence artificielle de 2 ans minimum (Chatbots, RPA, NLG, etc.) ou la Data Science,
Compétences en : Les langages statistiques (Python, R, etc.), le datamining, la connaissance des algorithmes de machine de learning et de deep learning, les langages NLG
Maitrise de l’écosystème Hadoop, Spark, Kafka ainsi que son intégration dans une architecture d’entreprise, connaissances en bases de données SQL et NoSQL, et ETL
Bon relationnel équipe et client
Sens de l’écoute, force de propositions et envie de partager tes connaissances et savoir-faire et d’apprendre de tes pairs.
Missions :
Bien plus qu’un emploi, une véritable aventure humaine au sein d’un marché prometteur
Assurer une veille technologique
Concevoir des architectures et infrastructures Big Data
Encadrer les data ingénieurs et data scientists dans leur implémentation
Optimiser en continu des infrastructures Data existantes
Etre capable de donner des formations et gérer des partenariats, faire du conseil.

Début :
Dès que possible
NB : Pour intégrer ses nouveaux collaborateurs, IPANEMA CONSULTING a conçu un programme spécifique d’intégration.
Rémunération :
En fonction de l’expérience."
Paris (75),,,Architecte Big Data H/F,Elitis,- Paris (75),"Afin d’accompagner nos clients dans leurs mises en place de lac de données et d’applications Data, nous recherchons des architectes Big Data. Dans le cadre de cette mission, vous serez amené(e) à :
Définir et/ou mettre en oeuvre des solutions / architectures / projets autour de l'écosystème Big Data
Participer à des avant-ventes
Mettre en oeuvre des Benchmark de solutions, des prototypes et des projets
Contribuer à définir et diffuser les bonnes pratiques au sein des équipes sur le Big Data
Supporter les équipes de réalisation par une expertise sur les solutions et/ou démarches Big Data
Contribuer à la veille technologique sur les solutions Big Data
Élaborer et présenter nos retours d'expérience auprès de nos clients
Environnement technologique/fonctionnel:
Architecture et Infrastructure Hadoop (Nifi, Kafka, Sqoop, Flume, Spark, Hive) et distributions associées
(HortonWorks, Cloudera, MapR)
Solutions Editeurs : Microsoft APS, IBM Big Insight / Watson, Oracle Big Data, HP Vertica / IDOL, Talend Big
Data, Splunk, Qlik, Tableau, AngularJS, appliances Teradata-Netezza-Exadata
Data Science (Python, Scala, R)
Data Visualisation (Solutions BI du marché)
Base de données noSQL : MongoDB, Cassandra, HBase, Neo4j
Gouvernance des données

Dans le cadre du développement important de son activité, nous recrutons pour notre client leader en France et en Europe dans le monde des service en IT: Un architecte Big Data H/F!

Titulaire d'un Bac +5 en informatique, vous disposez d'une expérience de 3 à 8 ans, avec des références significatives dans la définition d'architectures et la mise en oeuvre de projets et solutions Big Data chez des
clients.
Vous êtes un architecte système d'informations reconnu sur les systèmes de gestion des données.
Vous savez identifier et positionner les principales solutions évoquées ci-dessus, dans le domaine principal du Data Management, et éventuellement dans les domaines de Data Science et Data Visualisation gravitant
autour de l'écosystème Big Data.

Vous êtes reconnu pour votre capacité à animer, à fédérer autour d’une vision, pour votre rigueur, vos capacités d'analyse, de synthèse et d'innovation. Vous disposez d’un très bon niveau d’anglais."
Paris (75),CDI,,Data Engineer - Contract Management,Sept Lieues,- Paris (75),"Startup dans le secteur du contract management.
LE POSTE / LES MISSIONS
Vous participerez à la volonté de l'entreprise, pour cette année, d'automatiser les processus d'apprentissage (pour simplifier l'amélioration des modèles actuels et la création de nouveaux modèles).

Pour se faire, vous rejoindrez l'équipe Deep Learning de l'entreprise (3 Data Scientists et 1 data Engineer) et serez en collaboration avec les Data Scientists.

Vos missions:
Industrialiser et orchestrer des processus d'apprentissage de l'infrastructure de calcul
Garantir la sécurité des données tout au long de leur traitement
Mettre en place des outils de monitoring
Automatiser la mise en production

Votre principal langage de développement sera Python.
Les autres technos: Docker, Airflow, MongoDB.
PROFIL RECHERCHÉ
Formation d'Ingénieur Bac+5
Expérience sur des problématiques de data engineering
Maitrise de Python"
Paris (75),,,Senior Data Analyst (m/f/d),Artefact,- Paris (75),"Who we are
Artefact is a new generation of a data service provider, specialising in data consulting and data-driven information system, dedicated to transforming data into business impact across the entire value chain of organisations. We are proud to say we’re enjoying skyrocketing growth.
Our broad range of data-driven solutions in data consulting and information system are designed to meet our clients’ specific needs, always conceived with a business-centric approach and delivered with tangible results. Our data-driven services are built upon the deep AI expertise we’ve acquired with our 1000+ client base around the globe.
We have 1000 employees across 20 offices who are focused on accelerating digital transformation. Thanks to a unique mix of company assets: State of the art data technologies, lean AI agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client.
To support and develop its growth, Artefact is looking for the next talents of the data divizion to join the engineering team. Organized in feature team, you will work in project mode (ou pizza team) to advise your clients on their IA problematics, machine learning and Big Data. The projects you will work on can go from the migration of infrastructure to the Cloud (Deezer) to the construction of a predictive model of the water rises (Greenpeace).

What you will be doing: Key responsibilities
As a Data Analyst, your role will encompass:
Conducting projects to accompany the transformation of your clients’ businesses through the effective collection, processing, and visualisation of data
Extracting valuable insights from our clients’ marketing-related data sources.
Designing dashboards for marketing decision-making while taking into account the business needs
Accompanying our clients in the conception and implementation of data architectures and data pipelines, from collection to monitoring.
Actively contributing to the expertise level and competencies of the Data & Analytics team
Closely collaborate with the other divisions (Media & Activation, Creation, Consulting, Data Science and Data Engineer) to provide comprehensive services to your clients
Being a great tech role model
Demonstrating the skill and credibility required to ensure the success of our clients’ initiatives
Researching and developing new technical approaches to address problems efficiently
Staying up-to-date on developments within the industry, sharing best practices and actively contributing to Artefact’s institutional knowledge
Embodying Artefact’s values and inspiring others to do the same

Qualifications: Education & experience required
Academic level of education (Bachelor or Master)
A minimum of 3 years of work experience as a data specialist
Verifiable knowledge and experience of web analytics platforms like Google Analytics, Adobe Analytics, WebTrekk etc.
Verifiable knowledge and experience of tag management systems like Google Tag Manager, Tag Commander, Tealium IQ Tag Management, Relay42 etc.
Verifiable knowledge and experience of website optimization tools like Optimizely, Google Optimize, Convert, AB Tasty etc.
Knowledge of Data Management Platforms like BlueKai, Krux, Ysance, Weborama, Relay42, Adobe Audience Manager, Tealium Audience Streams etc.
Knowledge of computer and web-related technologies:
Network techniques/protocols
JavaScript, CSS and HTML (optionally AJAX, JSON, Angular)
Database techniques (REST API’s, SQL, No-SQL)
Cloud technology (Google Cloud Platform, Amazon Web Services, Microsoft Azure)
Optionally, knowledge of data processing and data modeling algorithms and techniques

What we are looking for
A Doer: you get things done and inspire your team to do the same
An Analyst: you LOVE data and think every company should take their decisions based on facts
A Pragmatist: you have a no-nonsense mindset that seeks for practical and realistic solutions
A Mentor: your clients and colleagues naturally seek you out for advice
An Adventurer: you’re an entrepreneur constantly looking for business opportunities
Why you should join us
Artefact is the place to be: come and build the future of marketing
Progress: every day offers new challenges and new opportunities to learn
Culture: join the best team you could ever imagine
Entrepreneurship: you will be joining a team of driven entrepreneurs. We won’t give up until we make a huge dent in this industry!
Come join us!"
Gif-sur-Yvette (91),,,Post-Doctoral Research Visit F/M Causal inference for high-dimensional data: application to brain imaging population studies,Inria,- Gif-sur-Yvette (91),"Le descriptif de l’offre ci-dessous est en Anglais
Type de contrat : CDD
Niveau de diplôme exigé : Thèse ou équivalent
Fonction : Post-Doctorant
A propos du centre ou de la direction fonctionnelle
Located at the heart of the main national research and higher education cluster, member of the Université Paris Saclay, a major actor in the French Investments for the Future Programme (Idex, LabEx, IRT, Equipex) and partner of the main establishments present on the plateau, the centre is particularly active in three major areas: data and knowledge; safety, security and reliability; modelling, simulation and optimisation (with priority given to energy).
The 450 researchers and engineers from Inria and its partners who work in the research centre's 28 teams, the 60 research support staff members, the high-level equipment at their disposal (image walls, high-performance computing clusters, sensor networks), and the privileged relationships with prestigious industrial partners, all make Inria Saclay Île-de-France a key research centre in the local landscape and one that is oriented towards Europe and the world.
Contexte et atouts du poste
Context: Modern health datasets present population characteristics with many variables and in
multiple modalities. They can ground prediction and understanding of individual outcomes. Machine
learning has made it possible to leverage the rich description of each individual to characterize
inter-individual differences and predict outcomes of interest. Still, the heterogeneous demographic,
behavioral, phenotypic, and sometimes genetic variables have complex relationships, making it hard
to tease apart each factor in an outcome of interest.
Potential outcome theory [7] provides a valuable framework to perform such inference. In this
framework, heterogeneous treatments effects models have been devised. In particular, it readily
incorporates interactions between background variables and treatment variables, as well as on treatment
effects. The statistical behavior (consistency and efficiency) under non-parametric models is
actively investigated [2, 6].
However, their behavior in high-dimensional settings, with both the number of features and the
number of samples are large, are still poorly understood. Moreover, there remains the possibility
that some confounders of the model are not disclosed explicitly, possibly leading to biased conclusions.
Our objective is thus to extend the theory and algorithms of causal inference to noisy highdimensional
settings, where the noise level implies that effects sizes are proportionally small, and
classic methods often become inefficient and potentially inaccurate due to overfit.
Mission confiée
Proposed work:
We have identified three promising directions that we plan to explore.
1. Mediation analysis and conditional independence
Mediation analysis considers the question of whether a variable z mediates all the effect of another
variable x onto a target variable y, aka outcome. It turns out that full-mediation analysis amounts to
testing whether x ? y|z, which is handled by a conditional independence test. When the dimensions
of these variables (z in particular, but also x and to some extent y) grow, the underlying statistical
inference procedures typically lose power, or even possibly error control. We propose to leverage our
experience on such high-dimensional inference problems [3, 5] to set up computationally efficient
and accurate solutions to this problem.
2. Latent variable models and confounders
The most important aspect of inferring causal effects from observational data is the handling of
confounders, factors that affect both an intervention and its outcome. A carefully designed observational
study attempts to measure all important confounders. However, even if one does not have
direct access to all confounders, there may exist noisy and uncertain measurement of proxies for
confounders. A case of interest here is brain organization, that is only observed through imaging
processes that have little explanatory power on outcomes of interest. Can we identify some latent
variables that better summarize brain intrinsic structure in view of the available data ?
There has been huge progress in the field of generative modeling in the recent years, as this approach
is part of many supervised or unsupervised learning (Variational Autencoders and generative
Adversarial Networks being prominent examples). We propose to leverage these effects to estimate
the unknown latent space summarizing the confounders and the causal effect on datasets with incomplete
information. In particular, we plan to extend the work in [4] to scale better to big data
settings.
3. The quest of model validation
In the classical potential outcome theory [7], causal effects are determined by both factual and
counterfactual outcomes, ground-truth effects can never be measured in an observational study. In
the absence of such measures, how can we evaluate the performance of causal inference methods?
Addressing this question is an important step for practical problems, in which one has to determine
if an effect can safely be considered non-zero, or heterogeneous through a population. Given
the many possible inference tools available, data-driven validation procedures are needed to guide
practitioner’s choice in practical setting. We propose to revisit the promising work of [1] analysing
in detail the shortcomings of the procedure (regarding both bias and variance), especially when the
model becomes high-dimensional.
Principales activités
Across these research directions, the work will proceed by considering carefully the theory and
identifying shortcomings, with a clear focus on high-dimensional, large-sample and small-effect-size
settings.
We will proceed with extensive simulations, standard benchmarks, then population studies on very
large-scale data (O(106) samples in the UKbiobank dataset), to study the effects of sociological
factors in conjunction with neurological factors (O(105) samples). We will also consider mediumsize
datasets, such as neuroimaging population studies with behavioral variables, and non-imaging
datasets in order to identify solutions with high generalization power. The work will be done in
Python and will be made available openly upon publication.
Compétences
Required skills: The successful candidate will be interested in applications of machine learning and in the understanding of human cognition. Knowledge of scientific computing in Python (Numpy, Scipy, scikit image, Pandas) is encouraged. All the work related to imaging will be based on the Nilearn library http://nilearn.github.io.
[1] Ahmed Alaa and Mihaela Van Der Schaar. Validating causal inference models via influence functions. In
Kamalika Chaudhuri and Ruslan Salakhutdinov, editors, Proceedings of the 36th International Conference
on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 191–201, Long
Beach, California, USA, 09–15 Jun 2019. PMLR.
[2] Susan Athey and Guido Imbens. The State of Applied Econometrics - Causality and Policy Evaluation.
ArXiv e-prints, page arXiv:1607.00699, July 2016.
[3] Jérôme-Alexis Chevalier, Joseph Salmon, and Bertrand Thirion. Statistical Inference with Ensemble
of Clustered Desparsified Lasso. In MICCAI, Grenade, Spain, 2018.
[4] Christos Louizos, Uri Shalit, Joris Mooij, David Sontag, Richard Zemel, and Max Welling. Causal Effect
Inference with Deep Latent-Variable Models. arXiv e-prints, page arXiv:1705.08821, May 2017.
[5] Tuan-Binh Nguyen, Jérôme-Alexis Chevalier, and Bertrand Thirion. ECKO: Ensemble of Clustered
Knockoffs for robust multivariate inference on MRI data. In IPMI, June 2019.
[6] Xinkun Nie and Stefan Wager. Quasi-Oracle Estimation of Heterogeneous Treatment Effects. ArXiv
e-prints, page arXiv:1712.04912, December 2017.
[7] Donald B Rubin. Estimating causal effects of treatments in randomized and nonrandomized studies.
Journal of educational Psychology, 66(5):688, 1974.
Avantages
Subsidized meals
Partial reimbursement of public transport costs
Leave: 7 weeks of annual leave + 10 extra days off due to RTT (statutory reduction in working hours) + possibility of exceptional leave (sick children, moving home, etc.)
Possibility of teleworking (after 6 months of employment) and flexible organization of working hours
Professional equipment available (videoconferencing, loan of computer equipment, etc.)
Social, cultural and sports events and activities
Access to vocational training
Social security coverage
Rémunération
Monthly gross salary : 2.653 euros"
Paris (75),,,Senior Audio Enhancement and Signal Processing Engineer,SoundHound Inc.,- Paris (75),"At SoundHound Inc., we believe every brand should have a voice. As the leading innovator of conversational technologies, we're trusted by top brands around the globe. Houndify, our independent Voice AI platform, with 70,000+ users, allows brands to create custom voice assistants that deliver results with unprecedented speed and accuracy.

Our mission is to enable humans to interact with the things around them in the same way we interact with each other: by speaking naturally. We're making that a reality through our SoundHound music discovery app and Hound voice assistant and through our strategic partnerships with brands like Mercedes-Benz, Hyundai, Deutsche Telekom, and Pandora. Today, our customized voice AI solutions allow people to talk to phones, cars, smart speakers, mobile apps, coffee machines, and every other part of the emerging 'voice-first' world.

Our diverse team of engineers, UX/UI designers, writers, data scientists and linguists are all passionate about creating a world with more conversations. With more than 14 years of expertise in voice technology, we have hundreds of millions of end users, and a worldwide team in six countries building solutions for a voice-first world.

About the Role:
Lead high-impact speech enhancement projects with the potential to reach two billion end users

Perform R&D to design innovative audio signal processing technologies for speech enhancement

Implement and evaluate signal processing algorithms

Requirements:
Experience with DSP algorithms, especially in the context of audio. Understanding of Fourier transforms, discrete signals, filter design.

Strong programming skills using C++

Working knowledge of MATLAB

MS or PhD in Computer Science or Electrical Engineering or Applied Mathematics or equivalent

5+ years of relevant industry experience

Nice-to-Haves:
Experience working with automatic speech recognition systems

Experience with speech enhancement, such as noise reduction, acoustic echo cancellation, gain control, microphone arrays, beamforming, or source separation

Knowledge of machine learning and familiarity with machine learning frameworks, such as Caffe, Tensorflow, Torch, PyTorch, MxNet, etc."
Paris (75),,,Manager Data Engineer (m/f/d),Artefact,- Paris (75),"Who are we ?
Artefact is a new generation of a data service provider, specialising in data consulting and data-driven information system, dedicated to transforming data into business impact across the entire value chain of organisations. We are proud to say we’re enjoying skyrocketing growth.
Our broad range of data-driven solutions in data consulting and information system are designed to meet our clients’ specific needs, always conceived with a business-centric approach and delivered with tangible results. Our data-driven services are built upon the deep AI expertise we’ve acquired with our 1000+ client base around the globe.
We have 1000 employees across 20 offices who are focused on accelerating digital transformation. Thanks to a unique mix of company assets: State of the art data technologies, lean AI agile methodologies for fast delivery, and cohesive teams of the finest business consultants, data analysts, data scientists, data engineers, and digital experts, all dedicated to bringing extra value to every client.
To support and develop its growth, Artefact is looking for the next talents of the data divizion to join the engineering team. Organized in feature team, you will work in project mode (ou pizza team) to advise your clients on their IA problematics, machine learning and Big Data. The projects you will work on can go from the migration of infrastructure to the Cloud (Deezer) to the construction of a predictive model of the water rises (Greenpeace).
Your assignments :
Management : You work within a team where mutual aid and development of competences are key, you coach interns and juniors, you carry out technological monitoring, you take part in technical training given by our partners such as Google or Azure.
Delivery: You are full owner of the front to back solution, responsible for devising, implementing and deploying it. You work within a team made up of engineers, consultants, data scientists, strategic planners to identify your client needs and define innovative solutions.
Project: You are a key actor to company success participating in pitches and securing deals. Your technical capacities will allow you forge ties with your clients while accompanying and guiding them in their data and digital transformation. You will contribute to making Artefact an essential business partner.

Consulting: You are adept at choosing and setting up the most suitable technical stack based on your client's needs. You have a critical mindset to understand and optimize the organisational functioning of large firms.
Your mindset
Curious, you are always on the lookout for the latest solutions to best meet client needs. You’re actively involved in the entire value chain, whether it be front-end, back end, big data infrastructure, ML model…
Entrepreneurial spirit, you come up with solutions, new ideas not only within your team but also within the entire Artefact world

Benevolent, your team fulfillment is key for you, thanks to constructive feedback you guide,drive and make your collaborators grow
Advocate of knowledge sharing, you actively participate in circulating information within Artefact (seminars, trainings, certifications, online KM)


Profile:
Ideally you hold a masters in Software Engineering or possibly machine Learning, mathematics, or computer science
Minimum three years of experience developing and implementing data driven solutions within a consulting firm

You have the capacity to actively participate in all the project value chain ( building infrastructure and platforms, collecting data, machine learning application models, setting up API’s REST, tests and continuous deployment)

You have in-depth knowledge of Python, you have a strong interest for DevOps, you’re familiar with Cloud technologies such as GCP or Azure. You master data technologies like Spark or Beam, with previous experience of Docker (Kubernetes is a plus)
You’re a ninja of the use and exploitation of data bus like Kafka or PubSub
You have practiced indexation system such as ElasticSearch and Vespa. Ideally, you have implementation experience of a LETOR

You have a proven capacity to vulgarize technical terms and solutions for those coming from the business field, you are a key player in a diverse team
You can foresee projects risks and mitigate them through your technological choices

You have a working command of business English

Why us ?

Cutting edge stack : Python,Kubernetes, Spinnaker, Kafka, Spark, Google Cloud Platform (BQ, Dataflow, Compute Engine, PubSub, AppEngine…) , Airflow, Docker
Wide variety of projects :
– Datalake set up
– Chatbot building
– Industrialisation of machine learning algorithms
– Define the data strategy
Young and challenging environment of skilled engineers , grow your skills thanks to our mentoring program
Internationally renowned : offices in Dubaï, London, Hong Kong, Sao Paulo
Come join us #FR !
Talents-fr@artefact.com"
Suresnes (92),,,Site Reliability Engineer/Cloud,Talend,- Suresnes (92),"WHO WE ARE:

Talend, a leader in data integration and data integrity, enables every company to find clarity amidst the chaos.

Talend Data Fabric brings together in a single platform all the necessary capabilities that ensure enterprise data is complete, clean, compliant, and readily available to everyone who needs it throughout the organization. It simplifies all aspects of working with data for analysis and use, driving critical business outcomes.

From Domino’s to L’Oréal, over 4,250 organizations across the globe rely on Talend to deliver exceptional customer experiences, make smarter decisions in the moment, drive innovation, and improve operations. Talend has been recognized as a leader in its field by leading analyst firms and industry publications including Forbes, InfoWorld and SD Times.

Talend is Nasdaq listed (TLND) and based in Redwood City, California.

Talend is looking for a Site Reliability Engineer to join our growing team in our Suresnes Office. In this role, you’ll be responsible for the security, stability, and scalability of our Talend Cloud service. You’ll get to work hands-on with plenty of exciting technology and scale challenges as we grow to support millions of transactions across hundreds of servers in our Talend Cloud environment. We are seeking candidates with expertise on both development and system administration.
Responsibilities
As a member of SRE team, you will have the following responsibilities:

Maintain and automate technical operations for our SaaS cloud infrastructure, including deployment and configuration.
Ensure high availability and reliability for production systems, including upgrade and release processes as well as incident handling and troubleshooting
Manage and deploy internal and external monitoring and alerting solutions
Define and evangelize cloud-related optimizations and best practices to improve reliability and performance
Abilities in troubleshooting cloud infrastructure, systems, network, and application stacks
Perform on-call duty as part of a team maintaining the availability and performance of our cloud-hosted production infrastructure
Required Skills and experience
Bachelors’ in Computer Science or a relevant field
Team player and ability to work in a distributed team - strong interpersonal and communications skills
1 year or more of cloud engineering experience with infrastructure as code: AWS and/or Azure, GCP
Strong knowledge in infrastructure as code: Ansible (preferred), Terraform, Puppet
Scripting (Python, Shell, …)
Problem solving capacity, Ability to read and understand logs from applications (mostly Java) and investigate.
Strong working knowledge of Linux (Centos) systems and Docker (container) usage
Knowledge of at least two of the following (usage, administration, configuration, tuning):
o Kubernetes, Helm Charts
o PostgreSQL
o ZooKeeper
o ElasticSearch, Kibana, Logstash
o Prometheus, Grafana
o Jenkins 2, Jenkinsfiles, and Jenkins automation
o ActiveMQ
o Kafka
o MongoDB
Good English, both written and verbal
Well aware of security and data protection methods
AND NOW, A LITTLE ABOUT US:

Talend has received some pretty impressive accolades along the way:
""2018 Best Public Cloud Computing Companies To Work For"" by Glassdoor
Named a Leader for Data Integration Tools in the Gartner Magic Quadrant
Named a Leader in Big Data Fabric for the Forrester Wave
Ranked in the DBTA “100 Companies that Matter Most in Data”
Listed in the CRN Big Data 100 Companies

We are passionate about helping companies become more data driven; and, if we can be honest, we are all geeks at heart who pride ourselves on the vibrant company culture that we have built.

As a global employer, at Talend, we believe our success depends on diversity, inclusion and mutual respect among our team members. We seek to recruit, develop and retain the most talented people from a diverse candidate pool. We are committed to making all employment decisions on the basis of business need, merit, capability and equality of opportunity. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, or national origin."
Paris (75),,,Engineering Team Lead - Data Processing,CybelAngel,- Paris (75),"Missions
Owns a technical perimeter: design & build new features while keeping good service levels in production,
Manage & mentor a small team of engineers,
Helps your team design efficient architectures that process Terabytes of Data,
Lead large-scale projects involving multiple teams,
Mentor engineers.
The Pro’s of the Job ✅
Work on high volumetry / high availability /Real-Time data infrastructure,
Work on the Core of CybelAngel product on complex technical projects with high business impact,
Combine technical thinking and people/project management Enjoy all the advantages of a fun and pleasant working environment every day.
Stack techno ️
Backend: Python, Java, Go,
Infra: GCP, Docker, Kubernetes, Datadog, Gitlab CI, RabbitMQ,
DBs: Elasticsearch,Redis, BigQuery.
Requirements
This job has been tailored for you if…
You have at least 2 previous significant experiences as Software Engineer or Engineering Manager A strong first experience of project or people management in an Agile environment,
You have excellent communication skills in order to be able to understand, synthesise and explain complex problems in a simple way and insure popularisation of technical problems,
You are fully autonomous in designing and implementing new solutions.
Appreciated Skills
A strong and good first experience on docker, kubernetes and microservice architectures,
Good knowledge on Agile methodology like Scrum,
Experience with Cloud environments, in particular Google Cloud Platform.
Benefits

We are meant to work together, and join the adventure
You are a real team player who want to build a big success story with us,
You want to work in an international and dynamic environment,
You want to learn, improve and gain responsibility (since others will come to you to learn).


Why come and join us, because we offer ❤️
An amazing working environment, designed for kindness and blossoming,
An attractive remuneration package,
Remote friendly policy,
Regular team and global events,
Restaurant tickets (Swile),
Great offices,coffee, fruits, snacks, Mario Kart tournament."
Antony (92),CDI,,Data Engineer Senior,INFOPRO DIGITAL,- Antony (92),"Plus largement, le périmètre non exclusif inclut également les missions associées suivantes :
Intérêt pour le Développement et Opérations (DevOps),
Collecte, stockage et exploitation fluide des données,
Gestion des applications, automatisation des déploiements et installation des différents contrôleurs,
Vous travaillez en étroite collaboration avec l’équipe de la DSI ainsi que des équipes techniques externes,
Vous concevrez et construirez les applications, mais devrez également les tester et les documenter.
Votre profil
De niveau Bac+2/5 ou équivalent en Informatique, vous justifiez au minimum de 5 ans d’expérience en développement Big Data. Vous êtes Senior et donc vous aurez un rôle d’encadrement et de référent au sein de l’équipe.
Compétences techniques:
Excellente connaissance de l’univers AWS (Lambda, S3, Kinesis, API Getway, CloudFormation, DynamoDB, etc),
Excellente connaissance de Spark ainsi que les langages Scala / Python,
Connaissance des environnements MySQL, MongoDB, Solr, Redis…
Connaissance de Snowflake serait un plus,
Connaissance de DataBricks serait un plus Compétences autres,
Bonnes capacités rédactionnelles,
Esprit de synthèse et capacité à prioriser facilement les problèmes.
Savoir être :
Capacité d’Analyse et de Synthèse,
Fiabilité,
Esprit d’équipe / convivialité,
Sens relationnel, force de proposition.
En savoir plus sur nous
Infopro Digital est un groupe leader d’information et de services professionnels en Europe (3 300 collaborateurs dont 1 400 hors de France, chiffre d’affaires total de 444 millions d’euros, 20% de croissance annuelle).
Nous couvrons plusieurs univers clés de l’économie : la distribution, le BTP, l’automobile, l’industrie, l’assurance et la finance, et le secteur public.
Infopro Digital a pour vocation d’offrir des services et des produits plurimédias (logiciels, salons professionnels, bases de données, plateformes de lead, formations, édition, événements…) à ces communautés professionnelles dans l’objectif de :
Faire croître leur activité commerciale en générant de nouvelles opportunités d’affaires ;
Leur permettre d’opérer plus rapidement et plus efficacement leurs métiers en leur donnant l’information et les outils nécessaires.
La stratégie du Groupe est orientée vers le développement de marques fortes, l’innovation et la transformation digitale. Pour atteindre nos objectifs, nous recherchons les talents qui contribueront à réussir cette belle aventure !"
Paris (75),,,Catastrophe Risks Modeling:European Windstorms - (F/H),GIE AXA,- Paris (75),"The Department :
The internship will be based at the AXA Group Risk Management (GRM) department.
AXA GRM brings together multidisciplinary high-level teams composed of actuaries, engineers, PhDs and financial analysts, based in Paris (65 people), Zurich (15 people) and Madrid (20 people).
The intern will join the Catastrophe Risk and Reinsurance team of AXA GRM, a dynamic 15-members team dedicated to the modeling and monitoring of risks associated with natural catastrophes for all of AXA’s entities in the context of the Solvency II framework.
Role and Responsibilities :
The Castrophe Risk and Reinsurance team develops Internal Catastrophe Models in order to assess the potential impacts of extreme natural events for the Group (more than 100 million customers protected worldwide).
The team is looking to update its modeling for European Windstorms, the leading peril in Europe (see Swiss Re - ""Natural catastrophes and man-made disasters in 2017: A year of record-breaking losses."" Sigma Report 1, 2018).
In that context, the candidate would be responsible:
To conduct bibliographical research on Catastrophe Risks Modeling and European Windstorms Modeling
To perform a critical assessment of the data and methodology used in the current model and propose an improvement plan
To participate in the implementation and documentation of the new version of the model

Qualifications
Profile Requirements :
Suitable candidates would have a master’s degree in geosciences, c omputer science, mathematics or equivalent (engineering schools…) with interest for academic research.




Candidates should have an analytical mindset, strong programming skills (Python, R, …), as well as good communication skills.


About AXA
Would you like to wake up every day driven and inspired by our noble mission and to work together as one global team to empower people to live a better life? Here at AXA we strive to lead the transformation of our industry. We are looking for talented individuals who come from varied backgrounds, think differently and want to be part of this exciting transformation by challenging the status quo so we can push AXA - a leading global brand and one of the most innovative companies in our industry - onto even greater things.
In a fast-evolving world and with a presence in 64 countries, our 165,000 employees and exclusive distributors anticipate change to offer services and solutions tailored to the current and future needs of our 107 million customers.
The headquarters of the AXA Group, based in Paris 8th, brings together the Group's corporate activities. It coordinates the various entities with the Group's strategy, and is responsible for managing international projects. The headquarters has approximately 800 employees and is distinguished by its strong international culture (39 nationalities).
What We Offer
We provide you regular career opportunities in international teams. If you want to join us, don’t hesitate to apply !
Information provided by applicants will be processed in strict confidentiality and may be used exclusively for recruitment processes."
Paris (75),50 000 € - 70 000 € par an,,Senior/Lead Data Engineer,Back Market,- Paris (75),"Chez Back Market, nous avons à cœur de promouvoir un nouveau mode de consommation favorisant l’économie circulaire tout en luttant contre le gâchis électronique et l’obsolescence programmée.
1ere marketplace européenne (et bientôt mondiale !!!) dédiée exclusivement à la vente de produits électroniques reconditionnés, nous connectons professionnels certifiés (usines de reconditionnement, distributeurs, etc..) donnant une seconde vie à vos équipements et clients à la recherche de qualité, d’accessibilité et d’un type de consommation plus écologique.

Ce que l'on recherche au sein de Back Market? Une bonne dose d'humour, respect et bienveillance, un amour pour les lapins, un peu de zèle et une réelle expertise dans ton domaine ! Pour la bonne personne, c’est l’occasion de participer à la construction d’une marketplace de premier plan, directement dans l'équipe au cœur de l’innovation : le Bureau Of Technology.

En savoir plus sur l'organisation des équipes techniques et les features teams. :
https://medium.com/back-market-engineering/refurbishing-our-tech-organization-at-back-market-e3b6f954d41d

Au sein du BoT, et plus particulièrement de notre Team Data Engineering, tu contribueras activement à la stratégie et à la construction de notre architecture Big Data au sein de notre équipe de Data Engineers
On a besoin de toi pour :
Participer, conseiller et soutenir les choix techniques des autres équipes impliquées (Data Scientists, Data Analysts, Business, Marketing, Product etc..)
Contribuer au recrutement des compétences techniques Data Engineering.
Construire et superviser la plateforme de données nous permettant de collecter les données internes et externes à Back Market
Collecter, consolider, enrichir et modéliser de gros volumes de données (Big Data, Data Warehouse, Data Lake).
Développer et automatiser les flux de données de l'ingestion jusqu'à la visualisation en dashboards, reporting.
S'assurer de la scalabilité, la sécurité, la stabilité et la disponibilité des données de la plateforme.
Tu seras comme un poisson dans l'eau si :
Tu possèdes une excellente maîtrise d’un langage de programmation (Python, Go…)
Tu es un adepte du manifeste ""Software Craftsmanship"", en quête d'amélioration continue
Tu sais communiquer des résultats de manière claire et synthétique
Tu as participé à la construction et superviser des architectures en production : Batch/Streaming (Spark, Kafka...), Data Warehouse (Snowflake), Big Data, Algorithm, NoSQL, Parallel Programming
Tu as des bonnes expériences et des convictions sur des architectures clouds
Tu as des bonnes expériences avec de l'infrastructure-as-code
Tu es flexible et créatif dans la résolution des problèmes
Tu es bien organisé, autonome, rigoureux et doté d'un très bon esprit d’équipe
Tu souhaites en apprendre plus sur :
Une architecture AWS serverless multi-région : Lambda, Dynamodb, SQS...
Créer des pipelines d'enrichissement des données RGPD compliant avec EMR et Apache Spark
Concevoir et développer des APIs RESTful serverless
Ordonnancer de nombreux traitements avec Airflow sur Kubernetes
L'Infrastructure-as-code: Terragrunt, Terraform, Terratest
La scalabilité, la sécurité et les tests d'infrastructure sur AWS
Pourquoi nous ?

Un salaire attractif (50/70K€), des stocks (BSPCE), avantages multiples (tickets restos, mutuelle, etc...), Fruits et petit dej, plusieurs jours de remote par semaine, journée avec des collègues sympas et et évènements offsite fréquents
Des challenges techniques à relever au quotidien : avec nous, tu n’auras pas le temps de t’ennuyer !
Un groupe d’experts qui t’apporteront leur savoir-faire technique et te permettront de monter en compétence sur ton domaine de prédilection mais pas que ! (Backademy, guildes techniques, Meet-up & Conférence)
Des perspectives d’évolution avec la possibilité de changer de team feature tous les 1 ans et différents plans de carrières possibles
Un job qui a du sens : à travers ton travail, tu convaincras des gens d’acquérir des produits ayant déjà vécu au lieu de les acheter neufs. Ce qui signifie réduire la production de déchets électroniques et lutter contre la surproduction. Ça compte.
Un projet en forte croissance : on était 3 il y a 5 ans. A présent, on est plus de 250, et on a ouvert dans 6 pays différents. Tu peux ainsi nous trouver en France, Italie, Espagne, Belgique, Allemagne et aux US. Boom.
Du groove, plein : tu auras l’opportunité de bosser avec des gens talentueux et super sympathiques."
Paris (75),CDI,,Senior Data Engineer,IC Resources,- Paris (75),"Salary: €50-70,000, Healthcare, Bonus and more!
Job Type: Permanent


This Senior Data Engineer vacancy is based in Paris, Île-de-France with an AI start-up. As a Senior Data Engineer part of your primary responsibilities will be building and managing data pipelines.

The successful Senior Data Engineer must have full working rights in France, at least 2 years industry experience building machine learning and data pipelines for machine learning and meet the following criteria:

1. MS or PhD from a top University in Computer Science, Mathematics or similar
2. Proven track record of building data and machine learning pipelines that work at scale
3. Python, Scala/Java

French fluency is not required but would be of benefit.

If this sounds like you and you’re keen to find out more then please apply with an English version of your CV.










Chris Wyatt
SENIOR CONSULTANT
T :
Afficher le nº de téléphone
E : chris.wyatt@ic-resources.com"
Paris (75),CDI,55 000 € - 70 000 € par an,LEAD DATA ENGINEER,Harnham,- Paris (75),"LEAD DATA ENGINEER
55-70K par an
Paris, France
Cette Data Agency fondée il y a maintenant 10 ans traite de nombreux sujets liés à la Data Science.
Vous travaillerez dans une équipe de passionné sur des projets à long terme que ce soit au sein de l'agence ou directement chez le client. Au programme problématique d'infrastructures, de mise en place de pipeline de donnée complexes, intelligence artificielle...
Aujourd'hui elle recherche son futur Lead Data Engineer afin d'accompagner les profils plus juniors et apporter son expertise sur les projets en cours.
LE POSTE :
Au sein d'une équipe Data composée de 7 Data Engineers :
Vous développerez des pipelines de données
Vous mettrez en place des Data Lake from scratch
Vous traiterez un très grand nombre de données
Vous développerez des applications de productions liées au Machine Learning.
Vous repenserez et travaillerez sur l'infrastructure mise en place (déploiement, intégration)
LE PROFIL :
Vous avez une expérience réussie Python, Java ou Scala
Vous justifiez d'une expérience de minimum 2 ans (hors stage)
Vous avez déjà travaillé sur AWS
Vous avez des connaissances solides sur la partie déploiement, infrastructures
Vous avez des connaissances ETL type Airflow
Vous êtes rigoureux et autonome à tous les niveaux
COMMENT POSTULER :
Si vous êtes intéressé(e), merci de faire part de votre CV à Pierre Gerbeau."
Paris (75),CDI,55 000 € - 70 000 € par an,Lead Data Engineer,Sept Lieues,- Paris (75),"Société fondée en 2017 productrice de données originales et actionnables dans des plateformes développées sur mesure dans les secteurs de l'énergie, rénovation, bâtiment, assurance, finance verte et culture.
Equipe composée de 40 personnes avec une expertise en Machine Learning, Computer Vision, Natural Language Processing.
LE POSTE / LES MISSIONS
Vous rejoignez l'équipe Data en tant que Lead Data Engineer, vos missions sont les suivantes :

Encadrement technique d'une équipe de Data Engineers en étant le référant technique sur des problématiques en lien avec des bases et flux de données.
Contribution à l'évolution de l'infrastructure de données vers des technologies scalables (Hadoop / Spark, BigQuery, Citus) intégrant plusieurs types de données
Etre le garant de la disponibilité des outils et bases de données utilisées par les équipes
S'assurer de la mise en production des données
Industrialisation des modèles des data scientists. Définition et implémentation d'une architecture fiable (GCP, Dataiku)

PROFIL RECHERCHÉ
Bac + 5 ou équivalent dans le domaine du Big Data / Data Science. Vous disposez d'au moins 3 ans d'expérience en data engineering avec idéalement une expérience en management ou gestion de projet.

Vous avez des connaissances dans les domaines suivants:
SQL, NoSQL
Développement Python avec des connaissances des outils de type Git, Docker
Projets intégrant des technologies cloud (GCP, AWS, Azur)

Vous êtes un bon communiquant avec une volonté de travailler en équipe."
Saint-Quentin-en-Yvelines (78),,,DATA ENGINEER H/F,Expleo,- Saint-Quentin-en-Yvelines (78),"Expleo propose une offre unique de services intégrés d'ingénierie, qualité et conseil stratégique pour la transformation digitale. Dans un contexte d'accélération technologique sans précédent, nous sommes le partenaire de confiance des entreprises qui innovent.
Expleo est présent dans tous les secteurs à forte intensité technologique qui contribuent à une société plus connectée, plus durable et plus sûre. Nous nous appuyons sur une forte expertise sectorielle et accompagnons nos clients sur l'ensemble de la chaîne de valeur : conseil et business agility, conception, production et services post développement, management de la qualité.
Nos 15 000 collaborateurs interviennent dans plus de 30 pays et nous avons réalisé un chiffre d'affaires de 1,1 milliard d'euros en 2019.

Au sein du département Data Science, vous serez intégré à une équipe soudée réalisant une veille scientifique et technique dont le but est de produire des solutions de qualité intégrées à la pratique métier du client. A cet égard, vous mènerez des projets complets et variés en termes de problématiques clients (industrie, transport, banque, …), d’ingestion de données (Hadoop, ETL) et d’architecture Big Data (Data WareHouse).
Vous collaborerez avec les experts métiers pour comprendre le besoin et accompagner les clients dans leur gain de maturité sur les sujets Data science et Big data.

Vous aurez pour missions de :
Comprendre les besoins clients
Extraire et nettoyer des données dans un workflow
Stocker des données dans un environnement Big Data
Mettre en place des environnements d’analyses de données
Développer des applications data science (sous forme d’API ou de dashboard)
Présenter les workflows
Ingénieur ou Diplômé d'un Master 2 avec une spécialisation en Data Engineering, vous possédez une première expérience dans les domaines de la gestion des données et d’industrialisation d’analyses.
Autonome et rigoureux, vous êtes doté d'un bon relationnel, d’un esprit de synthèse et un esprit innovant. Vous maîtrisez l'anglais aussi bien à l’oral qu’à l’écrit.

Compétences techniques :
Environnement Big Data : Hadoop, Spark, HUE, Nifi, Kafka
Stockage des données : ElasticSearch, HDFS, SQL, Oracle, MongoDB
Déploiement d’un workflow : Kubernetes, Docker, Google Cloud Platform
Maîtrise des langages Data Engineer : Scala, Java, Python, …
Capacités de synthèses et de vulgarisation
Notions en développement agile
Anglais technique
Maîtriser l’intégralité des compétences techniques précitées n’est pas un prérequis, nous sommes en mesure de vous former.
Discutons ensemble et venez écrire la nouvelle page de votre carrière dans notre groupe !"
Paris 1er (75),"Apprentissage, Contrat pro",,ALTERNANCE - Assistant(e) DATA Analyst,Forum Emploi-Formation-Alternance: Talents Handicap,- Paris 1er (75),"Rejoindre La Banque Postale, c'est intégrer une banque citoyenne, dynamique et innovante, qui poursuit un développement accéléré sur les marchés de la banque de détail, de l'assurance et de la gestion d'actifs.Banque de service public, La Banque Postale accompagne ses clients dans une relation bancaire durable : 11 millions de clients particuliers et 400 000 clients entreprises, professionnels, acteurs de l'économie sociale et du secteur public local lui font confiance.Attentive à ses collaborateurs, elle leur propose des parcours diversifiés et investit dans leur formation tout au long de leurs parcours professionnel.Vos missionsAu sein de l'Inspection Générale vous aurez pour mission de: - Préparer et constituer les échantillons de données.- Participer à la rédaction des rapports relatifs aux extractions et traitements de données réalisés.- Contribuer à la cohérence globale des données et à la gestion de leur connaissance ainsi qu'à la connaissance des outils SI.- Assister l'équipe SoData dans le cadre des contrôles et reporting internes à l'Inspection Générale.En fonction des missions, vous pourrez être partiellement ou totalement, intégré à l'équipe de mission et participer aux réunions et travaux.De formation supérieure Bac +3 à Bac +5 (école d'ingénieur ou université) avec une spécialisation Datamining, informatique et/ou Data Analyst, vous recherchez un contrat d'alternance dans le cadre de vos études.Vous maîtrisez les langages SQL, SAS, Python et R ainsi que les outils de bureautiques.Vous êtes autonome, rigoureux et avez une excellente capacité d'analyse. Rejoignez La Banque Postale, Banque et Citoyenne !"
Paris (75),,,Senior Data Engineer (Berlin/Paris),PriceHubble,- Paris (75),"PriceHubble is a PropTech company, set to radically improve the understanding and transparency of real estate markets based on data-driven insights. We aggregate and analyse a wide variety of data, run big data analytics and use state-of-the-art machine learning to generate stable and reliable valuations and predictive analytics for the real estate market. We are headquartered in Zürich, with offices in Paris, Berlin and Tokyo. We work on international markets. We are backed by world-class investors. We have a startup environment, low bureaucracy and international team and business.
Data engineers are the central productive force of PriceHubble. As a Senior data engineer, your mission will be to guide the data-engineering work in PriceHubble. You will be given the responsibility for substantial parts of our data engineering systems. Your daily challenges will be to mine a wide range and variety of new datasets of all sort. Doing so will expose you to a wide variety of tasks ranging from building the infrastructure (Spark on Kubernetes), to building machine-learning models extracting features from raw data, to generating pipeline to process and expose new data sources,

Your Mindset
You are convinced that success in data science is achieved via data-monopolies. You are highly motivated to join an organization who is committed to building the best in class data-engineering software for acquiring, processing, and enriching real-estate data.
The following challenges speak to you:
gather vast amounts of data about real estate
consolidate, improve, and link this data to generate data sets no one else has on the market
do that all over the world
You are keen to join a startup right in its growth phase, and are not afraid to refactor code to get it to the new engineering standards that will support the growth of the organisation.
At work, your team is your main asset: you are keen to mentor fellow team members. In the startup, you are committed to create the company you want to work in; in terms of competence, standards, and mindset.

Responsibilities
Extract, cleanup, structure and transform complex raw and processed datasets to extract insights from it
Retrieve a wide variety of datasets and integrate them into the data pipeline
Create and maintain an efficient data infrastructure
Build data enrichment pipelines, using machine-learning when appropriate
Continuously provide new ideas to improve our engines and products
Requirements
MSc in Computer Science or equivalent
At least 3 years of experience in a similar position
Proficiency in Python and at least one scripting language
In-depth understanding of basic data structures and algorithms
Familiarity with software engineering best practices (clean code, code review, test-driven development, ...) and version control systems
Experience with the ETL and data processing tools we’re using is a strong advantage:
PySpark, PostgreSQL, Luigi
Working experience with cloud providers (Google cloud, AWS or Azure)
Advanced knowledge of relational databases
Experience with Docker and Kubernetes orchestration is a strong advantage
Understanding of core machine learning concepts is an advantage
Worked previously in ‘agile’ team(s) and are looking forward to doing it again,
Comfortable working in English; you have a great read, good spoken command of it.
Benefits
Flexible work hours
Casual dress code
Free snacks, fruits, coffee, beers, sodas
Thursday drinks
✈️Relocation package
L&D program
Well-located offices
Competitive salary"
Paris (75),,,EU Privacy and Data Protection Regional Senior Manager,Amgen,- Paris (75),"OUR COMPANY

Amgen is one of the world’s leading biotechnology companies. Amgen is a values-based company, deeply rooted in science and innovation to transform new ideas and discoveries into medicines for patients with serious illnesses.
KEY RESPONSABILITIES
Provide advice, guidance and/or support to local DPOs, Compliance Managers and Compliance Associates regarding:
Any data protection issues arising at respective affiliates
DPA Notifications and Prior Approval submissions
Data Subject Inquiry responses (including, but not limited to access requests and requests for correction or deletion)
DPA inquiries and inspections (including advising on filing of DPA Notifications and Prior Approval)
Audit preparation
Regional execution of timely self-assessments to detect Privacy and Data Protection gaps and communicate gaps to CPO immediately (including liaison with business and IS to remediate self-assessments and audit gaps); and
Any needed privacy-related training
Provide advice, guidance and/or support to Global Privacy Office regarding:
Regional or local privacy regulations, DPA activities or Court decisions regarding relevant regions
Local and/or regional privacy risks
Status of the Privacy Compliance program in respective countries (on a quarterly basis)
Cross-borders issues and assist in the development and implementation of innovative approaches to Privacy and Data Protection compliance in assigned region and across Amgen
Best practices and how to improve cross-geographical and cross-functional awareness
Implementation and identifying any needed improvements in Privacy Incident Response process in regional affiliates in assigned region; and
Developing and supporting implementation activities for local level privacy and data protection policies and procedures
Ensure privacy compliance across various functions:
By providing training together with the DPO, and regular communications on Privacy and Data Protection Compliance to relevant staff in assigned region
By advising on Privacy and Data Protection issues, including drafting privacy notices, templates and consents and ensuring consistency in practices and forms with other regions and HQ
By collaborating with Law, Audit, IS and WC&BE functions regarding Privacy and Data Protection requirements to ensure compliance and programmatic improvement; and
By consulting the local Management, HR, and CPO on the nomination of new DPOs
BASIC QUALIFICATIONS :
Law degree
5+ years of relevant privacy experience at a law firm or global company

Please note:
An online assessment (capacity test and personality questionnaire) is part of the recruitment process
PREFERRED QUALIFICATIONS :
Strong working knowledge of global privacy and data protection laws and regulations
Excellent written and spoken communication skills, including strong presentation skills
Strong analytical skills, in particular with regard to complex rules, regulations and policies
Ability to develop and apply pragmatic solutions to complex legal/regulatory challenges
Proven record of success in working collaboratively as part of a team
Strong negotiation skills
Ability to work in a cross-functional, cross-cultural matrixed environment
Understanding of global aspect of position
Experience leading compliance initiatives in multinational organizations
Strong work ethic – commitment to getting the job done in the best manner possible
Commitment to being part of a global team, including required meetings at non-traditional work-hours
Ability/willingness to travel up to 40%
Language: English, plus at least one European language form country in covered region
Self-motivated, self-starter
CIPP certification from the International Association of Privacy Professionals
Background in, or familiarity with, information technology
Experience interacting with regulators and regulatory agencies
Healthcare/Pharmaceutical/Life Sciences experience
Crisis management experience (e.g. responding to data breaches)

Join Us
If you're seeking a career where you can truly make a difference in the lives of others, a career where you can work at the absolute forefront of biotechnology with the top minds in the field, you'll find it at Amgen.
Amgen, a biotechnology pioneer, discovers, develops and delivers innovative human therapeutics. Our medicines have helped millions of patients in the fight against cancer, kidney disease, rheumatoid arthritis and other serious illnesses.
As an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other but compete intensely to win. Together, we live the Amgen values as we continue advancing science to serve patients."
Paris (75),,,Search Relevance Engineer - Salesforce,Salesforce,- Paris (75),"Job Category
Products and Technology
Job Details
Search Relevance Engineer - Salesforce Search
France / Grenoble - France / Paris - Remote

Salesforce is looking for an exceptional engineer ideally with a dual background in machine learning and software engineering.
As part of the Search Relevance team, you will work on relevance features that drive the richness, quality and effectiveness of the search experience across all of Salesforce’s products.
You will be embedded in a cross-functional team of talented technologists who all share a passion for building data-driven, well-designed and well-tested products and systems.
The role requires a strong team player who is comfortable working closely with product and engineering using Agile principles.
Responsibilities
Design, develop, bring to production at a large scale and support “intelligence” features on a world-class search service that serves millions of requests daily on a diverse corpus of data including structured, unstructured and social feeds.
Design and operationalize usage metrics and patterns to identify opportunities to improve relevancy of search.
Analyze and understand the different products, devices and use cases that are driven by search across salesforce and develop strategies for improving relevancy.
Deploy models at scale and assess impact from A/B testing (including interpretation of results).
Develop new relevance features and techniques build upon the latest results from the research community.
Required Skills
At least 2 years of hands-on experience in engineering positions focused on Machine Learning, Information Retrieval, Recommendation systems or Data Mining, Natural Language Processing, Learning to Rank.
Strong programming skills in Java, Python or Scala
Strong understanding of Object Oriented design, advanced algorithms, data structures, etc.
Iteratively analyzing data, integrating new data sources, experimenting and optimizing.
Excellent oral and written communication skills
Desired Skills
Master’s or PhD in a relevant field and/or experience in any of the following is highly regarded: Machine learning, data science and modeling techniques including classification, regression and Bayesian analysis.
Experience with Lucene/Solr or similar search systems preferable
Experience working with large datasets, preferably using tools like Hadoop, Spark, Pig or Hive.
Good understanding of usability and visual design principles
Understanding of A/B testing, expertise in metric definition and analysis
Experience building Software as a Service (SaaS) applications
Experience with Agile software development and Test Driven Development methodologies

Salesforce, the Customer Success Platform and world's #1 CRM, empowers companies to connect with their customers in a whole new way. The company was founded on three disruptive ideas: a new technology model in cloud computing, a pay-as-you-go business model, and a new integrated corporate philanthropy model. These founding principles have taken our company to great heights, including being named one of Forbes’s “World’s Most Innovative Company” five years in a row and one of Fortune’s “100 Best Companies to Work For” eight years in a row. We are the fastest growing of the top 10 enterprise software companies, and this level of growth equals incredible opportunities to grow a career at Salesforce. Together, with our whole Ohana (Hawaiian for ""family"") made up of our employees, customers, partners and communities, we are working to improve the state of the world.
Accessibility - If you require accessibility assistance applying for open positions please contact the Salesforce.com Recruiting Department .
Posting Statement
Salesforce.com and Salesforce.org are Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Headhunters and recruitment agencies may not submit resumes/CVs through this Web site or directly to managers. Salesforce.com and Salesforce.org do not accept unsolicited headhunter and agency resumes. Salesforce.com and Salesforce.org will not pay fees to any third-party agency or company that does not have a signed agreement with Salesforce.com or Salesforce.org."
Paris (75),CDI,,Data Product Manager,Hi-Calibre International,- Paris (75),"Data Product Manager
Based: Paris
Salary: Excellent Basic + Bonus & Benefits
INTERVIEWING NOW FOR JANUARY START
An exceptional opportunity to be part of this fast growth Team for a Data or AI Innovative Leader. We are seeking an experienced Technical & Commercial Product Manager with both Functional & Technical Product Management Leadership within the data side of the business needs. You will work closely with Clients on site to “Champion” the product leadership and transformation for their data and digital needs. This may include: a new data platform with analytics, BI etc. for customer profiling and insight needs or a range of others, varying with each vertical market needs and data governance etc. You will be the Product Owner and subject matter expert to work closely with the Customer’s Teams in Agile or LEAN and their own Technical Product Owners, Business Analysts and next generation SaaS or Cloud etc. with Big Data Development Teams as needed.
Key Responsibilities:
You will work closely with the Business commercial needs and be responsible for the new Roadmap features and full Product Life cycle, (PLC) and Design needs with the Transformation team etc. You will create the User Stories and Epics to work with the Team to create the functionality for a range of products for the product suite needs for larger Enterprise, Tier 1 customers in Finance, Retail or other vertical markets and to support all aspects of secure digital journey needs as well as the mid-size markets and even start-up technology companies.
You will lead and manage the Agile methodology needs, daily Scrum, Sprint planning and product release dates etc. for the program of product needed to be delivered guiding them through full software application development lifecycle. Ideally, you will help to articulate the needs, working with UX Designer and architects on their Data Roadmap, poss. Micro Services for Cloud transformation or AI Platform or whatever the challenges are for the customer, understanding the tools available to them etc. Working with the Product Coach you will create new Product delivery processes, working with Customer’s Technical and Business Owners and Dev Ops to ensure best practice and costing for solutions for Larger Enterprise, customer centric needs to working with smaller customers looking for simple Analytical solutions for their Retail, e-Tail, mobile or telephone commercial needs. This will cover the full customer experience in a multi-channel model, SOA, Testing and deployment with even post sales customer support for call centre services etc. and new product introduction processes as needed.
You will work closely with the business & development departments for new products & modifications to the various applications needs to define and agree changes for new products and create and manage the full Product Delivery Roadmap, agreeing budgets and timescales with various Enterprise customers in fast transaction processing.
Also, provide Guidance to the respective functional lead in the preparation of training materials and Customer Workshops & On-Boarding, Customer Success etc.
Ideal Profile:
Experienced Product Manager or Proxy Product Owner or similar Senior BA/PO with 4 to 12 years of experience in delivering products with most of the above expertise.
Experience of Scrum, Agile with some Product Management delivery background.
A strong relationship builder with excellent communication skills up to Senior Director Level.
Used to working on Customer Site and with 3rd parties.
Must have fluent English and French to customer presentation level in both.
Ideally have worked for a European or Global Software Consulting Practice or Company in SaaS.
MSc in Data or BI, Analytics, BSc or similar could be good, any Agile or Scrum Certifications or Product Management Qualifications would be good.
This is an excellent opportunity to really help shape tomorrow’s technologies and Data Application Excellence and be a major contributor in this exciting expanding Company."
Paris (75),CDI,,Data Engineer - Network,Sept Lieues,- Paris (75),"Startup de mise en relation, sur le secteur de l'emploi, basée au centre de Paris
LE POSTE / LES MISSIONS
Vous rejoindrez l'entreprise en tant que data engineer.

A ce titre, vous aurez différentes missions, notamment:
Créer, développer et maintenir une large base de données
Travailler avec la team data et les équipes produits
Optimiser le système ETL existant
Automatiser les processus via Python

Vous bénéficierez de beaucoup d'autonomie évoluerez dans un environnement avec de beaux challenges techniques
PROFIL RECHERCHÉ
Formation d'Ingénieur en Mathématiques ou Data Science
Expérience de 3 ans sur des problématiques liées à la data
Maitrise de Python

Les plus: utilisation de MongoDB, bonne compréhension de l'architecture datawarehouse"
Voisins-le-Bretonneux (78),,,Talent Community - Senior Data Architect EMEA,Boston Scientific Corporation,- Voisins-le-Bretonneux (78),"Talent Community - Senior Data Architect EMEA
Are you interested in a collaboration with Boston Scientific? Then become part of the Boston Scientific Talent Community!
A position as ""Senior Data Architect EMEA"" might interest you and match your experience and skills? Then the following detailed job profile will certainly interest you.
For 40 years, Boston Scientific, the world's leading medical device company, has been working to improve patients' lives. Every day, we address the key challenges of the healthcare industry with innovative products, a culture of collaboration and a deep passion for improving human life - making a career at Boston Scientific more than just a job.
In order to continue to make a positive impact on patients' lives, and also to continuously support and improve the working environment in the healthcare industry, we are always looking for talented people to help develop progress for Boston Scientific in close collaboration with internal and external stakeholders.
Location: Near any European Boston Scientific main Hubs (Hemel Hempstead; Voisins-le-Bretonneux; Ratingen; Milan; Madrid; Kerkrade; Warsaw)
Tasks as Senior Data Architect EMEA at Boston Scientific:
Determine integrated modeling standards, guidelines and best practices and approved modeling techniques to ensure the accuracy, validity, and reusability of data
Supervise the creation and maintenance of all conceptual, logical and physical data models
Assess existing models to improve performance, reliability and scalability of data models, recommending new technologies, architectures and business workflow improvement
Identify the most significant data assets to the organization, as determined by the business impact, decision impact, risk mitigation or organizational impact of the information
Communicate, present, articulate complex technical architecture solutions to developers, architects and business stakeholders, translating business and organization requirements into data models
Supervise the data modeling staff and the data administration team, providing data architecture best practices and guidelines
Establish metrics for tracking and measuring the value of data architecture initiatives, measuring model reuse, impact on project costs or improved data consistency across diverse initiatives
Ensure the continuity and improve existing reports and communicated with senior managers
Build the database server solution that will hold the data architecture, in conjunction with IT team to ensure the solutions adapt to the software environment of the company
Lead the roadmap of software investments that will increase the efficiency of the data architecture, in close collaboration with the Global IT Team
Propose and build tools to make system use easier, in a “Proof of Concept” mode or for more sustainable use
Select, engage and manage relationship with third parties for the development of new capabilities, reviewing and evaluating proposed data models contained in packaged or commercially available applications
Manage projects for the implementation and the enhancement of new data architectures and support system integration of new tools/functionalities
To join our Boston Scientific Talent Community and be successful in such a role, you should have the following qualifications:
Minimum 10+ years professional experience in Business and IT, predominantly in Business Analytics
University Bachelor’s Degree in Information Technology, Computer Science or an engineering filed with a focus on Data Architecture
Proven experience in the maintenance and development of data models and data systems with large amount of data.
Data Server Skills Microsoft SQL Server, Azure, Oracle, Database Shell Script
Project Management experience
Other Excel (Visual Basic), Access, SQL, Tableau, Qlik (or similar)
Good knowledge of Sales Force and Adobe platforms
Good communication and networking skills to interact across matrix organization.
Familiarity with programming languages such as Matlab, R.
Fluency (native or equivalent) in English
Willing and able to travel frequently
Would you like to know more about it? Apply today for the job profile of a ""Senior Data Architect EMEA"" within the Boston Scientific Talent Community and we will contact you as soon as possible. If you show the right skills/abilities for this talent community, we will arrange for a discovery call and put you though a short interactive process to support you for future openings within the organization. This is not an open job vacancy.
We would like to thank you for your application to the Talent Community at this time!

Job Segment: Architecture, Database, Medical, Data Architect, HR, Technology, Engineering, Healthcare, Data, Human Resources"
Paris (75),,,Lead Data Engineer - Paris (FR) - E-Commerce,Digital Source,- Paris (75),"Do you want to start a new adventure as a lead data engineer?
Are you able to manage a team of data engineers?
Finally, are you available to work in Paris

We have a unique opportunity for you!
About our client
Our client is an ambitious company who use data to improve the understanding and transparency of real estate markets.
Your mission
As a Lead Data Engineer, you will manage the Data Engineers team to build and maintain the data infrastructure.
You will extract, clean up, structure and transform raw data to extract insights from it
You will propose great ideas to upgrade the engine and products
Your profile
You have at least 3 years of experience in a similar position. You have also an MSc degree in Computer Science or a similar equivalent. Finally, you understand real estate markets and urban-related data.
Soft Skills
You speak and write a great English
You can manage a team and give precise directions
You are comfortable in working within an Agile environment
Hard Skills
You have strong skills in Python & Spark
You are familiar with data engineers best practices
You have knowledge of working with cloud providers (e.g Google Cloud, AWS)
Bonus
You have knowledge about Docker & Kubernetes
You understand the core Machine Learning concepts
In return
Afterworks
A low bureaucracy environment
A top-notch international team
Flexible hours
Business Benefits (e.g Lunch Learning)
Attractive salary
Are you interested in this job?
Send us your CV now and we will contact you as soon as possible.
For more information about the position, contact us at frederic@digitalsource.io.

7677"
Paris (75),CDI,,"Lead Product Coach, Data",Hi-Calibre International,- Paris (75),"Lead Product Coach, Data
Based: Paris
Excellent salary, c 80K basic and bens
INTERVIEWING NOW TO START ASAP
An exceptional opportunity has arisen to join this rapidly expanding Trail Blazer in France for Innovation in Data, AI, Financial Digital Transformation and much more.
The Lead Product Coach is responsible for leading the adoption of LEAN or Agile for the product with all the Product Teams (members includes PO, Development, Dev Ops and Data Engineers etc.) and Client Leaders at a Product level in order to establish a common understanding across the product needs & define the Roadmap of deliverables.
The Lead Product Coach will evaluate the stability of the portfolio and respective products in order to identify opportunity for improvements around scaling LEAN or Agile and product management process and help the Client Internal teams mature their product vision, planning and delivery. This role will be accountable for working on Client Sites with leaders (poss. Customer’s VP of products and Directors across the portfolio) to develop a strategy to set and achieve the processes and product goals for their respective products. The position is new to the Practice so you will know what needs to be done and lead this.
Responsibilities may include:
Formally create, in conjunction with the product leaders, and execute against a product life cycle plan and communicate the plan to the Product Teams and the team’s leader chain (up to VP).
Provide Workshops & direction to Director+ leaders on Agile & LEAN for product processes.
Ensure Product Teams and leaders can demonstrate their adoption of processes based on the coaching plan.
Formally review the progress, outcomes, and observations (positive and negative) of the product coaching plan with the product leaders and the portfolio, VP’s etc.
Ensure all coaching engagements have a positive learning experience. The Lead Product Coach will be the expert of the product principles and product management techniques. As such, you will need to be involved with internal and external LEAN or Agile Teams and product management in order to stay current on best practices and strategies related to this way of working. The Lead Product Coach will need to actively participate in the thought leadership within these LEAN or Agile and Product communities and seek out opportunities to continuously improve their own skills in order to better support the products and companies.
Participate and promote internal Community of Practices to drive a learning culture.
Participate in external professional organizations relevant to product development and coaching for best practice etc.
Willingness to attend and present at conferences, trade shows, or industry events, as appropriate.
Training and Certification: The Lead Product Coach will be responsible for understanding and developing shared internal training and learning materials that apply the principles of LEAN or Agile to product life cycle. The Lead Product Coach will be responsible for the active coaching of Product Teams and leaders, facilitation and coaching of quarterly planning events, and development of product specific plans to enhance the Product Teams and leader’s skills and mindset, User Stories, EPICs etc. with Product Owners etc.
Coach leaders and teams in driving a learning culture rooted in product, LEAN, Agile and technology.
The Lead Product Coach will work closely with Consulting partners, particularly Scrum Masters, Product Managers and Engineer Managers, to evaluate a Product Teams agile and product maturity and strategies to address gaps. The Lead Product Coach will also work closely with Directors to establish Agile and product maturity strategies for the products, coach and educate one-on-one with leaders, provide direct feedback based on observations, and be a catalyst for promoting a Product culture.
Communicate with stakeholders to ensure that newly implemented product coaching strategies are working as planned.
Demonstrate product level adoption by the Product Teams and leaders of the best practices and repeatable processes.
Facilitate the definition of a product & full life cycle, backlog, risk management etc.
Proactively provide feedback to leaders and individuals based on direct observations.
Mentor and develop other Coaches and Scrum Masters and Product Owners etc.
Ideal Profile:
4+ years in Agile or LEAN leadership experience.
8+ years Product Management experience across a variety of LEAN and Agile methodologies and frameworks.
Leading large organizations/enterprise through LEAN and Product transformations.
Leading Product management and learning programs for product teams in Data etc.
Leading coaching in technology, product and business organizations.
Agile certifications (SAFe/Scaling, Product Owner, Coaching, etc.) RTE
LEAN, Kanban, Continuous Improvement, Process experience.
DevOps experience (build automation, test automation, test driven development (TDD), Continuous Integration (CI), Continuous Development (CD), Infrastructure as code, etc.)
Working with the Technical/development teams (Java/OOP. coding, scripting. SaaS infrastructure development, application development in multi-channel needs).
Presentation level English & French.
An excellent challenge and real opportunity to make a difference in Consulting and timely Product delivery etc."
Paris (75),,,Lead Product Development Manager,MOTION-ISE,- Paris (75),"Motion! is looking for an extremely entrepreneurial Product Manager Leader, an exceptionally talented product manager to guide the vision, roadmap, and development of our ""all-in-one"" smart innovation ecosystems platform. Day-to-day you will utilize your creativity, analytical skills, and entrepreneurial flair while collaborating with brilliant colleagues across functions to design, build, and deliver features that are both useful and delightful to our platform users.

You and your team will be focused on leading the product development and on delivering value to enterprise and platform customers and to our network of 3rd party developers, working in a cross-functional team with colleagues in design, development, and QA. You will oversee the global product management team as well as collaborate closely with content and technology providers, UX designers, engineers, data scientists, analysts, machine learning experts, marketers and other cross-functional team members within the organization to ensure that our products amaze and delight our users.

Responsibilities Will Include
Leading our product management organization
Responsible for project development from concept through testing and initial manufacturing
Own the product roadmap, prioritization, value proposition, and product development lifecycle
Attend industry conferences, build relationships with third party software vendors and be the go-to person for all financial planning needs – internally and externally
Working with internal stakeholders to devise a forward-looking product strategy for a dedicated product area. Build, drive and manage a product roadmap against that strategy.
Identify the business case for new products and features as well as enhancement of existing ones through analytics, customer interaction and feedback from internal stakeholders
Collaborate with design team to crate prototypes and user interface mockups illustrating user experience and product flows
Write clear and concise product specs, features cards, and other product documentation.
Guide and work closely with engineering teams throughout the development process to verify all products comply with guidelines and specifications
Owning delivery of product initiatives and releases
Defining, documenting, and communicating objectives, requirements and constraints for product initiatives and releases
Communicate development status to other stakeholders and document progress toward milestones
Facilitate communication between client stakeholders and development team members
Prioritize and sequence product initiatives
Willingness to travel 30%

Requirements For Position
A bachelor’s degree in finance, economics, computer science or related field is required; a graduate degree is preferred.
A minimum of five years of relevant and progressive experience in client service or product management.
Experience leading a product management organization within a start-up or B2B organization
You have a track record of growth and success in your past work experiences
An entrepreneurial work style - you're a self-starter
Strong sense for customer and user experience
Ability to create product vision’ based on market dynamics and understanding of market forces to shape the product roadmap and keeping it ahead of competition curve
Knowledge and experience with Agile development, and good technical acumen are plus.
Experience in planning and executing product releases
Ability to work well with designers and engineers
An analytical and metrics-driven work style and excellent organizational skills
Impeccable interpersonal and communication abilities
Comfort working in a fast-paced and dynamic environment
Passion for digital platforms, artificial intelligence, e-commerce and new technology
You have experience working with the common product management frameworks and concepts: agile, scrum, lean, MVP, user story, backlog, etc.
Experience in product management for complex software systems, data analytics, and/or machine learning products
You can manage the details without letting them overwhelm. You never lose sight of the big picture. You prioritize tasks and focus appropriately.
Background in artificial intelligence, security, and/or data science is a big plus
You do the right thing, and you treat others with respect.

Ideal job opportunity in Paris for professionals and expats seeking employment opportunities with English as the main working language.

If based in Paris, France, the Lead Product Manager must be native language speakers and/or fluent in English (able to lead and manage local and global teams and communicate in English with virtual teams from different locations).

Compensation:

This is a paid position commensurate with experience.

Please apply via the job portal or send your CV / Resume along with a cover letter to talent (Code LPDM).

** LOCAL CANDIDATES ONLY - NO VISA SPONSORING **
About Us:

Motion ! is an early-stage technology start-up company based in Paris, France and New York City, U.S. We are building the best ""all-in-one"" platform to access innovation easier, faster and more efficiently from anywhere, anytime, anyplace."
Paris (75),45 000 € - 60 000 € par an,,Data Project Manager pour une MedTech qui développe une solution de diagnostic de cancer,Data Recrutement,- Paris (75),"Soyez alerté de la prochaine offre similaire en cliquant ici.
Data Project Manager pour une MedTech qui développe une solution de diagnostic de cancer
Offre publiée le 18-05-2020.
Paris
Fonction Data engineer hadoop spark
Fonction Data scientist ml ia nlp dl
Fonction Ingenieur bi etl teradata
Fonction Consulting
Fonction Pm moa moe delivery
Teletravail partiel
Expérience 1 à 2 ans
Expérience 3 à 5 ans
Min 45k€
Max 60k€
L’ENTREPRISE : Une Startup e-santé qui développe une solution de détection de cancer
Entreprise
Equipe de 16 personnes
Projet d’intérêt médical : détection des cancers à un stade précoce
Solution primée à deux reprises
Levées de fonds > 5M€
Paris centre
Stack technique : Python, Django, Linux, DevOps, Docker, Sql, Json, Machine Learning, GitLab, GitLab CI
LA MISSION :
En lien direct avec le CTO et le Clinical Manager vous aurez à intéragir avec serez l'interface entre les équipes machine Learning, IT, devops et les médecins et partenaires.
Vos missions :
Etablir et accompagner des partenariat avec des hôpitaux/ des cliniques français, américains et Canadiens de manière à collecter de nouvelles données médicales à annoter
Gérer une plateforme d'annotation permettant de faire produire et valider en continu des données médicales expertes et avoir des data sets propres
En lien avec les médecins, contrôler le rendu de l’analyse automatisée du dispositif médical de manière à détecter et implémenter des axes d’amélioration pour obtenir l’analyse la plus performante possible
Remonter les feedbacks users de manière à améliorer la solution
+ : prévoir des déplacements aux USA et au Canada dans le cadre des partenariats
VOTRE PROFIL :
Vous êtes diplômé d’une école d’ingénieur
Vous avez de 1 à 5 ans d'expérience en gestion de projet en lien avec l'environnement médical / des cliniques
Vous êtes familier avec les enjeux du machine learning
Vous maitrisez parfaitement l'anglais à l'écrit comme à l'oral
+ : la connaissance de Python est un avantage pour le poste afin de lancer des requêtes
MODALITÉS :
Package de rémunération selon profil et expériences : 45/60 K€ selon profil et expérience
Télétravail possible : 1 à 2 jours par semaine
PROCESSUS DE RECRUTEMENT :
1 call avec Data Recrutement
1 call avec le CTO
1 rencontre avec le CTO et les équipes Data
Rencontre founders

Sélectionné par Renaud De Cock
Manager, Spécialiste Product & Design
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),,,Data Ingenieur Senior,IPANEMA CONSULTING,- Paris (75),"Contexte
Dans le cadre de son développement d’activité, IPANEMA CONSULTING recherche data Ingenieur.
La mission sera en étroite collaboration avec les fondateurs du projet et le CTO.
Mindset ipanema
Notre Vision est que la Révolution Numérique est une opportunité à saisir pour chaque entreprise, que les entreprises ont le droit à développer une vision augmentée d’elles même, Nous croyons aux démarches de conduite du changement pour faire évoluer les organisations dans une culture « Data Centric »
A l’ère du Digital, notre vision est que les entreprises ont plus que besoin de se ré-inventer grâce à des solutions non fantasmées, alignées et coordonnées avec précision.
Intégrer une communauté de « Data Refiners » et de mettre la puissance de l’intelligence artificielle au cœur de la transformation des entreprises et des administrations.
Notre mission
IPANEMA CONSULTING est un cabinet d’accompagnement à la transformation Numérique qui fédère des talents autour de la stratégie, du change management et de la data.
En plaçant la technologie et l’humain au cœur de la transition, nos équipes proposent des solutions pour les challenges des entreprises de demain.
La force de notre écosystème
Nous avons développé un écosystème fort pour accompagner nos clients dans leurs enjeux d’innovation et pour leur adresser des solutions les plus complètes possibles.
(M&A spécialisé en Tech, lab de starts up, accélérateur de starts up, expertises stratégie, expertise Océan Bleu, expertise Design thinking, expertise Data et blokchain).
Talent recherche :
Issu d’un cursus statistiques, mathématique ou ingénieur école top 5,
Une première expérience souhaitée dans l’intelligence artificielle (Chatbots, RPA, NLG, etc.) ou la Data Science
Compétences en : Java, Les langages statistiques (Python, R, etc.), le datamining, la connaissance des algorithmes de machine de learning et de deep learning, les langages NLG, JSON, XML…
Maitrise de techniques secrètes (frame patterns) de l’écosystème Hadoop, Spark, Kafka ainsi que son intégration dans une architecture d’entreprise, connaissances en bases de données SQL et NoSQL, et ETL
Sensible aux approches craftsmanship (CleanCode, TDD)
Familiarisé avec des Frameworks de tests tels que JUnit, Mockito, Gatling et les APIs REST
Bon relationnel équipe et client
Sens de l’écoute, force de propositions et envie de partager tes connaissances et savoir-faire et d’apprendre de tes pairs.
Missions :
Bien plus qu’un emploi, une véritable aventure humaine au sein d’un marché prometteur
Collaboration avec les équipes Big Data de nos clients pour concevoir et développer de nouvelles architectures de données
Mise en place ainsi qu’à l’enrichissement de datalakes basés sur l’écosystème Hadoop
Implémenteras des workflows complexes d’acquisition et d’analyse de la donnée pour faire émerger des possibilités métiers encore inexploitées
Travail de pair avec des Data Scientists dans un esprit de partage de compétences.
Début
Dès que possible
NB : Pour intégrer ses nouveaux collaborateurs, IPANEMA CONSULTING a conçu un programme spécifique d’intégration.
Rémunération
En fonction de l’expérience."
Paris (75),CDI,,SENIOR DATA MODELER - SAS,Harnham US,- Paris (75),"SENIOR DATA MODELER - SAS
Paris, France
45-75K + Bonus
A World Leading management consultancy are seeking an experienced Regulatory Analytics Consultant to take part in innovative projects related to regulatory solutions for major clients.
THE COMPANY
Recognised globally, this consulting firm are leaders in regulatory and reporting space. Recognised with multiple awards, such as 'Top Employers' Award, they are continually developing their client relationships with World Leading Brands, allowing their employees to have fantastic exposure to a wide variety of top level projects and network.
THE ROLE:
Working directly under the Senior Data Modeler Manager, on a variety of projects for companies in the financial world
Participating in data analytics, statistical model development, statistical testing, implementation testing of multiple complex models, and requirement documentation
Developing several statistical models for all the clients of the group within a financial/banking context (Bale 2/3, Forecasting models - IFRS 9, Stress Tests SREP and EBA)
Guaranteeing the performance of the models thanks to regular reviews and back testing, and will redesign the models where back testing is not satisfactory
Attending client meetings and to some extent participating in some presales work
YOUR PROFILE:
Bachelor's degree or Master's in Mathematics, Statistics or related technical field
Expertise with SAS, and experience with Data mining techniques, and statistical and scoring models
Knowledge of Python, R, and SQL is a plus
Fluent French and professional English
Authorised to work in the EU"
Paris (75),CDI,45 000 € - 63 000 € par an,Data Engineer Confirmé(e),Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data engineer hadoop spark
Taille entreprise de 21 à 50
Technologies Agile
Technologies C
Technologies Cassandra
Technologies Git
Technologies Hdfs
Technologies Hadoop
Technologies Hbase
Technologies Keras
Technologies Machine learning
Technologies Mongodb
Technologies No sql
Technologies Python
Technologies S3
Technologies Spark
Technologies Shell
Technologies Tensorflow
Expérience 3 à 5 ans
Statut CDI
Min 45k€
Max 63k€

CONSEIL EN STRATÉGIE & MANAGEMENT, SPÉCIALISÉ DATA
L'entreprise accompagne ses clients à valoriser leurs données en menant des projets big data et d'intelligence artificielle. Les consultants interviennent de bout en bout, de la conception de la stratégie à l'exploitation des plateformes technologiques.
Rejoindre l'aventure c'est se spécialiser sur des problématiques de machine learning, deep learning et big data.
Année de création : 2016
Effectif : 36 collaborateurs
Très bon positionnement : directions générales, marketing, innovation ou data lab (pas de DSI)
Clients diversifiés : média, banques, industries, retail
Problématiques : spécialisé data, à un niveau conseil en stratégie et management (vs agences)
Pur conseil : les missions sont vendues au forfait et vous revenez au cabinet 1 à 2 jours par semaine
Missions courtes : 2/3 mois
Équipes : grandes écoles et du TOP30 des cabinets de conseil
Top formation : conférences, formations internes… – le bon endroit pour monter en compétence
Top locaux : en plein coeur de Paris
Notre avis chez Data Recrutement, en tant que cabinet de chasse :
Le type de cabinet de conseil avec des missions très intéressantes (courtes, stratégiques, utiles) et une culture d’entreprise startup.
VOTRE MISSION : DATA ENGINEER DANS UN ENVIRONNEMENT BIG DATA ET IA
Avec une répartition de 70% de votre temps chez le client et 30% au sein des locaux, vous devrez :
Travailler en équipe sur les projets (avec d'autres data engineer, data scientist et équipes métiers)
Proposer des architectures Big Data et IA (applicative, batch ou temps réel)
Industrialiser les solutions
Mettre en production, définir la plateforme, les flux et les traitements de données
Encadrer et mentorer des data engineer juniors
Assurer une veille technologique
Être force de proposition
VOTRE PROFIL : DATA SCIENTIST CONFIRMÉ(E)
Rencontrons-nous si :
Vous êtes diplômé(e) d'un bac+5 orienté data ou une école d'ingénieur
Vous avez idéalement une première expérience dans un cabinet de conseil en stratégie et management
Vos 2 ans d’expérience minimum (hors stage) en tant que data engineer font de vous un(e) expert(e) :
Vos maîtrisez parfaitement Python et Hadoop et/ou Spark
Vous souhaitez participer à l’aventure d’un cabinet déjà très reconnu et en forte croissance dans une culture startup
C'est un plus si vous avez une appétence pour l'IA
Parler français/anglais couramment n'est pas un problème
MODALITÉS :
Package : 45/63k€ selon expérience
Processus de recrutement rapide :
Entretien téléphonique
Test technique
Rencontre avec le directeur technique
Sélectionné par Deborah Peter
Spécialiste Infra / DevOps / QA
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),,,Senior Solutions Architect - Customer Experience,AWS EMEA SARL (France Branch),- Paris (75),"You have the following qualifications and competences:
Expertise designing customer experience technical solutions in one of the following: (1) Multichannel Contact Centres (2) CRM solutions focused on Customer Experience (3) Contact Centre Workforce Optimisation/Management.
Passion for building solutions, either professionally or as a hobby, using cloud technologies and a coding language such as Python, Node.JS, C++ or similar.
Capability of deriving customer objectives, and creating and positioning compelling solutions that address these objectives. This capability has been gained through many customer engagements.
Experience managing complex engagements (or projects) involving multiple stakeholders.
Good presentation skills.
Advanced engineering or scientific degree, or equivalent relevant experience.
Fluent English

Role available in any AWS site across the EMEA region.

At Amazon Web Services (AWS), we have taken the technologies that have made Amazon one of most customer-centric businesses on the planet and created a customer experience platform that is growing at pace. We combine technologies from artificial intelligence, machine learning, real-time data streaming and database analytics, fronted by an easy-to-use call flow and chat designer to form a forward-looking customer experience service in the cloud. It’s architected around our Amazon Connect service, which integrates with other AWS services such as Amazon Lex (a chatbot powered by the same engine as Alexa), Amazon Kinesis (real-time streaming as used in IoT), AWS Lambda (serverless code execution), Amazon DynamoDB, Amazon Redshift and a range of other services.

About You

We are looking for creative Specialist Solutions Architects who are passionate about helping customers achieve their business outcomes with the Customer Experience solutions.
You already possess good contact centre expertise, and your enthusiasm for learning will allow you to develop your competence even further.
You enjoy building solutions – for a proof of concept or customized demonstration, for example – and you have an aptitude for integrating technologies including writing code.
You delight in earning the trust of your customers and you are empathetic with them to understand their business objectives, so that you are able to design compelling contact centre solutions and convey their benefits to your customers.
You present regularly with your customers and you are as comfortable discussing complex technical details with a room full of engineers as you are briefing an executive audience.
If you don’t already present to larger audiences, you are keen to gain the skills for this so that you can communicate with communities at AWS and industry events.
You are self-motivated and you are not only keen to achieve your own business goals, but you also identify and pursue your own business objectives.
You speak excellent English and if you’re based in a role in a country that does not speak English natively, then you’ll also be fluent in the language of that country.
About Your Role
Your role will be to help our customers and partners design and deploy their contact centers on AWS, which will involve coordinating teams from the customer, partners, and many internal AWS teams (e.g., Product Teams, Support, Professional Services, Sales, Field Solutions Architects).
You will help AWS exceed customer expectations in part by overcoming technical objections and ensuring that key stakeholders are on task with the project deliverables. Your deep technical skills and strong project management skills combine to help customers achieve their business objectives.
You will convey best practices with customers and partners so that you scale the delivery of robust solutions that deliver business goals.
You will create content in the form of blogs, whitepapers, best practices, demonstrations as part of a technical field community, with your peers across AWS.
You will present at AWS and industry summits to demonstrate the capabilities of AWS solutions to an ever-wider audience.
What We Give You

You will have the opportunity of developing some of the most exciting technical solutions that truly transform customer experience using the latest technologies such as AI, ML, serverless, real-time streaming and data analytics.
We provide an extensive on-boarding program to help you develop and complement your existing skills and you will have time each week to continually improve on your competencies with training that is tailored to your needs and your career aspirations.
We offer a very attractive remuneration package, which corresponds to the high value that you bring to your customers.

Ideally, you will have the following:
Direct experience implementing AWS services
Working knowledge of popular communications protocols and APIs such as WebRTC and SIP
High level of comfort communicating effectively to both large and small audiences"
Paris (75),,,Chief Data Officer H/F - Association de délégation de service public,Michael Page,- Paris (75),"En qualité de Chief Data Officer, vos principales missions sont :
Cadrer et décliner les cas d'usage identifiés avec les métiers,
Piloter, définir et documenter les principes de gouvernance des données de la plateforme Big Data (solution Cloudera),
Garantir la bonne application des principes de gouvernance des données,
Assurer la protection des données et de la vie privée en conformité avec le cadre réglementaire (RGPD, CNil),
Être le garant du cycle de vie de la donnée (collecte, transformation, exploitation et publication),
Développer des partenariats pour la collecte, le partage et l'exposition des données de la plateforme,
Établir les conventions associées à la collecte et exposition des données et assurer leur bonne application,
Sensibiliser, former et accompagner le métier des études et analyses en termes de sécurité et de gestion des données,
Coordonner les évolutions techniques de la plateforme de données avec les équipes d'infrastructure,
Contribuer à la transformation de l'association vers un rôle d'acteur de référence sur la donnée sociale.

De formation supérieure, vous maîtrisez la modélisation des données, la gestion des référentiels et la gestion de la qualité des données.

Vous avez une forte capacité à identifier, analyser et expliciter les aspects stratégiques de la gestion des données tout en sachant lui donner une réalité opérationnelle.

Vous possédez une bonne connaissance des écosystèmes technologiques et des outils du Big Data et de la Data Science (Cloudera Navigator, HDFS, Spark, Notebooks, Python...)."
Paris (75),CDI,,Data Engineer - Telecom,Sept Lieues,- Paris (75),"Groupe français spécialisé dans la distribution de Services Telecom
Acteur majeur et innovant sur son marché
Contexte : Stabilité et Croissance

Filiale R&D : +50 personnes à la DSI
+20 dévs sur le Mobile & Embarqué
Equipe data transverse
Culture start-up et Hiérarchie plate
Equipes confirmées et dynamiques

Les plus : Bonus annuel, Locaux, Repas, Mutuelle, Transports
LE POSTE / LES MISSIONS
Au sein de la R&D vous intégrez une entreprise avec +20 développeurs qui travaillent ensemble sur les parties Mobiles et Embarqué.
Vous rejoindrez l'équipe data et travaillerez en collaboration avec des Data Scientists, Product Managers, etc.

Vos missions :
Conception des pipelines de données
Développement et mise en production des pipelines de données
Déploiement et maintien des environnements containérisés
Gestion de l'évolution des solutions en production
Participation à la mise en place d'outils de data visualisation

Technos: Java / Scala / Python / Kafka
Outils: Ansible, Docker

L'ambiance de travail :
Contexte agile dynamique et hiérarchie plate
Participation aux évènements R&D Groupe
Veille technologique permanente

PROFIL RECHERCHÉ
Profil :
Ingénieur de formation, Master ou équivalent
Expérience en tant que Data Engineer : 3 ans minimum
Esprit d'Equipe, Curieux et en Veille technologique active sur la Data

Des plus pour votre candidature :
Exp. dans le secteur Telecom
Projets persos et/ou Github"
Paris (75),,,CDI - SGL - Experience Analysis Actuary,SCOR,- Paris (75),"EMEA
Paris France (FR)
|
CDI - SGL - Experience Analysis Actuary
Permanent
Actuarial
About SCOR
SCOR, the 4th largest reinsurer in the world, provides insurance companies with a diversified and innovative range of solutions and services to control and manage risk. Using its experience and expertise, “ The Art & Science of Risk ”, SCOR provides cutting-edge financial solutions, analytics tools and services in all areas related to risk – in Life & Health insurance as well as in P&C insurance. Our specialist teams operate in over 120 countries, developing value added and innovative products and services and making long-term commitments to their clients, namely insurers and large corporations.
SCOR's aim, as an independent global reinsurance company, is to develop its Life and P&C business lines, to provide its clients with a broad range of innovative reinsurance solutions and to pursue an underwriting policy founded on profitability, supported by effective risk management and a prudent investment policy, in order to offer its clients an optimum level of security, to create value for its shareholders, and to contribute to the welfare and resilience of Society by helping to protect insureds against the risks they face.
- Department
The Knowledge Department within SCOR Life coordinates our expertise and supports all research & development activities on actuarial & medical risks, data analytics and behavioral science.

- Job summary
Provide best-in-class tools and methods to all Experience Analysis stakeholders and support the development of new data services.

- Key duties and responsibilities
Part of the global Experience Analysis team, your role is to maintain and enhance APEX, SCOR’s new global Experience Analysis solution, support local users with best practices and support the development of new data services.
You support the transition of new teams to APEX via trainings and hands-on study support, and expand and promote best practices for producing high quality Experience Analysis studies for various internal and external stakeholders.
You assure the continued improvement of APEX with value-adding and user-friendly functionalities, via:
Specification of new requirements based on user needs
Support of their implementation in close collaboration with IT
User Acceptance Testing
Training and documentation
In line with SCOR’s strategic plan you support local markets in their data initiatives, promoting new types of services to local teams and support their development with best practices and best-in-class tools. Among others you support the use of modern data visualization tools (Tableau)

- Required experience & competencies
You are a confident individual with strong team player qualities and communication skills
You apply your strong analytical skills to find efficient and practical solutions in a business context
You are organized, efficient and autonomous, keen to take responsibility for your projects
You are attracted by an international work context and relationships with various local and functional teams of SGL.
You are someone who enjoys innovating and learning new technologies
Preferably you are an actuary with experience in life insurance
You are fluent in English, French is a plus.
A thorough knowledge of R (or Python) is a plus

- Required education
Master degree"
Paris (75),CDI,60 000 € - 80 000 € par an,Data engineer pour un grand groupe d'assurance (confirmé/sénior),Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Python engineer
Teletravail ponctuel
Technologies Git
Technologies Jenkins
Technologies Jira
Technologies Pyspark
Technologies Python
Expérience 3 à 5 ans
Expérience 6 à 10 ans
Statut CDI
Min 90k€
Max 120k€

L'ENTREPRISE : LEADER DE L'ASSURANCE
Leader français et européen de l'assurance et des services financiers, cette entreprise cherche aujourd'hui à constituer et à faire grandir sa propre équipe sur des problématiques big data.
Quelques informations :
Plus de 20 ans d'expertise
Effectif big data / IA / data science : 30 personnes
Plus de 5 millions de clients
Plus de 12 millions de chiffre d'affaires
Plus de 10000 collaborateurs partout en France

VOS MISSIONS :
Au sein de la direction voix du client, big data et intelligence artificielle composée d’une trentaine de personnes vous aurez à :
Mettre en place les architectures data
Définir les solutions de stockage
Déployer des flux de données entre les systèmes
Industrialiser des flux (batch, API, real time …)
Mettre en place les solutions techniques permettant de transmettre ces données à des systèmes tiers
Participer, au développement d’applications adaptées à l’infrastructure
Tester et faire évoluer ses applications
Participer au développement de l’infrastructure (git, jira, Jenkins)
Industrialiser les prototypes

VOTRE PROFIL : DATA ENGINEER CONFIRMÉ(E)
Vous êtes idéalement issu(e) d'une formation bac+5 (ingénieur ou scientifique)
Fort(e) d'au moins 5/6 ans d'expérience en data science vous avez un excellent niveau technique
Python, Pyspark sont vos technologies de prédilection
Vous parlez anglais (communication quotidienne avec des personnes ne parlant pas français)
La rigueur, l'esprit d'équipe et l’autonomie vous caractérisent

VOS +:
Vous avez une expérience dans un grand groupe ou/et dans l'assurance
Le DevOps ne vous est pas inconnu

MODALITÉS :
Rémunération attractive :
Package entre 90 et 120k€ ( 60 à 80K€ de fixe + intéressement et participation)
Plan d’épargne entreprise et retraite complémentaire
Plan d’actionnariat
Compte épargne temps
CE
Plus de 25 jours de CP
Plus de 15 jours de RTT
Restaurant d’entreprise
Sélectionné par Thomas Gourmelon
Spécialiste Python, Ruby, Go & Data Scientist
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris 17e (75),,,Consultant technique / Architecte Big Data (H/F),Nexworld,- Paris 17e (75),"Description de l'entreprise
Notre société est comme qui dirait un OVNI sur le marché !
Nexworld est un cabinet de conseil IT positionné entre l’ESN et le client final, spécialisé dans la transformation SI et la disruption des activités Business, nous accompagnons nos clients grands comptes à chaque étape clés de la transformation de leurs systèmes d’information et de leurs projets stratégiques face aux nouveaux enjeux de l’économie numérique (Architecture d’Entreprise, API Management, Fast Data, Intelligence Artificielle, Conteneurs, Microservices, DevOps, Low Code, RPA, Design Thinking...)

Description du poste
L’architecte data est responsable de la conception, du déploiement et de l'administration de plateformes de calculs distribués et de stockage de données massives (Big Data).

Vous travaillez de concert avec les équipes de développement, de Data Science, de Business Intelligence et d'administration système pour concevoir des architectures data qui correspondent aux besoins métiers. Vous anticipez les besoins futurs et respectez les contraintes imposées par les architectures existantes. Vous êtes le garant du bon fonctionnement, de la haute disponibilité, de la capacité de montée en charge et de la résilience des plateformes data.

Au sein de Nexworld, vous rejoignez la practice Data constituée de consultants Data motivés, dynamiques qui réalisent des projets métiers complexes de data science dans les secteurs de la construction, de l’industrie et fondés sur des architectures Data à l’état de l’art.
Vous apportez des acquis techniques fondamentaux pour les clients de Nexworld.
Vos missions si vous les acceptez
Bâtir une architecture BigData pour nos clients et notre plateforme interne de recherche, On Premise ou dans le Cloud
Installer toutes les stacks techniques des architectures Lambda/Kappa
Auditer les architectures déployées chez nos clients qui visent à les optimiser, les sécuriser et les rendre scalables
Participer activement à un projet Data de bout en bout, répondant aux attentes métiers de nos clients (prédiction, décision temps réel) couvrant toutes les phases depuis l’acquisition des données, le stockage, le traitement de quantités massives de données, en passant par la DataPrep/Dataviz pour travailler de concert avec vos collègues DataScientist, DataEngineer
Dimensionner les architectures et à en estimer le coût.
Quels seront vos meilleurs outils ?
Vous êtes expert sur un ou plusieurs frameworks et produits suivants : Hadoop/HortonWorks/Cloudera en priorité, MongoDB, Cassandra, Redis, Hive, Couchbase, Confluent, MapR
Vous avez des connaissances approfondies sur les frameworks de traitement temps réel : Kakfa, Kafka Stream, Flink, Spark Streaming, Samza
Les solutions de ChangeDataCapture ne vous sont pas totalement inconnues ainsi que les APIs
Une maitrise des stacks techniques et infrastructures de serveurs est attendue
Savoir conteneuriser des composants de la stack data est un plus ainsi que des connaissances en développement sur les langages de programmations : Java, Python, Scala
Vos expériences antérieures éventuelles sur : Trifacta, Attunity, Debezium, Amazon (EMR, Kinesis, Redshift, DynamoDB), Google (Cloud Storage, Big Table, Big Query, DataFlow, DataProc) et/ou Azure (HD Insight, Data Factory, DataBricks, CosmosDB) seront les bienvenues ainsi que les contraintes liées aux architectures hybrides.

Qualifications
Vous êtes diplômé(e) d’une école d’ingénieur ou équivalent universitaire et vous aimez relever les challenges technologiques ? Vous avez acquis vos compétences sur les infrastructures Data depuis au moins 4 ans. Vous êtes force de proposition et avez une appétence pour les nouvelles technologies autour du vaste sujet de la Data ? Vous désirez travailler sur des projets innovants de R&D et mettre en pratique vos acquis lors de réalisations pour nos clients ?
And last, but not least, you speak English ?
Cette offre est faite pour vous !

Informations complémentaires
On vous a donné envie ?
Vous avez certainement des questions, postulez et rencontrez-nous !
Poste en CDI, basé à Paris 17ème.
Statut Cadre.
Avantages sociaux : formations, prime de vacances, participation, tickets restaurant, mutuelle, CE, crèche d'entreprise….

Rendez-vous sur www.nexworld.fr"
Paris (75),CDI,50 000 € - 70 000 € par an,Data Engineer confirmé l Startup/Cabinet de conseil l Paris l 50/70k€,Data Recrutement,- Paris (75),"Offre publiée le 18-05-2020.
Paris
Fonction Data engineer hadoop spark
Fonction Consultant data
Expérience 3 à 5 ans
Statut CDI
Min 50k€
Max 70k€

L'ENTREPRISE : STARTUP CONSEIL EN MANAGEMENT BIG DATA PARIS
Un acteur du conseil en organisation & management :
90+ consultants
Multi secteurs : public, distribution, banque, télécom, cosmétique, …
Basé au coeur de Paris
Une équipe Data composée de 25 personnes
Vos activités s’appuieront sur le Lab du cabinet et sur son catalogue d’outils et technologies :
Développement : Angular, React, TypeScript, ES6, Vue.js, Node.js, Express.js
Bases de données : MongoDB, ElasticSearch, PostgreSQL, Redis
DevOps : Docker, Jenkins, Vagrant, AWS, CircleCI, GitHub
Data science : Dataiku DSS, Vertica, Spark, Python

VOTRE MISSION : ACCOMPAGNER VOS CLIENTS DANS LA MISE EN PLACE ET L'EXÉCUTION DE LEURS PROJETS DATA
Au sein d’une équipe de 25 consultants, vous intervenez comme Data Engineer sur des missions auprès de groupes du CAC40 (DSI, datalab, ...). Vous travaillez sur les outils de type ETL/ELT, idéalement Talend, ADF (Azure Data Factory) ou Informatica. Vous intervenez sur l’ensemble des projets :
Cadrage via l’animation d’ateliers techniques et fonctionnels
Conception des solutions
Intégration des outils

VOTRE PROFIL : DATA ENGINEER EXPÉRIMENTÉ
Vous :
Démontrez 3 à 5 d'expériences réussies en tant que Data Engineer sur des projets ETL/ELT : Talend, ADF ou informatica... ?
Êtes autant à l’aise sur les enjeux fonctionnels que techniques ?
Souhaitez rejoindre une forte culture startup : formation/veille active, forte croissance, très bon niveau de l’équipe, ...

Sélectionné par Aurélien
Spécialiste tech & Product
CONNAÎTRE LE NOM DE L’ENTREPRISE"
Paris (75),,,Data Engineer H/F - Association de délégation de Service Public,Michael Page,- Paris (75),"En qualité de Data Engineer, vos principales missions sont :
Porter l'expertise interne sur l'infrastructure big data mise en oeuvre en lien avec l'équipe projet,
Être force de proposition sur les évolutions de l'infrastructure afin de répondre aux attentes actuelles et futures des équipes,
Administrer, sécuriser et maintenir en condition opérationnelle la plate-forme (Cloudera On Premise) en lien avec l'équipe exploitation,
Être le garant de la documentation technique de la plate-forme (documents d'architecture, procédures…)
Faciliter l'industrialisation et la collecte des données à la suite des phases d'expérimentation menées avec le métier étude et analyse,
Accompagner le métier étude et analyse sur l'optimisation des traitements de données et des calculs distribués,
Organiser et mettre en oeuvre les montées de version des logiciels tout en garantissant les non-régressions,
Assurer la gestion des sauvegardes et restaurations ainsi que les bascules sur site de secours,
Maîtriser les technologies Yarn, Kubernetes, Docker, Spark et les écosystèmes Linux,
Connaître les langages de programmation Python, R, Scala,
Être en mesure de vulgariser des concepts technologiques innovants auprès des métiers.

De formation supérieure, Bac +5 minimum, vous avez au moins 3 ans d'expérience sur XP, similaire et maîtrisez l'anglais. Doté d'une grande autonomie, vous maîtrisez l'architecture d'écosystème Hadoop en général et celle de Cloudera en particulier, de même pour la partie infrastructures associées. Vous maîtrisez les concepts liés aux enjeux de sécurisation des données. Vous êtes en capacité de challenger et orienter les métiers sur les différentes technologies de développement en lien avec des projets de data science (Spark, Scala, Python, R)."
Paris (75),,,Architecte Big Data,IBM interactive,- Paris (75),"Filiale 100% IBM France, et GBS, entité de conseil d’IBM, offrent à leurs clients toute la palette de services, depuis la définition de stratégies métier jusqu’à la mise en œuvre des projets et des solutions techniques nécessaires. IBM Interactive et GBS sont dotées d’une forte expertise métier par industrie, expertise traduite en solutions intégrées et innovantes : Watson, Blockchain , IOT, Cloud…permettant à IBM d’accompagner ses clients dans la définition et la mise en œuvre de leur transformation digitale, de bout en bout.
Au sein de la practice :
Complex SI and Architecture
le candidat motivé , curieux, rigoureux et volontaire assistera les équipes dans la réalisation de nos projets au contact avec nos clients.
Vos missions :
Contexte projet / Equipe
Au sein de la practice Complex System Integration, vous devez appréhender l’univers complexe de nos clients, qui combine différents niveaux de maturité organisationnelle et technologique sur la gestion de la donnée.

Toujours à l’affût des nouvelles tendances, vous êtes avant tout passionné(e) par le Digital, les données, les enjeux qu’elles représentent et l’écosystème technologique gravitant autour (Hadoop, Kafka, ElasticSearch, Spark, Cassandra…). Vous intervenez en particulier sur des projets de transformation liés à la refonte des schémas directeurs et des architectures (techniques et fonctionnelles) d’information management et Big Data de nos clients.
Missions
En tant qu’Architecte BigData, vos missions seront les suivantes :
Vous travaillerez au sein d’une équipe IBM ou directement avec le client afin de comprendre son besoin et ses enjeux autour de ses données.
Vous concevrez des solutions innovantes de traitements de la donnée, la construction de plateformes orientées données reposant sur les architectures de références.
Vous présenterez et argumenterez vos propositions de conception et résultats auprès du client et de votre équipe.
Vous partagerez votre connaissance et expérience auprès de votre équipe.
Vous contribuerez à la préparation et à l’animation d’ateliers avec l’équipe projet.
Formation
Bac + 5
Expérience
Minimum 2 ans
Compétences ""soft skills""
Capacité d'adaptation
Capacité d'auto-formation sur un périmètre technique large
Compétences techniques
Une très bonne connaissance de l’écosystème Hadoop
Une bonne connaissance des environnements systèmes Linux ;
Connaissance étendue et approfondie sur différentes solutions techniques notamment:
Cloud : IBM, AWS, AZURE
Hadoop : Hortonworks ou Cloudera
Base de données NoSQL: HDFS, Hive, HBase, MongoDB, Cassandra...
Framework (bigdata): Spark, Kafka, Flume, Oozie,...
Langage : Java, Scala, Python, javascript...
Container (Docker / Kubernetes),
Devops (Jenkins / Ansible)
Sécurité (Contrôle d’accés / encryption )
Réseau et performance.

Seront un atout :
Une bonne connaissance des moteurs d'indexation tels que Elasticsearch ou SolR;
La connaissance des outils développement (Git, Maven, etc...) et des langages de développement Java, Scala, R, Python.
Langues
Français et Anglais courant"
Paris (75),55 000 € - 70 000 € par an,,LEAD DEVELOPPEUR FULL STACK –REACT.JS VUE.JS/ NODE.JS PHP – ANALYSE DE DATA – PARIS 10EME,In-Team,- Paris (75),"Vous recherchez un nouveau challenge en tant que Lead développeur Fullstack pour travailler sur des projets ambitieux et complexes liés au Big Data?
Le poste
Située au cœur de Paris, cette startup de 40 personnes est spécialisée dans la collecte et l’analyse de Data dans le E-commerce. Chaque jour, près de 200 millions de données initialement inexploitables sont traitées pour donner aux entreprises et aux consommateurs les bons outils d’aide à la décision et mesurer leurs impacts.
En 4 ans, l’entreprise se révèle comme un des leaders européens dans son domaine et poursuit son expansion via une levée de fonds, en investissant massivement dans le Big Data et en voulant augmenter ses effectif de 50% d’ici 6 mois. C’est dans ce contexte qu’elle recherche à recruter dans son équipe un nouveau Lead développeur Fullstack.
La Stack technique:
ReactJS, VueJS, JQuery, Bootstrap, PHP, Python, NodeJS, C++, Symfony, Go, MongoDb

Les responsabilités
Techniques
Challenger l’existant en proposant des solutions pour l’optimiser
Concevoir et développer de nouvelles fonctionnalités
Maintenir une bonne hygiène de code et optimiser les process de développement
Mise en œuvre de la Road map
Management
Encadrer, structurer et accompagner les développeurs
Participer à la construction de l’équipe (recrutement etc.)
Établir les liens avec les autres équipes de la société
Pourquoi venir travailler pour ce client ?
S’investir dans une Startup en pleine croissance
Travailler sur des projets complexes et des technos modernes
Poste clef pour l’entreprise avec un vrai pouvoir d’actions des responsabilités
Très bien située au cœur de Paris
Esprit d’équipe, d’entraide et bienveillance
Salaire & avantages
Contrat CDI
Salaire allant de 55K€/70K€
RTT, Tickets restos
Bonus annuel
Thé café eau à volonté, Fruits, biscuits, chocolat sur site
Navigo à 50%, Mutuelle
Prochaine étape ?
Si vous avez lu jusqu’ici, c’est que ce poste est fait pour vous !
Appelez-moi directement au
Afficher le nº de téléphone
A tout de suite !"
Paris (75),,,Architecte Big Data H/F in Paris,Elitis Search,- Paris (75),"Afin d’accompagner nos clients dans leurs mises en place de lac de données et d’applications Data, nous recherchons des architectes Big Data. Dans le cadre de cette mission, vous serez amené(e) à :
Définir et/ou mettre en oeuvre des solutions / architectures / projets autour de l'écosystème Big Data
Participer à des avant-ventes
Mettre en oeuvre des Benchmark de solutions, des prototypes et des projets
Contribuer à définir et diffuser les bonnes pratiques au sein des équipes sur le Big Data
Supporter les équipes de réalisation par une expertise sur les solutions et/ou démarches Big Data
Contribuer à la veille technologique sur les solutions Big Data
Élaborer et présenter nos retours d'expérience auprès de nos clients
Environnement technologique/fonctionnel:
Architecture et Infrastructure Hadoop (Nifi, Kafka, Sqoop, Flume, Spark, Hive) et distributions associées
(HortonWorks, Cloudera, MapR)
Solutions Editeurs : Microsoft APS, IBM Big Insight / Watson, Oracle Big Data, HP Vertica / IDOL, Talend Big
Data, Splunk, Qlik, Tableau, AngularJS, appliances Teradata-Netezza-Exadata
Data Science (Python, Scala, R)
Data Visualisation (Solutions BI du marché)
Base de données noSQL : MongoDB, Cassandra, HBase, Neo4j
Gouvernance des données
PROFIL
Titulaire d'un Bac +5 en informatique, vous disposez d'une expérience de 3 à 8 ans, avec des références significatives dans la définition d'architectures et la mise en oeuvre de projets et solutions Big Data chez des
clients.
Vous êtes un architecte système d'informations reconnu sur les systèmes de gestion des données.
Vous savez identifier et positionner les principales solutions évoquées ci-dessus, dans le domaine principal du Data Management, et éventuellement dans les domaines de Data Science et Data Visualisation gravitant
autour de l'écosystème Big Data.


Vous êtes reconnu pour votre capacité à animer, à fédérer autour d’une vision, pour votre rigueur, vos capacités d'analyse, de synthèse et d'innovation. Vous disposez d’un très bon niveau d’anglais."
Paris (75),,,CDI - SGL - Lead IT Auditor,SCOR,- Paris (75),"EMEA
Paris France (FR)
|
CDI - SGL - Lead IT Auditor
Permanent
Legal & Compliance
About SCOR
SCOR, the 4th largest reinsurer in the world, provides insurance companies with a diversified and innovative range of solutions and services to control and manage risk. Using its experience and expertise, “ The Art & Science of Risk ”, SCOR provides cutting-edge financial solutions, analytics tools and services in all areas related to risk – in Life & Health insurance as well as in P&C insurance. Our specialist teams operate in over 120 countries, developing value added and innovative products and services and making long-term commitments to their clients, namely insurers and large corporations.
SCOR's aim, as an independent global reinsurance company, is to develop its Life and P&C business lines, to provide its clients with a broad range of innovative reinsurance solutions and to pursue an underwriting policy founded on profitability, supported by effective risk management and a prudent investment policy, in order to offer its clients an optimum level of security, to create value for its shareholders, and to contribute to the welfare and resilience of Society by helping to protect insureds against the risks they face.
- Department
Group Internal Audit
- Job Summary
Within the Group Internal Audit Department (New York, London, Paris, Zurich and Singapore) and under the supervision of the Deputy Head in charge of IT Audit, the Lead IT Auditor is primarily responsible for conducting a variety of IT audit assignments on a global or local scale in the areas of IT Security, Operations and IT Applications to independently assess the adequacy of the control environment and key controls design and effectiveness, and support the Group development strategy in a dynamic and evolving IT environment, as defined by the Group Strategy “Quantum Leap”.
- Key duties and responsibilities
Under the supervision of the Deputy Head in charge of IT Audit:
Understand the business and technology environment; partner with stakeholders to provide relationship management of the associated risk and control environment
Execute the IT audit programs in accordance with internal audit policies, procedures, methodologies, regulatory requirements and the Standards for the Professional Practice of Internal Auditing.
Assess design and operating effectiveness of IT General and Application Controls (ITGC, ITAC) through inquiry, observation, and inspection testing
Proactively seek ways to make the best use of data as part of our IT audit process including to inform our understanding of risks, test controls and provide relevant insights to the business
Provide input and assist in the identification of relevant IT standards (COBIT, ITIL, ISO 27001 and NIST Cybersecurity Framework) and regulatory requirements for incorporation as part of the audit scope and work program.
Deliver on time, high quality audits, reviews, and advisory projects, with participation in all phases: planning/scoping, fieldwork, and reporting
Communicate and discuss findings with business unit management
Develop audit reports which identify deficiencies and underlying root causes; provide recommendations to mitigate/address deficiencies while adding value
Conduct research and successfully complete assigned training requirements necessary to maintain relevance.
Work closely with Group IT Department and business units at all levels to develop recommendations for audit findings, business process optimization, internal control and compliance
Conduct follow-up reviews of recommendations noted during audits.
- Required experience & competencies
Experience:
3 to 6 years of professional experience in an IT audit related role, ideally in a multinational company within a regulated financial services environment and/or in an auditing firm.
Personal Competencies
Utmost ethics and integrity
Excellent level of English required (as the majority of oral and written communications are in English), as well as in French
Strong communication and interpersonal skills, as well as the ability to work with different cultures.
Strong analytical skills, good overview, critical sense and ability to deal with complex issues and influence change.
A team player who can also work independently and rigorously in accordance with IIA Standards.
Position based in Paris 16th district with travel globally up to around 20% (Americas, Europe, Asia).
Technical Competencies:
Knowledge of auditing either Cybersecurity, technology Infrastructure (including databases, operating systems and networks), application development or project management
Knowledge of technology risk management principles and an understanding of relevant standards like COBIT, ITIL, ISO 27001 and NIST Cybersecurity Framework.
Knowledge of emerging IT Risks, internal audit trends and best practices.
Strong interest in new technologies (Artificial Intelligence, Machine Learning, Big data and Data Science, Robotics, etc.)
- Required Education
Master’s degree in IT Audit, Computer Science or similar
Professional credentials (e.g., CISA, CIA, CISSP, CFE or equivalent) or professional qualifications (ITIL, Project Management) are seen as a strong plus."
Paris (75),,,"Staff Cloud Architect, PAR",DoiT International,- Paris (75),"In Cloud Engineering, we collaborate and connect with customers that love technology as much as we do. Our team interacts with developers and operations specialists across the globe both at 1:1 meetings as well as online, and advocates for Google Cloud and Amazon Web Services. Our focus is on supporting tech companies who build applications and businesses on these platforms. Not afraid to be hands-on, you might write sample code, author client libraries, working with strategic partners to facilitate and organize our developer communities.
As a Staff Cloud Architect, you will connect with our clients and speak externally about cutting-edge technologies on conference panels, meetups, and on blogs. Your work will foster a community of developers integrating with Google and AWS technologies and will help drive strategy around Cloud Engineering. You might appear on our YouTube channels, podcasts, training, or support channels to troubleshoot and debug technical problems encountered by our clients. In collaboration with our partner's teams, you will improve products by conveying feedback from developers, reviewing and contributing to API designs, writing production-ready code, and testing new features.
Responsibilities
Build and manage the local team of Cloud Architects specializing in container orchestration, cyber-security, data and analytics, machine learning.
Advocate for our clients and influence our strategy by working with product, marketing, and other cross-functional teams.
Improve and standardize client experience. Educate clients on best practices of effective integration with Google & AWS products.
Provide 1:1 support for our clients on social and open source software platforms. Help clients design integrations, fix bugs and solve problems at scale.
Work on the core source code of our products and identify, reproduce, and/or fix issues that are affecting our users
Minimum qualifications:
Bachelor's degree in Computer Science or equivalent practical experience.
4 years of experience as a software engineer, developer, or equivalent technical experience.
Experience in technical consulting or client-facing capacity.
Experience working with JavaScript, Java, Kotlin, PHP, Python, Ruby, Node.js, Go, .NET, WASM, CSS, HTML, iOS, C++, Mobile Games tech, Android and/or Mobile App development.
Experience with large group communications and presentations.
Experience working in a consultant capacity or a track record of helping fellow developers."
Paris (75),,,Full stack engineer - GH,Dataiku,- Paris (75),"Dataiku’s mission is big: to enable all people throughout companies around the world to use data by removing friction surrounding data access, cleaning, modeling, deployment, and more. But it’s not just about technology and processes; at Dataiku, we also believe that people (including our people!) are a critical piece of the equation.

As a full stack developer in the Dataiku engineering team, focusing on Governance Hub (GH), you will play a crucial role in helping us bootstrapping this new product.

GH is an application that monitors and manages data initiatives across the various departments of a company. It ensures that good practices and governance rules are enforced. It is fully customizable to fit policies and processes of the company.

Our backend is mainly written in Java and the storage layer uses PostgreSQL 12. Our frontend is based on the latest version of Angular.

One of the most unique characteristics of GH is its fully-custom model and a strong integration with numerous external tools (project management, visualization, data science, etc.). This makes it interesting and challenging to design and develop such a software.

This is a full-time position, based in France either in our Paris office or remote.
RESPONSIBILITES
Turn ideas or simplistic specifications into full-fledged product features, including unit and end-to-end tests.
Tackle complex problems that range from performance and scalability to usability, so that complicated machineries look straightforward and simple to use for our users.
Help your coworkers: review code, spread your technical expertise, improve our tool chain
Bring your energy to the team!
You are the ideal recruit if:
You are mastering a programming language (Java, C#, Python, Javascript, You-name-it, ...).
You know that low-level Java code and slick web applications in Javascript are two sides of the same coin and are eager to use both.
You are not surprised that “Math.max()<Math.min()” is true in JS
You have a first experience (either professional or personal) building a real product.
Hiring process:
Initial call with the talent acquisition manager
On-site meeting (or video call) with the hiring manager
Home test to show your skills
Final on-site interviews
To fulfill its mission, Dataiku is growing fast! In 2019, we achieved unicorn status, went from 200 to 400 people and opened new offices across the globe. We now serve our global customer base from our headquarters in New York City as well as offices in Paris, London, Munich, Amsterdam, Denver, Los Angeles, Singapore, Sydney and Dubaï. Each of them has a unique culture, but underpinning local nuances, we always value curiosity, collaboration, and can-do attitudes!"
Paris (75),,,Full Stack Engineer - DSS,Dataiku,- Paris (75),"Dataiku’s mission is big: to enable all people throughout companies around the world to use data by removing friction surrounding data access, cleaning, modeling, deployment, and more. But it’s not just about technology and processes; at Dataiku, we also believe that people (including our people!) are a critical piece of the equation.

As a full stack developer in the Dataiku engineering team, you will play a crucial role in helping us have a real impact on the daily life of data analysts and scientists. You will be joining one of 3 teams that develop new features and improve existing parts of Data Science Studio (DSS) based on user feedback.

DSS is an on-premises application that connects together all big data technologies. We work with SQL databases, Spark, Kubernetes, Hadoop, Elasticsearch, MLlib, scikit-learn, Shiny, … and many more. Basically, our technological stack is made of all the technologies present in Technoslavia!

Our backend is mainly written in Java but also includes large chunks in Scala, Python and R. Our frontend is based on Angular and also makes vast usage of d3.js.

One of the most unique characteristics of DSS is the breadth of its scope and the fact that it caters both to data analysts (with visual and easy to use analytics) and data scientists (with deep integration in code and libraries, and a web-based IDE).

This is a full-time position, based in France either in our Paris office or remote.
Your missions
Turn ideas or simplistic specifications into full-fledged product features, including unit and end-to-end tests.
Tackle complex problems that range from performance and scalability to usability, so that complicated machineries look straightforward and simple to use for our users.
Help your coworkers: review code, spread your technical expertise, improve our tool chain
Bring your energy to the team!
You are the ideal recruit if
You are mastering a programming language (Java, C#, Python, Javascript, You-name-it, ...).
You know that low-level Java code and slick web applications in Javascript are two sides of the same coin and are eager to use both.
You know that ACID is not a chemistry term.
You have a first experience (either professional or personal) building a real product or working with big data or cloud technologies.
Hiring process
Initial call with the talent acquisition manager
On-site meeting (or video call) with the hiring manager
Home test to show your skills
Final on-site interviews

To fulfill its mission, Dataiku is growing fast! In 2019, we achieved unicorn status, went from 200 to 400 people and opened new offices across the globe. We now serve our global customer base from our headquarters in New York City as well as offices in Paris, London, Munich, Amsterdam, Denver, Los Angeles, Singapore, Sydney and Dubaï. Each of them has a unique culture, but underpinning local nuances, we always value curiosity, collaboration, and can-do attitudes!"
Paris (75),,,Full stack Engineer,Dataiku,- Paris (75),"Dataiku’s mission is big: to enable all people throughout companies around the world to use data by removing friction surrounding data access, cleaning, modeling, deployment, and more. But it’s not just about technology and processes; at Dataiku, we also believe that people (including our people!) are a critical piece of the equation.

As a full stack engineer in the Dataiku engineering team, you will play a crucial role in developing new features from scratch and improving existing ones. You will be joining one of 6 teams that work on our main product Data Science Studio (DSS) or our new one, Governance Hub (GH).

DSS is an end to end and collaborative data analytics platform having a real impact on the daily life of data analysts and scientists. It connects together all big data technologies and includes machine learning models. GH is an application that monitors and manages data initiatives across the various departments of a company. It ensures that good practices and governance rules are enforced. It is fully customizable to fit policies and processes of the company.

Join Dataiku to be part of a passionate and highly qualified developers team working with the Big Data and Data Science technologies (Kubernetes, Docker, Hadoop, Azure, GCP, AWS, Scala, Python, TensorFlow)!
RESPONSIBILITIES
Turn ideas or simplistic specifications into full-fledged product features, including unit and end-to-end tests.
Tackle complex problems that range from performance and scalability to usability, so that complicated machineries look straightforward and simple to use for our users.
Help your coworkers: review code, spread your technical expertise, improve our tool chain
Bring your energy to the team!
You are the ideal recruit if:
You are mastering a programming language (Java, C#, Python, Javascript, You-name-it, ...).
You know that low-level Java code and slick web applications in Javascript are two sides of the same coin and are eager to use both.
You are not surprised that “Math.max()<Math.min()” is true in JS
You have experience (either professional or personal) in building a real product or working with big data or cloud technologies.
Hiring process:
Initial call with the talent acquisition manager
On-site meeting (or video call) with the hiring manager
Home test to show your skills
Final on-site interviews
To fulfill its mission, Dataiku is growing fast! In 2019, we achieved unicorn status, went from 200 to 400 people and opened new offices across the globe. We now serve our global customer base from our headquarters in New York City as well as offices in Paris, London, Munich, Amsterdam, Denver, Los Angeles, Singapore, Sydney and Dubaï. Each of them has a unique culture, but underpinning local nuances, we always value curiosity, collaboration, and can-do attitudes!"
Paris (75),,,"Senior Cloud Architect (Core), PAR",DoiT International,- Paris (75),"Customer Reliability Engineering is what you get when you treat operations and data as if it's a software problem. Our mission is to architect, build, secure and provide for the software and systems behind all of our customer's services, with an ever-watchful eye on their availability, latency, performance, and capacity.
This is an unusual job, unlike others in the industry. Like traditional operations groups, we design, build and help to keep important, revenue-critical systems up and running despite downtimes, traffic outages, and configuration problems.
Unlike traditional operations groups, we often have an ability and authority to fix, extend, and scale the code to keep it working and harden it against all the vagaries of the internet. We hire people from both systems and software backgrounds. Strong candidates will have experience with both.
As an Customer Reliability Engineer on our team, you will have the opportunity to tackle the complex problems of scale which are sometimes unique to our customers while using your expertise in resolving problems, coding, algorithms, complexity analysis and large-scale system design.
This is a hands-on technical expert role with a high potential for learning new things and creating new experiences. If you are a positive-thinking, versatile technical leader who has that kind of i-want-to-know-everything drive, and you thrive in a fast-paced, startup-like environment, we want you on-board with our all-star winning team.
CRE's culture of diversity, intellectual curiosity, problem solving and openness is key to its success. Our organization brings together people with a wide variety of backgrounds, experiences and perspectives. We encourage them to collaborate, think big and take risks in a blame-free environment. We promote self-direction to work on meaningful projects, while we also strive to create an environment that provides the support and mentorship needed to learn and grow.
Requirements:
BS degree in Computer Science or related technical field involving systems engineering (e.g., physics or mathematics), or equivalent practical experience.
Experience in one or more of the following: C, C++, Java, Python, Go, Perl, Ruby or shell scripting.
Experience with Unix/Linux operating systems internals and administration (e.g., filesystems, inodes, system calls) or networking (e.g., TCP/IP, routing, network topologies and hardware, SDN).
Expertise in designing, analyzing and troubleshooting large-scale distributed systems.
Systematic problem-solving approach, coupled with strong communication skills and a sense of ownership and drive.
Ability to debug and optimize code and automate routine tasks."
Paris (75),,,Senior Full-Stack Engineer,Scality,- Paris (75),"Senior Full Stack Engineer

Scality is an industry leader in software-defined and multi-cloud storage at petabyte-scale. Founded in 2009, Scality has deployed software-based storage solutions that deliver billions of files to more than two hundred million users daily with 100% availability. Scality’s customers include four of the top ten cable operators in the US, the second largest Telco in France, leading operators in Japan, leading television network in Germany, and the second largest online video site in the world.

Our internal motto? “Work hard, play hard, eat well, and AMAZE the customer!”

Learn more about Scality on our Careers page, and follow us on Linkedin, Twitter & Glassdoor to stay up to date on jobs and company news. Also, you can get an inside look into the culture and life at Scality (via The Muse).

Download “Creating Magic” (our latest Scality book)

Description:

Scality is cloud storage leader and a vendor of high-performance distributed solutions, pursuing our mission of giving the company’s customers the freedom and control necessary to be competitive in a data driven economy. We are active in the open source world and a member of the Cloud Native Computing Foundation (CNCF).

Scality is seeking a Senior Full Stack Engineer to design and implement features for the new Scality Platform (on which rely all core Scality components), someone who is eager to join our MetalK8s squad and apply their strong technical and analytical skills to the quick and efficient solving of tough problems. The Senior Full Stack Engineer will also work as part of the UI/UX chapter in order to define and maintain state of the art architecture for our UI suite.

Specifically, the successful candidate will work to enhance MetalK8s – Scality’s open source Kubernetes distribution – in terms of administration and monitoring capabilities. In addition, the candidate will shoulder significant responsibility for providing other teams with the right architecture, frameworks and guidelines to develop and maintain specific Scality components UIs using our React styled components library: core-ui. MetalK8s and core-ui are entirely open source projects that anyone can clone and test.
Environment
Work on state-of-the-art technical stacks (e.g., Kubernetes, Prometheus, React…)
Strong continuous integration and testing culture and infrastructure
Good presence and contribution in open source world
High-end equipment (Apple/Dell laptop computers, Bring-Your-Own-OS policy, multiple screens)
Spacious, modern office space in central Paris (Madeleine)
Stock options distribution
Individual performance rewards
Remote Work policy
Sports and Wellness programs
Ample training allowance (e.g., internal/external skills training, conferences, coaching)
Donation-matching
Annual off-site company-wide “Kick-Off” event
Food fun: weekly company breakfast, a lunch delivery service, unlimited hot soothing coffee/tea/chocolate drinks, and more
Office fun: Babyfoot, Ping-Pong, board and card games, planned group activities
The mission of the Senior Full-Stack Developer
Understand product specifications and user workflow
Develop and test new features on MetalK8s and core-ui
Deliver modular web components and APIs
Ensure high quality deliveries on time and budget
Review colleagues’ code and mentor team mates
Contribute to the web applications’ build and deployment on Kubernetes
Work with UX designers to solve UX problems and implement attractive designs
Influence development best-practice and guidelines.
Technology watch and knowledge sharing with teams
Technical Skills
Proven experience as a Full-Stack Developer
Experience with Javascript, HTML5, CSS3 and popular frameworks such as React, Angular or Vue
Experience with development tools such as Git, Jira, Docker
Familiar with Cloud technologies like Kubernetes, Openstack, AWS
Backend development experience on at least one of the following language: Python, NodeJS or Go
Experience working in cross-functional teams consisting of Product Manager, Developers and Designers
A reasonable level of fluency in EnglishBS or MS degree in Computer Engineering, Computer Science, or equivalent
Interpersonal Skills
Curious and open-minded, oriented knowledge sharing and mentorship, able to create synergies between different teams
Good communication skills as well as ability to work well in teams, respecting and welcoming ideas from colleagues
Keep abreast of and have strong interest in learning new technologies
Have strong analytical and problem solving aptitude"
Paris (75),,,"Sales Engineer, Smart Analytics Specialist, Google Cloud",Google,- Paris (75),"Minimum qualifications:
Bachelor's degree in Computer Science or related technical field or equivalent practical experience.
Experience in data and information management as it relates to Big Data or relational-databases.
Experience with one or more of the following: MapReduce, Hadoop, Spark, Flume, Hive, Impala, SparkSQL, BigQuery.

Preferred qualifications:
Master's degree in Computer Science or other technical field with experience with Big Data, PaaS, and IaaS technologies.
Experience in software development platforms and solutions in J2EE, Java servlets, Python, Go, or Ajax.
Experience as a data engineer, database architect, or database administrator.
Experience as a technology consultant, technical architect, enterprise architect, technical sales engineer, or solutions architect.
Experience in web application development and integration.
Ability to quickly learn, understand, and work with new emerging technologies, methodologies, and solutions in the cloud/data engineering technology space.
About the job
When leading companies choose Google Cloud it's a huge win for spreading the power of cloud computing globally. Once educational institutions, government agencies, and other businesses sign on to use Google Cloud products, you come in to facilitate making their work more productive, mobile, and collaborative. You assist fellow sales Googlers by problem-solving key technical issues for our customers. You liaise with the product marketing management and engineering teams to stay on top of industry trends and devise enhancements to Google Cloud products.
The Google Cloud Platform team helps customers transform and evolve their business through the use of Google’s global network, web-scale data centers and software infrastructure. As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers, employees and partners.

In this role, you will work with Sales teams as a data analytics solutions subject matter expert to differentiate and paint the vision of Google Cloud to our customers. You'll help prospective customers and partners understand the power of Google Cloud, explaining technical features, helping customers design architectures, engage in proof of concepts, and troubleshoot potential roadblocks related to analytics workloads and projects. You will architect the best solutions for the customer using Google Cloud’s unique technology.

As a Sales Engineer, you'll contribute experience in data analytics strategies and data engineering. You'll use your skills with big data processing and traditional data warehouse knowledge and bring a functional understanding of cloud and data center network topologies, enterprise security, cloud identity, and troubleshooting techniques.
Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what’s next for their business — all with technology built in the cloud. Our products are engineered for security, reliability and scalability, running the full stack from infrastructure to applications to devices and hardware. And our teams are dedicated to helping our customers and developers see the benefits of our technology come to life.
Responsibilities
Accelerate the adoption of Google Cloud solutions. Work with the team to identify and qualify business opportunities, identify key customer technical objections, and develop a strategy to resolve technical blockers.
Manage responsibility for Go-to-Market strategy from a technical perspective. Craft the strategy to transform the customers, identify customer technical objections and develop a strategy to resolve technical blockers.
Share in-depth data analytics and data engineering knowledge to support the technical relationship with Google’s customers, including product and solution briefings, proof-of-concept work, and the coordination and prioritization of solutions impacting customer adoption of Google Cloud.
Recommend integration strategies, enterprise architectures, platforms and application infrastructure required to successfully implement a complete solution using best practices on Google Cloud.
Travel to customer sites, conferences, and other related events as required.
At Google, we don’t just accept difference—we celebrate it, we support it, and we thrive on it for the benefit of our employees, our products and our community. Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing this form."
Paris (75),,,Better understanding of Natural Hazards in a changing climate (F/H),GIE AXA,- Paris (75),"Environment:
The AXA Group
The AXA Group, a worldwide leader in Financial Protection, supports and advises its customers, individuals and businesses at every stage of their lives by meeting their needs for products and insurance, pension, savings and wealth transmission.
The headquarters of AXA Group, based in Paris 8th, brings together the Group's corporate activities. It coordinates the various entities with the Group's strategy, and is responsible for managing international projects. The peculiarity of the seat lies particularly in the presence of a strong international culture (37 nationalities).
Aware of the challenges, AXA is a responsible and innovative Group that is constantly redefining standards to better serve its customers and employees.
The Departments
The internship will be based at the AXA Group Risk Management (GRM) department.
AXA GRM brings together multidisciplinary high-level teams composed of actuaries, engineers, PhDs and financial analysts, based in Paris (65 people), Zurich (15 people) and Madrid (20 people).
The Natural Hazards Team of AXA GRM is looking for an intern for 3-4 months . The intern will join a dynamic 12-members team dedicated to the modeling and monitoring of the CAT risks borne by the company.
Role and Responsibilities :

The large-scale and complex nature of climate change makes it difficult to assess and quantify the impact on insurance activities. Climate risks management is at heart of AXA priorities. Climate change is likely affecting the probability of natural hazard occurrence in terms of severity and/or frequency. The major objectives of the internship will be to estimate such changes on hazard risks as well as to develop innovative methodologies to infer impacts on risk management.
A first but important task will consist in reviewing the most relevant reports or studies already published on this topic. It will notably include a deep analysis of IPCC, TCFD and reinsurers such as Munich Re and Swiss Re studies. Common conclusions as well as potential deviations will help us to give to the internship study a framework with its uncertainties.
A second part of the work will consist in analyzing a Pan-European gridded data sets of the probability of occurrence of river floods, and winter windstorms under present and future climate. Objectives here will be to estimate the changes in intensity, frequency and spatial extent of possible future extremes events.
For instance, what would look like a flood event in EU with a current return period of 100 years in 2100 under different climate scenarios?
The internship will lastly focus on innovative methodologies – through simplified risk analysis framework – to convert such results to natural catastrophes losses projection. An important part of the work will rely on addressing the uncertainties beyond the developed methodologies and found results.
Qualifications
Profile Requirements :
Suitable candidates would have a master’s degree in geoscience, mathematics, c omputer science, or equivalent (engineering schools…) with interest for academic research. Candidates should have strong analytical mindset, strong programming skills (Python, R), as well as good communication skills to be able to work as part of a team.
The candidate should have a strong interest in Climate Change topics.



About AXA
Would you like to wake up every day driven and inspired by our noble mission and to work together as one global team to empower people to live a better life? Here at AXA we strive to lead the transformation of our industry. We are looking for talented individuals who come from varied backgrounds, think differently and want to be part of this exciting transformation by challenging the status quo so we can push AXA - a leading global brand and one of the most innovative companies in our industry - onto even greater things.
In a fast-evolving world and with a presence in 64 countries, our 165,000 employees and exclusive distributors anticipate change to offer services and solutions tailored to the current and future needs of our 107 million customers.
The headquarters of the AXA Group, based in Paris 8th, brings together the Group's corporate activities. It coordinates the various entities with the Group's strategy, and is responsible for managing international projects. The headquarters has approximately 800 employees and is distinguished by its strong international culture (39 nationalities).
What We Offer
We provide you regular career opportunities in international teams. If you want to join us, don’t hesitate to apply !
Information provided by applicants will be processed in strict confidentiality and may be used exclusively for recruitment processes."
Paris (75),,,Senior Software Engineer - Full Stack,Doctrine,- Paris (75),"Our mission: we are advancing open justice around the world.
Our products: we are building legal research and analytics software for legal professionals to search through the law, handle their cases, and grow their business.
Our ambition: in a ""traditional"" industry, we strive daily to offer our customers the latest technologies, especially in the field of artificial intelligence, through simple and well-designed products

-

We are looking for a Senior Software Engineer with strong ambitions in both backend development and frontend development, willing to take advantage of our fullstack environment. On the backend side, reliability, security and performance will be some or your focus points. On the frontend side, you will work on providing the best experience together with our Product designers. And like all our Engineering team, a passion for building the best products for our users is a must.
In this role, you will:
Design, develop and maintain REST APIs
Implement and maintain optimized Elasticsearch and SQL queries
Work with Machine Learning Engineers to help them prepare and process data
Collaborate with Product Designers to iterate on the design and implementation of our product user experience
Perform code reviews and write tests to keep quality up to our standards
Instrument your code so it can be monitored in production
Review and improve the legacy code to prevent production bug and keep the technical stack up to date
Write technical documentation
And globally as all Engineering contributors you will:
Mentor and challenge your peers
Educate others to best practices in use in the company and elsewhere
Participate to all our in-house rituals for knowledge sharing
Contribute to hire other outstanding colleagues
For these responsibilities, we are looking for teammates with:
5+ years of industry experience working as a Software Engineer (possibly with different levels of seniority in Backend and Frontend)
Very good knowledge of NodeJS and/or Python
Good knowledge of SQL and/or Elasticsearch
Knowledge of React/Redux
A passion for code quality and overall development best practices (testing, CI/CD...)
The ambition of delivering highly-available and highly-reliable applications
A commitment to build the best user experience
A knack for sharing and make people around you better teammates
Excitement about taking cutting-edge technologies and techniques to one of the most important and most conservative industries; your work will have a deep impact on Doctrine’s growth and how legaltechs will shape the future of law jobs!
English fluency
-

Why you should apply:
It's the ideal time to join Doctrine in terms of growth and opportunities
We have a strong team spirit and company culture, we live our values at a daily basis
Top-notch learning environment: ongoing mentorship, weekly best practices sharing
We work in a cool and classy office in the heart of Paris (Métro Sentier)
Regular feedback and compensation reviews - we nurture the feedback culture and reward great work

Benefits:
Competitive package, including stock options
Unlimited time off
Referral bonuses
A great health insurance policy
Lunch coupons

Other perks:
IT equipments
Free coffee, tea, and fresh fruits
Thursday beers, Wednesday breakfasts and monthly events with the team


We are an equal opportunity employer and value diversity at our company. We do not discriminate on any basis including religion, color, origin, gender, sexual orientation, age, marital status, veteran status, or disability status.

Remote applicants: This position is based in our office in Paris. If you're interested in remote work, check back soon as our needs may change."
Paris (75),,,Technical Architect (DevOps & Cloud),IQVIA,- Paris (75),"IQVIA™ is the leading human data science company focused on helping healthcare clients find unparalleled insights and better solutions for patients. Formed through the merger of IMS Health and Quintiles, IQVIA offers a broad range of solutions that harness the power of healthcare data, domain expertise, transformative technology, and advanced analytics to drive healthcare forward.

Main Mission
Within the Architecture and Standards team, you will integrate the DevOps team and work on a strong AWS cloud context, following the Standard operating procedures (SOPs) with DevOps Agile Squads.
You will report to our Associated Director - Solution Architect, and play a role of a highly technical leader, interface and support within DevOps team.
You will be mostly in charge of these four main following topics:
Define technical architecture standards and communicate across Technology solutions teams, in close collaboration with DevOps Director and Associate Director
Design the optimum quality technical architecture based on application architecture provided by product pillars
Getting approval from Technical Design Architecture board
Acting as a technical interface leader for DevOps squads and ProdOps team (support and train)
Define/build training programs/presentation to improve DevOps team skills to be up-to-date on technological topics
Provide L3 technical support to clients


What we are looking for:
You should have experience and knowledge in a wide spectrum of technologies On-Premises and on Cloud (AWS preferably) contexts with good architecture role experiences (2-5 years)
Experience on designing and documenting architectures, also with security on prem and in the cloud
Ability to work with DevOps team Pilots/POCs
Experience in designing IaC, CI-CD (GitLab version control, Gitlab CI, Jenkins, Nexus Sonatype, BlackDuck, Terraform)
Good knowledge with containerization (Kubernetes, Analytics tools)
Knowledge on Linux/POSIX and Windows-based systems
Good knowledge on general networking
Good knowledge of RDBMS (Oracle, Sql Server, MySQL) and NoSql (MongoDB), ElasticSearch
Expertise on monitoring/log management (Nagios, Icinga2, Prometheus, Splunk, ELK)
Keeping up to date with new technologies
Fluent in English
Technical Environment:
Cloud: AWS
System: Linux, Windows Server 2008/2012...
Infrastructure: kubernetes, EKS (AWS kubenetes), Docker, Nginx, Mesos, VmWare
Data: Oracle 11.x/12c SE/EE, MS sql, Elasticsearch, Mongo
Networking: F5 (Big-IP), AWS ELBs, VPNs (Cisco, Juniper, AWS)
Monitoring & Log Management: Prometheus, Nagios, Splunk, ELK
Analytics: Apache SPARK, Cloudera (Hadoop), DCOS 1.8/1.9.x
ETL: Informatica PwC from 8.6.x to 10.1.x
Framework: ASP.net, Node.js
DevOps Tools: Jira, Confluence, GitLab/GitLab CI, Jenkins, Terraform, CloudFormation (AWS), Subversion
Scripting: Shell, Python, Perl, Json, javascript, PL/SQL
Automated testing Tools: (Neoload, Selenium, JMeter).
Learn more here: https://www.youtube.com/watch?v=G9HJfI2Iav0
Join Us
Making a positive impact on human health takes insight, curiosity, and intellectual courage. It takes brave minds, pushing the boundaries to transform healthcare. Regardless of your role, you will have the opportunity to play an important part in helping our clients drive healthcare forward and ultimately improve outcomes for patients.
Forge a career with greater purpose, make an impact, and never stop learning.

Job ID: R1065039"
Paris (75),CDI,55 000 € - 65 000 € par an,SENIOR DATA SCIENTIST - startup tech,Harnham,- Paris (75),"Senior Data Scientist - startup tech
Paris, France
50-65K
Cette start-up de 20 personnes a développé une plateforme SaaS dans le domaine du marketing et de la publicité en ligne. Cette technologie basée sur de nombreux algorithmes prédictifs permet aux entreprises d'affiner leur stratégie publicitaire. La société souhaite continuer sa croissance en recrutant un profil de Senior Data Scientist et consolider son expertise technique.
Véritable couteau-suisse, vous aurez nécessairement une première expérience de quelques année au sein d'une équipe Data et pourrez amener votre savoir faire data science. Vous travaillerez par ailleurs main dans la main avec le senior data engineer de l'équipe.
LE POSTE
Hiérarchiquement directement en dessous du CTO, vous avez un rôle stratégique avec de l'impact!
Faire un état des lieux des solutions techniques en internes, de la plateforme, et continuer la roadmap data science
Tirer profit de la grande volumétrie de donnée et continuer le développement de solutions en temps réel
Vous travaillerez sur la création d'algos du côté Machine Learning, qui décupleront l'impact de la plateforme créée par la société
Environnement techno : R / Python / Spark / Scala
VOTRE PROFIL:
Background académique sur un sujet pertinent (Stats, Data Science, Computer Science, Maths..)
Une sensibilité sur les aspects Engineering/Développement sera utile
Une ou des expériences sur des problématiques Data Science au sein d'une équipe data dans l'industrie (non académique)
Expérience dans le secteur des média/pub/marketing serait un plus
COMMENT POSTULER:
Merci de me faire part de votre CV à jour et je vous recontacterai au plus vite."
